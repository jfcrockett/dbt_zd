{"metadata": {"dbt_schema_version": "https://schemas.getdbt.com/dbt/manifest/v4.json", "dbt_version": "1.0.3", "generated_at": "2022-03-11T16:07:06.609452Z", "invocation_id": "2c193007-8666-4523-a248-8e05cdf22b10", "env": {}, "project_id": "759b74ce43947f5f4c91aeddc3e5bad3", "user_id": "57178664-37b2-4047-9572-68ec8b488cd7", "send_anonymous_usage_stats": true, "adapter_type": "bigquery"}, "nodes": {"model.zendesk.zendesk__ticket_enriched": {"raw_sql": "-- this model enriches the ticket table with ticket-related dimensions.  This table will not include any metrics.\n-- for metrics, see ticket_metrics!\n\nwith ticket as (\n\n    select *\n    from {{ ref('int_zendesk__ticket_aggregates') }}\n\n--If you use using_ticket_form_history this will be included, if not it will be ignored.\n{% if var('using_ticket_form_history', True) %}\n), latest_ticket_form as (\n\n    select *\n    from {{ ref('int_zendesk__latest_ticket_form') }}\n{% endif %}\n\n), latest_satisfaction_ratings as (\n\n    select *\n    from {{ ref('int_zendesk__ticket_historical_satisfaction') }}\n\n), users as (\n\n    select *\n    from {{ ref('int_zendesk__user_aggregates') }}\n\n), requester_updates as (\n\n    select *\n    from {{ ref('int_zendesk__requester_updates') }}\n\n), assignee_updates as (\n\n    select *\n    from {{ ref('int_zendesk__assignee_updates') }}\n\n), ticket_group as (\n    \n    select *\n    from {{ ref('stg_zendesk__group') }}\n\n), organization as (\n\n    select *\n    from {{ ref('int_zendesk__organization_aggregates') }}\n\n), joined as (\n\n    select \n\n        ticket.*,\n\n        --If you use using_ticket_form_history this will be included, if not it will be ignored.\n        {% if var('using_ticket_form_history', True) %}\n        latest_ticket_form.name as ticket_form_name,\n        {% endif %}\n\n        latest_satisfaction_ratings.count_satisfaction_scores as ticket_total_satisfaction_scores,\n        latest_satisfaction_ratings.first_satisfaction_score as ticket_first_satisfaction_score,\n        latest_satisfaction_ratings.latest_satisfaction_score as ticket_satisfaction_score,\n        latest_satisfaction_ratings.latest_satisfaction_comment as ticket_satisfaction_comment,\n        latest_satisfaction_ratings.latest_satisfaction_reason as ticket_satisfaction_reason,\n        latest_satisfaction_ratings.is_good_to_bad_satisfaction_score,\n        latest_satisfaction_ratings.is_bad_to_good_satisfaction_score,\n\n        --If you use using_domain_names tags this will be included, if not it will be ignored.\n        {% if var('using_domain_names', True) %}\n        organization.domain_names as ticket_organization_domain_names,\n        requester_org.domain_names as requester_organization_domain_names,\n        {% endif %}\n\n        requester.external_id as requester_external_id,\n        requester.created_at as requester_created_at,\n        requester.updated_at as requester_updated_at,\n        requester.role as requester_role,\n        requester.email as requester_email,\n        requester.name as requester_name,\n        requester.is_active as is_requester_active,\n        requester.locale as requester_locale,\n        requester.time_zone as requester_time_zone,\n        coalesce(requester_updates.total_updates, 0) as requester_ticket_update_count,\n        requester_updates.last_updated as requester_ticket_last_update_at,\n        requester.last_login_at as requester_last_login_at,\n        requester.organization_id as requester_organization_id,\n        requester_org.name as requester_organization_name,\n\n        --If you use organization tags this will be included, if not it will be ignored.\n        {% if var('using_organization_tags', True) %}\n        requester_org.organization_tags as requester_organization_tags,\n        {% endif %}\n        requester_org.external_id as requester_organization_external_id,\n        requester_org.created_at as requester_organization_created_at,\n        requester_org.updated_at as requester_organization_updated_at,\n        submitter.external_id as submitter_external_id,\n        submitter.role as submitter_role,\n        case when submitter.role in ('Agent','Admin') \n            then true \n            else false\n                end as is_agent_submitted,\n        submitter.email as submitter_email,\n        submitter.name as submitter_name,\n        submitter.is_active as is_submitter_active,\n        submitter.locale as submitter_locale,\n        submitter.time_zone as submitter_time_zone,\n        assignee.external_id as assignee_external_id,\n        assignee.role as assignee_role,\n        assignee.email as assignee_email,\n        assignee.name as assignee_name,\n        assignee.is_active as is_assignee_active,\n        assignee.locale as assignee_locale,\n        assignee.time_zone as assignee_time_zone,\n        coalesce(assignee_updates.total_updates, 0) as assignee_ticket_update_count,\n        assignee_updates.last_updated as assignee_ticket_last_update_at,\n        assignee.last_login_at as assignee_last_login_at,\n        ticket_group.name as group_name,\n        organization.name as organization_name\n\n        --If you use using_user_tags this will be included, if not it will be ignored.\n        {% if var('using_user_tags', True) %}\n        ,requester.user_tags as requester_tag,\n        submitter.user_tags as submitter_tag,\n        assignee.user_tags as assignee_tag\n        {% endif %}\n\n    \n    from ticket\n\n    --Requester Joins\n    join users as requester\n        on requester.user_id = ticket.requester_id\n\n    left join organization as requester_org\n        on requester_org.organization_id = requester.organization_id\n\n    left join requester_updates\n        on requester_updates.ticket_id = ticket.ticket_id\n            and requester_updates.requester_id = ticket.requester_id\n    \n    --Submitter Joins\n    join users as submitter\n        on submitter.user_id = ticket.submitter_id\n    \n    --Assignee Joins\n    left join users as assignee\n        on assignee.user_id = ticket.assignee_id\n\n    left join assignee_updates\n        on assignee_updates.ticket_id = ticket.ticket_id\n            and assignee_updates.assignee_id = ticket.assignee_id\n\n    --Ticket, Org, and Brand Joins\n    left join ticket_group\n        on ticket_group.group_id = ticket.group_id\n\n    --If you use using_ticket_form_history this will be included, if not it will be ignored.\n    {% if var('using_ticket_form_history', True) %}\n    left join latest_ticket_form\n        on latest_ticket_form.ticket_form_id = ticket.ticket_form_id\n    {% endif %}\n\n    left join organization\n        on organization.organization_id = ticket.organization_id\n\n    left join latest_satisfaction_ratings\n        on latest_satisfaction_ratings.ticket_id = ticket.ticket_id\n)\n\nselect *\nfrom joined", "compiled": true, "resource_type": "model", "depends_on": {"macros": [], "nodes": ["model.zendesk.int_zendesk__ticket_aggregates", "model.zendesk.int_zendesk__latest_ticket_form", "model.zendesk.int_zendesk__ticket_historical_satisfaction", "model.zendesk.int_zendesk__user_aggregates", "model.zendesk.int_zendesk__requester_updates", "model.zendesk.int_zendesk__assignee_updates", "model.zendesk_source.stg_zendesk__group", "model.zendesk.int_zendesk__organization_aggregates"]}, "config": {"enabled": true, "alias": null, "schema": "zendesk_docs", "database": null, "tags": [], "meta": {}, "materialized": "table", "persist_docs": {}, "quoting": {}, "column_types": {}, "full_refresh": null, "on_schema_change": "ignore", "post-hook": [], "pre-hook": []}, "database": "bq-project", "schema": "dbt_joe_zendesk_docs", "fqn": ["zendesk", "zendesk__ticket_enriched"], "unique_id": "model.zendesk.zendesk__ticket_enriched", "package_name": "zendesk", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/zendesk", "path": "zendesk__ticket_enriched.sql", "original_file_path": "models/zendesk__ticket_enriched.sql", "name": "zendesk__ticket_enriched", "alias": "zendesk__ticket_enriched", "checksum": {"name": "sha256", "checksum": "8fcc608ab898e878e9f17383218093918a9a0b5585a19a72e390898c38ad5605"}, "tags": [], "refs": [["int_zendesk__ticket_aggregates"], ["int_zendesk__latest_ticket_form"], ["int_zendesk__ticket_historical_satisfaction"], ["int_zendesk__user_aggregates"], ["int_zendesk__requester_updates"], ["int_zendesk__assignee_updates"], ["stg_zendesk__group"], ["int_zendesk__organization_aggregates"]], "sources": [], "description": "Each record represents a Zendesk ticket, enriched with data about it's tags, assignees, requester, submitter, organization and group.", "columns": {"ticket_id": {"name": "ticket_id", "description": "Automatically assigned when the ticket is created", "meta": {}, "data_type": null, "quote": null, "tags": []}, "url": {"name": "url", "description": "The API url of this ticket", "meta": {}, "data_type": null, "quote": null, "tags": []}, "assignee_id": {"name": "assignee_id", "description": "The agent currently assigned to the ticket", "meta": {}, "data_type": null, "quote": null, "tags": []}, "assignee_role": {"name": "assignee_role", "description": "The role of the agent currently assigned to the ticket", "meta": {}, "data_type": null, "quote": null, "tags": []}, "assignee_email": {"name": "assignee_email", "description": "The email of the agent currently assigned to the ticket", "meta": {}, "data_type": null, "quote": null, "tags": []}, "assignee_name": {"name": "assignee_name", "description": "The name of the agent currently assigned to the ticket", "meta": {}, "data_type": null, "quote": null, "tags": []}, "brand_id": {"name": "brand_id", "description": "Enterprise only. The id of the brand this ticket is associated with", "meta": {}, "data_type": null, "quote": null, "tags": []}, "created_at": {"name": "created_at", "description": "When this record was created", "meta": {}, "data_type": null, "quote": null, "tags": []}, "type": {"name": "type", "description": "The type of this ticket, possible values are problem, incident, question or task", "meta": {}, "data_type": null, "quote": null, "tags": []}, "subject": {"name": "subject", "description": "The value of the subject field for this ticket", "meta": {}, "data_type": null, "quote": null, "tags": []}, "description": {"name": "description", "description": "Read-only first comment on the ticket", "meta": {}, "data_type": null, "quote": null, "tags": []}, "priority": {"name": "priority", "description": "The urgency with which the ticket should be addressed, possible values are urgent, high, normal and low", "meta": {}, "data_type": null, "quote": null, "tags": []}, "status": {"name": "status", "description": "The state of the ticket, possible values are new, open, pending, hold, solved and closed", "meta": {}, "data_type": null, "quote": null, "tags": []}, "recipient": {"name": "recipient", "description": "The original recipient e-mail address of the ticket", "meta": {}, "data_type": null, "quote": null, "tags": []}, "requester_id": {"name": "requester_id", "description": "The user who requested this ticket", "meta": {}, "data_type": null, "quote": null, "tags": []}, "requester_role": {"name": "requester_role", "description": "The role of the user who requested this ticket", "meta": {}, "data_type": null, "quote": null, "tags": []}, "requester_email": {"name": "requester_email", "description": "The email of the user who requested this ticket", "meta": {}, "data_type": null, "quote": null, "tags": []}, "requester_name": {"name": "requester_name", "description": "The name of the user who requested this ticket", "meta": {}, "data_type": null, "quote": null, "tags": []}, "submitter_id": {"name": "submitter_id", "description": "The user who submitted the ticket. The submitter always becomes the author of the first comment on the ticket", "meta": {}, "data_type": null, "quote": null, "tags": []}, "submitter_role": {"name": "submitter_role", "description": "The role of the user who submitted the ticket.", "meta": {}, "data_type": null, "quote": null, "tags": []}, "submitter_email": {"name": "submitter_email", "description": "The email of the user who submitted the ticket.", "meta": {}, "data_type": null, "quote": null, "tags": []}, "submitter_name": {"name": "submitter_name", "description": "The name of the user who submitted the ticket.", "meta": {}, "data_type": null, "quote": null, "tags": []}, "organization_id": {"name": "organization_id", "description": "The organization of the requester", "meta": {}, "data_type": null, "quote": null, "tags": []}, "organization_name": {"name": "organization_name", "description": "The name of the organization of the requester", "meta": {}, "data_type": null, "quote": null, "tags": []}, "external_id": {"name": "external_id", "description": "The external id of the ticket", "meta": {}, "data_type": null, "quote": null, "tags": []}, "group_id": {"name": "group_id", "description": "The group this ticket is assigned to", "meta": {}, "data_type": null, "quote": null, "tags": []}, "group_name": {"name": "group_name", "description": "The name of the group this ticket is assigned to", "meta": {}, "data_type": null, "quote": null, "tags": []}, "due_at": {"name": "due_at", "description": "If this is a ticket of type \"task\" it has a due date. Due date format uses ISO 8601 format.", "meta": {}, "data_type": null, "quote": null, "tags": []}, "ticket_form_id": {"name": "ticket_form_id", "description": "Enterprise only. The id of the ticket form to render for the ticket", "meta": {}, "data_type": null, "quote": null, "tags": []}, "is_public": {"name": "is_public", "description": "Is true if any comments are public, false otherwise", "meta": {}, "data_type": null, "quote": null, "tags": []}, "updated_at": {"name": "updated_at", "description": "When this record last got updated", "meta": {}, "data_type": null, "quote": null, "tags": []}, "created_channel": {"name": "created_channel", "description": "The channel the ticket was created from", "meta": {}, "data_type": null, "quote": null, "tags": []}, "source_from_id": {"name": "source_from_id", "description": "The channel the ticket was created from", "meta": {}, "data_type": null, "quote": null, "tags": []}, "source_from_title": {"name": "source_from_title", "description": "The channel the ticket was created from", "meta": {}, "data_type": null, "quote": null, "tags": []}, "source_rel": {"name": "source_rel", "description": "The rel the ticket was created from", "meta": {}, "data_type": null, "quote": null, "tags": []}, "source_to_address": {"name": "source_to_address", "description": "The address of the source the ticket was created from", "meta": {}, "data_type": null, "quote": null, "tags": []}, "source_to_name": {"name": "source_to_name", "description": "The name of the source the ticket was created from", "meta": {}, "data_type": null, "quote": null, "tags": []}, "ticket_tags": {"name": "ticket_tags", "description": "A list of all tags assigned to this ticket", "meta": {}, "data_type": null, "quote": null, "tags": []}, "problem_id": {"name": "problem_id", "description": "The reference to the problem if the ticket is listed as a problem", "meta": {}, "data_type": null, "quote": null, "tags": []}, "is_incident": {"name": "is_incident", "description": "Boolean indicating whether the ticket is listed as an incident", "meta": {}, "data_type": null, "quote": null, "tags": []}, "ticket_brand_name": {"name": "ticket_brand_name", "description": "The brand name of with the ticket", "meta": {}, "data_type": null, "quote": null, "tags": []}, "ticket_form_name": {"name": "ticket_form_name", "description": "The form name of the ticket", "meta": {}, "data_type": null, "quote": null, "tags": []}, "ticket_satisfaction_rating": {"name": "ticket_satisfaction_rating", "description": "The ticket satisfaction rating", "meta": {}, "data_type": null, "quote": null, "tags": []}, "ticket_satisfaction_comment": {"name": "ticket_satisfaction_comment", "description": "The ticket satisfaction comment", "meta": {}, "data_type": null, "quote": null, "tags": []}, "ticket_satisfaction_reason": {"name": "ticket_satisfaction_reason", "description": "The ticket satisfaction reason", "meta": {}, "data_type": null, "quote": null, "tags": []}, "ticket_organization_domain_names": {"name": "ticket_organization_domain_names", "description": "The organization associated with the ticket domain names", "meta": {}, "data_type": null, "quote": null, "tags": []}, "requester_organization_domain_names": {"name": "requester_organization_domain_names", "description": "The ticket requesters organization domain names", "meta": {}, "data_type": null, "quote": null, "tags": []}, "requester_external_id": {"name": "requester_external_id", "description": "The ticket requester external id", "meta": {}, "data_type": null, "quote": null, "tags": []}, "requester_created_at": {"name": "requester_created_at", "description": "The date the ticket requester was created", "meta": {}, "data_type": null, "quote": null, "tags": []}, "requester_updated_at": {"name": "requester_updated_at", "description": "The date the ticket requester was last updated", "meta": {}, "data_type": null, "quote": null, "tags": []}, "is_requester_active": {"name": "is_requester_active", "description": "Boolean indicating whether the requester is currently active", "meta": {}, "data_type": null, "quote": null, "tags": []}, "requester_locale": {"name": "requester_locale", "description": "The locale of the ticket requester", "meta": {}, "data_type": null, "quote": null, "tags": []}, "requester_time_zone": {"name": "requester_time_zone", "description": "The timezone of the ticket requester", "meta": {}, "data_type": null, "quote": null, "tags": []}, "requester_ticket_update_count": {"name": "requester_ticket_update_count", "description": "The number of times the requester has updated the ticket", "meta": {}, "data_type": null, "quote": null, "tags": []}, "requester_ticket_last_update_at": {"name": "requester_ticket_last_update_at", "description": "The last date the requester updated the ticket", "meta": {}, "data_type": null, "quote": null, "tags": []}, "requester_last_login_at": {"name": "requester_last_login_at", "description": "The last login of the ticket requester", "meta": {}, "data_type": null, "quote": null, "tags": []}, "requester_organization_id": {"name": "requester_organization_id", "description": "The organization id of the ticket requester", "meta": {}, "data_type": null, "quote": null, "tags": []}, "requester_organization_name": {"name": "requester_organization_name", "description": "The organization name of the ticket requester", "meta": {}, "data_type": null, "quote": null, "tags": []}, "requester_organization_tags": {"name": "requester_organization_tags", "description": "The organization tags of the ticket requester", "meta": {}, "data_type": null, "quote": null, "tags": []}, "requester_organization_external_id": {"name": "requester_organization_external_id", "description": "The organization external id of the ticket requester", "meta": {}, "data_type": null, "quote": null, "tags": []}, "requester_organization_created_at": {"name": "requester_organization_created_at", "description": "The date the ticket requesters organization was created", "meta": {}, "data_type": null, "quote": null, "tags": []}, "requester_organization_updated_at": {"name": "requester_organization_updated_at", "description": "The date the ticket requesters organization was last updated", "meta": {}, "data_type": null, "quote": null, "tags": []}, "submitter_external_id": {"name": "submitter_external_id", "description": "The ticket submitter external id", "meta": {}, "data_type": null, "quote": null, "tags": []}, "is_agent_submitted": {"name": "is_agent_submitted", "description": "Boolean indicating if the submitter has an agent role", "meta": {}, "data_type": null, "quote": null, "tags": []}, "is_submitter_active": {"name": "is_submitter_active", "description": "Boolean indicating if the ticket submitter is active", "meta": {}, "data_type": null, "quote": null, "tags": []}, "submitter_locale": {"name": "submitter_locale", "description": "The locale of the ticket submitter", "meta": {}, "data_type": null, "quote": null, "tags": []}, "submitter_time_zone": {"name": "submitter_time_zone", "description": "The time zone of the ticket submitter", "meta": {}, "data_type": null, "quote": null, "tags": []}, "assignee_external_id": {"name": "assignee_external_id", "description": "The external id of the ticket assignee", "meta": {}, "data_type": null, "quote": null, "tags": []}, "is_assignee_active": {"name": "is_assignee_active", "description": "Boolean indicating if the ticket assignee is active", "meta": {}, "data_type": null, "quote": null, "tags": []}, "assignee_locale": {"name": "assignee_locale", "description": "The locale of the ticket assignee", "meta": {}, "data_type": null, "quote": null, "tags": []}, "assignee_time_zone": {"name": "assignee_time_zone", "description": "The time zone of the ticket assignee", "meta": {}, "data_type": null, "quote": null, "tags": []}, "assignee_ticket_update_count": {"name": "assignee_ticket_update_count", "description": "The number of times the ticket assignee has updated the ticket", "meta": {}, "data_type": null, "quote": null, "tags": []}, "assignee_ticket_last_update_at": {"name": "assignee_ticket_last_update_at", "description": "The last date the ticket assignee updated the ticket", "meta": {}, "data_type": null, "quote": null, "tags": []}, "assignee_last_login_at": {"name": "assignee_last_login_at", "description": "The date the ticket assignee last logged in", "meta": {}, "data_type": null, "quote": null, "tags": []}, "requester_tag": {"name": "requester_tag", "description": "The tags associated with the ticket requester.", "meta": {}, "data_type": null, "quote": null, "tags": []}, "submitter_tag": {"name": "submitter_tag", "description": "The tags associated with the ticket submitter.", "meta": {}, "data_type": null, "quote": null, "tags": []}, "assignee_tag": {"name": "assignee_tag", "description": "The tags associated with the ticket assignee.", "meta": {}, "data_type": null, "quote": null, "tags": []}, "ticket_total_satisfaction_scores": {"name": "ticket_total_satisfaction_scores", "description": "The total number of satisfaction scores the ticket received.", "meta": {}, "data_type": null, "quote": null, "tags": []}, "ticket_first_satisfaction_score": {"name": "ticket_first_satisfaction_score", "description": "The first satisfaction score the ticket received.", "meta": {}, "data_type": null, "quote": null, "tags": []}, "ticket_satisfaction_score": {"name": "ticket_satisfaction_score", "description": "The latest satisfaction score the ticket received.", "meta": {}, "data_type": null, "quote": null, "tags": []}, "is_good_to_bad_satisfaction_score": {"name": "is_good_to_bad_satisfaction_score", "description": "Boolean indicating if the ticket had a satisfaction score went from good to bad.", "meta": {}, "data_type": null, "quote": null, "tags": []}, "is_bad_to_good_satisfaction_score": {"name": "is_bad_to_good_satisfaction_score", "description": "Boolean indicating if the ticket had a satisfaction score went from bad to good.", "meta": {}, "data_type": null, "quote": null, "tags": []}}, "meta": {}, "docs": {"show": true}, "patch_path": "zendesk://models/zendesk.yml", "compiled_path": "target/compiled/zendesk/models/zendesk__ticket_enriched.sql", "build_path": null, "deferred": false, "unrendered_config": {"schema": "zendesk_docs", "materialized": "table"}, "created_at": 1647014737.8410308, "compiled_sql": "-- this model enriches the ticket table with ticket-related dimensions.  This table will not include any metrics.\n-- for metrics, see ticket_metrics!\n\nwith ticket as (\n\n    select *\n    from `bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__ticket_aggregates`\n\n--If you use using_ticket_form_history this will be included, if not it will be ignored.\n\n), latest_ticket_form as (\n\n    select *\n    from `bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__latest_ticket_form`\n\n\n), latest_satisfaction_ratings as (\n\n    select *\n    from `bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__ticket_historical_satisfaction`\n\n), users as (\n\n    select *\n    from `bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__user_aggregates`\n\n), requester_updates as (\n\n    select *\n    from `bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__requester_updates`\n\n), assignee_updates as (\n\n    select *\n    from `bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__assignee_updates`\n\n), ticket_group as (\n    \n    select *\n    from `bq-project`.`dbt_joe_zendesk_docs`.`stg_zendesk__group`\n\n), organization as (\n\n    select *\n    from `bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__organization_aggregates`\n\n), joined as (\n\n    select \n\n        ticket.*,\n\n        --If you use using_ticket_form_history this will be included, if not it will be ignored.\n        \n        latest_ticket_form.name as ticket_form_name,\n        \n\n        latest_satisfaction_ratings.count_satisfaction_scores as ticket_total_satisfaction_scores,\n        latest_satisfaction_ratings.first_satisfaction_score as ticket_first_satisfaction_score,\n        latest_satisfaction_ratings.latest_satisfaction_score as ticket_satisfaction_score,\n        latest_satisfaction_ratings.latest_satisfaction_comment as ticket_satisfaction_comment,\n        latest_satisfaction_ratings.latest_satisfaction_reason as ticket_satisfaction_reason,\n        latest_satisfaction_ratings.is_good_to_bad_satisfaction_score,\n        latest_satisfaction_ratings.is_bad_to_good_satisfaction_score,\n\n        --If you use using_domain_names tags this will be included, if not it will be ignored.\n        \n\n        requester.external_id as requester_external_id,\n        requester.created_at as requester_created_at,\n        requester.updated_at as requester_updated_at,\n        requester.role as requester_role,\n        requester.email as requester_email,\n        requester.name as requester_name,\n        requester.is_active as is_requester_active,\n        requester.locale as requester_locale,\n        requester.time_zone as requester_time_zone,\n        coalesce(requester_updates.total_updates, 0) as requester_ticket_update_count,\n        requester_updates.last_updated as requester_ticket_last_update_at,\n        requester.last_login_at as requester_last_login_at,\n        requester.organization_id as requester_organization_id,\n        requester_org.name as requester_organization_name,\n\n        --If you use organization tags this will be included, if not it will be ignored.\n        \n        requester_org.external_id as requester_organization_external_id,\n        requester_org.created_at as requester_organization_created_at,\n        requester_org.updated_at as requester_organization_updated_at,\n        submitter.external_id as submitter_external_id,\n        submitter.role as submitter_role,\n        case when submitter.role in ('Agent','Admin') \n            then true \n            else false\n                end as is_agent_submitted,\n        submitter.email as submitter_email,\n        submitter.name as submitter_name,\n        submitter.is_active as is_submitter_active,\n        submitter.locale as submitter_locale,\n        submitter.time_zone as submitter_time_zone,\n        assignee.external_id as assignee_external_id,\n        assignee.role as assignee_role,\n        assignee.email as assignee_email,\n        assignee.name as assignee_name,\n        assignee.is_active as is_assignee_active,\n        assignee.locale as assignee_locale,\n        assignee.time_zone as assignee_time_zone,\n        coalesce(assignee_updates.total_updates, 0) as assignee_ticket_update_count,\n        assignee_updates.last_updated as assignee_ticket_last_update_at,\n        assignee.last_login_at as assignee_last_login_at,\n        ticket_group.name as group_name,\n        organization.name as organization_name\n\n        --If you use using_user_tags this will be included, if not it will be ignored.\n        \n\n    \n    from ticket\n\n    --Requester Joins\n    join users as requester\n        on requester.user_id = ticket.requester_id\n\n    left join organization as requester_org\n        on requester_org.organization_id = requester.organization_id\n\n    left join requester_updates\n        on requester_updates.ticket_id = ticket.ticket_id\n            and requester_updates.requester_id = ticket.requester_id\n    \n    --Submitter Joins\n    join users as submitter\n        on submitter.user_id = ticket.submitter_id\n    \n    --Assignee Joins\n    left join users as assignee\n        on assignee.user_id = ticket.assignee_id\n\n    left join assignee_updates\n        on assignee_updates.ticket_id = ticket.ticket_id\n            and assignee_updates.assignee_id = ticket.assignee_id\n\n    --Ticket, Org, and Brand Joins\n    left join ticket_group\n        on ticket_group.group_id = ticket.group_id\n\n    --If you use using_ticket_form_history this will be included, if not it will be ignored.\n    \n    left join latest_ticket_form\n        on latest_ticket_form.ticket_form_id = ticket.ticket_form_id\n    \n\n    left join organization\n        on organization.organization_id = ticket.organization_id\n\n    left join latest_satisfaction_ratings\n        on latest_satisfaction_ratings.ticket_id = ticket.ticket_id\n)\n\nselect *\nfrom joined", "extra_ctes_injected": true, "extra_ctes": [], "relation_name": "`bq-project`.`dbt_joe_zendesk_docs`.`zendesk__ticket_enriched`"}, "model.zendesk.zendesk__ticket_metrics": {"raw_sql": "with ticket_enriched as (\n\n  select *\n  from {{ ref('zendesk__ticket_enriched') }}\n\n), ticket_resolution_times_calendar as (\n\n  select *\n  from {{ ref('int_zendesk__ticket_resolution_times_calendar') }}\n\n), ticket_reply_times_calendar as (\n\n  select *\n  from {{ ref('int_zendesk__ticket_reply_times_calendar') }}\n\n), ticket_comments as (\n\n  select *\n  from {{ ref('int_zendesk__comment_metrics') }}\n\n), ticket_work_time_calendar as (\n\n  select *\n  from {{ ref('int_zendesk__ticket_work_time_calendar') }}\n\n-- business hour CTEs\n{% if var('using_schedules', True) %}\n\n), ticket_first_resolution_time_business as (\n\n  select *\n  from {{ ref('int_zendesk__ticket_first_resolution_time_business') }}\n\n), ticket_full_resolution_time_business as (\n\n  select *\n  from {{ ref('int_zendesk__ticket_full_resolution_time_business') }}\n\n), ticket_work_time_business as (\n\n  select *\n  from {{ ref('int_zendesk__ticket_work_time_business') }}\n\n), ticket_first_reply_time_business as (\n\n  select *\n  from {{ ref('int_zendesk__ticket_first_reply_time_business') }}\n\n{% endif %}\n-- end business hour CTEs\n\n), calendar_hour_metrics as (\n\nselect\n  ticket_enriched.*,\n  case when coalesce(ticket_comments.count_public_agent_comments, 0) = 0\n    then null\n    else ticket_reply_times_calendar.first_reply_time_calendar_minutes\n      end as first_reply_time_calendar_minutes,\n  case when coalesce(ticket_comments.count_public_agent_comments, 0) = 0\n    then null\n    else ticket_reply_times_calendar.total_reply_time_calendar_minutes\n      end as total_reply_time_calendar_minutes,\n  coalesce(ticket_comments.count_agent_comments, 0) as count_agent_comments,\n  coalesce(ticket_comments.count_public_agent_comments, 0) as count_public_agent_comments,\n  coalesce(ticket_comments.count_end_user_comments, 0) as count_end_user_comments,\n  coalesce(ticket_comments.count_public_comments, 0) as count_public_comments,\n  coalesce(ticket_comments.count_internal_comments, 0) as count_internal_comments,\n  coalesce(ticket_comments.total_comments, 0) as total_comments,\n  coalesce(ticket_comments.count_ticket_handoffs, 0) as count_ticket_handoffs, -- the number of distinct internal users who commented on the ticket\n  ticket_comments.last_comment_added_at as ticket_last_comment_date,\n  ticket_resolution_times_calendar.unique_assignee_count,\n  ticket_resolution_times_calendar.assignee_stations_count,\n  ticket_resolution_times_calendar.group_stations_count,\n  ticket_resolution_times_calendar.first_assignee_id,\n  ticket_resolution_times_calendar.last_assignee_id,\n  ticket_resolution_times_calendar.first_agent_assignment_date,\n  ticket_resolution_times_calendar.last_agent_assignment_date,\n  ticket_resolution_times_calendar.first_solved_at,\n  ticket_resolution_times_calendar.last_solved_at,\n  case when ticket_enriched.status in ('solved', 'closed')\n    then ticket_resolution_times_calendar.first_assignment_to_resolution_calendar_minutes\n    else null\n      end as first_assignment_to_resolution_calendar_minutes,\n  case when ticket_enriched.status in ('solved', 'closed')\n    then ticket_resolution_times_calendar.last_assignment_to_resolution_calendar_minutes\n    else null\n      end as last_assignment_to_resolution_calendar_minutes,\n  ticket_resolution_times_calendar.ticket_unassigned_duration_calendar_minutes,\n  ticket_resolution_times_calendar.first_resolution_calendar_minutes,\n  ticket_resolution_times_calendar.final_resolution_calendar_minutes,\n  ticket_resolution_times_calendar.total_resolutions as count_resolutions,\n  ticket_resolution_times_calendar.count_reopens,\n  ticket_work_time_calendar.ticket_deleted_count,\n  ticket_work_time_calendar.total_ticket_recoveries,\n  ticket_work_time_calendar.last_status_assignment_date,\n  ticket_work_time_calendar.new_status_duration_in_calendar_minutes,\n  ticket_work_time_calendar.open_status_duration_in_calendar_minutes,\n  ticket_work_time_calendar.agent_wait_time_in_calendar_minutes,\n  ticket_work_time_calendar.requester_wait_time_in_calendar_minutes,\n  ticket_work_time_calendar.agent_work_time_in_calendar_minutes,\n  ticket_work_time_calendar.on_hold_time_in_calendar_minutes,\n  coalesce(ticket_comments.count_agent_comments, 0) as total_agent_replies,\n  \n  case when ticket_enriched.is_requester_active = true and ticket_enriched.requester_last_login_at is not null\n    then ({{ dbt_utils.datediff(\"ticket_enriched.requester_last_login_at\", dbt_utils.current_timestamp(), 'second') }} /60)\n      end as requester_last_login_age_minutes,\n  case when ticket_enriched.is_assignee_active = true and ticket_enriched.assignee_last_login_at is not null\n    then ({{ dbt_utils.datediff(\"ticket_enriched.assignee_last_login_at\", dbt_utils.current_timestamp(), 'second') }} /60)\n      end as assignee_last_login_age_minutes,\n  case when lower(ticket_enriched.status) not in ('solved','closed')\n    then ({{ dbt_utils.datediff(\"ticket_enriched.created_at\", dbt_utils.current_timestamp(), 'second') }} /60)\n      end as unsolved_ticket_age_minutes,\n  case when lower(ticket_enriched.status) not in ('solved','closed')\n    then ({{ dbt_utils.datediff(\"ticket_enriched.updated_at\", dbt_utils.current_timestamp(), 'second') }} /60)\n      end as unsolved_ticket_age_since_update_minutes,\n  case when lower(ticket_enriched.status) in ('solved','closed') and ticket_comments.is_one_touch_resolution \n    then true\n    else false\n      end as is_one_touch_resolution,\n  case when lower(ticket_enriched.status) in ('solved','closed') and ticket_comments.is_two_touch_resolution \n    then true\n    else false \n      end as is_two_touch_resolution,\n  case when lower(ticket_enriched.status) in ('solved','closed') and not ticket_comments.is_one_touch_resolution \n    then true\n    else false \n      end as is_multi_touch_resolution\n\n\nfrom ticket_enriched\n\nleft join ticket_reply_times_calendar\n  using (ticket_id)\n\nleft join ticket_resolution_times_calendar\n  using (ticket_id)\n\nleft join ticket_work_time_calendar\n  using (ticket_id)\n\nleft join ticket_comments\n  using(ticket_id)\n\n{% if var('using_schedules', True) %}\n\n), business_hour_metrics as (\n\n  select \n    ticket_enriched.ticket_id,\n    ticket_first_resolution_time_business.first_resolution_business_minutes,\n    ticket_full_resolution_time_business.full_resolution_business_minutes,\n    ticket_first_reply_time_business.first_reply_time_business_minutes,\n    ticket_work_time_business.agent_wait_time_in_business_minutes,\n    ticket_work_time_business.requester_wait_time_in_business_minutes,\n    ticket_work_time_business.agent_work_time_in_business_minutes,\n    ticket_work_time_business.on_hold_time_in_business_minutes\n\n  from ticket_enriched\n\n  left join ticket_first_resolution_time_business\n    using (ticket_id)\n\n  left join ticket_full_resolution_time_business\n    using (ticket_id)\n  \n  left join ticket_first_reply_time_business\n    using (ticket_id)  \n  \n  left join ticket_work_time_business\n    using (ticket_id)\n\n)\n\nselect\n  calendar_hour_metrics.*,\n  case when calendar_hour_metrics.status in ('solved', 'closed')\n    then business_hour_metrics.first_resolution_business_minutes\n    else null\n      end as first_resolution_business_minutes,\n  case when calendar_hour_metrics.status in ('solved', 'closed')\n    then business_hour_metrics.full_resolution_business_minutes\n    else null\n      end as full_resolution_business_minutes,\n  case when coalesce(calendar_hour_metrics.count_public_agent_comments, 0) = 0\n    then null\n    else business_hour_metrics.first_reply_time_business_minutes\n      end as first_reply_time_business_minutes,\n  business_hour_metrics.agent_wait_time_in_business_minutes,\n  business_hour_metrics.requester_wait_time_in_business_minutes,\n  business_hour_metrics.agent_work_time_in_business_minutes,\n  business_hour_metrics.on_hold_time_in_business_minutes\n\nfrom calendar_hour_metrics\n\nleft join business_hour_metrics \n  using (ticket_id)\n\n{% else %}\n\n) \n\nselect *\nfrom calendar_hour_metrics\n\n{% endif %}", "compiled": true, "resource_type": "model", "depends_on": {"macros": ["macro.dbt_utils.current_timestamp", "macro.dbt_utils.datediff"], "nodes": ["model.zendesk.zendesk__ticket_enriched", "model.zendesk.int_zendesk__ticket_resolution_times_calendar", "model.zendesk.int_zendesk__ticket_reply_times_calendar", "model.zendesk.int_zendesk__comment_metrics", "model.zendesk.int_zendesk__ticket_work_time_calendar", "model.zendesk.int_zendesk__ticket_first_resolution_time_business", "model.zendesk.int_zendesk__ticket_full_resolution_time_business", "model.zendesk.int_zendesk__ticket_work_time_business", "model.zendesk.int_zendesk__ticket_first_reply_time_business"]}, "config": {"enabled": true, "alias": null, "schema": "zendesk_docs", "database": null, "tags": [], "meta": {}, "materialized": "table", "persist_docs": {}, "quoting": {}, "column_types": {}, "full_refresh": null, "on_schema_change": "ignore", "post-hook": [], "pre-hook": []}, "database": "bq-project", "schema": "dbt_joe_zendesk_docs", "fqn": ["zendesk", "zendesk__ticket_metrics"], "unique_id": "model.zendesk.zendesk__ticket_metrics", "package_name": "zendesk", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/zendesk", "path": "zendesk__ticket_metrics.sql", "original_file_path": "models/zendesk__ticket_metrics.sql", "name": "zendesk__ticket_metrics", "alias": "zendesk__ticket_metrics", "checksum": {"name": "sha256", "checksum": "42389f1b04f003c1957f7a71f5f8c20b0fbd3a88d0145fb17ad97dc239983526"}, "tags": [], "refs": [["zendesk__ticket_enriched"], ["int_zendesk__ticket_resolution_times_calendar"], ["int_zendesk__ticket_reply_times_calendar"], ["int_zendesk__comment_metrics"], ["int_zendesk__ticket_work_time_calendar"], ["int_zendesk__ticket_first_resolution_time_business"], ["int_zendesk__ticket_full_resolution_time_business"], ["int_zendesk__ticket_work_time_business"], ["int_zendesk__ticket_first_reply_time_business"]], "sources": [], "description": "Each record represents a Zendesk ticket, enriched with metrics about reply times, resolution times and work times.  Calendar and business hours are supported", "columns": {"first_reply_time_calendar_minutes": {"name": "first_reply_time_calendar_minutes", "description": "The number of calendar minutes between when the ticket was created and when the first public agent response occurred", "meta": {}, "data_type": null, "quote": null, "tags": []}, "first_reply_time_business_minutes": {"name": "first_reply_time_business_minutes", "description": "The number of business minutes between when the ticket was created and when the first public agent response occurred", "meta": {}, "data_type": null, "quote": null, "tags": []}, "total_reply_time_calendar_minutes": {"name": "total_reply_time_calendar_minutes", "description": "The combined calendar time between all end-user comments and the next public agent response", "meta": {}, "data_type": null, "quote": null, "tags": []}, "first_solved_at": {"name": "first_solved_at", "description": "The time the ticket was first in 'solved' status", "meta": {}, "data_type": null, "quote": null, "tags": []}, "last_solved_at": {"name": "last_solved_at", "description": "The time the ticket was last in 'solved' status", "meta": {}, "data_type": null, "quote": null, "tags": []}, "first_resolution_calendar_minutes": {"name": "first_resolution_calendar_minutes", "description": "The number of calendar minutes between the ticket created time and the time the ticket was first set to solved status", "meta": {}, "data_type": null, "quote": null, "tags": []}, "final_resolution_calendar_minutes": {"name": "final_resolution_calendar_minutes", "description": "The number of calendar minutes between the ticket created time and the time the ticket was last set to solved status", "meta": {}, "data_type": null, "quote": null, "tags": []}, "is_one_touch_resolution": {"name": "is_one_touch_resolution", "description": "A boolean field indicating that the ticket has one public agent response and is in solved status", "meta": {}, "data_type": null, "quote": null, "tags": []}, "first_resolution_business_minutes": {"name": "first_resolution_business_minutes", "description": "The number of business minutes between the ticket created time and the time the ticket was first set to solved status", "meta": {}, "data_type": null, "quote": null, "tags": []}, "full_resolution_business_minutes": {"name": "full_resolution_business_minutes", "description": "The number of business minutes between the ticket created time and the time the ticket was last set to solved status", "meta": {}, "data_type": null, "quote": null, "tags": []}, "agent_wait_time_in_business_minutes": {"name": "agent_wait_time_in_business_minutes", "description": "The combined number of business minutes the ticket was in 'pending' status", "meta": {}, "data_type": null, "quote": null, "tags": []}, "requester_wait_time_in_business_minutes": {"name": "requester_wait_time_in_business_minutes", "description": "The combined number of business minutes the ticket was in 'new', 'open', or 'hold' status", "meta": {}, "data_type": null, "quote": null, "tags": []}, "agent_work_time_in_business_minutes": {"name": "agent_work_time_in_business_minutes", "description": "The combined number of business minutes the ticket was in 'new' or 'open' status", "meta": {}, "data_type": null, "quote": null, "tags": []}, "on_hold_time_in_business_minutes": {"name": "on_hold_time_in_business_minutes", "description": "The combined number of business minutes the ticket was on 'hold' status", "meta": {}, "data_type": null, "quote": null, "tags": []}, "agent_wait_time_in_calendar_minutes": {"name": "agent_wait_time_in_calendar_minutes", "description": "The combined number of calendar minutes the ticket was in 'pending' status", "meta": {}, "data_type": null, "quote": null, "tags": []}, "requester_wait_time_in_calendar_minutes": {"name": "requester_wait_time_in_calendar_minutes", "description": "The combined number of calendar minutes the ticket was in 'new', 'open', or 'hold' status", "meta": {}, "data_type": null, "quote": null, "tags": []}, "agent_work_time_in_calendar_minutes": {"name": "agent_work_time_in_calendar_minutes", "description": "The combined number of calendar minutes the ticket was in 'new' or 'open' status", "meta": {}, "data_type": null, "quote": null, "tags": []}, "on_hold_time_in_calendar_minutes": {"name": "on_hold_time_in_calendar_minutes", "description": "The combined number of calendar minutes the ticket was on 'hold' status", "meta": {}, "data_type": null, "quote": null, "tags": []}, "ticket_id": {"name": "ticket_id", "description": "Automatically assigned when the ticket is created", "meta": {}, "data_type": null, "quote": null, "tags": []}, "url": {"name": "url", "description": "The API url of this ticket", "meta": {}, "data_type": null, "quote": null, "tags": []}, "assignee_id": {"name": "assignee_id", "description": "The agent currently assigned to the ticket", "meta": {}, "data_type": null, "quote": null, "tags": []}, "assignee_role": {"name": "assignee_role", "description": "The role of the agent currently assigned to the ticket", "meta": {}, "data_type": null, "quote": null, "tags": []}, "assignee_email": {"name": "assignee_email", "description": "The email of the agent currently assigned to the ticket", "meta": {}, "data_type": null, "quote": null, "tags": []}, "assignee_name": {"name": "assignee_name", "description": "The name of the agent currently assigned to the ticket", "meta": {}, "data_type": null, "quote": null, "tags": []}, "brand_id": {"name": "brand_id", "description": "Enterprise only. The id of the brand this ticket is associated with", "meta": {}, "data_type": null, "quote": null, "tags": []}, "created_at": {"name": "created_at", "description": "When this record was created", "meta": {}, "data_type": null, "quote": null, "tags": []}, "type": {"name": "type", "description": "The type of this ticket, possible values are problem, incident, question or task", "meta": {}, "data_type": null, "quote": null, "tags": []}, "subject": {"name": "subject", "description": "The value of the subject field for this ticket", "meta": {}, "data_type": null, "quote": null, "tags": []}, "description": {"name": "description", "description": "Read-only first comment on the ticket", "meta": {}, "data_type": null, "quote": null, "tags": []}, "priority": {"name": "priority", "description": "The urgency with which the ticket should be addressed, possible values are urgent, high, normal and low", "meta": {}, "data_type": null, "quote": null, "tags": []}, "status": {"name": "status", "description": "The state of the ticket, possible values are new, open, pending, hold, solved and closed", "meta": {}, "data_type": null, "quote": null, "tags": []}, "recipient": {"name": "recipient", "description": "The original recipient e-mail address of the ticket", "meta": {}, "data_type": null, "quote": null, "tags": []}, "requester_id": {"name": "requester_id", "description": "The user who requested this ticket", "meta": {}, "data_type": null, "quote": null, "tags": []}, "requester_role": {"name": "requester_role", "description": "The role of the user who requested this ticket", "meta": {}, "data_type": null, "quote": null, "tags": []}, "requester_email": {"name": "requester_email", "description": "The email of the user who requested this ticket", "meta": {}, "data_type": null, "quote": null, "tags": []}, "requester_name": {"name": "requester_name", "description": "The name of the user who requested this ticket", "meta": {}, "data_type": null, "quote": null, "tags": []}, "submitter_id": {"name": "submitter_id", "description": "The user who submitted the ticket. The submitter always becomes the author of the first comment on the ticket", "meta": {}, "data_type": null, "quote": null, "tags": []}, "submitter_role": {"name": "submitter_role", "description": "The role of the user who submitted the ticket.", "meta": {}, "data_type": null, "quote": null, "tags": []}, "submitter_email": {"name": "submitter_email", "description": "The email of the user who submitted the ticket.", "meta": {}, "data_type": null, "quote": null, "tags": []}, "submitter_name": {"name": "submitter_name", "description": "The name of the user who submitted the ticket.", "meta": {}, "data_type": null, "quote": null, "tags": []}, "organization_id": {"name": "organization_id", "description": "The organization of the requester", "meta": {}, "data_type": null, "quote": null, "tags": []}, "organization_name": {"name": "organization_name", "description": "The name of the organization of the requester", "meta": {}, "data_type": null, "quote": null, "tags": []}, "external_id": {"name": "external_id", "description": "The external id of the ticket", "meta": {}, "data_type": null, "quote": null, "tags": []}, "group_id": {"name": "group_id", "description": "The group this ticket is assigned to", "meta": {}, "data_type": null, "quote": null, "tags": []}, "group_name": {"name": "group_name", "description": "The name of the group this ticket is assigned to", "meta": {}, "data_type": null, "quote": null, "tags": []}, "due_at": {"name": "due_at", "description": "If this is a ticket of type \"task\" it has a due date. Due date format uses ISO 8601 format.", "meta": {}, "data_type": null, "quote": null, "tags": []}, "ticket_form_id": {"name": "ticket_form_id", "description": "Enterprise only. The id of the ticket form to render for the ticket", "meta": {}, "data_type": null, "quote": null, "tags": []}, "is_public": {"name": "is_public", "description": "Is true if any comments are public, false otherwise", "meta": {}, "data_type": null, "quote": null, "tags": []}, "updated_at": {"name": "updated_at", "description": "When this record last got updated", "meta": {}, "data_type": null, "quote": null, "tags": []}, "created_channel": {"name": "created_channel", "description": "The channel the ticket was created from", "meta": {}, "data_type": null, "quote": null, "tags": []}, "source_from_id": {"name": "source_from_id", "description": "The channel the ticket was created from", "meta": {}, "data_type": null, "quote": null, "tags": []}, "source_from_title": {"name": "source_from_title", "description": "The channel the ticket was created from", "meta": {}, "data_type": null, "quote": null, "tags": []}, "source_rel": {"name": "source_rel", "description": "The rel the ticket was created from", "meta": {}, "data_type": null, "quote": null, "tags": []}, "source_to_address": {"name": "source_to_address", "description": "The address of the source the ticket was created from", "meta": {}, "data_type": null, "quote": null, "tags": []}, "source_to_name": {"name": "source_to_name", "description": "The name of the source the ticket was created from", "meta": {}, "data_type": null, "quote": null, "tags": []}, "ticket_tags": {"name": "ticket_tags", "description": "A list of all tags assigned to this ticket", "meta": {}, "data_type": null, "quote": null, "tags": []}, "problem_id": {"name": "problem_id", "description": "The reference to the problem if the ticket is listed as a problem", "meta": {}, "data_type": null, "quote": null, "tags": []}, "is_incident": {"name": "is_incident", "description": "Boolean indicating whether the ticket is listed as an incident", "meta": {}, "data_type": null, "quote": null, "tags": []}, "ticket_brand_name": {"name": "ticket_brand_name", "description": "The brand name of with the ticket", "meta": {}, "data_type": null, "quote": null, "tags": []}, "ticket_form_name": {"name": "ticket_form_name", "description": "The form name of the ticket", "meta": {}, "data_type": null, "quote": null, "tags": []}, "ticket_satisfaction_rating": {"name": "ticket_satisfaction_rating", "description": "The ticket satisfaction rating", "meta": {}, "data_type": null, "quote": null, "tags": []}, "ticket_satisfaction_comment": {"name": "ticket_satisfaction_comment", "description": "The ticket satisfaction comment", "meta": {}, "data_type": null, "quote": null, "tags": []}, "ticket_satisfaction_reason": {"name": "ticket_satisfaction_reason", "description": "The ticket satisfaction reason", "meta": {}, "data_type": null, "quote": null, "tags": []}, "ticket_organization_domain_names": {"name": "ticket_organization_domain_names", "description": "The organization associated with the ticket domain names", "meta": {}, "data_type": null, "quote": null, "tags": []}, "requester_organization_domain_names": {"name": "requester_organization_domain_names", "description": "The ticket requesters organization domain names", "meta": {}, "data_type": null, "quote": null, "tags": []}, "requester_external_id": {"name": "requester_external_id", "description": "The ticket requester external id", "meta": {}, "data_type": null, "quote": null, "tags": []}, "requester_created_at": {"name": "requester_created_at", "description": "The date the ticket requester was created", "meta": {}, "data_type": null, "quote": null, "tags": []}, "requester_updated_at": {"name": "requester_updated_at", "description": "The date the ticket requester was last updated", "meta": {}, "data_type": null, "quote": null, "tags": []}, "is_requester_active": {"name": "is_requester_active", "description": "Boolean indicating whether the requester is currently active", "meta": {}, "data_type": null, "quote": null, "tags": []}, "requester_locale": {"name": "requester_locale", "description": "The locale of the ticket requester", "meta": {}, "data_type": null, "quote": null, "tags": []}, "requester_time_zone": {"name": "requester_time_zone", "description": "The timezone of the ticket requester", "meta": {}, "data_type": null, "quote": null, "tags": []}, "requester_ticket_update_count": {"name": "requester_ticket_update_count", "description": "The number of times the requester has updated the ticket", "meta": {}, "data_type": null, "quote": null, "tags": []}, "requester_ticket_last_update_at": {"name": "requester_ticket_last_update_at", "description": "The last date the requester updated the ticket", "meta": {}, "data_type": null, "quote": null, "tags": []}, "requester_last_login_at": {"name": "requester_last_login_at", "description": "The last login of the ticket requester", "meta": {}, "data_type": null, "quote": null, "tags": []}, "requester_organization_id": {"name": "requester_organization_id", "description": "The organization id of the ticket requester", "meta": {}, "data_type": null, "quote": null, "tags": []}, "requester_organization_name": {"name": "requester_organization_name", "description": "The organization name of the ticket requester", "meta": {}, "data_type": null, "quote": null, "tags": []}, "requester_organization_tags": {"name": "requester_organization_tags", "description": "The organization tags of the ticket requester", "meta": {}, "data_type": null, "quote": null, "tags": []}, "requester_organization_external_id": {"name": "requester_organization_external_id", "description": "The organization external id of the ticket requester", "meta": {}, "data_type": null, "quote": null, "tags": []}, "requester_organization_created_at": {"name": "requester_organization_created_at", "description": "The date the ticket requesters organization was created", "meta": {}, "data_type": null, "quote": null, "tags": []}, "requester_organization_updated_at": {"name": "requester_organization_updated_at", "description": "The date the ticket requesters organization was last updated", "meta": {}, "data_type": null, "quote": null, "tags": []}, "submitter_external_id": {"name": "submitter_external_id", "description": "The ticket submitter external id", "meta": {}, "data_type": null, "quote": null, "tags": []}, "is_agent_submitted": {"name": "is_agent_submitted", "description": "Boolean indicating if the submitter has an agent role", "meta": {}, "data_type": null, "quote": null, "tags": []}, "is_submitter_active": {"name": "is_submitter_active", "description": "Boolean indicating if the ticket submitter is active", "meta": {}, "data_type": null, "quote": null, "tags": []}, "submitter_locale": {"name": "submitter_locale", "description": "The locale of the ticket submitter", "meta": {}, "data_type": null, "quote": null, "tags": []}, "submitter_time_zone": {"name": "submitter_time_zone", "description": "The time zone of the ticket submitter", "meta": {}, "data_type": null, "quote": null, "tags": []}, "assignee_external_id": {"name": "assignee_external_id", "description": "The external id of the ticket assignee", "meta": {}, "data_type": null, "quote": null, "tags": []}, "is_assignee_active": {"name": "is_assignee_active", "description": "Boolean indicating if the ticket assignee is active", "meta": {}, "data_type": null, "quote": null, "tags": []}, "assignee_locale": {"name": "assignee_locale", "description": "The locale of the ticket assignee", "meta": {}, "data_type": null, "quote": null, "tags": []}, "assignee_time_zone": {"name": "assignee_time_zone", "description": "The time zone of the ticket assignee", "meta": {}, "data_type": null, "quote": null, "tags": []}, "assignee_ticket_update_count": {"name": "assignee_ticket_update_count", "description": "The number of times the ticket assignee has updated the ticket", "meta": {}, "data_type": null, "quote": null, "tags": []}, "assignee_ticket_last_update_at": {"name": "assignee_ticket_last_update_at", "description": "The last date the ticket assignee updated the ticket", "meta": {}, "data_type": null, "quote": null, "tags": []}, "assignee_last_login_at": {"name": "assignee_last_login_at", "description": "The date the ticket assignee last logged in", "meta": {}, "data_type": null, "quote": null, "tags": []}, "requester_tag": {"name": "requester_tag", "description": "The tags associated with the ticket requester.", "meta": {}, "data_type": null, "quote": null, "tags": []}, "submitter_tag": {"name": "submitter_tag", "description": "The tags associated with the ticket submitter.", "meta": {}, "data_type": null, "quote": null, "tags": []}, "assignee_tag": {"name": "assignee_tag", "description": "The tags associated with the ticket assignee.", "meta": {}, "data_type": null, "quote": null, "tags": []}, "ticket_total_satisfaction_scores": {"name": "ticket_total_satisfaction_scores", "description": "The total number of satisfaction scores the ticket received.", "meta": {}, "data_type": null, "quote": null, "tags": []}, "ticket_first_satisfaction_score": {"name": "ticket_first_satisfaction_score", "description": "The first satisfaction score the ticket received.", "meta": {}, "data_type": null, "quote": null, "tags": []}, "ticket_satisfaction_score": {"name": "ticket_satisfaction_score", "description": "The latest satisfaction score the ticket received.", "meta": {}, "data_type": null, "quote": null, "tags": []}, "is_good_to_bad_satisfaction_score": {"name": "is_good_to_bad_satisfaction_score", "description": "Boolean indicating if the ticket had a satisfaction score went from good to bad.", "meta": {}, "data_type": null, "quote": null, "tags": []}, "is_bad_to_good_satisfaction_score": {"name": "is_bad_to_good_satisfaction_score", "description": "Boolean indicating if the ticket had a satisfaction score went from bad to good.", "meta": {}, "data_type": null, "quote": null, "tags": []}, "count_agent_comments": {"name": "count_agent_comments", "description": "Count of agent comments within the ticket", "meta": {}, "data_type": null, "quote": null, "tags": []}, "count_public_agent_comments": {"name": "count_public_agent_comments", "description": "Count of public agent comments within the ticket", "meta": {}, "data_type": null, "quote": null, "tags": []}, "count_end_user_comments": {"name": "count_end_user_comments", "description": "Count of end user comments within the ticket", "meta": {}, "data_type": null, "quote": null, "tags": []}, "count_internal_comments": {"name": "count_internal_comments", "description": "Count of internal comments within the ticket", "meta": {}, "data_type": null, "quote": null, "tags": []}, "count_public_comments": {"name": "count_public_comments", "description": "Count of public comments within the ticket", "meta": {}, "data_type": null, "quote": null, "tags": []}, "total_comments": {"name": "total_comments", "description": "Total count of all comments within the ticket", "meta": {}, "data_type": null, "quote": null, "tags": []}, "count_ticket_handoffs": {"name": "count_ticket_handoffs", "description": "", "meta": {}, "data_type": null, "quote": null, "tags": [], "dev_snowflake": "Count of distinct internal users who have touched/commented on the ticket."}, "unique_assignee_count": {"name": "unique_assignee_count", "description": "The count of unique assignees that were assigned to the ticket", "meta": {}, "data_type": null, "quote": null, "tags": []}, "assignee_stations_count": {"name": "assignee_stations_count", "description": "The total number of assignees that were assigned to the ticket", "meta": {}, "data_type": null, "quote": null, "tags": []}, "group_stations_count": {"name": "group_stations_count", "description": "The total count of group stations within the ticket", "meta": {}, "data_type": null, "quote": null, "tags": []}, "first_assignee_id": {"name": "first_assignee_id", "description": "Assignee id of the first agent assigned to the ticket", "meta": {}, "data_type": null, "quote": null, "tags": []}, "last_assignee_id": {"name": "last_assignee_id", "description": "Assignee id of the last agent assigned to the ticket", "meta": {}, "data_type": null, "quote": null, "tags": []}, "first_agent_assignment_date": {"name": "first_agent_assignment_date", "description": "The date the first agent was assigned to the ticket", "meta": {}, "data_type": null, "quote": null, "tags": []}, "last_agent_assignment_date": {"name": "last_agent_assignment_date", "description": "The date the last agent was assigned to the ticket", "meta": {}, "data_type": null, "quote": null, "tags": []}, "first_assignment_to_resolution_calendar_minutes": {"name": "first_assignment_to_resolution_calendar_minutes", "description": "The time in calendar minutes between the first assignment and resolution of the ticket", "meta": {}, "data_type": null, "quote": null, "tags": []}, "last_assignment_to_resolution_calendar_minutes": {"name": "last_assignment_to_resolution_calendar_minutes", "description": "The time in calendar minutes between the last assignment and resolution of the ticket", "meta": {}, "data_type": null, "quote": null, "tags": []}, "count_resolutions": {"name": "count_resolutions", "description": "The count of ticket resolutions", "meta": {}, "data_type": null, "quote": null, "tags": []}, "count_reopens": {"name": "count_reopens", "description": "The count of ticket reopen events", "meta": {}, "data_type": null, "quote": null, "tags": []}, "new_status_duration_in_calendar_minutes": {"name": "new_status_duration_in_calendar_minutes", "description": "The duration in calendar minutes the ticket was in the \"new\" status", "meta": {}, "data_type": null, "quote": null, "tags": []}, "open_status_duration_in_calendar_minutes": {"name": "open_status_duration_in_calendar_minutes", "description": "The duration in calendar minutes the ticket was in the \"open\" status", "meta": {}, "data_type": null, "quote": null, "tags": []}, "total_agent_replies": {"name": "total_agent_replies", "description": "The total number of agent replies within the ticket", "meta": {}, "data_type": null, "quote": null, "tags": []}, "requester_last_login_age_minutes": {"name": "requester_last_login_age_minutes", "description": "The time in minutes since the ticket requester was last logged in", "meta": {}, "data_type": null, "quote": null, "tags": []}, "assignee_last_login_age_minutes": {"name": "assignee_last_login_age_minutes", "description": "The time in minutes since the ticket assignee was last logged in", "meta": {}, "data_type": null, "quote": null, "tags": []}, "unsolved_ticket_age_minutes": {"name": "unsolved_ticket_age_minutes", "description": "The time in minutes the ticket has been in an unsolved state", "meta": {}, "data_type": null, "quote": null, "tags": []}, "unsolved_ticket_age_since_update_minutes": {"name": "unsolved_ticket_age_since_update_minutes", "description": "The time in minutes the ticket has been unsolved since the last update", "meta": {}, "data_type": null, "quote": null, "tags": []}, "is_two_touch_resolution": {"name": "is_two_touch_resolution", "description": "Boolean indicating if the ticket was resolved in two public comments", "meta": {}, "data_type": null, "quote": null, "tags": []}, "is_multi_touch_resolution": {"name": "is_multi_touch_resolution", "description": "Boolean indicating if the ticket was resolved in two or more public comments", "meta": {}, "data_type": null, "quote": null, "tags": []}, "ticket_last_comment_date": {"name": "ticket_last_comment_date", "description": "The time the last comment was applied to the ticket", "meta": {}, "data_type": null, "quote": null, "tags": []}, "ticket_unassigned_duration_calendar_minutes": {"name": "ticket_unassigned_duration_calendar_minutes", "description": "The time in minutes the ticket was in an unassigned state", "meta": {}, "data_type": null, "quote": null, "tags": []}, "last_status_assignment_date": {"name": "last_status_assignment_date", "description": "The time the status was last changed on the ticket", "meta": {}, "data_type": null, "quote": null, "tags": []}}, "meta": {}, "docs": {"show": true}, "patch_path": "zendesk://models/zendesk.yml", "compiled_path": "target/compiled/zendesk/models/zendesk__ticket_metrics.sql", "build_path": null, "deferred": false, "unrendered_config": {"schema": "zendesk_docs", "materialized": "table"}, "created_at": 1647014737.9020522, "compiled_sql": "with  __dbt__cte__int_zendesk__ticket_resolution_times_calendar as (\nwith historical_solved_status as (\n\n    select *\n    from `bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__ticket_historical_status`\n    where status = 'solved'\n\n), ticket as (\n\n    select *\n    from `bq-project`.`dbt_joe_zendesk_docs`.`stg_zendesk__ticket`\n\n), ticket_historical_assignee as (\n\n    select *\n    from `bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__ticket_historical_assignee`\n\n), ticket_historical_group as (\n\n  select *\n  from `bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__ticket_historical_group`\n\n), solved_times as (\n  \n  select\n  \n    ticket_id,\n    min(valid_starting_at) as first_solved_at,\n    max(valid_starting_at) as last_solved_at,\n    count(status) as solved_count \n\n  from historical_solved_status\n  group by 1\n\n)\n\n  select\n\n    ticket.ticket_id,\n    ticket.created_at,\n    solved_times.first_solved_at,\n    solved_times.last_solved_at,\n    ticket_historical_assignee.unique_assignee_count,\n    ticket_historical_assignee.assignee_stations_count,\n    ticket_historical_group.group_stations_count,\n    ticket_historical_assignee.first_assignee_id,\n    ticket_historical_assignee.last_assignee_id,\n    ticket_historical_assignee.first_agent_assignment_date,\n    ticket_historical_assignee.last_agent_assignment_date,\n    ticket_historical_assignee.ticket_unassigned_duration_calendar_minutes,\n    solved_times.solved_count as total_resolutions,\n    case when solved_times.solved_count <= 1\n      then 0\n      else solved_times.solved_count - 1 --subtracting one as the first solve is not a reopen.\n        end as count_reopens,\n\n    \n  \n\n    timestamp_diff(\n        solved_times.last_solved_at,\n        ticket_historical_assignee.first_agent_assignment_date,\n        minute\n    )\n\n\n as first_assignment_to_resolution_calendar_minutes,\n    \n  \n\n    timestamp_diff(\n        solved_times.last_solved_at,\n        ticket_historical_assignee.last_agent_assignment_date,\n        minute\n    )\n\n\n as last_assignment_to_resolution_calendar_minutes,\n    \n  \n\n    timestamp_diff(\n        solved_times.first_solved_at,\n        ticket.created_at,\n        minute\n    )\n\n\n as first_resolution_calendar_minutes,\n    \n  \n\n    timestamp_diff(\n        solved_times.last_solved_at,\n        ticket.created_at,\n        minute\n    )\n\n\n as final_resolution_calendar_minutes\n\n  from ticket\n\n  left join ticket_historical_assignee\n    using(ticket_id)\n\n  left join ticket_historical_group\n    using(ticket_id)\n\n  left join solved_times\n    using(ticket_id)\n),  __dbt__cte__int_zendesk__comments_enriched as (\nwith ticket_comment as (\n\n    select *\n    from `bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__updates`\n    where field_name = 'comment'\n\n), users as (\n\n    select *\n    from `bq-project`.`dbt_joe_zendesk_docs`.`stg_zendesk__user`\n\n), joined as (\n\n    select \n\n        ticket_comment.*,\n        case when commenter.role = 'end-user' then 'external_comment'\n            when commenter.role in ('agent','admin') then 'internal_comment'\n            else 'unknown' end as commenter_role\n    \n    from ticket_comment\n    \n    join users as commenter\n        on commenter.user_id = ticket_comment.user_id\n\n), add_previous_commenter_role as (\n    /*\n    In int_zendesk__ticket_reply_times we will only be focusing on reply times between public tickets.\n    The below union explicitly identifies the previous commentor roles of public and not public comments.\n    */\n    select\n        *,\n        coalesce(\n            lag(commenter_role) over (partition by ticket_id order by valid_starting_at)\n            , 'first_comment') \n            as previous_commenter_role\n    from joined\n    where is_public\n\n    union all\n\n    select\n        *,\n        'non_public_comment' as previous_commenter_role\n    from joined\n    where not is_public\n)\n\nselect \n    *,\n    first_value(valid_starting_at) over (partition by ticket_id order by valid_starting_at desc, ticket_id rows unbounded preceding) as last_comment_added_at,\n    sum(case when not is_public then 1 else 0 end) over (partition by ticket_id order by valid_starting_at rows between unbounded preceding and current row) as previous_internal_comment_count\nfrom add_previous_commenter_role\n),  __dbt__cte__int_zendesk__ticket_reply_times as (\nwith ticket_public_comments as (\n\n    select *\n    from __dbt__cte__int_zendesk__comments_enriched\n    where is_public\n\n), end_user_comments as (\n  \n  select \n    ticket_id,\n    valid_starting_at as end_user_comment_created_at,\n    ticket_created_date,\n    commenter_role,\n    previous_internal_comment_count,\n    previous_commenter_role = 'first_comment' as is_first_comment\n  from ticket_public_comments \n  where (commenter_role = 'external_comment'\n    and ticket_public_comments.previous_commenter_role != 'external_comment') -- we only care about net new end user comments\n    or previous_commenter_role = 'first_comment' -- We also want to take into consideration internal first comment replies\n\n), reply_timestamps as (  \n\n  select\n    end_user_comments.ticket_id,\n    -- If the commentor was internal, a first comment, and had previous non public internal comments then we want the ticket created date to be the end user comment created date\n    -- Otherwise we will want to end user comment created date\n    case when is_first_comment then end_user_comments.ticket_created_date else end_user_comments.end_user_comment_created_at end as end_user_comment_created_at,\n    end_user_comments.is_first_comment,\n    min(case when is_first_comment \n        and end_user_comments.commenter_role != 'external_comment' \n        and (end_user_comments.previous_internal_comment_count > 0)\n          then end_user_comments.end_user_comment_created_at \n        else agent_comments.valid_starting_at end) as agent_responded_at\n  from end_user_comments\n  left join ticket_public_comments as agent_comments\n    on agent_comments.ticket_id = end_user_comments.ticket_id\n    and agent_comments.commenter_role = 'internal_comment'\n    and agent_comments.valid_starting_at > end_user_comments.end_user_comment_created_at\n  group by 1,2,3\n\n)\n\n  select\n    *,\n    (\n  \n\n    timestamp_diff(\n        agent_responded_at,\n        end_user_comment_created_at,\n        second\n    )\n\n\n / 60) as reply_time_calendar_minutes\n  from reply_timestamps\n  order by 1,2\n),  __dbt__cte__int_zendesk__ticket_reply_times_calendar as (\nwith ticket as (\n\n  select *\n  from `bq-project`.`dbt_joe_zendesk_docs`.`stg_zendesk__ticket`\n\n), ticket_reply_times as (\n\n  select *\n  from __dbt__cte__int_zendesk__ticket_reply_times\n\n)\n\nselect\n\n  ticket.ticket_id,\n  sum(case when is_first_comment then reply_time_calendar_minutes\n    else null end) as first_reply_time_calendar_minutes,\n  sum(reply_time_calendar_minutes) as total_reply_time_calendar_minutes --total combined time the customer waits for internal response\n  \nfrom ticket\nleft join ticket_reply_times\n  using (ticket_id)\n\ngroup by 1\n),  __dbt__cte__int_zendesk__ticket_work_time_calendar as (\nwith ticket_historical_status as (\n\n    select *\n    from `bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__ticket_historical_status`\n\n), calendar_minutes as (\n  \n    select \n        ticket_id,\n        status,\n        case when status in ('pending') then status_duration_calendar_minutes\n            else 0 end as agent_wait_time_in_minutes,\n        case when status in ('new', 'open', 'hold') then status_duration_calendar_minutes\n            else 0 end as requester_wait_time_in_minutes,\n        case when status in ('new', 'open') then status_duration_calendar_minutes\n            else 0 end as agent_work_time_in_minutes,\n        case when status in ('hold') then status_duration_calendar_minutes\n            else 0 end as on_hold_time_in_minutes,\n        case when status = 'new' then status_duration_calendar_minutes\n            else 0 end as new_status_duration_minutes,\n        case when status = 'open' then status_duration_calendar_minutes\n            else 0 end as open_status_duration_minutes,\n        case when status = 'deleted' then 1\n            else 0 end as ticket_deleted,\n        first_value(valid_starting_at) over (partition by ticket_id order by valid_starting_at desc, ticket_id rows unbounded preceding) as last_status_assignment_date,\n        case when lag(status) over (partition by ticket_id order by valid_starting_at) = 'deleted' and status != 'deleted'\n            then 1\n            else 0\n                end as ticket_recoveries\n\n    from ticket_historical_status\n\n)\n\nselect \n  ticket_id,\n  last_status_assignment_date,\n  sum(ticket_deleted) as ticket_deleted_count,\n  sum(agent_wait_time_in_minutes) as agent_wait_time_in_calendar_minutes,\n  sum(requester_wait_time_in_minutes) as requester_wait_time_in_calendar_minutes,\n  sum(agent_work_time_in_minutes) as agent_work_time_in_calendar_minutes,\n  sum(on_hold_time_in_minutes) as on_hold_time_in_calendar_minutes,\n  sum(new_status_duration_minutes) as new_status_duration_in_calendar_minutes,\n  sum(open_status_duration_minutes) as open_status_duration_in_calendar_minutes,\n  sum(ticket_recoveries) as total_ticket_recoveries\nfrom calendar_minutes\ngroup by 1, 2\n),  __dbt__cte__int_zendesk__ticket_first_resolution_time_business as (\n\n\nwith ticket_resolution_times_calendar as (\n\n    select *\n    from __dbt__cte__int_zendesk__ticket_resolution_times_calendar\n\n), ticket_schedules as (\n\n    select *\n    from `bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__ticket_schedules`\n\n), schedule as (\n\n    select *\n    from `bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__schedule_spine`\n\n), ticket_first_resolution_time as (\n\n  select \n    ticket_resolution_times_calendar.ticket_id,\n    ticket_schedules.schedule_created_at,\n    ticket_schedules.schedule_invalidated_at,\n    ticket_schedules.schedule_id,\n\n    -- bringing this in the determine which schedule (Daylight Savings vs Standard time) to use\n    min(ticket_resolution_times_calendar.first_solved_at) as first_solved_at,\n    \n    (\n  \n\n    timestamp_diff(\n        ticket_schedules.schedule_created_at,\n        \n    timestamp_trunc(\n        cast(ticket_schedules.schedule_created_at as timestamp),\n        week\n    )\n\n,\n        second\n    )\n\n\n /60\n          ) as start_time_in_minutes_from_week,\n    greatest(0,\n      (\n        \n  \n\n    timestamp_diff(\n        least(ticket_schedules.schedule_invalidated_at, min(ticket_resolution_times_calendar.first_solved_at)),\n        ticket_schedules.schedule_created_at,\n        second\n    )\n\n\n/60\n        )) as raw_delta_in_minutes\n      \n  from ticket_resolution_times_calendar\n  join ticket_schedules on ticket_resolution_times_calendar.ticket_id = ticket_schedules.ticket_id\n  group by 1, 2, 3, 4\n\n), weeks as (\n\n    \n\n    \n\n    with p as (\n        select 0 as generated_number union all select 1\n    ), unioned as (\n\n    select\n\n    \n    p0.generated_number * power(2, 0)\n     + \n    \n    p1.generated_number * power(2, 1)\n     + \n    \n    p2.generated_number * power(2, 2)\n     + \n    \n    p3.generated_number * power(2, 3)\n     + \n    \n    p4.generated_number * power(2, 4)\n     + \n    \n    p5.generated_number * power(2, 5)\n     + \n    \n    p6.generated_number * power(2, 6)\n     + \n    \n    p7.generated_number * power(2, 7)\n    \n    \n    + 1\n    as generated_number\n\n    from\n\n    \n    p as p0\n     cross join \n    \n    p as p1\n     cross join \n    \n    p as p2\n     cross join \n    \n    p as p3\n     cross join \n    \n    p as p4\n     cross join \n    \n    p as p5\n     cross join \n    \n    p as p6\n     cross join \n    \n    p as p7\n    \n    \n\n    )\n\n    select *\n    from unioned\n    where generated_number <= 208\n    order by generated_number\n\n\n\n), weeks_cross_ticket_first_resolution_time as (\n    -- because time is reported in minutes since the beginning of the week, we have to split up time spent on the ticket into calendar weeks\n    select \n\n      ticket_first_resolution_time.*,\n      generated_number - 1 as week_number\n\n    from ticket_first_resolution_time\n    cross join weeks\n    where floor((start_time_in_minutes_from_week + raw_delta_in_minutes) / (7*24*60)) >= generated_number - 1\n\n\n), weekly_periods as (\n  \n    select \n\n      weeks_cross_ticket_first_resolution_time.*,\n      greatest(0, start_time_in_minutes_from_week - week_number * (7*24*60)) as ticket_week_start_time,\n      least(start_time_in_minutes_from_week + raw_delta_in_minutes - week_number * (7*24*60), (7*24*60)) as ticket_week_end_time\n    \n    from weeks_cross_ticket_first_resolution_time\n\n), intercepted_periods as (\n\n  select ticket_id,\n         week_number,\n         weekly_periods.schedule_id,\n         ticket_week_start_time,\n         ticket_week_end_time,\n         schedule.start_time_utc as schedule_start_time,\n         schedule.end_time_utc as schedule_end_time,\n         least(ticket_week_end_time, schedule.end_time_utc) - greatest(ticket_week_start_time, schedule.start_time_utc) as scheduled_minutes\n  from weekly_periods\n  join schedule on ticket_week_start_time <= schedule.end_time_utc \n    and ticket_week_end_time >= schedule.start_time_utc\n    and weekly_periods.schedule_id = schedule.schedule_id\n    -- this chooses the Daylight Savings Time or Standard Time version of the schedule\n    and weekly_periods.first_solved_at >= cast(schedule.valid_from as \n    timestamp\n)\n    and weekly_periods.first_solved_at < cast(schedule.valid_until as \n    timestamp\n) \n    \n)\n\n  select \n    ticket_id,\n    sum(scheduled_minutes) as first_resolution_business_minutes\n  from intercepted_periods\n  group by 1\n),  __dbt__cte__int_zendesk__ticket_full_resolution_time_business as (\n\n\nwith ticket_resolution_times_calendar as (\n\n    select *\n    from __dbt__cte__int_zendesk__ticket_resolution_times_calendar\n\n), ticket_schedules as (\n\n    select *\n    from `bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__ticket_schedules`\n\n), schedule as (\n\n    select *\n    from `bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__schedule_spine`\n\n), ticket_full_resolution_time as (\n\n  select \n    ticket_resolution_times_calendar.ticket_id,\n    ticket_schedules.schedule_created_at,\n    ticket_schedules.schedule_invalidated_at,\n    ticket_schedules.schedule_id,\n\n    -- bringing this in the determine which schedule (Daylight Savings vs Standard time) to use\n    min(ticket_resolution_times_calendar.last_solved_at) as last_solved_at,\n    \n    (\n  \n\n    timestamp_diff(\n        ticket_schedules.schedule_created_at,\n        \n    timestamp_trunc(\n        cast(ticket_schedules.schedule_created_at as timestamp),\n        week\n    )\n\n,\n        second\n    )\n\n\n /60\n          ) as start_time_in_minutes_from_week,\n    greatest(0,\n      (\n        \n  \n\n    timestamp_diff(\n        least(ticket_schedules.schedule_invalidated_at, min(ticket_resolution_times_calendar.last_solved_at)),\n        ticket_schedules.schedule_created_at,\n        second\n    )\n\n\n/60\n        )) as raw_delta_in_minutes\n      \n  from ticket_resolution_times_calendar\n  join ticket_schedules on ticket_resolution_times_calendar.ticket_id = ticket_schedules.ticket_id\n  group by 1, 2, 3, 4\n\n), weeks as (\n\n    \n\n    \n\n    with p as (\n        select 0 as generated_number union all select 1\n    ), unioned as (\n\n    select\n\n    \n    p0.generated_number * power(2, 0)\n     + \n    \n    p1.generated_number * power(2, 1)\n     + \n    \n    p2.generated_number * power(2, 2)\n     + \n    \n    p3.generated_number * power(2, 3)\n     + \n    \n    p4.generated_number * power(2, 4)\n     + \n    \n    p5.generated_number * power(2, 5)\n     + \n    \n    p6.generated_number * power(2, 6)\n     + \n    \n    p7.generated_number * power(2, 7)\n    \n    \n    + 1\n    as generated_number\n\n    from\n\n    \n    p as p0\n     cross join \n    \n    p as p1\n     cross join \n    \n    p as p2\n     cross join \n    \n    p as p3\n     cross join \n    \n    p as p4\n     cross join \n    \n    p as p5\n     cross join \n    \n    p as p6\n     cross join \n    \n    p as p7\n    \n    \n\n    )\n\n    select *\n    from unioned\n    where generated_number <= 208\n    order by generated_number\n\n\n\n), weeks_cross_ticket_full_resolution_time as (\n    -- because time is reported in minutes since the beginning of the week, we have to split up time spent on the ticket into calendar weeks\n    select \n\n      ticket_full_resolution_time.*,\n      generated_number - 1 as week_number\n\n    from ticket_full_resolution_time\n    cross join weeks\n    where floor((start_time_in_minutes_from_week + raw_delta_in_minutes) / (7*24*60)) >= generated_number - 1\n\n), weekly_periods as (\n  \n  select \n\n    weeks_cross_ticket_full_resolution_time.*,\n    greatest(0, start_time_in_minutes_from_week - week_number * (7*24*60)) as ticket_week_start_time,\n    least(start_time_in_minutes_from_week + raw_delta_in_minutes - week_number * (7*24*60), (7*24*60)) as ticket_week_end_time\n  \n  from weeks_cross_ticket_full_resolution_time\n\n), intercepted_periods as (\n\n  select \n    ticket_id,\n    week_number,\n    weekly_periods.schedule_id,\n    ticket_week_start_time,\n    ticket_week_end_time,\n    schedule.start_time_utc as schedule_start_time,\n    schedule.end_time_utc as schedule_end_time,\n    least(ticket_week_end_time, schedule.end_time_utc) - greatest(ticket_week_start_time, schedule.start_time_utc) as scheduled_minutes\n  from weekly_periods\n  join schedule on ticket_week_start_time <= schedule.end_time_utc \n    and ticket_week_end_time >= schedule.start_time_utc\n    and weekly_periods.schedule_id = schedule.schedule_id\n    -- this chooses the Daylight Savings Time or Standard Time version of the schedule\n    and weekly_periods.last_solved_at >= cast(schedule.valid_from as \n    timestamp\n)\n    and weekly_periods.last_solved_at < cast(schedule.valid_until as \n    timestamp\n) \n    \n)\n\n  select \n    ticket_id,\n    sum(scheduled_minutes) as full_resolution_business_minutes\n  from intercepted_periods\n  group by 1\n),  __dbt__cte__int_zendesk__ticket_work_time_business as (\n\n\nwith ticket_historical_status as (\n\n    select *\n    from `bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__ticket_historical_status`\n\n), ticket_schedules as (\n\n    select *\n    from `bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__ticket_schedules`\n\n), schedule as (\n\n    select *\n    from `bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__schedule_spine`\n\n), ticket_status_crossed_with_schedule as (\n  \n    select\n      ticket_historical_status.ticket_id,\n      ticket_historical_status.status as ticket_status,\n      ticket_schedules.schedule_id,\n\n      -- take the intersection of the intervals in which the status and the schedule were both active, for calculating the business minutes spent working on the ticket\n      greatest(valid_starting_at, schedule_created_at) as status_schedule_start,\n      least(valid_ending_at, schedule_invalidated_at) as status_schedule_end,\n\n      -- bringing the following in the determine which schedule (Daylight Savings vs Standard time) to use\n      ticket_historical_status.valid_starting_at as status_valid_starting_at,\n      ticket_historical_status.valid_ending_at as status_valid_ending_at\n\n    from ticket_historical_status\n    left join ticket_schedules\n      on ticket_historical_status.ticket_id = ticket_schedules.ticket_id\n      where \n  \n\n    timestamp_diff(\n        least(valid_ending_at, schedule_invalidated_at),\n        greatest(valid_starting_at, schedule_created_at),\n        second\n    )\n\n\n > 0\n\n), ticket_full_solved_time as (\n\n    select \n      ticket_status_crossed_with_schedule.*,\n      (\n  \n\n    timestamp_diff(\n        ticket_status_crossed_with_schedule.status_schedule_start,\n        \n    timestamp_trunc(\n        cast(ticket_status_crossed_with_schedule.status_schedule_start as timestamp),\n        week\n    )\n\n,\n        second\n    )\n\n\n /60\n            ) as start_time_in_minutes_from_week,\n      (\n  \n\n    timestamp_diff(\n        ticket_status_crossed_with_schedule.status_schedule_end,\n        ticket_status_crossed_with_schedule.status_schedule_start,\n        second\n    )\n\n\n /60\n            ) as raw_delta_in_minutes\n    from ticket_status_crossed_with_schedule\n    group by 1,2,3,4,5,6,7\n\n), weeks as (\n\n    \n\n    \n\n    with p as (\n        select 0 as generated_number union all select 1\n    ), unioned as (\n\n    select\n\n    \n    p0.generated_number * power(2, 0)\n     + \n    \n    p1.generated_number * power(2, 1)\n     + \n    \n    p2.generated_number * power(2, 2)\n     + \n    \n    p3.generated_number * power(2, 3)\n     + \n    \n    p4.generated_number * power(2, 4)\n     + \n    \n    p5.generated_number * power(2, 5)\n     + \n    \n    p6.generated_number * power(2, 6)\n     + \n    \n    p7.generated_number * power(2, 7)\n    \n    \n    + 1\n    as generated_number\n\n    from\n\n    \n    p as p0\n     cross join \n    \n    p as p1\n     cross join \n    \n    p as p2\n     cross join \n    \n    p as p3\n     cross join \n    \n    p as p4\n     cross join \n    \n    p as p5\n     cross join \n    \n    p as p6\n     cross join \n    \n    p as p7\n    \n    \n\n    )\n\n    select *\n    from unioned\n    where generated_number <= 208\n    order by generated_number\n\n\n\n), weeks_cross_ticket_full_solved_time as (\n    -- because time is reported in minutes since the beginning of the week, we have to split up time spent on the ticket into calendar weeks\n    select \n      ticket_full_solved_time.*,\n      generated_number - 1 as week_number\n    from ticket_full_solved_time\n    cross join weeks\n    where floor((start_time_in_minutes_from_week + raw_delta_in_minutes) / (7*24*60)) >= generated_number -1\n\n), weekly_periods as (\n\n    select\n\n      weeks_cross_ticket_full_solved_time.*,\n      greatest(0, start_time_in_minutes_from_week - week_number * (7*24*60)) as ticket_week_start_time,\n      least(start_time_in_minutes_from_week + raw_delta_in_minutes - week_number * (7*24*60), (7*24*60)) as ticket_week_end_time\n    \n    from weeks_cross_ticket_full_solved_time\n\n), intercepted_periods as (\n  \n    select \n      weekly_periods.ticket_id,\n      weekly_periods.week_number,\n      weekly_periods.schedule_id,\n      weekly_periods.ticket_status,\n      weekly_periods.ticket_week_start_time,\n      weekly_periods.ticket_week_end_time,\n      schedule.start_time_utc as schedule_start_time,\n      schedule.end_time_utc as schedule_end_time,\n      least(ticket_week_end_time, schedule.end_time_utc) - greatest(weekly_periods.ticket_week_start_time, schedule.start_time_utc) as scheduled_minutes\n    from weekly_periods\n    join schedule on ticket_week_start_time <= schedule.end_time_utc \n      and ticket_week_end_time >= schedule.start_time_utc\n      and weekly_periods.schedule_id = schedule.schedule_id\n      -- this chooses the Daylight Savings Time or Standard Time version of the schedule\n      and weekly_periods.status_valid_ending_at >= cast(schedule.valid_from as \n    timestamp\n)\n      and weekly_periods.status_valid_starting_at < cast(schedule.valid_until as \n    timestamp\n) \n  \n), business_minutes as (\n  \n    select \n      ticket_id,\n      ticket_status,\n      case when ticket_status in ('pending') then scheduled_minutes\n          else 0 end as agent_wait_time_in_minutes,\n      case when ticket_status in ('new', 'open', 'hold') then scheduled_minutes\n          else 0 end as requester_wait_time_in_minutes,\n      case when ticket_status in ('new', 'open') then scheduled_minutes\n          else 0 end as agent_work_time_in_minutes,\n      case when ticket_status in ('hold') then scheduled_minutes\n          else 0 end as on_hold_time_in_minutes\n    from intercepted_periods\n\n)\n  \n    select \n      ticket_id,\n      sum(agent_wait_time_in_minutes) as agent_wait_time_in_business_minutes,\n      sum(requester_wait_time_in_minutes) as requester_wait_time_in_business_minutes,\n      sum(agent_work_time_in_minutes) as agent_work_time_in_business_minutes,\n      sum(on_hold_time_in_minutes) as on_hold_time_in_business_minutes\n    from business_minutes\n    group by 1\n),  __dbt__cte__int_zendesk__ticket_first_reply_time_business as (\n\n\nwith ticket_reply_times as (\n\n    select *\n    from __dbt__cte__int_zendesk__ticket_reply_times\n\n), ticket_schedules as (\n\n    select *\n    from `bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__ticket_schedules`\n\n), schedule as (\n\n    select *\n    from `bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__schedule_spine`\n\n), first_reply_time as (\n\n    select\n      ticket_id,\n      end_user_comment_created_at,\n      agent_responded_at\n\n    from ticket_reply_times\n    where is_first_comment\n\n), ticket_first_reply_time as (\n\n  select \n    first_reply_time.ticket_id,\n    ticket_schedules.schedule_created_at,\n    ticket_schedules.schedule_invalidated_at,\n    ticket_schedules.schedule_id,\n\n    -- bringing this in the determine which schedule (Daylight Savings vs Standard time) to use\n    min(first_reply_time.agent_responded_at) as agent_responded_at,\n\n    (\n  \n\n    timestamp_diff(\n        ticket_schedules.schedule_created_at,\n        \n    timestamp_trunc(\n        cast(ticket_schedules.schedule_created_at as timestamp),\n        week\n    )\n\n,\n        second\n    )\n\n\n /60\n          ) as start_time_in_minutes_from_week,\n    greatest(0,\n      (\n        \n  \n\n    timestamp_diff(\n        least(ticket_schedules.schedule_invalidated_at, min(first_reply_time.agent_responded_at)),\n        ticket_schedules.schedule_created_at,\n        second\n    )\n\n\n/60\n        )) as raw_delta_in_minutes\n  \n  from first_reply_time\n  join ticket_schedules on first_reply_time.ticket_id = ticket_schedules.ticket_id\n  group by 1, 2, 3, 4\n\n), weeks as (\n\n    \n\n    \n\n    with p as (\n        select 0 as generated_number union all select 1\n    ), unioned as (\n\n    select\n\n    \n    p0.generated_number * power(2, 0)\n     + \n    \n    p1.generated_number * power(2, 1)\n     + \n    \n    p2.generated_number * power(2, 2)\n     + \n    \n    p3.generated_number * power(2, 3)\n     + \n    \n    p4.generated_number * power(2, 4)\n     + \n    \n    p5.generated_number * power(2, 5)\n     + \n    \n    p6.generated_number * power(2, 6)\n     + \n    \n    p7.generated_number * power(2, 7)\n    \n    \n    + 1\n    as generated_number\n\n    from\n\n    \n    p as p0\n     cross join \n    \n    p as p1\n     cross join \n    \n    p as p2\n     cross join \n    \n    p as p3\n     cross join \n    \n    p as p4\n     cross join \n    \n    p as p5\n     cross join \n    \n    p as p6\n     cross join \n    \n    p as p7\n    \n    \n\n    )\n\n    select *\n    from unioned\n    where generated_number <= 208\n    order by generated_number\n\n\n\n), weeks_cross_ticket_first_reply as (\n    -- because time is reported in minutes since the beginning of the week, we have to split up time spent on the ticket into calendar weeks\n    select \n\n      ticket_first_reply_time.*,\n      generated_number - 1 as week_number\n\n    from ticket_first_reply_time\n    cross join weeks\n    where floor((start_time_in_minutes_from_week + raw_delta_in_minutes) / (7*24*60)) >= generated_number - 1\n\n), weekly_periods as (\n  \n    select \n      weeks_cross_ticket_first_reply.*, \n      greatest(0, start_time_in_minutes_from_week - week_number * (7*24*60)) as ticket_week_start_time,\n      least(start_time_in_minutes_from_week + raw_delta_in_minutes - week_number * (7*24*60), (7*24*60)) as ticket_week_end_time\n    from weeks_cross_ticket_first_reply\n\n), intercepted_periods as (\n\n  select ticket_id,\n      week_number,\n      weekly_periods.schedule_id,\n      ticket_week_start_time,\n      ticket_week_end_time,\n      schedule.start_time_utc as schedule_start_time,\n      schedule.end_time_utc as schedule_end_time,\n      least(ticket_week_end_time, schedule.end_time_utc) - greatest(ticket_week_start_time, schedule.start_time_utc) as scheduled_minutes\n  from weekly_periods\n  join schedule on ticket_week_start_time <= schedule.end_time_utc \n    and ticket_week_end_time >= schedule.start_time_utc\n    and weekly_periods.schedule_id = schedule.schedule_id\n    -- this chooses the Daylight Savings Time or Standard Time version of the schedule\n    and weekly_periods.agent_responded_at >= cast(schedule.valid_from as \n    timestamp\n)\n    and weekly_periods.agent_responded_at < cast(schedule.valid_until as \n    timestamp\n) \n\n)\n\n  select ticket_id,\n         sum(scheduled_minutes) as first_reply_time_business_minutes\n  from intercepted_periods\n  group by 1\n),ticket_enriched as (\n\n  select *\n  from `bq-project`.`dbt_joe_zendesk_docs`.`zendesk__ticket_enriched`\n\n), ticket_resolution_times_calendar as (\n\n  select *\n  from __dbt__cte__int_zendesk__ticket_resolution_times_calendar\n\n), ticket_reply_times_calendar as (\n\n  select *\n  from __dbt__cte__int_zendesk__ticket_reply_times_calendar\n\n), ticket_comments as (\n\n  select *\n  from `bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__comment_metrics`\n\n), ticket_work_time_calendar as (\n\n  select *\n  from __dbt__cte__int_zendesk__ticket_work_time_calendar\n\n-- business hour CTEs\n\n\n), ticket_first_resolution_time_business as (\n\n  select *\n  from __dbt__cte__int_zendesk__ticket_first_resolution_time_business\n\n), ticket_full_resolution_time_business as (\n\n  select *\n  from __dbt__cte__int_zendesk__ticket_full_resolution_time_business\n\n), ticket_work_time_business as (\n\n  select *\n  from __dbt__cte__int_zendesk__ticket_work_time_business\n\n), ticket_first_reply_time_business as (\n\n  select *\n  from __dbt__cte__int_zendesk__ticket_first_reply_time_business\n\n\n-- end business hour CTEs\n\n), calendar_hour_metrics as (\n\nselect\n  ticket_enriched.*,\n  case when coalesce(ticket_comments.count_public_agent_comments, 0) = 0\n    then null\n    else ticket_reply_times_calendar.first_reply_time_calendar_minutes\n      end as first_reply_time_calendar_minutes,\n  case when coalesce(ticket_comments.count_public_agent_comments, 0) = 0\n    then null\n    else ticket_reply_times_calendar.total_reply_time_calendar_minutes\n      end as total_reply_time_calendar_minutes,\n  coalesce(ticket_comments.count_agent_comments, 0) as count_agent_comments,\n  coalesce(ticket_comments.count_public_agent_comments, 0) as count_public_agent_comments,\n  coalesce(ticket_comments.count_end_user_comments, 0) as count_end_user_comments,\n  coalesce(ticket_comments.count_public_comments, 0) as count_public_comments,\n  coalesce(ticket_comments.count_internal_comments, 0) as count_internal_comments,\n  coalesce(ticket_comments.total_comments, 0) as total_comments,\n  coalesce(ticket_comments.count_ticket_handoffs, 0) as count_ticket_handoffs, -- the number of distinct internal users who commented on the ticket\n  ticket_comments.last_comment_added_at as ticket_last_comment_date,\n  ticket_resolution_times_calendar.unique_assignee_count,\n  ticket_resolution_times_calendar.assignee_stations_count,\n  ticket_resolution_times_calendar.group_stations_count,\n  ticket_resolution_times_calendar.first_assignee_id,\n  ticket_resolution_times_calendar.last_assignee_id,\n  ticket_resolution_times_calendar.first_agent_assignment_date,\n  ticket_resolution_times_calendar.last_agent_assignment_date,\n  ticket_resolution_times_calendar.first_solved_at,\n  ticket_resolution_times_calendar.last_solved_at,\n  case when ticket_enriched.status in ('solved', 'closed')\n    then ticket_resolution_times_calendar.first_assignment_to_resolution_calendar_minutes\n    else null\n      end as first_assignment_to_resolution_calendar_minutes,\n  case when ticket_enriched.status in ('solved', 'closed')\n    then ticket_resolution_times_calendar.last_assignment_to_resolution_calendar_minutes\n    else null\n      end as last_assignment_to_resolution_calendar_minutes,\n  ticket_resolution_times_calendar.ticket_unassigned_duration_calendar_minutes,\n  ticket_resolution_times_calendar.first_resolution_calendar_minutes,\n  ticket_resolution_times_calendar.final_resolution_calendar_minutes,\n  ticket_resolution_times_calendar.total_resolutions as count_resolutions,\n  ticket_resolution_times_calendar.count_reopens,\n  ticket_work_time_calendar.ticket_deleted_count,\n  ticket_work_time_calendar.total_ticket_recoveries,\n  ticket_work_time_calendar.last_status_assignment_date,\n  ticket_work_time_calendar.new_status_duration_in_calendar_minutes,\n  ticket_work_time_calendar.open_status_duration_in_calendar_minutes,\n  ticket_work_time_calendar.agent_wait_time_in_calendar_minutes,\n  ticket_work_time_calendar.requester_wait_time_in_calendar_minutes,\n  ticket_work_time_calendar.agent_work_time_in_calendar_minutes,\n  ticket_work_time_calendar.on_hold_time_in_calendar_minutes,\n  coalesce(ticket_comments.count_agent_comments, 0) as total_agent_replies,\n  \n  case when ticket_enriched.is_requester_active = true and ticket_enriched.requester_last_login_at is not null\n    then (\n\n    datetime_diff(\n        cast(\n    current_timestamp\n as datetime),\n        cast(ticket_enriched.requester_last_login_at as datetime),\n        second\n    )\n\n /60)\n      end as requester_last_login_age_minutes,\n  case when ticket_enriched.is_assignee_active = true and ticket_enriched.assignee_last_login_at is not null\n    then (\n\n    datetime_diff(\n        cast(\n    current_timestamp\n as datetime),\n        cast(ticket_enriched.assignee_last_login_at as datetime),\n        second\n    )\n\n /60)\n      end as assignee_last_login_age_minutes,\n  case when lower(ticket_enriched.status) not in ('solved','closed')\n    then (\n\n    datetime_diff(\n        cast(\n    current_timestamp\n as datetime),\n        cast(ticket_enriched.created_at as datetime),\n        second\n    )\n\n /60)\n      end as unsolved_ticket_age_minutes,\n  case when lower(ticket_enriched.status) not in ('solved','closed')\n    then (\n\n    datetime_diff(\n        cast(\n    current_timestamp\n as datetime),\n        cast(ticket_enriched.updated_at as datetime),\n        second\n    )\n\n /60)\n      end as unsolved_ticket_age_since_update_minutes,\n  case when lower(ticket_enriched.status) in ('solved','closed') and ticket_comments.is_one_touch_resolution \n    then true\n    else false\n      end as is_one_touch_resolution,\n  case when lower(ticket_enriched.status) in ('solved','closed') and ticket_comments.is_two_touch_resolution \n    then true\n    else false \n      end as is_two_touch_resolution,\n  case when lower(ticket_enriched.status) in ('solved','closed') and not ticket_comments.is_one_touch_resolution \n    then true\n    else false \n      end as is_multi_touch_resolution\n\n\nfrom ticket_enriched\n\nleft join ticket_reply_times_calendar\n  using (ticket_id)\n\nleft join ticket_resolution_times_calendar\n  using (ticket_id)\n\nleft join ticket_work_time_calendar\n  using (ticket_id)\n\nleft join ticket_comments\n  using(ticket_id)\n\n\n\n), business_hour_metrics as (\n\n  select \n    ticket_enriched.ticket_id,\n    ticket_first_resolution_time_business.first_resolution_business_minutes,\n    ticket_full_resolution_time_business.full_resolution_business_minutes,\n    ticket_first_reply_time_business.first_reply_time_business_minutes,\n    ticket_work_time_business.agent_wait_time_in_business_minutes,\n    ticket_work_time_business.requester_wait_time_in_business_minutes,\n    ticket_work_time_business.agent_work_time_in_business_minutes,\n    ticket_work_time_business.on_hold_time_in_business_minutes\n\n  from ticket_enriched\n\n  left join ticket_first_resolution_time_business\n    using (ticket_id)\n\n  left join ticket_full_resolution_time_business\n    using (ticket_id)\n  \n  left join ticket_first_reply_time_business\n    using (ticket_id)  \n  \n  left join ticket_work_time_business\n    using (ticket_id)\n\n)\n\nselect\n  calendar_hour_metrics.*,\n  case when calendar_hour_metrics.status in ('solved', 'closed')\n    then business_hour_metrics.first_resolution_business_minutes\n    else null\n      end as first_resolution_business_minutes,\n  case when calendar_hour_metrics.status in ('solved', 'closed')\n    then business_hour_metrics.full_resolution_business_minutes\n    else null\n      end as full_resolution_business_minutes,\n  case when coalesce(calendar_hour_metrics.count_public_agent_comments, 0) = 0\n    then null\n    else business_hour_metrics.first_reply_time_business_minutes\n      end as first_reply_time_business_minutes,\n  business_hour_metrics.agent_wait_time_in_business_minutes,\n  business_hour_metrics.requester_wait_time_in_business_minutes,\n  business_hour_metrics.agent_work_time_in_business_minutes,\n  business_hour_metrics.on_hold_time_in_business_minutes\n\nfrom calendar_hour_metrics\n\nleft join business_hour_metrics \n  using (ticket_id)\n\n", "extra_ctes_injected": true, "extra_ctes": [{"id": "model.zendesk.int_zendesk__ticket_resolution_times_calendar", "sql": " __dbt__cte__int_zendesk__ticket_resolution_times_calendar as (\nwith historical_solved_status as (\n\n    select *\n    from `bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__ticket_historical_status`\n    where status = 'solved'\n\n), ticket as (\n\n    select *\n    from `bq-project`.`dbt_joe_zendesk_docs`.`stg_zendesk__ticket`\n\n), ticket_historical_assignee as (\n\n    select *\n    from `bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__ticket_historical_assignee`\n\n), ticket_historical_group as (\n\n  select *\n  from `bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__ticket_historical_group`\n\n), solved_times as (\n  \n  select\n  \n    ticket_id,\n    min(valid_starting_at) as first_solved_at,\n    max(valid_starting_at) as last_solved_at,\n    count(status) as solved_count \n\n  from historical_solved_status\n  group by 1\n\n)\n\n  select\n\n    ticket.ticket_id,\n    ticket.created_at,\n    solved_times.first_solved_at,\n    solved_times.last_solved_at,\n    ticket_historical_assignee.unique_assignee_count,\n    ticket_historical_assignee.assignee_stations_count,\n    ticket_historical_group.group_stations_count,\n    ticket_historical_assignee.first_assignee_id,\n    ticket_historical_assignee.last_assignee_id,\n    ticket_historical_assignee.first_agent_assignment_date,\n    ticket_historical_assignee.last_agent_assignment_date,\n    ticket_historical_assignee.ticket_unassigned_duration_calendar_minutes,\n    solved_times.solved_count as total_resolutions,\n    case when solved_times.solved_count <= 1\n      then 0\n      else solved_times.solved_count - 1 --subtracting one as the first solve is not a reopen.\n        end as count_reopens,\n\n    \n  \n\n    timestamp_diff(\n        solved_times.last_solved_at,\n        ticket_historical_assignee.first_agent_assignment_date,\n        minute\n    )\n\n\n as first_assignment_to_resolution_calendar_minutes,\n    \n  \n\n    timestamp_diff(\n        solved_times.last_solved_at,\n        ticket_historical_assignee.last_agent_assignment_date,\n        minute\n    )\n\n\n as last_assignment_to_resolution_calendar_minutes,\n    \n  \n\n    timestamp_diff(\n        solved_times.first_solved_at,\n        ticket.created_at,\n        minute\n    )\n\n\n as first_resolution_calendar_minutes,\n    \n  \n\n    timestamp_diff(\n        solved_times.last_solved_at,\n        ticket.created_at,\n        minute\n    )\n\n\n as final_resolution_calendar_minutes\n\n  from ticket\n\n  left join ticket_historical_assignee\n    using(ticket_id)\n\n  left join ticket_historical_group\n    using(ticket_id)\n\n  left join solved_times\n    using(ticket_id)\n)"}, {"id": "model.zendesk.int_zendesk__comments_enriched", "sql": " __dbt__cte__int_zendesk__comments_enriched as (\nwith ticket_comment as (\n\n    select *\n    from `bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__updates`\n    where field_name = 'comment'\n\n), users as (\n\n    select *\n    from `bq-project`.`dbt_joe_zendesk_docs`.`stg_zendesk__user`\n\n), joined as (\n\n    select \n\n        ticket_comment.*,\n        case when commenter.role = 'end-user' then 'external_comment'\n            when commenter.role in ('agent','admin') then 'internal_comment'\n            else 'unknown' end as commenter_role\n    \n    from ticket_comment\n    \n    join users as commenter\n        on commenter.user_id = ticket_comment.user_id\n\n), add_previous_commenter_role as (\n    /*\n    In int_zendesk__ticket_reply_times we will only be focusing on reply times between public tickets.\n    The below union explicitly identifies the previous commentor roles of public and not public comments.\n    */\n    select\n        *,\n        coalesce(\n            lag(commenter_role) over (partition by ticket_id order by valid_starting_at)\n            , 'first_comment') \n            as previous_commenter_role\n    from joined\n    where is_public\n\n    union all\n\n    select\n        *,\n        'non_public_comment' as previous_commenter_role\n    from joined\n    where not is_public\n)\n\nselect \n    *,\n    first_value(valid_starting_at) over (partition by ticket_id order by valid_starting_at desc, ticket_id rows unbounded preceding) as last_comment_added_at,\n    sum(case when not is_public then 1 else 0 end) over (partition by ticket_id order by valid_starting_at rows between unbounded preceding and current row) as previous_internal_comment_count\nfrom add_previous_commenter_role\n)"}, {"id": "model.zendesk.int_zendesk__ticket_reply_times", "sql": " __dbt__cte__int_zendesk__ticket_reply_times as (\nwith ticket_public_comments as (\n\n    select *\n    from __dbt__cte__int_zendesk__comments_enriched\n    where is_public\n\n), end_user_comments as (\n  \n  select \n    ticket_id,\n    valid_starting_at as end_user_comment_created_at,\n    ticket_created_date,\n    commenter_role,\n    previous_internal_comment_count,\n    previous_commenter_role = 'first_comment' as is_first_comment\n  from ticket_public_comments \n  where (commenter_role = 'external_comment'\n    and ticket_public_comments.previous_commenter_role != 'external_comment') -- we only care about net new end user comments\n    or previous_commenter_role = 'first_comment' -- We also want to take into consideration internal first comment replies\n\n), reply_timestamps as (  \n\n  select\n    end_user_comments.ticket_id,\n    -- If the commentor was internal, a first comment, and had previous non public internal comments then we want the ticket created date to be the end user comment created date\n    -- Otherwise we will want to end user comment created date\n    case when is_first_comment then end_user_comments.ticket_created_date else end_user_comments.end_user_comment_created_at end as end_user_comment_created_at,\n    end_user_comments.is_first_comment,\n    min(case when is_first_comment \n        and end_user_comments.commenter_role != 'external_comment' \n        and (end_user_comments.previous_internal_comment_count > 0)\n          then end_user_comments.end_user_comment_created_at \n        else agent_comments.valid_starting_at end) as agent_responded_at\n  from end_user_comments\n  left join ticket_public_comments as agent_comments\n    on agent_comments.ticket_id = end_user_comments.ticket_id\n    and agent_comments.commenter_role = 'internal_comment'\n    and agent_comments.valid_starting_at > end_user_comments.end_user_comment_created_at\n  group by 1,2,3\n\n)\n\n  select\n    *,\n    (\n  \n\n    timestamp_diff(\n        agent_responded_at,\n        end_user_comment_created_at,\n        second\n    )\n\n\n / 60) as reply_time_calendar_minutes\n  from reply_timestamps\n  order by 1,2\n)"}, {"id": "model.zendesk.int_zendesk__ticket_reply_times_calendar", "sql": " __dbt__cte__int_zendesk__ticket_reply_times_calendar as (\nwith ticket as (\n\n  select *\n  from `bq-project`.`dbt_joe_zendesk_docs`.`stg_zendesk__ticket`\n\n), ticket_reply_times as (\n\n  select *\n  from __dbt__cte__int_zendesk__ticket_reply_times\n\n)\n\nselect\n\n  ticket.ticket_id,\n  sum(case when is_first_comment then reply_time_calendar_minutes\n    else null end) as first_reply_time_calendar_minutes,\n  sum(reply_time_calendar_minutes) as total_reply_time_calendar_minutes --total combined time the customer waits for internal response\n  \nfrom ticket\nleft join ticket_reply_times\n  using (ticket_id)\n\ngroup by 1\n)"}, {"id": "model.zendesk.int_zendesk__ticket_work_time_calendar", "sql": " __dbt__cte__int_zendesk__ticket_work_time_calendar as (\nwith ticket_historical_status as (\n\n    select *\n    from `bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__ticket_historical_status`\n\n), calendar_minutes as (\n  \n    select \n        ticket_id,\n        status,\n        case when status in ('pending') then status_duration_calendar_minutes\n            else 0 end as agent_wait_time_in_minutes,\n        case when status in ('new', 'open', 'hold') then status_duration_calendar_minutes\n            else 0 end as requester_wait_time_in_minutes,\n        case when status in ('new', 'open') then status_duration_calendar_minutes\n            else 0 end as agent_work_time_in_minutes,\n        case when status in ('hold') then status_duration_calendar_minutes\n            else 0 end as on_hold_time_in_minutes,\n        case when status = 'new' then status_duration_calendar_minutes\n            else 0 end as new_status_duration_minutes,\n        case when status = 'open' then status_duration_calendar_minutes\n            else 0 end as open_status_duration_minutes,\n        case when status = 'deleted' then 1\n            else 0 end as ticket_deleted,\n        first_value(valid_starting_at) over (partition by ticket_id order by valid_starting_at desc, ticket_id rows unbounded preceding) as last_status_assignment_date,\n        case when lag(status) over (partition by ticket_id order by valid_starting_at) = 'deleted' and status != 'deleted'\n            then 1\n            else 0\n                end as ticket_recoveries\n\n    from ticket_historical_status\n\n)\n\nselect \n  ticket_id,\n  last_status_assignment_date,\n  sum(ticket_deleted) as ticket_deleted_count,\n  sum(agent_wait_time_in_minutes) as agent_wait_time_in_calendar_minutes,\n  sum(requester_wait_time_in_minutes) as requester_wait_time_in_calendar_minutes,\n  sum(agent_work_time_in_minutes) as agent_work_time_in_calendar_minutes,\n  sum(on_hold_time_in_minutes) as on_hold_time_in_calendar_minutes,\n  sum(new_status_duration_minutes) as new_status_duration_in_calendar_minutes,\n  sum(open_status_duration_minutes) as open_status_duration_in_calendar_minutes,\n  sum(ticket_recoveries) as total_ticket_recoveries\nfrom calendar_minutes\ngroup by 1, 2\n)"}, {"id": "model.zendesk.int_zendesk__ticket_first_resolution_time_business", "sql": " __dbt__cte__int_zendesk__ticket_first_resolution_time_business as (\n\n\nwith ticket_resolution_times_calendar as (\n\n    select *\n    from __dbt__cte__int_zendesk__ticket_resolution_times_calendar\n\n), ticket_schedules as (\n\n    select *\n    from `bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__ticket_schedules`\n\n), schedule as (\n\n    select *\n    from `bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__schedule_spine`\n\n), ticket_first_resolution_time as (\n\n  select \n    ticket_resolution_times_calendar.ticket_id,\n    ticket_schedules.schedule_created_at,\n    ticket_schedules.schedule_invalidated_at,\n    ticket_schedules.schedule_id,\n\n    -- bringing this in the determine which schedule (Daylight Savings vs Standard time) to use\n    min(ticket_resolution_times_calendar.first_solved_at) as first_solved_at,\n    \n    (\n  \n\n    timestamp_diff(\n        ticket_schedules.schedule_created_at,\n        \n    timestamp_trunc(\n        cast(ticket_schedules.schedule_created_at as timestamp),\n        week\n    )\n\n,\n        second\n    )\n\n\n /60\n          ) as start_time_in_minutes_from_week,\n    greatest(0,\n      (\n        \n  \n\n    timestamp_diff(\n        least(ticket_schedules.schedule_invalidated_at, min(ticket_resolution_times_calendar.first_solved_at)),\n        ticket_schedules.schedule_created_at,\n        second\n    )\n\n\n/60\n        )) as raw_delta_in_minutes\n      \n  from ticket_resolution_times_calendar\n  join ticket_schedules on ticket_resolution_times_calendar.ticket_id = ticket_schedules.ticket_id\n  group by 1, 2, 3, 4\n\n), weeks as (\n\n    \n\n    \n\n    with p as (\n        select 0 as generated_number union all select 1\n    ), unioned as (\n\n    select\n\n    \n    p0.generated_number * power(2, 0)\n     + \n    \n    p1.generated_number * power(2, 1)\n     + \n    \n    p2.generated_number * power(2, 2)\n     + \n    \n    p3.generated_number * power(2, 3)\n     + \n    \n    p4.generated_number * power(2, 4)\n     + \n    \n    p5.generated_number * power(2, 5)\n     + \n    \n    p6.generated_number * power(2, 6)\n     + \n    \n    p7.generated_number * power(2, 7)\n    \n    \n    + 1\n    as generated_number\n\n    from\n\n    \n    p as p0\n     cross join \n    \n    p as p1\n     cross join \n    \n    p as p2\n     cross join \n    \n    p as p3\n     cross join \n    \n    p as p4\n     cross join \n    \n    p as p5\n     cross join \n    \n    p as p6\n     cross join \n    \n    p as p7\n    \n    \n\n    )\n\n    select *\n    from unioned\n    where generated_number <= 208\n    order by generated_number\n\n\n\n), weeks_cross_ticket_first_resolution_time as (\n    -- because time is reported in minutes since the beginning of the week, we have to split up time spent on the ticket into calendar weeks\n    select \n\n      ticket_first_resolution_time.*,\n      generated_number - 1 as week_number\n\n    from ticket_first_resolution_time\n    cross join weeks\n    where floor((start_time_in_minutes_from_week + raw_delta_in_minutes) / (7*24*60)) >= generated_number - 1\n\n\n), weekly_periods as (\n  \n    select \n\n      weeks_cross_ticket_first_resolution_time.*,\n      greatest(0, start_time_in_minutes_from_week - week_number * (7*24*60)) as ticket_week_start_time,\n      least(start_time_in_minutes_from_week + raw_delta_in_minutes - week_number * (7*24*60), (7*24*60)) as ticket_week_end_time\n    \n    from weeks_cross_ticket_first_resolution_time\n\n), intercepted_periods as (\n\n  select ticket_id,\n         week_number,\n         weekly_periods.schedule_id,\n         ticket_week_start_time,\n         ticket_week_end_time,\n         schedule.start_time_utc as schedule_start_time,\n         schedule.end_time_utc as schedule_end_time,\n         least(ticket_week_end_time, schedule.end_time_utc) - greatest(ticket_week_start_time, schedule.start_time_utc) as scheduled_minutes\n  from weekly_periods\n  join schedule on ticket_week_start_time <= schedule.end_time_utc \n    and ticket_week_end_time >= schedule.start_time_utc\n    and weekly_periods.schedule_id = schedule.schedule_id\n    -- this chooses the Daylight Savings Time or Standard Time version of the schedule\n    and weekly_periods.first_solved_at >= cast(schedule.valid_from as \n    timestamp\n)\n    and weekly_periods.first_solved_at < cast(schedule.valid_until as \n    timestamp\n) \n    \n)\n\n  select \n    ticket_id,\n    sum(scheduled_minutes) as first_resolution_business_minutes\n  from intercepted_periods\n  group by 1\n)"}, {"id": "model.zendesk.int_zendesk__ticket_full_resolution_time_business", "sql": " __dbt__cte__int_zendesk__ticket_full_resolution_time_business as (\n\n\nwith ticket_resolution_times_calendar as (\n\n    select *\n    from __dbt__cte__int_zendesk__ticket_resolution_times_calendar\n\n), ticket_schedules as (\n\n    select *\n    from `bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__ticket_schedules`\n\n), schedule as (\n\n    select *\n    from `bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__schedule_spine`\n\n), ticket_full_resolution_time as (\n\n  select \n    ticket_resolution_times_calendar.ticket_id,\n    ticket_schedules.schedule_created_at,\n    ticket_schedules.schedule_invalidated_at,\n    ticket_schedules.schedule_id,\n\n    -- bringing this in the determine which schedule (Daylight Savings vs Standard time) to use\n    min(ticket_resolution_times_calendar.last_solved_at) as last_solved_at,\n    \n    (\n  \n\n    timestamp_diff(\n        ticket_schedules.schedule_created_at,\n        \n    timestamp_trunc(\n        cast(ticket_schedules.schedule_created_at as timestamp),\n        week\n    )\n\n,\n        second\n    )\n\n\n /60\n          ) as start_time_in_minutes_from_week,\n    greatest(0,\n      (\n        \n  \n\n    timestamp_diff(\n        least(ticket_schedules.schedule_invalidated_at, min(ticket_resolution_times_calendar.last_solved_at)),\n        ticket_schedules.schedule_created_at,\n        second\n    )\n\n\n/60\n        )) as raw_delta_in_minutes\n      \n  from ticket_resolution_times_calendar\n  join ticket_schedules on ticket_resolution_times_calendar.ticket_id = ticket_schedules.ticket_id\n  group by 1, 2, 3, 4\n\n), weeks as (\n\n    \n\n    \n\n    with p as (\n        select 0 as generated_number union all select 1\n    ), unioned as (\n\n    select\n\n    \n    p0.generated_number * power(2, 0)\n     + \n    \n    p1.generated_number * power(2, 1)\n     + \n    \n    p2.generated_number * power(2, 2)\n     + \n    \n    p3.generated_number * power(2, 3)\n     + \n    \n    p4.generated_number * power(2, 4)\n     + \n    \n    p5.generated_number * power(2, 5)\n     + \n    \n    p6.generated_number * power(2, 6)\n     + \n    \n    p7.generated_number * power(2, 7)\n    \n    \n    + 1\n    as generated_number\n\n    from\n\n    \n    p as p0\n     cross join \n    \n    p as p1\n     cross join \n    \n    p as p2\n     cross join \n    \n    p as p3\n     cross join \n    \n    p as p4\n     cross join \n    \n    p as p5\n     cross join \n    \n    p as p6\n     cross join \n    \n    p as p7\n    \n    \n\n    )\n\n    select *\n    from unioned\n    where generated_number <= 208\n    order by generated_number\n\n\n\n), weeks_cross_ticket_full_resolution_time as (\n    -- because time is reported in minutes since the beginning of the week, we have to split up time spent on the ticket into calendar weeks\n    select \n\n      ticket_full_resolution_time.*,\n      generated_number - 1 as week_number\n\n    from ticket_full_resolution_time\n    cross join weeks\n    where floor((start_time_in_minutes_from_week + raw_delta_in_minutes) / (7*24*60)) >= generated_number - 1\n\n), weekly_periods as (\n  \n  select \n\n    weeks_cross_ticket_full_resolution_time.*,\n    greatest(0, start_time_in_minutes_from_week - week_number * (7*24*60)) as ticket_week_start_time,\n    least(start_time_in_minutes_from_week + raw_delta_in_minutes - week_number * (7*24*60), (7*24*60)) as ticket_week_end_time\n  \n  from weeks_cross_ticket_full_resolution_time\n\n), intercepted_periods as (\n\n  select \n    ticket_id,\n    week_number,\n    weekly_periods.schedule_id,\n    ticket_week_start_time,\n    ticket_week_end_time,\n    schedule.start_time_utc as schedule_start_time,\n    schedule.end_time_utc as schedule_end_time,\n    least(ticket_week_end_time, schedule.end_time_utc) - greatest(ticket_week_start_time, schedule.start_time_utc) as scheduled_minutes\n  from weekly_periods\n  join schedule on ticket_week_start_time <= schedule.end_time_utc \n    and ticket_week_end_time >= schedule.start_time_utc\n    and weekly_periods.schedule_id = schedule.schedule_id\n    -- this chooses the Daylight Savings Time or Standard Time version of the schedule\n    and weekly_periods.last_solved_at >= cast(schedule.valid_from as \n    timestamp\n)\n    and weekly_periods.last_solved_at < cast(schedule.valid_until as \n    timestamp\n) \n    \n)\n\n  select \n    ticket_id,\n    sum(scheduled_minutes) as full_resolution_business_minutes\n  from intercepted_periods\n  group by 1\n)"}, {"id": "model.zendesk.int_zendesk__ticket_work_time_business", "sql": " __dbt__cte__int_zendesk__ticket_work_time_business as (\n\n\nwith ticket_historical_status as (\n\n    select *\n    from `bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__ticket_historical_status`\n\n), ticket_schedules as (\n\n    select *\n    from `bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__ticket_schedules`\n\n), schedule as (\n\n    select *\n    from `bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__schedule_spine`\n\n), ticket_status_crossed_with_schedule as (\n  \n    select\n      ticket_historical_status.ticket_id,\n      ticket_historical_status.status as ticket_status,\n      ticket_schedules.schedule_id,\n\n      -- take the intersection of the intervals in which the status and the schedule were both active, for calculating the business minutes spent working on the ticket\n      greatest(valid_starting_at, schedule_created_at) as status_schedule_start,\n      least(valid_ending_at, schedule_invalidated_at) as status_schedule_end,\n\n      -- bringing the following in the determine which schedule (Daylight Savings vs Standard time) to use\n      ticket_historical_status.valid_starting_at as status_valid_starting_at,\n      ticket_historical_status.valid_ending_at as status_valid_ending_at\n\n    from ticket_historical_status\n    left join ticket_schedules\n      on ticket_historical_status.ticket_id = ticket_schedules.ticket_id\n      where \n  \n\n    timestamp_diff(\n        least(valid_ending_at, schedule_invalidated_at),\n        greatest(valid_starting_at, schedule_created_at),\n        second\n    )\n\n\n > 0\n\n), ticket_full_solved_time as (\n\n    select \n      ticket_status_crossed_with_schedule.*,\n      (\n  \n\n    timestamp_diff(\n        ticket_status_crossed_with_schedule.status_schedule_start,\n        \n    timestamp_trunc(\n        cast(ticket_status_crossed_with_schedule.status_schedule_start as timestamp),\n        week\n    )\n\n,\n        second\n    )\n\n\n /60\n            ) as start_time_in_minutes_from_week,\n      (\n  \n\n    timestamp_diff(\n        ticket_status_crossed_with_schedule.status_schedule_end,\n        ticket_status_crossed_with_schedule.status_schedule_start,\n        second\n    )\n\n\n /60\n            ) as raw_delta_in_minutes\n    from ticket_status_crossed_with_schedule\n    group by 1,2,3,4,5,6,7\n\n), weeks as (\n\n    \n\n    \n\n    with p as (\n        select 0 as generated_number union all select 1\n    ), unioned as (\n\n    select\n\n    \n    p0.generated_number * power(2, 0)\n     + \n    \n    p1.generated_number * power(2, 1)\n     + \n    \n    p2.generated_number * power(2, 2)\n     + \n    \n    p3.generated_number * power(2, 3)\n     + \n    \n    p4.generated_number * power(2, 4)\n     + \n    \n    p5.generated_number * power(2, 5)\n     + \n    \n    p6.generated_number * power(2, 6)\n     + \n    \n    p7.generated_number * power(2, 7)\n    \n    \n    + 1\n    as generated_number\n\n    from\n\n    \n    p as p0\n     cross join \n    \n    p as p1\n     cross join \n    \n    p as p2\n     cross join \n    \n    p as p3\n     cross join \n    \n    p as p4\n     cross join \n    \n    p as p5\n     cross join \n    \n    p as p6\n     cross join \n    \n    p as p7\n    \n    \n\n    )\n\n    select *\n    from unioned\n    where generated_number <= 208\n    order by generated_number\n\n\n\n), weeks_cross_ticket_full_solved_time as (\n    -- because time is reported in minutes since the beginning of the week, we have to split up time spent on the ticket into calendar weeks\n    select \n      ticket_full_solved_time.*,\n      generated_number - 1 as week_number\n    from ticket_full_solved_time\n    cross join weeks\n    where floor((start_time_in_minutes_from_week + raw_delta_in_minutes) / (7*24*60)) >= generated_number -1\n\n), weekly_periods as (\n\n    select\n\n      weeks_cross_ticket_full_solved_time.*,\n      greatest(0, start_time_in_minutes_from_week - week_number * (7*24*60)) as ticket_week_start_time,\n      least(start_time_in_minutes_from_week + raw_delta_in_minutes - week_number * (7*24*60), (7*24*60)) as ticket_week_end_time\n    \n    from weeks_cross_ticket_full_solved_time\n\n), intercepted_periods as (\n  \n    select \n      weekly_periods.ticket_id,\n      weekly_periods.week_number,\n      weekly_periods.schedule_id,\n      weekly_periods.ticket_status,\n      weekly_periods.ticket_week_start_time,\n      weekly_periods.ticket_week_end_time,\n      schedule.start_time_utc as schedule_start_time,\n      schedule.end_time_utc as schedule_end_time,\n      least(ticket_week_end_time, schedule.end_time_utc) - greatest(weekly_periods.ticket_week_start_time, schedule.start_time_utc) as scheduled_minutes\n    from weekly_periods\n    join schedule on ticket_week_start_time <= schedule.end_time_utc \n      and ticket_week_end_time >= schedule.start_time_utc\n      and weekly_periods.schedule_id = schedule.schedule_id\n      -- this chooses the Daylight Savings Time or Standard Time version of the schedule\n      and weekly_periods.status_valid_ending_at >= cast(schedule.valid_from as \n    timestamp\n)\n      and weekly_periods.status_valid_starting_at < cast(schedule.valid_until as \n    timestamp\n) \n  \n), business_minutes as (\n  \n    select \n      ticket_id,\n      ticket_status,\n      case when ticket_status in ('pending') then scheduled_minutes\n          else 0 end as agent_wait_time_in_minutes,\n      case when ticket_status in ('new', 'open', 'hold') then scheduled_minutes\n          else 0 end as requester_wait_time_in_minutes,\n      case when ticket_status in ('new', 'open') then scheduled_minutes\n          else 0 end as agent_work_time_in_minutes,\n      case when ticket_status in ('hold') then scheduled_minutes\n          else 0 end as on_hold_time_in_minutes\n    from intercepted_periods\n\n)\n  \n    select \n      ticket_id,\n      sum(agent_wait_time_in_minutes) as agent_wait_time_in_business_minutes,\n      sum(requester_wait_time_in_minutes) as requester_wait_time_in_business_minutes,\n      sum(agent_work_time_in_minutes) as agent_work_time_in_business_minutes,\n      sum(on_hold_time_in_minutes) as on_hold_time_in_business_minutes\n    from business_minutes\n    group by 1\n)"}, {"id": "model.zendesk.int_zendesk__ticket_first_reply_time_business", "sql": " __dbt__cte__int_zendesk__ticket_first_reply_time_business as (\n\n\nwith ticket_reply_times as (\n\n    select *\n    from __dbt__cte__int_zendesk__ticket_reply_times\n\n), ticket_schedules as (\n\n    select *\n    from `bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__ticket_schedules`\n\n), schedule as (\n\n    select *\n    from `bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__schedule_spine`\n\n), first_reply_time as (\n\n    select\n      ticket_id,\n      end_user_comment_created_at,\n      agent_responded_at\n\n    from ticket_reply_times\n    where is_first_comment\n\n), ticket_first_reply_time as (\n\n  select \n    first_reply_time.ticket_id,\n    ticket_schedules.schedule_created_at,\n    ticket_schedules.schedule_invalidated_at,\n    ticket_schedules.schedule_id,\n\n    -- bringing this in the determine which schedule (Daylight Savings vs Standard time) to use\n    min(first_reply_time.agent_responded_at) as agent_responded_at,\n\n    (\n  \n\n    timestamp_diff(\n        ticket_schedules.schedule_created_at,\n        \n    timestamp_trunc(\n        cast(ticket_schedules.schedule_created_at as timestamp),\n        week\n    )\n\n,\n        second\n    )\n\n\n /60\n          ) as start_time_in_minutes_from_week,\n    greatest(0,\n      (\n        \n  \n\n    timestamp_diff(\n        least(ticket_schedules.schedule_invalidated_at, min(first_reply_time.agent_responded_at)),\n        ticket_schedules.schedule_created_at,\n        second\n    )\n\n\n/60\n        )) as raw_delta_in_minutes\n  \n  from first_reply_time\n  join ticket_schedules on first_reply_time.ticket_id = ticket_schedules.ticket_id\n  group by 1, 2, 3, 4\n\n), weeks as (\n\n    \n\n    \n\n    with p as (\n        select 0 as generated_number union all select 1\n    ), unioned as (\n\n    select\n\n    \n    p0.generated_number * power(2, 0)\n     + \n    \n    p1.generated_number * power(2, 1)\n     + \n    \n    p2.generated_number * power(2, 2)\n     + \n    \n    p3.generated_number * power(2, 3)\n     + \n    \n    p4.generated_number * power(2, 4)\n     + \n    \n    p5.generated_number * power(2, 5)\n     + \n    \n    p6.generated_number * power(2, 6)\n     + \n    \n    p7.generated_number * power(2, 7)\n    \n    \n    + 1\n    as generated_number\n\n    from\n\n    \n    p as p0\n     cross join \n    \n    p as p1\n     cross join \n    \n    p as p2\n     cross join \n    \n    p as p3\n     cross join \n    \n    p as p4\n     cross join \n    \n    p as p5\n     cross join \n    \n    p as p6\n     cross join \n    \n    p as p7\n    \n    \n\n    )\n\n    select *\n    from unioned\n    where generated_number <= 208\n    order by generated_number\n\n\n\n), weeks_cross_ticket_first_reply as (\n    -- because time is reported in minutes since the beginning of the week, we have to split up time spent on the ticket into calendar weeks\n    select \n\n      ticket_first_reply_time.*,\n      generated_number - 1 as week_number\n\n    from ticket_first_reply_time\n    cross join weeks\n    where floor((start_time_in_minutes_from_week + raw_delta_in_minutes) / (7*24*60)) >= generated_number - 1\n\n), weekly_periods as (\n  \n    select \n      weeks_cross_ticket_first_reply.*, \n      greatest(0, start_time_in_minutes_from_week - week_number * (7*24*60)) as ticket_week_start_time,\n      least(start_time_in_minutes_from_week + raw_delta_in_minutes - week_number * (7*24*60), (7*24*60)) as ticket_week_end_time\n    from weeks_cross_ticket_first_reply\n\n), intercepted_periods as (\n\n  select ticket_id,\n      week_number,\n      weekly_periods.schedule_id,\n      ticket_week_start_time,\n      ticket_week_end_time,\n      schedule.start_time_utc as schedule_start_time,\n      schedule.end_time_utc as schedule_end_time,\n      least(ticket_week_end_time, schedule.end_time_utc) - greatest(ticket_week_start_time, schedule.start_time_utc) as scheduled_minutes\n  from weekly_periods\n  join schedule on ticket_week_start_time <= schedule.end_time_utc \n    and ticket_week_end_time >= schedule.start_time_utc\n    and weekly_periods.schedule_id = schedule.schedule_id\n    -- this chooses the Daylight Savings Time or Standard Time version of the schedule\n    and weekly_periods.agent_responded_at >= cast(schedule.valid_from as \n    timestamp\n)\n    and weekly_periods.agent_responded_at < cast(schedule.valid_until as \n    timestamp\n) \n\n)\n\n  select ticket_id,\n         sum(scheduled_minutes) as first_reply_time_business_minutes\n  from intercepted_periods\n  group by 1\n)"}], "relation_name": "`bq-project`.`dbt_joe_zendesk_docs`.`zendesk__ticket_metrics`"}, "model.zendesk.zendesk__ticket_summary": {"raw_sql": "with ticket_metrics as (\n    select *\n    from {{ ref('zendesk__ticket_metrics') }}\n\n), user_table as (\n    select *\n    from {{ ref('stg_zendesk__user') }}\n\n), user_sum as (\n    select\n        cast(1 as {{ dbt_utils.type_int() }}) as summary_helper,\n        sum(case when is_active = true\n            then 1\n            else 0\n                end) as user_count,\n        sum(case when lower(role) != 'end-user' and is_active = true\n            then 1\n            else 0\n                end) as active_agent_count,\n        sum(case when is_active = false\n            then 1\n            else 0\n                end) as deleted_user_count,\n        sum(case when lower(role) = 'end-user' and is_active = true\n            then 1\n            else 0\n                end) as end_user_count,\n        sum(case when is_suspended = true\n            then 1\n            else 0\n                end) as suspended_user_count\n    from user_table\n\n    group by 1\n\n), ticket_metric_sum as (\n    select \n        cast(1 as {{ dbt_utils.type_int() }}) as summary_helper,\n        sum(case when lower(status) = 'new'\n            then 1\n            else 0\n                end) as new_ticket_count,\n        sum(case when lower(status) = 'hold'\n            then 1\n            else 0\n                end) as on_hold_ticket_count,\n        sum(case when lower(status) = 'open'\n            then 1\n            else 0\n                end) as open_ticket_count,\n        sum(case when lower(status) = 'pending'\n            then 1\n            else 0\n                end) as pending_ticket_count,\n        sum(case when lower(type) = 'problem'\n            then 1\n            else 0\n                end) as problem_ticket_count,\n        sum(case when first_assignee_id != last_assignee_id\n            then 1\n            else 0\n                end) as reassigned_ticket_count,\n        sum(case when count_reopens > 0\n            then 1\n            else 0\n                end) as reopened_ticket_count,\n\n        sum(case when lower(ticket_satisfaction_score) in ('offered', 'good', 'bad')\n            then 1\n            else 0\n                end) as surveyed_satisfaction_ticket_count,\n\n        sum(case when assignee_id is null and lower(status) not in ('solved', 'closed')\n            then 1\n            else 0\n                end) as unassigned_unsolved_ticket_count,\n        sum(case when total_agent_replies < 0\n            then 1\n            else 0\n                end) as unreplied_ticket_count,\n        sum(case when total_agent_replies < 0 and lower(status) not in ('solved', 'closed')\n            then 1\n            else 0\n                end) as unreplied_unsolved_ticket_count,\n        sum(case when lower(status) not in ('solved', 'closed')\n            then 1\n            else 0\n                end) as unsolved_ticket_count,\n        sum(case when lower(status) in ('solved', 'closed')\n            then 1\n            else 0\n                end) as solved_ticket_count,\n        sum(case when lower(status) in ('deleted')\n            then 1\n            else 0\n                end) as deleted_ticket_count,\n        sum(case when total_ticket_recoveries > 0\n            then 1\n            else 0\n                end) as recovered_ticket_count,\n        sum(case when assignee_stations_count > 0\n            then 1\n            else 0\n                end) as assigned_ticket_count,\n        count(count_internal_comments) as total_internal_comments,\n        count(count_public_comments) as total_public_comments,\n        count(total_comments)\n    from ticket_metrics\n    \n    group by 1\n\n\n), final as (\n    select\n        user_sum.user_count,\n        user_sum.active_agent_count,\n        user_sum.deleted_user_count,\n        user_sum.end_user_count,\n        user_sum.suspended_user_count,\n        ticket_metric_sum.new_ticket_count,\n        ticket_metric_sum.on_hold_ticket_count,\n        ticket_metric_sum.open_ticket_count,\n        ticket_metric_sum.pending_ticket_count,\n        ticket_metric_sum.solved_ticket_count,\n        ticket_metric_sum.problem_ticket_count,\n        ticket_metric_sum.assigned_ticket_count,\n        ticket_metric_sum.reassigned_ticket_count,\n        ticket_metric_sum.reopened_ticket_count,\n        ticket_metric_sum.surveyed_satisfaction_ticket_count,\n        ticket_metric_sum.unassigned_unsolved_ticket_count,\n        ticket_metric_sum.unreplied_ticket_count,\n        ticket_metric_sum.unreplied_unsolved_ticket_count,\n        ticket_metric_sum.unsolved_ticket_count,\n        ticket_metric_sum.recovered_ticket_count,\n        ticket_metric_sum.deleted_ticket_count\n    from user_sum\n\n    left join ticket_metric_sum\n        using(summary_helper)\n)\n\nselect *\nfrom final", "compiled": true, "resource_type": "model", "depends_on": {"macros": ["macro.dbt_utils.type_int"], "nodes": ["model.zendesk.zendesk__ticket_metrics", "model.zendesk_source.stg_zendesk__user"]}, "config": {"enabled": true, "alias": null, "schema": "zendesk_docs", "database": null, "tags": [], "meta": {}, "materialized": "table", "persist_docs": {}, "quoting": {}, "column_types": {}, "full_refresh": null, "on_schema_change": "ignore", "post-hook": [], "pre-hook": []}, "database": "bq-project", "schema": "dbt_joe_zendesk_docs", "fqn": ["zendesk", "zendesk__ticket_summary"], "unique_id": "model.zendesk.zendesk__ticket_summary", "package_name": "zendesk", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/zendesk", "path": "zendesk__ticket_summary.sql", "original_file_path": "models/zendesk__ticket_summary.sql", "name": "zendesk__ticket_summary", "alias": "zendesk__ticket_summary", "checksum": {"name": "sha256", "checksum": "9430b74382989b212a68d21d168d54b0faba32a56434d583b7c58d58e64e9d9f"}, "tags": [], "refs": [["zendesk__ticket_metrics"], ["stg_zendesk__user"]], "sources": [], "description": "A single record table containing Zendesk ticket and user summary metrics. These metrics are updated for the current day the model is run.", "columns": {"user_count": {"name": "user_count", "description": "Total count of users created", "meta": {}, "data_type": null, "quote": null, "tags": []}, "active_agent_count": {"name": "active_agent_count", "description": "Total count of agents", "meta": {}, "data_type": null, "quote": null, "tags": []}, "deleted_user_count": {"name": "deleted_user_count", "description": "Total deleted user count", "meta": {}, "data_type": null, "quote": null, "tags": []}, "end_user_count": {"name": "end_user_count", "description": "Total end user count", "meta": {}, "data_type": null, "quote": null, "tags": []}, "suspended_user_count": {"name": "suspended_user_count", "description": "Total count of users in a suspended state", "meta": {}, "data_type": null, "quote": null, "tags": []}, "new_ticket_count": {"name": "new_ticket_count", "description": "Total count of tickets in the \"new\" status", "meta": {}, "data_type": null, "quote": null, "tags": []}, "on_hold_ticket_count": {"name": "on_hold_ticket_count", "description": "Total count of tickets in the \"hold\" status", "meta": {}, "data_type": null, "quote": null, "tags": []}, "open_ticket_count": {"name": "open_ticket_count", "description": "Total count of tickets in the \"open\" status", "meta": {}, "data_type": null, "quote": null, "tags": []}, "pending_ticket_count": {"name": "pending_ticket_count", "description": "Total count of tickets in the \"pending\" status", "meta": {}, "data_type": null, "quote": null, "tags": []}, "solved_ticket_count": {"name": "solved_ticket_count", "description": "Total count of solved tickets", "meta": {}, "data_type": null, "quote": null, "tags": []}, "problem_ticket_count": {"name": "problem_ticket_count", "description": "Total count of tickets labeled as problems", "meta": {}, "data_type": null, "quote": null, "tags": []}, "reassigned_ticket_count": {"name": "reassigned_ticket_count", "description": "Total count of tickets that have been reassigned", "meta": {}, "data_type": null, "quote": null, "tags": []}, "reopened_ticket_count": {"name": "reopened_ticket_count", "description": "Total count of tickets that have been reopened", "meta": {}, "data_type": null, "quote": null, "tags": []}, "surveyed_satisfaction_ticket_count": {"name": "surveyed_satisfaction_ticket_count", "description": "Total count of tickets that have been surveyed for a satisfaction response", "meta": {}, "data_type": null, "quote": null, "tags": []}, "unassigned_unsolved_ticket_count": {"name": "unassigned_unsolved_ticket_count", "description": "Total count of tickets that are unassigned and unsolved", "meta": {}, "data_type": null, "quote": null, "tags": []}, "unreplied_ticket_count": {"name": "unreplied_ticket_count", "description": "Total count of tickets that have not had a reply", "meta": {}, "data_type": null, "quote": null, "tags": []}, "unreplied_unsolved_ticket_count": {"name": "unreplied_unsolved_ticket_count", "description": "Total count of tickets that have not had a reply and are unsolved", "meta": {}, "data_type": null, "quote": null, "tags": []}, "unsolved_ticket_count": {"name": "unsolved_ticket_count", "description": "Total count of unsolved tickets", "meta": {}, "data_type": null, "quote": null, "tags": []}, "assigned_ticket_count": {"name": "assigned_ticket_count", "description": "Total count of assigned tickets", "meta": {}, "data_type": null, "quote": null, "tags": []}, "deleted_ticket_count": {"name": "deleted_ticket_count", "description": "Total count of deleted tickets", "meta": {}, "data_type": null, "quote": null, "tags": []}, "recovered_ticket_count": {"name": "recovered_ticket_count", "description": "Total count of tickets that were deleted then reopened", "meta": {}, "data_type": null, "quote": null, "tags": []}}, "meta": {}, "docs": {"show": true}, "patch_path": "zendesk://models/zendesk.yml", "compiled_path": "target/compiled/zendesk/models/zendesk__ticket_summary.sql", "build_path": null, "deferred": false, "unrendered_config": {"schema": "zendesk_docs", "materialized": "table"}, "created_at": 1647014737.909802, "compiled_sql": "with ticket_metrics as (\n    select *\n    from `bq-project`.`dbt_joe_zendesk_docs`.`zendesk__ticket_metrics`\n\n), user_table as (\n    select *\n    from `bq-project`.`dbt_joe_zendesk_docs`.`stg_zendesk__user`\n\n), user_sum as (\n    select\n        cast(1 as \n    int64\n) as summary_helper,\n        sum(case when is_active = true\n            then 1\n            else 0\n                end) as user_count,\n        sum(case when lower(role) != 'end-user' and is_active = true\n            then 1\n            else 0\n                end) as active_agent_count,\n        sum(case when is_active = false\n            then 1\n            else 0\n                end) as deleted_user_count,\n        sum(case when lower(role) = 'end-user' and is_active = true\n            then 1\n            else 0\n                end) as end_user_count,\n        sum(case when is_suspended = true\n            then 1\n            else 0\n                end) as suspended_user_count\n    from user_table\n\n    group by 1\n\n), ticket_metric_sum as (\n    select \n        cast(1 as \n    int64\n) as summary_helper,\n        sum(case when lower(status) = 'new'\n            then 1\n            else 0\n                end) as new_ticket_count,\n        sum(case when lower(status) = 'hold'\n            then 1\n            else 0\n                end) as on_hold_ticket_count,\n        sum(case when lower(status) = 'open'\n            then 1\n            else 0\n                end) as open_ticket_count,\n        sum(case when lower(status) = 'pending'\n            then 1\n            else 0\n                end) as pending_ticket_count,\n        sum(case when lower(type) = 'problem'\n            then 1\n            else 0\n                end) as problem_ticket_count,\n        sum(case when first_assignee_id != last_assignee_id\n            then 1\n            else 0\n                end) as reassigned_ticket_count,\n        sum(case when count_reopens > 0\n            then 1\n            else 0\n                end) as reopened_ticket_count,\n\n        sum(case when lower(ticket_satisfaction_score) in ('offered', 'good', 'bad')\n            then 1\n            else 0\n                end) as surveyed_satisfaction_ticket_count,\n\n        sum(case when assignee_id is null and lower(status) not in ('solved', 'closed')\n            then 1\n            else 0\n                end) as unassigned_unsolved_ticket_count,\n        sum(case when total_agent_replies < 0\n            then 1\n            else 0\n                end) as unreplied_ticket_count,\n        sum(case when total_agent_replies < 0 and lower(status) not in ('solved', 'closed')\n            then 1\n            else 0\n                end) as unreplied_unsolved_ticket_count,\n        sum(case when lower(status) not in ('solved', 'closed')\n            then 1\n            else 0\n                end) as unsolved_ticket_count,\n        sum(case when lower(status) in ('solved', 'closed')\n            then 1\n            else 0\n                end) as solved_ticket_count,\n        sum(case when lower(status) in ('deleted')\n            then 1\n            else 0\n                end) as deleted_ticket_count,\n        sum(case when total_ticket_recoveries > 0\n            then 1\n            else 0\n                end) as recovered_ticket_count,\n        sum(case when assignee_stations_count > 0\n            then 1\n            else 0\n                end) as assigned_ticket_count,\n        count(count_internal_comments) as total_internal_comments,\n        count(count_public_comments) as total_public_comments,\n        count(total_comments)\n    from ticket_metrics\n    \n    group by 1\n\n\n), final as (\n    select\n        user_sum.user_count,\n        user_sum.active_agent_count,\n        user_sum.deleted_user_count,\n        user_sum.end_user_count,\n        user_sum.suspended_user_count,\n        ticket_metric_sum.new_ticket_count,\n        ticket_metric_sum.on_hold_ticket_count,\n        ticket_metric_sum.open_ticket_count,\n        ticket_metric_sum.pending_ticket_count,\n        ticket_metric_sum.solved_ticket_count,\n        ticket_metric_sum.problem_ticket_count,\n        ticket_metric_sum.assigned_ticket_count,\n        ticket_metric_sum.reassigned_ticket_count,\n        ticket_metric_sum.reopened_ticket_count,\n        ticket_metric_sum.surveyed_satisfaction_ticket_count,\n        ticket_metric_sum.unassigned_unsolved_ticket_count,\n        ticket_metric_sum.unreplied_ticket_count,\n        ticket_metric_sum.unreplied_unsolved_ticket_count,\n        ticket_metric_sum.unsolved_ticket_count,\n        ticket_metric_sum.recovered_ticket_count,\n        ticket_metric_sum.deleted_ticket_count\n    from user_sum\n\n    left join ticket_metric_sum\n        using(summary_helper)\n)\n\nselect *\nfrom final", "extra_ctes_injected": true, "extra_ctes": [], "relation_name": "`bq-project`.`dbt_joe_zendesk_docs`.`zendesk__ticket_summary`"}, "model.zendesk.zendesk__ticket_field_history": {"raw_sql": "{{ \n    config(\n        materialized='incremental',\n        partition_by = {'field': 'date_day', 'data_type': 'date'},\n        unique_key='ticket_day_id'\n        ) \n}}\n\n{%- set change_data_columns = adapter.get_columns_in_relation(ref('int_zendesk__field_history_scd')) -%}\n\nwith change_data as (\n\n    select *\n    from {{ ref('int_zendesk__field_history_scd') }}\n  \n    {% if is_incremental() %}\n    where valid_from >= (select max(date_day) from {{ this }})\n\n-- If no issue fields have been updated since the last incremental run, the pivoted_daily_history CTE will return no record/rows.\n-- When this is the case, we need to grab the most recent day's records from the previously built table so that we can persist \n-- those values into the future.\n\n), most_recent_data as ( \n\n    select \n        *\n    from {{ this }}\n    where date_day = (select max(date_day) from {{ this }} )\n\n{% endif %}\n\n), calendar as (\n\n    select *\n    from {{ ref('int_zendesk__field_calendar_spine') }}\n    where date_day <= current_date\n    {% if is_incremental() %}\n    and date_day >= (select max(date_day) from {{ this }})\n    {% endif %}\n\n), joined as (\n\n    select \n        calendar.date_day,\n        calendar.ticket_id\n        {% if is_incremental() %}    \n            {% for col in change_data_columns if col.name|lower not in ['ticket_id','valid_from','valid_to','ticket_day_id'] %} \n            , coalesce(change_data.{{ col.name }}, most_recent_data.{{ col.name }}) as {{ col.name }}\n            {% endfor %}\n        \n        {% else %}\n            {% for col in change_data_columns if col.name|lower not in ['ticket_id','valid_from','valid_to','ticket_day_id'] %} \n            , {{ col.name }}\n            {% endfor %}\n        {% endif %}\n\n    from calendar\n    left join change_data\n        on calendar.ticket_id = change_data.ticket_id\n        and calendar.date_day = change_data.valid_from\n    \n    {% if is_incremental() %}\n    left join most_recent_data\n        on calendar.ticket_id = most_recent_data.ticket_id\n        and calendar.date_day = most_recent_data.date_day\n    {% endif %}\n\n), set_values as (\n\n    select\n        date_day,\n        ticket_id\n\n        {% for col in change_data_columns if col.name|lower not in ['ticket_id','valid_from','valid_to','ticket_day_id'] %}\n        , {{ col.name }}\n        -- create a batch/partition once a new value is provided\n        , sum( case when {{ col.name }} is null then 0 else 1 end) over ( partition by ticket_id\n            order by date_day rows unbounded preceding) as {{ col.name }}_field_partition\n\n        {% endfor %}\n\n    from joined\n),\n\nfill_values as (\n\n    select  \n        date_day,\n        ticket_id\n\n        {% for col in change_data_columns if col.name|lower not in ['ticket_id','valid_from','valid_to','ticket_day_id'] %}\n        -- grab the value that started this batch/partition\n        , first_value( {{ col.name }} ) over (\n            partition by ticket_id, {{ col.name }}_field_partition \n            order by date_day asc rows between unbounded preceding and current row) as {{ col.name }}\n        {% endfor %}\n\n    from set_values\n\n), fix_null_values as (\n\n    select  \n        date_day,\n        ticket_id\n        {% for col in change_data_columns if col.name|lower not in  ['ticket_id','valid_from','valid_to','ticket_day_id'] %} \n\n        -- we de-nulled the true null values earlier in order to differentiate them from nulls that just needed to be backfilled\n        , case when  cast( {{ col.name }} as {{ dbt_utils.type_string() }} ) = 'is_null' then null else {{ col.name }} end as {{ col.name }}\n        {% endfor %}\n\n    from fill_values\n\n), surrogate_key as (\n\n    select\n        {{ dbt_utils.surrogate_key(['date_day','ticket_id']) }} as ticket_day_id,\n        *\n\n    from fix_null_values\n)\n\nselect *\nfrom surrogate_key", "compiled": true, "resource_type": "model", "depends_on": {"macros": ["macro.dbt.is_incremental", "macro.dbt_utils.surrogate_key", "macro.dbt_utils.type_string"], "nodes": ["model.zendesk.int_zendesk__field_history_scd", "model.zendesk.int_zendesk__field_history_scd", "model.zendesk.int_zendesk__field_calendar_spine"]}, "config": {"enabled": true, "alias": null, "schema": "zendesk_docs", "database": null, "tags": [], "meta": {}, "materialized": "incremental", "persist_docs": {}, "quoting": {}, "column_types": {}, "full_refresh": null, "on_schema_change": "ignore", "partition_by": {"field": "date_day", "data_type": "date"}, "unique_key": "ticket_day_id", "post-hook": [], "pre-hook": []}, "database": "bq-project", "schema": "dbt_joe_zendesk_docs", "fqn": ["zendesk", "zendesk__ticket_field_history"], "unique_id": "model.zendesk.zendesk__ticket_field_history", "package_name": "zendesk", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/zendesk", "path": "zendesk__ticket_field_history.sql", "original_file_path": "models/zendesk__ticket_field_history.sql", "name": "zendesk__ticket_field_history", "alias": "zendesk__ticket_field_history", "checksum": {"name": "sha256", "checksum": "be59067e9a87c1231424f889849db3f69c1840553678121811f143614b84a3f0"}, "tags": [], "refs": [["int_zendesk__field_history_scd"], ["int_zendesk__field_history_scd"], ["int_zendesk__field_calendar_spine"]], "sources": [], "description": "A daily historical view of the ticket field values defined in the `ticket_field_history_columns` variable  and the corresponding updater fields defined in the `ticket_field_history_updater_columns` variable.\n", "columns": {"date_day": {"name": "date_day", "description": "The date of the day associated with the field values.", "meta": {}, "data_type": null, "quote": null, "tags": []}, "ticket_id": {"name": "ticket_id", "description": "A ticket's unique identifier, it is automatically assigned when the ticket is created", "meta": {}, "data_type": null, "quote": null, "tags": []}, "ticket_day_id": {"name": "ticket_day_id", "description": "The unique key of the table, a surrogate key of date_day and ticket_id.", "meta": {}, "data_type": null, "quote": null, "tags": []}, "assignee_id": {"name": "assignee_id", "description": "The assignee id assigned to the ticket", "meta": {}, "data_type": null, "quote": null, "tags": []}, "status": {"name": "status", "description": "The status of the ticket", "meta": {}, "data_type": null, "quote": null, "tags": []}, "priority": {"name": "priority", "description": "The tickets priority ranking", "meta": {}, "data_type": null, "quote": null, "tags": []}}, "meta": {}, "docs": {"show": true}, "patch_path": "zendesk://models/zendesk.yml", "compiled_path": "target/compiled/zendesk/models/zendesk__ticket_field_history.sql", "build_path": null, "deferred": false, "unrendered_config": {"schema": "zendesk_docs", "materialized": "incremental", "partition_by": {"field": "date_day", "data_type": "date"}, "unique_key": "ticket_day_id"}, "created_at": 1647014737.84929, "compiled_sql": "with change_data as (\n\n    select *\n    from `bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__field_history_scd`\n  \n    \n    where valid_from >= (select max(date_day) from `bq-project`.`dbt_joe_zendesk_docs`.`zendesk__ticket_field_history`)\n\n-- If no issue fields have been updated since the last incremental run, the pivoted_daily_history CTE will return no record/rows.\n-- When this is the case, we need to grab the most recent day's records from the previously built table so that we can persist \n-- those values into the future.\n\n), most_recent_data as ( \n\n    select \n        *\n    from `bq-project`.`dbt_joe_zendesk_docs`.`zendesk__ticket_field_history`\n    where date_day = (select max(date_day) from `bq-project`.`dbt_joe_zendesk_docs`.`zendesk__ticket_field_history` )\n\n\n\n), calendar as (\n\n    select *\n    from `bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__field_calendar_spine`\n    where date_day <= current_date\n    \n    and date_day >= (select max(date_day) from `bq-project`.`dbt_joe_zendesk_docs`.`zendesk__ticket_field_history`)\n    \n\n), joined as (\n\n    select \n        calendar.date_day,\n        calendar.ticket_id\n            \n             \n            , coalesce(change_data.assignee_id, most_recent_data.assignee_id) as assignee_id\n             \n            , coalesce(change_data.status, most_recent_data.status) as status\n             \n            , coalesce(change_data.priority, most_recent_data.priority) as priority\n            \n        \n        \n\n    from calendar\n    left join change_data\n        on calendar.ticket_id = change_data.ticket_id\n        and calendar.date_day = change_data.valid_from\n    \n    \n    left join most_recent_data\n        on calendar.ticket_id = most_recent_data.ticket_id\n        and calendar.date_day = most_recent_data.date_day\n    \n\n), set_values as (\n\n    select\n        date_day,\n        ticket_id\n\n        \n        , assignee_id\n        -- create a batch/partition once a new value is provided\n        , sum( case when assignee_id is null then 0 else 1 end) over ( partition by ticket_id\n            order by date_day rows unbounded preceding) as assignee_id_field_partition\n\n        \n        , status\n        -- create a batch/partition once a new value is provided\n        , sum( case when status is null then 0 else 1 end) over ( partition by ticket_id\n            order by date_day rows unbounded preceding) as status_field_partition\n\n        \n        , priority\n        -- create a batch/partition once a new value is provided\n        , sum( case when priority is null then 0 else 1 end) over ( partition by ticket_id\n            order by date_day rows unbounded preceding) as priority_field_partition\n\n        \n\n    from joined\n),\n\nfill_values as (\n\n    select  \n        date_day,\n        ticket_id\n\n        \n        -- grab the value that started this batch/partition\n        , first_value( assignee_id ) over (\n            partition by ticket_id, assignee_id_field_partition \n            order by date_day asc rows between unbounded preceding and current row) as assignee_id\n        \n        -- grab the value that started this batch/partition\n        , first_value( status ) over (\n            partition by ticket_id, status_field_partition \n            order by date_day asc rows between unbounded preceding and current row) as status\n        \n        -- grab the value that started this batch/partition\n        , first_value( priority ) over (\n            partition by ticket_id, priority_field_partition \n            order by date_day asc rows between unbounded preceding and current row) as priority\n        \n\n    from set_values\n\n), fix_null_values as (\n\n    select  \n        date_day,\n        ticket_id\n         \n\n        -- we de-nulled the true null values earlier in order to differentiate them from nulls that just needed to be backfilled\n        , case when  cast( assignee_id as \n    string\n ) = 'is_null' then null else assignee_id end as assignee_id\n         \n\n        -- we de-nulled the true null values earlier in order to differentiate them from nulls that just needed to be backfilled\n        , case when  cast( status as \n    string\n ) = 'is_null' then null else status end as status\n         \n\n        -- we de-nulled the true null values earlier in order to differentiate them from nulls that just needed to be backfilled\n        , case when  cast( priority as \n    string\n ) = 'is_null' then null else priority end as priority\n        \n\n    from fill_values\n\n), surrogate_key as (\n\n    select\n        to_hex(md5(cast(coalesce(cast(date_day as \n    string\n), '') || '-' || coalesce(cast(ticket_id as \n    string\n), '') as \n    string\n))) as ticket_day_id,\n        *\n\n    from fix_null_values\n)\n\nselect *\nfrom surrogate_key", "extra_ctes_injected": true, "extra_ctes": [], "relation_name": "`bq-project`.`dbt_joe_zendesk_docs`.`zendesk__ticket_field_history`"}, "model.zendesk.zendesk__sla_policies": {"raw_sql": "--final step where we union together all of the reply time, agent work time, and requester wait time sla's\n\nwith reply_time_sla as (\n\n  select * \n  from {{ ref('int_zendesk__reply_time_combined') }}\n\n), agent_work_calendar_sla as (\n\n  select *\n  from {{ ref('int_zendesk__agent_work_time_calendar_hours') }}\n\n), requester_wait_calendar_sla as (\n\n  select *\n  from {{ ref('int_zendesk__requester_wait_time_calendar_hours') }}\n\n{% if var('using_schedules', True) %}\n\n), agent_work_business_sla as (\n\n  select *\n  from {{ ref('int_zendesk__agent_work_time_business_hours') }}\n\n), requester_wait_business_sla as (\n  select *\n  from {{ ref('int_zendesk__requester_wait_time_business_hours') }}\n\n{% endif %}\n\n), all_slas_unioned as (\n  select\n    ticket_id,\n    sla_policy_name,\n    metric,\n    sla_applied_at,\n    target,\n    in_business_hours,\n    sla_breach_at,\n    sla_elapsed_time,\n    is_sla_breached\n  from reply_time_sla\n\nunion all\n\n  select\n    ticket_id,\n    sla_policy_name,\n    'agent_work_time' as metric,\n    sla_applied_at,\n    target,\n    false as in_business_hours,\n    max(sla_breach_at) as sla_breach_at,\n    sum(running_total_calendar_minutes) as sla_elapsed_time,\n    {{ fivetran_utils.max_bool(\"is_breached_during_schedule\") }}\n  from agent_work_calendar_sla\n\n  group by 1, 2, 3, 4, 5, 6\n\nunion all\n\n  select\n    ticket_id,\n    sla_policy_name,\n    'requester_wait_time' as metric,\n    sla_applied_at,\n    target,\n    false as in_business_hours,\n    max(sla_breach_at) as sla_breach_at,\n    sum(running_total_calendar_minutes) as sla_elapsed_time,\n    {{ fivetran_utils.max_bool(\"is_breached_during_schedule\") }}\n  from requester_wait_calendar_sla\n\n  group by 1, 2, 3, 4, 5, 6\n\n\n{% if var('using_schedules', True) %}\n\nunion all \n\n  select \n    ticket_id,\n    sla_policy_name,\n    'agent_work_time' as metric,\n    sla_applied_at,\n    target,\n    true as in_business_hours,\n    max(sla_breach_at) as sla_breach_at,\n    sum(running_total_scheduled_minutes) as sla_elapsed_time,\n    {{ fivetran_utils.max_bool(\"is_breached_during_schedule\") }}\n  from agent_work_business_sla\n  \n  group by 1, 2, 3, 4, 5, 6\n\nunion all \n\n  select \n    ticket_id,\n    sla_policy_name,\n    'requester_wait_time' as metric,\n    sla_applied_at,\n    target,\n    true as in_business_hours,\n    max(sla_breach_at) as sla_breach_at,\n    sum(running_total_scheduled_minutes) as sla_elapsed_time,\n    {{ fivetran_utils.max_bool(\"is_breached_during_schedule\") }}\n    \n  from requester_wait_business_sla\n  \n  group by 1, 2, 3, 4, 5, 6\n\n{% endif %}\n\n)\n\nselect \n  {{ dbt_utils.surrogate_key(['ticket_id', 'metric', 'sla_applied_at']) }} as sla_event_id,\n  ticket_id,\n  sla_policy_name,\n  metric,\n  sla_applied_at,\n  target,\n  in_business_hours,\n  sla_breach_at,\n  case when sla_elapsed_time is null\n    then {{ dbt_utils.datediff(\"sla_applied_at\", dbt_utils.current_timestamp(), 'minute') }}  --This will create an entry for active sla's\n    else sla_elapsed_time\n      end as sla_elapsed_time,\n  sla_breach_at > current_timestamp as is_active_sla,\n  case when (sla_breach_at > {{ dbt_utils.current_timestamp() }})\n    then null\n    else is_sla_breached\n      end as is_sla_breach\nfrom all_slas_unioned", "compiled": true, "resource_type": "model", "depends_on": {"macros": ["macro.fivetran_utils.max_bool", "macro.dbt_utils.surrogate_key", "macro.dbt_utils.current_timestamp", "macro.dbt_utils.datediff"], "nodes": ["model.zendesk.int_zendesk__reply_time_combined", "model.zendesk.int_zendesk__agent_work_time_calendar_hours", "model.zendesk.int_zendesk__requester_wait_time_calendar_hours", "model.zendesk.int_zendesk__agent_work_time_business_hours", "model.zendesk.int_zendesk__requester_wait_time_business_hours"]}, "config": {"enabled": true, "alias": null, "schema": "zendesk_docs", "database": null, "tags": [], "meta": {}, "materialized": "table", "persist_docs": {}, "quoting": {}, "column_types": {}, "full_refresh": null, "on_schema_change": "ignore", "post-hook": [], "pre-hook": []}, "database": "bq-project", "schema": "dbt_joe_zendesk_docs", "fqn": ["zendesk", "zendesk__sla_policies"], "unique_id": "model.zendesk.zendesk__sla_policies", "package_name": "zendesk", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/zendesk", "path": "zendesk__sla_policies.sql", "original_file_path": "models/zendesk__sla_policies.sql", "name": "zendesk__sla_policies", "alias": "zendesk__sla_policies", "checksum": {"name": "sha256", "checksum": "cea71b796170de5f20d9a0da02fa2384c5b1e8b91e8c8526d196f8f7e7d076a4"}, "tags": [], "refs": [["int_zendesk__reply_time_combined"], ["int_zendesk__agent_work_time_calendar_hours"], ["int_zendesk__requester_wait_time_calendar_hours"], ["int_zendesk__agent_work_time_business_hours"], ["int_zendesk__requester_wait_time_business_hours"]], "sources": [], "description": "Each record represents an SLA policy event and additional sla breach and achievement metrics. Calendar and business hour SLA breaches are supported.", "columns": {"sla_event_id": {"name": "sla_event_id", "description": "A surrogate key generated from the combination of ticket_id, metric, and sla_applied_at fields", "meta": {}, "data_type": null, "quote": null, "tags": []}, "ticket_id": {"name": "ticket_id", "description": "A ticket's unique identifier, it is automatically assigned when the ticket is created", "meta": {}, "data_type": null, "quote": null, "tags": []}, "sla_policy_name": {"name": "sla_policy_name", "description": "The name of the SLA policy associated with the SLA metric", "meta": {}, "data_type": null, "quote": null, "tags": []}, "metric": {"name": "metric", "description": "The SLA metric, either agent_work_time, requester_wait_time, first_reply_time or next_reply_time", "meta": {}, "data_type": null, "quote": null, "tags": []}, "sla_applied_at": {"name": "sla_applied_at", "description": "When the SLA target was triggered. This is the starting time", "meta": {}, "data_type": null, "quote": null, "tags": []}, "target": {"name": "target", "description": "The SLA target, in minutes", "meta": {}, "data_type": null, "quote": null, "tags": []}, "in_business_hours": {"name": "in_business_hours", "description": "Boolean field indicating if the SLA target is in business hours (true) or calendar hours (false)", "meta": {}, "data_type": null, "quote": null, "tags": []}, "sla_breach_at": {"name": "sla_breach_at", "description": "The time or expected time of the SLA breach event", "meta": {}, "data_type": null, "quote": null, "tags": []}, "sla_elapsed_time": {"name": "sla_elapsed_time", "description": "The total elapsed time to achieve the SLA metric whether breached or achieved", "meta": {}, "data_type": null, "quote": null, "tags": []}, "is_active_sla": {"name": "is_active_sla", "description": "Boolean field indicating that the SLA event is currently active and not breached (true) or past (false)", "meta": {}, "data_type": null, "quote": null, "tags": []}, "is_sla_breach": {"name": "is_sla_breach", "description": "Boolean field indicating if the SLA has been breached (true) or was achieved (false)", "meta": {}, "data_type": null, "quote": null, "tags": []}}, "meta": {}, "docs": {"show": true}, "patch_path": "zendesk://models/zendesk.yml", "compiled_path": "target/compiled/zendesk/models/zendesk__sla_policies.sql", "build_path": null, "deferred": false, "unrendered_config": {"schema": "zendesk_docs", "materialized": "table"}, "created_at": 1647014737.846119, "compiled_sql": "--final step where we union together all of the reply time, agent work time, and requester wait time sla's\n\nwith reply_time_sla as (\n\n  select * \n  from `bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__reply_time_combined`\n\n), agent_work_calendar_sla as (\n\n  select *\n  from `bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__agent_work_time_calendar_hours`\n\n), requester_wait_calendar_sla as (\n\n  select *\n  from `bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__requester_wait_time_calendar_hours`\n\n\n\n), agent_work_business_sla as (\n\n  select *\n  from `bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__agent_work_time_business_hours`\n\n), requester_wait_business_sla as (\n  select *\n  from `bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__requester_wait_time_business_hours`\n\n\n\n), all_slas_unioned as (\n  select\n    ticket_id,\n    sla_policy_name,\n    metric,\n    sla_applied_at,\n    target,\n    in_business_hours,\n    sla_breach_at,\n    sla_elapsed_time,\n    is_sla_breached\n  from reply_time_sla\n\nunion all\n\n  select\n    ticket_id,\n    sla_policy_name,\n    'agent_work_time' as metric,\n    sla_applied_at,\n    target,\n    false as in_business_hours,\n    max(sla_breach_at) as sla_breach_at,\n    sum(running_total_calendar_minutes) as sla_elapsed_time,\n    \n\n    max( is_breached_during_schedule )\n\n\n  from agent_work_calendar_sla\n\n  group by 1, 2, 3, 4, 5, 6\n\nunion all\n\n  select\n    ticket_id,\n    sla_policy_name,\n    'requester_wait_time' as metric,\n    sla_applied_at,\n    target,\n    false as in_business_hours,\n    max(sla_breach_at) as sla_breach_at,\n    sum(running_total_calendar_minutes) as sla_elapsed_time,\n    \n\n    max( is_breached_during_schedule )\n\n\n  from requester_wait_calendar_sla\n\n  group by 1, 2, 3, 4, 5, 6\n\n\n\n\nunion all \n\n  select \n    ticket_id,\n    sla_policy_name,\n    'agent_work_time' as metric,\n    sla_applied_at,\n    target,\n    true as in_business_hours,\n    max(sla_breach_at) as sla_breach_at,\n    sum(running_total_scheduled_minutes) as sla_elapsed_time,\n    \n\n    max( is_breached_during_schedule )\n\n\n  from agent_work_business_sla\n  \n  group by 1, 2, 3, 4, 5, 6\n\nunion all \n\n  select \n    ticket_id,\n    sla_policy_name,\n    'requester_wait_time' as metric,\n    sla_applied_at,\n    target,\n    true as in_business_hours,\n    max(sla_breach_at) as sla_breach_at,\n    sum(running_total_scheduled_minutes) as sla_elapsed_time,\n    \n\n    max( is_breached_during_schedule )\n\n\n    \n  from requester_wait_business_sla\n  \n  group by 1, 2, 3, 4, 5, 6\n\n\n\n)\n\nselect \n  to_hex(md5(cast(coalesce(cast(ticket_id as \n    string\n), '') || '-' || coalesce(cast(metric as \n    string\n), '') || '-' || coalesce(cast(sla_applied_at as \n    string\n), '') as \n    string\n))) as sla_event_id,\n  ticket_id,\n  sla_policy_name,\n  metric,\n  sla_applied_at,\n  target,\n  in_business_hours,\n  sla_breach_at,\n  case when sla_elapsed_time is null\n    then \n\n    datetime_diff(\n        cast(\n    current_timestamp\n as datetime),\n        cast(sla_applied_at as datetime),\n        minute\n    )\n\n  --This will create an entry for active sla's\n    else sla_elapsed_time\n      end as sla_elapsed_time,\n  sla_breach_at > current_timestamp as is_active_sla,\n  case when (sla_breach_at > \n    current_timestamp\n)\n    then null\n    else is_sla_breached\n      end as is_sla_breach\nfrom all_slas_unioned", "extra_ctes_injected": true, "extra_ctes": [], "relation_name": "`bq-project`.`dbt_joe_zendesk_docs`.`zendesk__sla_policies`"}, "model.zendesk.zendesk__ticket_backlog": {"raw_sql": "--This model will only run if 'status' is included within the `ticket_field_history_columns` variable.\n{{ config(enabled = 'status' in var('ticket_field_history_columns')) }}\n\nwith ticket_field_history as (\n    select *\n    from {{ ref('zendesk__ticket_field_history') }}\n\n), tickets as (\n    select *\n    from {{ ref('stg_zendesk__ticket') }}\n\n), group_names as (\n    select *\n    from {{ ref('stg_zendesk__group') }}\n\n), users as (\n    select *\n    from {{ ref('stg_zendesk__user') }}\n\n), brands as (\n    select *\n    from {{ ref('stg_zendesk__brand') }}\n\n--The below model is excluded if the user does not include ticket_form_id in the variable as a low percentage of accounts use ticket forms.\n{% if 'ticket_form_id' in var('ticket_field_history_columns') %}\n), ticket_forms as (\n    select *\n    from {{ ref('int_zendesk__latest_ticket_form') }}\n{% endif %}\n\n), organizations as (\n    select *\n    from {{ ref('stg_zendesk__organization') }}\n\n), backlog as (\n    select\n        ticket_field_history.date_day\n        ,ticket_field_history.ticket_id\n        ,ticket_field_history.status\n        ,tickets.created_channel\n        {% for col in var('ticket_field_history_columns') if col != 'status' %} --Looking at all history fields the users passed through in their dbt_project.yml file\n            {% if col in ['assignee_id'] %} --Standard ID field where the name can easily be joined from stg model.\n                ,assignee.name as assignee_name\n\n            {% elif col in ['requester_id'] %} --Standard ID field where the name can easily be joined from stg model.\n                ,requester.name as requester_name\n\n            {% elif col in ['ticket_form_id'] %} --Standard ID field where the name can easily be joined from stg model.\n                ,ticket_forms.name as ticket_form_name\n\n            {% elif col in ['organization_id'] %} --Standard ID field where the name can easily be joined from stg model.\n                ,organizations.name as organization_name\n\n            {% elif col in ['brand_id'] %} --Standard ID field where the name can easily be joined from stg model.\n                ,brands.name as brand_name\n\n            {% elif col in ['group_id'] %} --Standard ID field where the name can easily be joined from stg model.\n                ,group_names.name as group_name\n\n            {% elif col in ['locale_id'] %} --Standard ID field where the name can easily be joined from stg model.\n                ,assignee.locale as local_name\n\n            {% else %} --All other fields are not ID's and can simply be included in the query.\n                ,ticket_field_history.{{ col }}\n            {% endif %}\n        {% endfor %}\n\n    from ticket_field_history\n\n    left join tickets\n        on tickets.ticket_id = ticket_field_history.ticket_id\n\n    {% if 'ticket_form_id' in var('ticket_field_history_columns') %} --Join not needed if field is not located in variable, otherwise it is included.\n    left join ticket_forms\n        on ticket_forms.ticket_form_id = cast(ticket_field_history.ticket_form_id as {{ dbt_utils.type_bigint() }})\n    {% endif %}\n\n    {% if 'group_id' in var('ticket_field_history_columns') %}--Join not needed if field is not located in variable, otherwise it is included.\n    left join group_names\n        on group_names.group_id = cast(ticket_field_history.group_id as {{ dbt_utils.type_bigint() }})\n    {% endif %}\n\n    {% if 'assignee_id' in var('ticket_field_history_columns') or 'requester_id' in var('ticket_field_history_columns') or 'locale_id' in var('ticket_field_history_columns')%} --Join not needed if fields is not located in variable, otherwise it is included.\n    left join users as assignee\n        on assignee.user_id = cast(ticket_field_history.assignee_id as {{ dbt_utils.type_bigint() }})\n    {% endif %}\n\n    {% if 'requester_id' in var('ticket_field_history_columns') %} --Join not needed if field is not located in variable, otherwise it is included.\n    left join users as requester\n        on requester.user_id = cast(ticket_field_history.requester_id as {{ dbt_utils.type_bigint() }})\n    {% endif %}\n\n    {% if 'brand_id' in var('ticket_field_history_columns') %} --Join not needed if field is not located in variable, otherwise it is included.\n    left join brands\n        on brands.brand_id = cast(ticket_field_history.brand_id as {{ dbt_utils.type_bigint() }})\n    {% endif %}\n\n    {% if 'organization_id' in var('ticket_field_history_columns') %} --Join not needed if field is not located in variable, otherwise it is included.\n    left join organizations\n        on organizations.organization_id = cast(ticket_field_history.organization_id as {{ dbt_utils.type_bigint() }})\n    {% endif %}\n\n    where ticket_field_history.status not in ('closed', 'solved', 'deleted')\n)\n\nselect *\nfrom backlog", "compiled": true, "resource_type": "model", "depends_on": {"macros": ["macro.dbt_utils.type_bigint"], "nodes": ["model.zendesk.zendesk__ticket_field_history", "model.zendesk_source.stg_zendesk__ticket", "model.zendesk_source.stg_zendesk__group", "model.zendesk_source.stg_zendesk__user", "model.zendesk_source.stg_zendesk__brand", "model.zendesk_source.stg_zendesk__organization"]}, "config": {"enabled": true, "alias": null, "schema": "zendesk_docs", "database": null, "tags": [], "meta": {}, "materialized": "table", "persist_docs": {}, "quoting": {}, "column_types": {}, "full_refresh": null, "on_schema_change": "ignore", "post-hook": [], "pre-hook": []}, "database": "bq-project", "schema": "dbt_joe_zendesk_docs", "fqn": ["zendesk", "zendesk__ticket_backlog"], "unique_id": "model.zendesk.zendesk__ticket_backlog", "package_name": "zendesk", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/zendesk", "path": "zendesk__ticket_backlog.sql", "original_file_path": "models/zendesk__ticket_backlog.sql", "name": "zendesk__ticket_backlog", "alias": "zendesk__ticket_backlog", "checksum": {"name": "sha256", "checksum": "60d905c450664e94cb2771d3f9d3ab0b00d583d838ec37ac4c1ebea5f84ec50d"}, "tags": [], "refs": [["zendesk__ticket_field_history"], ["stg_zendesk__ticket"], ["stg_zendesk__group"], ["stg_zendesk__user"], ["stg_zendesk__brand"], ["stg_zendesk__organization"]], "sources": [], "description": "A daily historical view of the ticket field values defined in the `ticket_field_history_columns` variable  for all backlog tickets. Backlog tickets being defined as any ticket not a 'closed', 'deleted', or 'solved' status.\n", "columns": {"date_day": {"name": "date_day", "description": "The date of the day associated with the field values", "meta": {}, "data_type": null, "quote": null, "tags": []}, "ticket_id": {"name": "ticket_id", "description": "A ticket's unique identifier, it is automatically assigned when the ticket is created", "meta": {}, "data_type": null, "quote": null, "tags": []}, "status": {"name": "status", "description": "The status of the ticket", "meta": {}, "data_type": null, "quote": null, "tags": []}, "created_channel": {"name": "created_channel", "description": "The channel where the ticket was created", "meta": {}, "data_type": null, "quote": null, "tags": []}, "assignee_name": {"name": "assignee_name", "description": "The assignee name assigned to the ticket", "meta": {}, "data_type": null, "quote": null, "tags": []}, "priority": {"name": "priority", "description": "The tickets priority ranking", "meta": {}, "data_type": null, "quote": null, "tags": []}}, "meta": {}, "docs": {"show": true}, "patch_path": "zendesk://models/zendesk.yml", "compiled_path": "target/compiled/zendesk/models/zendesk__ticket_backlog.sql", "build_path": null, "deferred": false, "unrendered_config": {"schema": "zendesk_docs", "materialized": "table", "enabled": true}, "created_at": 1647014737.91237, "compiled_sql": "--This model will only run if 'status' is included within the `ticket_field_history_columns` variable.\n\n\nwith ticket_field_history as (\n    select *\n    from `bq-project`.`dbt_joe_zendesk_docs`.`zendesk__ticket_field_history`\n\n), tickets as (\n    select *\n    from `bq-project`.`dbt_joe_zendesk_docs`.`stg_zendesk__ticket`\n\n), group_names as (\n    select *\n    from `bq-project`.`dbt_joe_zendesk_docs`.`stg_zendesk__group`\n\n), users as (\n    select *\n    from `bq-project`.`dbt_joe_zendesk_docs`.`stg_zendesk__user`\n\n), brands as (\n    select *\n    from `bq-project`.`dbt_joe_zendesk_docs`.`stg_zendesk__brand`\n\n--The below model is excluded if the user does not include ticket_form_id in the variable as a low percentage of accounts use ticket forms.\n\n\n), organizations as (\n    select *\n    from `bq-project`.`dbt_joe_zendesk_docs`.`stg_zendesk__organization`\n\n), backlog as (\n    select\n        ticket_field_history.date_day\n        ,ticket_field_history.ticket_id\n        ,ticket_field_history.status\n        ,tickets.created_channel\n         --Looking at all history fields the users passed through in their dbt_project.yml file\n             --Standard ID field where the name can easily be joined from stg model.\n                ,assignee.name as assignee_name\n\n            \n         --Looking at all history fields the users passed through in their dbt_project.yml file\n             --All other fields are not ID's and can simply be included in the query.\n                ,ticket_field_history.priority\n            \n        \n\n    from ticket_field_history\n\n    left join tickets\n        on tickets.ticket_id = ticket_field_history.ticket_id\n\n    \n\n    \n\n     --Join not needed if fields is not located in variable, otherwise it is included.\n    left join users as assignee\n        on assignee.user_id = cast(ticket_field_history.assignee_id as \n    int64\n)\n    \n\n    \n\n    \n\n    \n\n    where ticket_field_history.status not in ('closed', 'solved', 'deleted')\n)\n\nselect *\nfrom backlog", "extra_ctes_injected": true, "extra_ctes": [], "relation_name": "`bq-project`.`dbt_joe_zendesk_docs`.`zendesk__ticket_backlog`"}, "model.zendesk.int_zendesk__sla_policy_applied": {"raw_sql": "-- step 1, figure out when sla was applied to tickets\n\n-- more on SLA policies here: https://support.zendesk.com/hc/en-us/articles/204770038-Defining-and-using-SLA-policies-Professional-and-Enterprise-\n-- SLA policies are calculated for next_reply_time, first_reply_time, agent_work_time, requester_wait_time.  If you're company uses other SLA metrics, and would like this\n-- package to support those, please reach out to the Fivetran team on Slack.\n\nwith ticket_field_history as (\n\n  select *\n  from {{ ref('int_zendesk__updates') }}\n\n), sla_policy_name as (\n\n  select \n    *\n  from {{ ref('int_zendesk__updates') }}\n  where field_name = ('sla_policy')\n\n), ticket as (\n\n  select *\n  from {{ ref('int_zendesk__ticket_aggregates') }}\n\n), sla_policy_applied as (\n\n  select\n    ticket_field_history.ticket_id,\n    ticket.created_at as ticket_created_at,\n    ticket_field_history.valid_starting_at,\n    ticket.status as ticket_current_status,\n    ticket_field_history.field_name as metric,\n    case when ticket_field_history.field_name = 'first_reply_time' then row_number() over (partition by ticket_field_history.ticket_id, ticket_field_history.field_name order by ticket_field_history.valid_starting_at desc) else 1 end as latest_sla,\n    case when ticket_field_history.field_name = 'first_reply_time' then ticket.created_at else ticket_field_history.valid_starting_at end as sla_applied_at,\n    cast({{ fivetran_utils.json_extract('ticket_field_history.value', 'minutes') }} as {{ dbt_utils.type_int() }} ) as target,\n    {{ fivetran_utils.json_extract('ticket_field_history.value', 'in_business_hours') }} = 'true' as in_business_hours\n  from ticket_field_history\n  join ticket\n    on ticket.ticket_id = ticket_field_history.ticket_id\n  where ticket_field_history.value is not null\n    and ticket_field_history.field_name in ('next_reply_time', 'first_reply_time', 'agent_work_time', 'requester_wait_time')\n\n), final as (\n  select\n    sla_policy_applied.*,\n    sla_policy_name.value as sla_policy_name\n  from sla_policy_applied\n  left join sla_policy_name\n    on sla_policy_name.ticket_id = sla_policy_applied.ticket_id\n      and sla_policy_applied.valid_starting_at >= sla_policy_name.valid_starting_at\n      and sla_policy_applied.valid_starting_at < coalesce(sla_policy_name.valid_ending_at, {{ dbt_utils.current_timestamp() }}) \n  where sla_policy_applied.latest_sla = 1\n)\n\nselect *\nfrom final", "compiled": true, "resource_type": "model", "depends_on": {"macros": ["macro.fivetran_utils.json_extract", "macro.dbt_utils.type_int", "macro.dbt_utils.current_timestamp"], "nodes": ["model.zendesk.int_zendesk__updates", "model.zendesk.int_zendesk__updates", "model.zendesk.int_zendesk__ticket_aggregates"]}, "config": {"enabled": true, "alias": null, "schema": "zendesk_docs", "database": null, "tags": [], "meta": {}, "materialized": "table", "persist_docs": {}, "quoting": {}, "column_types": {}, "full_refresh": null, "on_schema_change": "ignore", "post-hook": [], "pre-hook": []}, "database": "bq-project", "schema": "dbt_joe_zendesk_docs", "fqn": ["zendesk", "sla_policy", "int_zendesk__sla_policy_applied"], "unique_id": "model.zendesk.int_zendesk__sla_policy_applied", "package_name": "zendesk", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/zendesk", "path": "sla_policy/int_zendesk__sla_policy_applied.sql", "original_file_path": "models/sla_policy/int_zendesk__sla_policy_applied.sql", "name": "int_zendesk__sla_policy_applied", "alias": "int_zendesk__sla_policy_applied", "checksum": {"name": "sha256", "checksum": "0841f05cd030353ce53ac732a8d3c24538979b3707d3bd579b24a7b61e6f383b"}, "tags": [], "refs": [["int_zendesk__updates"], ["int_zendesk__updates"], ["int_zendesk__ticket_aggregates"]], "sources": [], "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "compiled_path": "target/compiled/zendesk/models/sla_policy/int_zendesk__sla_policy_applied.sql", "build_path": null, "deferred": false, "unrendered_config": {"schema": "zendesk_docs", "materialized": "table"}, "created_at": 1647014737.007702, "compiled_sql": "-- step 1, figure out when sla was applied to tickets\n\n-- more on SLA policies here: https://support.zendesk.com/hc/en-us/articles/204770038-Defining-and-using-SLA-policies-Professional-and-Enterprise-\n-- SLA policies are calculated for next_reply_time, first_reply_time, agent_work_time, requester_wait_time.  If you're company uses other SLA metrics, and would like this\n-- package to support those, please reach out to the Fivetran team on Slack.\n\nwith ticket_field_history as (\n\n  select *\n  from `bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__updates`\n\n), sla_policy_name as (\n\n  select \n    *\n  from `bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__updates`\n  where field_name = ('sla_policy')\n\n), ticket as (\n\n  select *\n  from `bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__ticket_aggregates`\n\n), sla_policy_applied as (\n\n  select\n    ticket_field_history.ticket_id,\n    ticket.created_at as ticket_created_at,\n    ticket_field_history.valid_starting_at,\n    ticket.status as ticket_current_status,\n    ticket_field_history.field_name as metric,\n    case when ticket_field_history.field_name = 'first_reply_time' then row_number() over (partition by ticket_field_history.ticket_id, ticket_field_history.field_name order by ticket_field_history.valid_starting_at desc) else 1 end as latest_sla,\n    case when ticket_field_history.field_name = 'first_reply_time' then ticket.created_at else ticket_field_history.valid_starting_at end as sla_applied_at,\n    cast(\n\n  json_extract_scalar(ticket_field_history.value, '$.minutes' )\n\n as \n    int64\n ) as target,\n    \n\n  json_extract_scalar(ticket_field_history.value, '$.in_business_hours' )\n\n = 'true' as in_business_hours\n  from ticket_field_history\n  join ticket\n    on ticket.ticket_id = ticket_field_history.ticket_id\n  where ticket_field_history.value is not null\n    and ticket_field_history.field_name in ('next_reply_time', 'first_reply_time', 'agent_work_time', 'requester_wait_time')\n\n), final as (\n  select\n    sla_policy_applied.*,\n    sla_policy_name.value as sla_policy_name\n  from sla_policy_applied\n  left join sla_policy_name\n    on sla_policy_name.ticket_id = sla_policy_applied.ticket_id\n      and sla_policy_applied.valid_starting_at >= sla_policy_name.valid_starting_at\n      and sla_policy_applied.valid_starting_at < coalesce(sla_policy_name.valid_ending_at, \n    current_timestamp\n) \n  where sla_policy_applied.latest_sla = 1\n)\n\nselect *\nfrom final", "extra_ctes_injected": true, "extra_ctes": [], "relation_name": "`bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__sla_policy_applied`"}, "model.zendesk.int_zendesk__agent_work_time_business_hours": {"raw_sql": "{{ config(enabled=var('using_schedules', True)) }}\n\n-- AGENT WORK TIME\n-- This is complicated, as SLAs minutes are only counted while the ticket is in 'new' or 'open' status.\n\n-- Additionally, for business hours, only 'new' or 'open' status hours are counted if they are also during business hours\nwith agent_work_time_filtered_statuses as (\n\n  select *\n  from {{ ref('int_zendesk__agent_work_time_filtered_statuses') }}\n  where in_business_hours\n\n), schedule as (\n\n  select * \n  from {{ ref('int_zendesk__schedule_spine') }}\n\n), ticket_schedules as (\n\n  select * \n  from {{ ref('int_zendesk__ticket_schedules') }}\n  \n-- cross schedules with work time\n), ticket_status_crossed_with_schedule as (\n  \n    select\n      agent_work_time_filtered_statuses.ticket_id,\n      agent_work_time_filtered_statuses.sla_applied_at,\n      agent_work_time_filtered_statuses.target,    \n      agent_work_time_filtered_statuses.sla_policy_name,    \n      ticket_schedules.schedule_id,\n\n      -- take the intersection of the intervals in which the status and the schedule were both active, for calculating the business minutes spent working on the ticket\n      greatest(valid_starting_at, schedule_created_at) as valid_starting_at,\n      least(valid_ending_at, schedule_invalidated_at) as valid_ending_at,\n\n      -- bringing the following in the determine which schedule (Daylight Savings vs Standard time) to use\n      valid_starting_at as status_valid_starting_at,\n      valid_ending_at as status_valid_ending_at\n\n    from agent_work_time_filtered_statuses\n    left join ticket_schedules\n      on agent_work_time_filtered_statuses.ticket_id = ticket_schedules.ticket_id\n    where {{ fivetran_utils.timestamp_diff(\n              'greatest(valid_starting_at, schedule_created_at)', \n              'least(valid_ending_at, schedule_invalidated_at)', \n              'second') }} > 0\n\n), ticket_full_solved_time as (\n\n    select \n      ticket_status_crossed_with_schedule.*,\n      ({{ fivetran_utils.timestamp_diff(\n              \"\" ~ dbt_utils.date_trunc(\n                  'week',\n                  'ticket_status_crossed_with_schedule.valid_starting_at') ~ \"\", \n              'ticket_status_crossed_with_schedule.valid_starting_at', \n              'second') }} /60\n            ) as valid_starting_at_in_minutes_from_week,\n      ({{ fivetran_utils.timestamp_diff(\n              'ticket_status_crossed_with_schedule.valid_starting_at', \n              'ticket_status_crossed_with_schedule.valid_ending_at',\n              'second') }} /60\n            ) as raw_delta_in_minutes\n    from ticket_status_crossed_with_schedule\n    {{ dbt_utils.group_by(n=10) }}\n\n), weeks as (\n\n    {{ dbt_utils.generate_series(208) }}\n\n), weeks_cross_ticket_full_solved_time as (\n    -- because time is reported in minutes since the beginning of the week, we have to split up time spent on the ticket into calendar weeks\n    select \n      ticket_full_solved_time.*,\n      generated_number - 1 as week_number\n    from ticket_full_solved_time\n    cross join weeks\n    where floor((valid_starting_at_in_minutes_from_week + raw_delta_in_minutes) / (7*24*60)) >= generated_number -1\n\n), weekly_period_agent_work_time as (\n\n    select \n\n      ticket_id,\n      sla_applied_at,\n      valid_starting_at,\n      valid_ending_at,\n      status_valid_starting_at,\n      status_valid_ending_at,\n      target,\n      sla_policy_name,\n      valid_starting_at_in_minutes_from_week,\n      raw_delta_in_minutes,\n      week_number,\n      schedule_id,\n      greatest(0, valid_starting_at_in_minutes_from_week - week_number * (7*24*60)) as ticket_week_start_time_minute,\n      least(valid_starting_at_in_minutes_from_week + raw_delta_in_minutes - week_number * (7*24*60), (7*24*60)) as ticket_week_end_time_minute\n    \n    from weeks_cross_ticket_full_solved_time\n\n), intercepted_periods_agent as (\n  \n    select \n      weekly_period_agent_work_time.ticket_id,\n      weekly_period_agent_work_time.sla_applied_at,\n      weekly_period_agent_work_time.target,\n      weekly_period_agent_work_time.sla_policy_name,\n      weekly_period_agent_work_time.valid_starting_at,\n      weekly_period_agent_work_time.valid_ending_at,\n      weekly_period_agent_work_time.week_number,\n      weekly_period_agent_work_time.ticket_week_start_time_minute,\n      weekly_period_agent_work_time.ticket_week_end_time_minute,\n      schedule.start_time_utc as schedule_start_time,\n      schedule.end_time_utc as schedule_end_time,\n      least(ticket_week_end_time_minute, schedule.end_time_utc) - greatest(weekly_period_agent_work_time.ticket_week_start_time_minute, schedule.start_time_utc) as scheduled_minutes\n    from weekly_period_agent_work_time\n    join schedule on ticket_week_start_time_minute <= schedule.end_time_utc \n      and ticket_week_end_time_minute >= schedule.start_time_utc\n      and weekly_period_agent_work_time.schedule_id = schedule.schedule_id\n      -- this chooses the Daylight Savings Time or Standard Time version of the schedule\n      and weekly_period_agent_work_time.status_valid_ending_at >= cast(schedule.valid_from as {{ dbt_utils.type_timestamp() }})\n      and weekly_period_agent_work_time.status_valid_starting_at < cast(schedule.valid_until as {{ dbt_utils.type_timestamp() }}) \n  \n), intercepted_periods_with_running_total as (\n  \n    select \n      *,\n      sum(scheduled_minutes) over \n        (partition by ticket_id, sla_applied_at \n          order by valid_starting_at, week_number, schedule_end_time\n          rows between unbounded preceding and current row)\n        as running_total_scheduled_minutes\n\n    from intercepted_periods_agent\n\n\n), intercepted_periods_agent_with_breach_flag as (\n  select \n    intercepted_periods_with_running_total.*,\n    target - running_total_scheduled_minutes as remaining_target_minutes,\n    lag(target - running_total_scheduled_minutes) over\n          (partition by ticket_id, sla_applied_at order by valid_starting_at, week_number, schedule_end_time) as lag_check,\n    case when (target - running_total_scheduled_minutes) = 0 then true\n       when (target - running_total_scheduled_minutes) < 0 \n        and \n          (lag(target - running_total_scheduled_minutes) over\n          (partition by ticket_id, sla_applied_at order by valid_starting_at, week_number, schedule_end_time) > 0 \n          or \n          lag(target - running_total_scheduled_minutes) over\n          (partition by ticket_id, sla_applied_at order by valid_starting_at, week_number, schedule_end_time) is null) \n          then true else false end as is_breached_during_schedule\n          \n  from  intercepted_periods_with_running_total\n\n), intercepted_periods_agent_filtered as (\n\n  select\n    *,\n    (remaining_target_minutes + scheduled_minutes) as breach_minutes,\n    greatest(ticket_week_start_time_minute, schedule_start_time) + (remaining_target_minutes + scheduled_minutes) as breach_minutes_from_week\n  from intercepted_periods_agent_with_breach_flag\n  \n), agent_work_business_breach as (\n  \n  select \n    *,\n    {{ fivetran_utils.timestamp_add(\n      \"minute\",\n      \"cast(((7*24*60) * week_number) + breach_minutes_from_week as \" ~ dbt_utils.type_int() ~ \" )\",\n      \"\" ~ dbt_utils.date_trunc('week', 'valid_starting_at') ~ \"\",\n      ) }} as sla_breach_at\n  from intercepted_periods_agent_filtered\n\n)\n\nselect * \nfrom agent_work_business_breach", "compiled": true, "resource_type": "model", "depends_on": {"macros": ["macro.fivetran_utils.timestamp_diff", "macro.dbt_utils.date_trunc", "macro.dbt_utils.group_by", "macro.dbt_utils.generate_series", "macro.dbt_utils.type_timestamp", "macro.dbt_utils.type_int", "macro.fivetran_utils.timestamp_add"], "nodes": ["model.zendesk.int_zendesk__agent_work_time_filtered_statuses", "model.zendesk.int_zendesk__schedule_spine", "model.zendesk.int_zendesk__ticket_schedules"]}, "config": {"enabled": true, "alias": null, "schema": "zendesk_docs", "database": null, "tags": [], "meta": {}, "materialized": "table", "persist_docs": {}, "quoting": {}, "column_types": {}, "full_refresh": null, "on_schema_change": "ignore", "post-hook": [], "pre-hook": []}, "database": "bq-project", "schema": "dbt_joe_zendesk_docs", "fqn": ["zendesk", "sla_policy", "agent_work_time", "int_zendesk__agent_work_time_business_hours"], "unique_id": "model.zendesk.int_zendesk__agent_work_time_business_hours", "package_name": "zendesk", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/zendesk", "path": "sla_policy/agent_work_time/int_zendesk__agent_work_time_business_hours.sql", "original_file_path": "models/sla_policy/agent_work_time/int_zendesk__agent_work_time_business_hours.sql", "name": "int_zendesk__agent_work_time_business_hours", "alias": "int_zendesk__agent_work_time_business_hours", "checksum": {"name": "sha256", "checksum": "41d7620cd91487666d0d79ed8cfe73ca2d0f3e6d90a6674b44fc35c2f4338300"}, "tags": [], "refs": [["int_zendesk__agent_work_time_filtered_statuses"], ["int_zendesk__schedule_spine"], ["int_zendesk__ticket_schedules"]], "sources": [], "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "compiled_path": "target/compiled/zendesk/models/sla_policy/agent_work_time/int_zendesk__agent_work_time_business_hours.sql", "build_path": null, "deferred": false, "unrendered_config": {"schema": "zendesk_docs", "materialized": "table", "enabled": true}, "created_at": 1647014737.017258, "compiled_sql": "\n\n-- AGENT WORK TIME\n-- This is complicated, as SLAs minutes are only counted while the ticket is in 'new' or 'open' status.\n\n-- Additionally, for business hours, only 'new' or 'open' status hours are counted if they are also during business hours\nwith agent_work_time_filtered_statuses as (\n\n  select *\n  from `bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__agent_work_time_filtered_statuses`\n  where in_business_hours\n\n), schedule as (\n\n  select * \n  from `bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__schedule_spine`\n\n), ticket_schedules as (\n\n  select * \n  from `bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__ticket_schedules`\n  \n-- cross schedules with work time\n), ticket_status_crossed_with_schedule as (\n  \n    select\n      agent_work_time_filtered_statuses.ticket_id,\n      agent_work_time_filtered_statuses.sla_applied_at,\n      agent_work_time_filtered_statuses.target,    \n      agent_work_time_filtered_statuses.sla_policy_name,    \n      ticket_schedules.schedule_id,\n\n      -- take the intersection of the intervals in which the status and the schedule were both active, for calculating the business minutes spent working on the ticket\n      greatest(valid_starting_at, schedule_created_at) as valid_starting_at,\n      least(valid_ending_at, schedule_invalidated_at) as valid_ending_at,\n\n      -- bringing the following in the determine which schedule (Daylight Savings vs Standard time) to use\n      valid_starting_at as status_valid_starting_at,\n      valid_ending_at as status_valid_ending_at\n\n    from agent_work_time_filtered_statuses\n    left join ticket_schedules\n      on agent_work_time_filtered_statuses.ticket_id = ticket_schedules.ticket_id\n    where \n  \n\n    timestamp_diff(\n        least(valid_ending_at, schedule_invalidated_at),\n        greatest(valid_starting_at, schedule_created_at),\n        second\n    )\n\n\n > 0\n\n), ticket_full_solved_time as (\n\n    select \n      ticket_status_crossed_with_schedule.*,\n      (\n  \n\n    timestamp_diff(\n        ticket_status_crossed_with_schedule.valid_starting_at,\n        \n    timestamp_trunc(\n        cast(ticket_status_crossed_with_schedule.valid_starting_at as timestamp),\n        week\n    )\n\n,\n        second\n    )\n\n\n /60\n            ) as valid_starting_at_in_minutes_from_week,\n      (\n  \n\n    timestamp_diff(\n        ticket_status_crossed_with_schedule.valid_ending_at,\n        ticket_status_crossed_with_schedule.valid_starting_at,\n        second\n    )\n\n\n /60\n            ) as raw_delta_in_minutes\n    from ticket_status_crossed_with_schedule\n    group by 1,2,3,4,5,6,7,8,9,10\n\n), weeks as (\n\n    \n\n    \n\n    with p as (\n        select 0 as generated_number union all select 1\n    ), unioned as (\n\n    select\n\n    \n    p0.generated_number * power(2, 0)\n     + \n    \n    p1.generated_number * power(2, 1)\n     + \n    \n    p2.generated_number * power(2, 2)\n     + \n    \n    p3.generated_number * power(2, 3)\n     + \n    \n    p4.generated_number * power(2, 4)\n     + \n    \n    p5.generated_number * power(2, 5)\n     + \n    \n    p6.generated_number * power(2, 6)\n     + \n    \n    p7.generated_number * power(2, 7)\n    \n    \n    + 1\n    as generated_number\n\n    from\n\n    \n    p as p0\n     cross join \n    \n    p as p1\n     cross join \n    \n    p as p2\n     cross join \n    \n    p as p3\n     cross join \n    \n    p as p4\n     cross join \n    \n    p as p5\n     cross join \n    \n    p as p6\n     cross join \n    \n    p as p7\n    \n    \n\n    )\n\n    select *\n    from unioned\n    where generated_number <= 208\n    order by generated_number\n\n\n\n), weeks_cross_ticket_full_solved_time as (\n    -- because time is reported in minutes since the beginning of the week, we have to split up time spent on the ticket into calendar weeks\n    select \n      ticket_full_solved_time.*,\n      generated_number - 1 as week_number\n    from ticket_full_solved_time\n    cross join weeks\n    where floor((valid_starting_at_in_minutes_from_week + raw_delta_in_minutes) / (7*24*60)) >= generated_number -1\n\n), weekly_period_agent_work_time as (\n\n    select \n\n      ticket_id,\n      sla_applied_at,\n      valid_starting_at,\n      valid_ending_at,\n      status_valid_starting_at,\n      status_valid_ending_at,\n      target,\n      sla_policy_name,\n      valid_starting_at_in_minutes_from_week,\n      raw_delta_in_minutes,\n      week_number,\n      schedule_id,\n      greatest(0, valid_starting_at_in_minutes_from_week - week_number * (7*24*60)) as ticket_week_start_time_minute,\n      least(valid_starting_at_in_minutes_from_week + raw_delta_in_minutes - week_number * (7*24*60), (7*24*60)) as ticket_week_end_time_minute\n    \n    from weeks_cross_ticket_full_solved_time\n\n), intercepted_periods_agent as (\n  \n    select \n      weekly_period_agent_work_time.ticket_id,\n      weekly_period_agent_work_time.sla_applied_at,\n      weekly_period_agent_work_time.target,\n      weekly_period_agent_work_time.sla_policy_name,\n      weekly_period_agent_work_time.valid_starting_at,\n      weekly_period_agent_work_time.valid_ending_at,\n      weekly_period_agent_work_time.week_number,\n      weekly_period_agent_work_time.ticket_week_start_time_minute,\n      weekly_period_agent_work_time.ticket_week_end_time_minute,\n      schedule.start_time_utc as schedule_start_time,\n      schedule.end_time_utc as schedule_end_time,\n      least(ticket_week_end_time_minute, schedule.end_time_utc) - greatest(weekly_period_agent_work_time.ticket_week_start_time_minute, schedule.start_time_utc) as scheduled_minutes\n    from weekly_period_agent_work_time\n    join schedule on ticket_week_start_time_minute <= schedule.end_time_utc \n      and ticket_week_end_time_minute >= schedule.start_time_utc\n      and weekly_period_agent_work_time.schedule_id = schedule.schedule_id\n      -- this chooses the Daylight Savings Time or Standard Time version of the schedule\n      and weekly_period_agent_work_time.status_valid_ending_at >= cast(schedule.valid_from as \n    timestamp\n)\n      and weekly_period_agent_work_time.status_valid_starting_at < cast(schedule.valid_until as \n    timestamp\n) \n  \n), intercepted_periods_with_running_total as (\n  \n    select \n      *,\n      sum(scheduled_minutes) over \n        (partition by ticket_id, sla_applied_at \n          order by valid_starting_at, week_number, schedule_end_time\n          rows between unbounded preceding and current row)\n        as running_total_scheduled_minutes\n\n    from intercepted_periods_agent\n\n\n), intercepted_periods_agent_with_breach_flag as (\n  select \n    intercepted_periods_with_running_total.*,\n    target - running_total_scheduled_minutes as remaining_target_minutes,\n    lag(target - running_total_scheduled_minutes) over\n          (partition by ticket_id, sla_applied_at order by valid_starting_at, week_number, schedule_end_time) as lag_check,\n    case when (target - running_total_scheduled_minutes) = 0 then true\n       when (target - running_total_scheduled_minutes) < 0 \n        and \n          (lag(target - running_total_scheduled_minutes) over\n          (partition by ticket_id, sla_applied_at order by valid_starting_at, week_number, schedule_end_time) > 0 \n          or \n          lag(target - running_total_scheduled_minutes) over\n          (partition by ticket_id, sla_applied_at order by valid_starting_at, week_number, schedule_end_time) is null) \n          then true else false end as is_breached_during_schedule\n          \n  from  intercepted_periods_with_running_total\n\n), intercepted_periods_agent_filtered as (\n\n  select\n    *,\n    (remaining_target_minutes + scheduled_minutes) as breach_minutes,\n    greatest(ticket_week_start_time_minute, schedule_start_time) + (remaining_target_minutes + scheduled_minutes) as breach_minutes_from_week\n  from intercepted_periods_agent_with_breach_flag\n  \n), agent_work_business_breach as (\n  \n  select \n    *,\n    \n\n        timestamp_add(\n    timestamp_trunc(\n        cast(valid_starting_at as timestamp),\n        week\n    )\n\n, interval  cast(((7*24*60) * week_number) + breach_minutes_from_week as \n    int64\n ) minute)\n\n as sla_breach_at\n  from intercepted_periods_agent_filtered\n\n)\n\nselect * \nfrom agent_work_business_breach", "extra_ctes_injected": true, "extra_ctes": [], "relation_name": "`bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__agent_work_time_business_hours`"}, "model.zendesk.int_zendesk__agent_work_time_calendar_hours": {"raw_sql": "-- Calculate breach time for agent work time, calendar hours\nwith agent_work_time_filtered_statuses as (\n\n  select *\n  from {{ ref('int_zendesk__agent_work_time_filtered_statuses') }}\n  where not in_business_hours\n\n), agent_work_time_calendar_minutes as (\n\n  select \n    *,\n    {{ fivetran_utils.timestamp_diff(\n        'valid_starting_at',\n        'valid_ending_at',\n        'minute' )}} as calendar_minutes,\n    sum({{ fivetran_utils.timestamp_diff(\n            'valid_starting_at', \n            'valid_ending_at', \n            'minute') }} ) \n      over (partition by ticket_id, sla_applied_at order by valid_starting_at rows between unbounded preceding and current row) as running_total_calendar_minutes\n  from agent_work_time_filtered_statuses\n\n), agent_work_time_calendar_minutes_flagged as (\n\nselect \n  agent_work_time_calendar_minutes.*,\n  target - running_total_calendar_minutes as remaining_target_minutes,\n  case when (target - running_total_calendar_minutes) < 0 \n      and \n        (lag(target - running_total_calendar_minutes) over\n        (partition by ticket_id, sla_applied_at order by valid_starting_at) >= 0 \n        or \n        lag(target - running_total_calendar_minutes) over\n        (partition by ticket_id, sla_applied_at order by valid_starting_at) is null) \n        then true else false end as is_breached_during_schedule\n        \nfrom  agent_work_time_calendar_minutes\n\n), final as (\n  select\n    *,\n    (remaining_target_minutes + calendar_minutes) as breach_minutes,\n    {{ fivetran_utils.timestamp_add(\n      'minute',\n      '(remaining_target_minutes + calendar_minutes)',\n      'valid_starting_at', \n      ) }} as sla_breach_at\n  from agent_work_time_calendar_minutes_flagged\n\n)\n\nselect *\nfrom final", "compiled": true, "resource_type": "model", "depends_on": {"macros": ["macro.fivetran_utils.timestamp_diff", "macro.fivetran_utils.timestamp_add"], "nodes": ["model.zendesk.int_zendesk__agent_work_time_filtered_statuses"]}, "config": {"enabled": true, "alias": null, "schema": "zendesk_docs", "database": null, "tags": [], "meta": {}, "materialized": "table", "persist_docs": {}, "quoting": {}, "column_types": {}, "full_refresh": null, "on_schema_change": "ignore", "post-hook": [], "pre-hook": []}, "database": "bq-project", "schema": "dbt_joe_zendesk_docs", "fqn": ["zendesk", "sla_policy", "agent_work_time", "int_zendesk__agent_work_time_calendar_hours"], "unique_id": "model.zendesk.int_zendesk__agent_work_time_calendar_hours", "package_name": "zendesk", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/zendesk", "path": "sla_policy/agent_work_time/int_zendesk__agent_work_time_calendar_hours.sql", "original_file_path": "models/sla_policy/agent_work_time/int_zendesk__agent_work_time_calendar_hours.sql", "name": "int_zendesk__agent_work_time_calendar_hours", "alias": "int_zendesk__agent_work_time_calendar_hours", "checksum": {"name": "sha256", "checksum": "ca37b41feefafd32fbbc726e7bf3921affa528a2263862ef606a8ca9826d0661"}, "tags": [], "refs": [["int_zendesk__agent_work_time_filtered_statuses"]], "sources": [], "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "compiled_path": "target/compiled/zendesk/models/sla_policy/agent_work_time/int_zendesk__agent_work_time_calendar_hours.sql", "build_path": null, "deferred": false, "unrendered_config": {"schema": "zendesk_docs", "materialized": "table"}, "created_at": 1647014737.050045, "compiled_sql": "-- Calculate breach time for agent work time, calendar hours\nwith agent_work_time_filtered_statuses as (\n\n  select *\n  from `bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__agent_work_time_filtered_statuses`\n  where not in_business_hours\n\n), agent_work_time_calendar_minutes as (\n\n  select \n    *,\n    \n  \n\n    timestamp_diff(\n        valid_ending_at,\n        valid_starting_at,\n        minute\n    )\n\n\n as calendar_minutes,\n    sum(\n  \n\n    timestamp_diff(\n        valid_ending_at,\n        valid_starting_at,\n        minute\n    )\n\n\n ) \n      over (partition by ticket_id, sla_applied_at order by valid_starting_at rows between unbounded preceding and current row) as running_total_calendar_minutes\n  from agent_work_time_filtered_statuses\n\n), agent_work_time_calendar_minutes_flagged as (\n\nselect \n  agent_work_time_calendar_minutes.*,\n  target - running_total_calendar_minutes as remaining_target_minutes,\n  case when (target - running_total_calendar_minutes) < 0 \n      and \n        (lag(target - running_total_calendar_minutes) over\n        (partition by ticket_id, sla_applied_at order by valid_starting_at) >= 0 \n        or \n        lag(target - running_total_calendar_minutes) over\n        (partition by ticket_id, sla_applied_at order by valid_starting_at) is null) \n        then true else false end as is_breached_during_schedule\n        \nfrom  agent_work_time_calendar_minutes\n\n), final as (\n  select\n    *,\n    (remaining_target_minutes + calendar_minutes) as breach_minutes,\n    \n\n        timestamp_add(valid_starting_at, interval  (remaining_target_minutes + calendar_minutes) minute)\n\n as sla_breach_at\n  from agent_work_time_calendar_minutes_flagged\n\n)\n\nselect *\nfrom final", "extra_ctes_injected": true, "extra_ctes": [], "relation_name": "`bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__agent_work_time_calendar_hours`"}, "model.zendesk.int_zendesk__agent_work_time_filtered_statuses": {"raw_sql": "with agent_work_time_sla as (\n\n  select *\n  from {{ ref('int_zendesk__sla_policy_applied') }}\n  where metric = 'agent_work_time'\n\n), ticket_historical_status as (\n\n  select *\n  from {{ ref('int_zendesk__ticket_historical_status') }}\n    \n--This captures the statuses of the ticket while the agent work time sla was active for the ticket.\n), agent_work_time_filtered_statuses as (\n\n  select  \n    ticket_historical_status.ticket_id,\n    greatest(ticket_historical_status.valid_starting_at, agent_work_time_sla.sla_applied_at) as valid_starting_at,\n    coalesce(\n      ticket_historical_status.valid_ending_at, \n      {{ fivetran_utils.timestamp_add('day', 30, \"\" ~ dbt_utils.current_timestamp() ~ \"\") }} ) as valid_ending_at, --assumes current status continues into the future. This is necessary to predict future SLA breaches (not just past).\n    ticket_historical_status.status as ticket_status,\n    agent_work_time_sla.sla_applied_at,\n    agent_work_time_sla.target,    \n    agent_work_time_sla.sla_policy_name,\n    agent_work_time_sla.ticket_created_at,\n    agent_work_time_sla.in_business_hours\n  from ticket_historical_status\n  join agent_work_time_sla\n    on ticket_historical_status.ticket_id = agent_work_time_sla.ticket_id\n  where ticket_historical_status.status in ('new', 'open') -- these are the only statuses that count as \"agent work time\"\n  and sla_applied_at < valid_ending_at\n\n)\nselect *\nfrom agent_work_time_filtered_statuses", "compiled": true, "resource_type": "model", "depends_on": {"macros": ["macro.dbt_utils.current_timestamp", "macro.fivetran_utils.timestamp_add"], "nodes": ["model.zendesk.int_zendesk__sla_policy_applied", "model.zendesk.int_zendesk__ticket_historical_status"]}, "config": {"enabled": true, "alias": null, "schema": "zendesk_docs", "database": null, "tags": [], "meta": {}, "materialized": "table", "persist_docs": {}, "quoting": {}, "column_types": {}, "full_refresh": null, "on_schema_change": "ignore", "post-hook": [], "pre-hook": []}, "database": "bq-project", "schema": "dbt_joe_zendesk_docs", "fqn": ["zendesk", "sla_policy", "agent_work_time", "int_zendesk__agent_work_time_filtered_statuses"], "unique_id": "model.zendesk.int_zendesk__agent_work_time_filtered_statuses", "package_name": "zendesk", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/zendesk", "path": "sla_policy/agent_work_time/int_zendesk__agent_work_time_filtered_statuses.sql", "original_file_path": "models/sla_policy/agent_work_time/int_zendesk__agent_work_time_filtered_statuses.sql", "name": "int_zendesk__agent_work_time_filtered_statuses", "alias": "int_zendesk__agent_work_time_filtered_statuses", "checksum": {"name": "sha256", "checksum": "8516523042e9dedfb12a9f5c5a240c79b03a01eab0a98d1e901b450bf331a0a0"}, "tags": [], "refs": [["int_zendesk__sla_policy_applied"], ["int_zendesk__ticket_historical_status"]], "sources": [], "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "compiled_path": "target/compiled/zendesk/models/sla_policy/agent_work_time/int_zendesk__agent_work_time_filtered_statuses.sql", "build_path": null, "deferred": false, "unrendered_config": {"schema": "zendesk_docs", "materialized": "table"}, "created_at": 1647014737.056406, "compiled_sql": "with agent_work_time_sla as (\n\n  select *\n  from `bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__sla_policy_applied`\n  where metric = 'agent_work_time'\n\n), ticket_historical_status as (\n\n  select *\n  from `bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__ticket_historical_status`\n    \n--This captures the statuses of the ticket while the agent work time sla was active for the ticket.\n), agent_work_time_filtered_statuses as (\n\n  select  \n    ticket_historical_status.ticket_id,\n    greatest(ticket_historical_status.valid_starting_at, agent_work_time_sla.sla_applied_at) as valid_starting_at,\n    coalesce(\n      ticket_historical_status.valid_ending_at, \n      \n\n        timestamp_add(\n    current_timestamp\n, interval  30 day)\n\n ) as valid_ending_at, --assumes current status continues into the future. This is necessary to predict future SLA breaches (not just past).\n    ticket_historical_status.status as ticket_status,\n    agent_work_time_sla.sla_applied_at,\n    agent_work_time_sla.target,    \n    agent_work_time_sla.sla_policy_name,\n    agent_work_time_sla.ticket_created_at,\n    agent_work_time_sla.in_business_hours\n  from ticket_historical_status\n  join agent_work_time_sla\n    on ticket_historical_status.ticket_id = agent_work_time_sla.ticket_id\n  where ticket_historical_status.status in ('new', 'open') -- these are the only statuses that count as \"agent work time\"\n  and sla_applied_at < valid_ending_at\n\n)\nselect *\nfrom agent_work_time_filtered_statuses", "extra_ctes_injected": true, "extra_ctes": [], "relation_name": "`bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__agent_work_time_filtered_statuses`"}, "model.zendesk.int_zendesk__reply_time_business_hours": {"raw_sql": "{{ config(enabled=var('using_schedules', True)) }}\n\n-- step 3, determine when an SLA will breach for SLAs that are in business hours\n\nwith ticket_schedules as (\n \n  select *\n  from {{ ref('int_zendesk__ticket_schedules') }}\n\n), schedule as (\n \n  select *\n  from {{ ref('int_zendesk__schedule_spine') }}\n\n), sla_policy_applied as (\n \n  select *\n  from {{ ref('int_zendesk__sla_policy_applied') }}\n\n\n), schedule_business_hours as (\n\n  select \n    schedule_id,\n    sum(end_time - start_time) as total_schedule_weekly_business_minutes\n  -- referrinng to stg_zendesk__schedule instead of int_zendesk__schedule_spine just to calculcate total minutes\n  from {{ ref('stg_zendesk__schedule') }}\n  group by 1\n\n), ticket_sla_applied_with_schedules as (\n\n  select \n    sla_policy_applied.*,\n    ticket_schedules.schedule_id,\n    (\n      {{ fivetran_utils.timestamp_diff(\n        \"\" ~ dbt_utils.date_trunc('week', 'sla_policy_applied.sla_applied_at') ~ \"\",\n        'sla_policy_applied.sla_applied_at', \n        'second') }} /60\n      ) as start_time_in_minutes_from_week,\n      schedule_business_hours.total_schedule_weekly_business_minutes\n  from sla_policy_applied\n  left join ticket_schedules on sla_policy_applied.ticket_id = ticket_schedules.ticket_id\n    and {{ fivetran_utils.timestamp_add('second', -1, 'ticket_schedules.schedule_created_at') }} <= sla_policy_applied.sla_applied_at\n    and {{ fivetran_utils.timestamp_add('second', -1, 'ticket_schedules.schedule_invalidated_at') }} > sla_policy_applied.sla_applied_at\n  left join schedule_business_hours \n    on ticket_schedules.schedule_id = schedule_business_hours.schedule_id\n  where sla_policy_applied.in_business_hours\n    and metric in ('next_reply_time', 'first_reply_time')\n  \n), weeks as (\n\n    {{ dbt_utils.generate_series(208) }}\n\n), weeks_cross_ticket_sla_applied as (\n    -- because time is reported in minutes since the beginning of the week, we have to split up time spent on the ticket into calendar weeks\n    select \n\n      ticket_sla_applied_with_schedules.*,\n      generated_number - 1 as week_number\n\n    from ticket_sla_applied_with_schedules\n    cross join weeks\n    where {{ fivetran_utils.ceiling('target/total_schedule_weekly_business_minutes') }} >= generated_number - 1\n\n), weekly_periods as (\n  \n  select \n    weeks_cross_ticket_sla_applied.*,\n    greatest(0, start_time_in_minutes_from_week - week_number * (7*24*60)) as ticket_week_start_time,\n    (7*24*60) as ticket_week_end_time\n  from weeks_cross_ticket_sla_applied\n\n), intercepted_periods as (\n\n  select \n    weekly_periods.*,\n    schedule.start_time_utc as schedule_start_time,\n    schedule.end_time_utc as schedule_end_time,\n    (schedule.end_time_utc - greatest(ticket_week_start_time,schedule.start_time_utc)) as lapsed_business_minutes,\n    sum(schedule.end_time_utc - greatest(ticket_week_start_time,schedule.start_time_utc)) over \n      (partition by ticket_id, metric, sla_applied_at \n        order by week_number, schedule.start_time_utc\n        rows between unbounded preceding and current row) as sum_lapsed_business_minutes\n  from weekly_periods\n  join schedule on ticket_week_start_time <= schedule.end_time_utc \n    and ticket_week_end_time >= schedule.start_time_utc\n    and weekly_periods.schedule_id = schedule.schedule_id\n    -- this chooses the Daylight Savings Time or Standard Time version of the schedule\n    and weekly_periods.sla_applied_at >= cast(schedule.valid_from as {{ dbt_utils.type_timestamp() }})\n    and weekly_periods.sla_applied_at < cast(schedule.valid_until as {{ dbt_utils.type_timestamp() }})\n  \n), intercepted_periods_with_breach_flag as (\n  \n  select \n    *,\n    target - sum_lapsed_business_minutes as remaining_minutes,\n    case when (target - sum_lapsed_business_minutes) < 0 \n      and \n        (lag(target - sum_lapsed_business_minutes) over\n        (partition by ticket_id, metric, sla_applied_at order by week_number, schedule_start_time) >= 0 \n        or \n        lag(target - sum_lapsed_business_minutes) over\n        (partition by ticket_id, metric, sla_applied_at order by week_number, schedule_start_time) is null) \n        then true else false end as is_breached_during_schedule -- this flags the scheduled period on which the breach took place\n  from intercepted_periods\n\n), intercepted_periods_with_breach_flag_calculated as (\n\n  select\n    *,\n    schedule_end_time + remaining_minutes as breached_at_minutes,\n    {{ dbt_utils.date_trunc('week', 'sla_applied_at') }} as starting_point,\n    {{ fivetran_utils.timestamp_add(\n        \"minute\",\n        \"cast(((7*24*60) * week_number) + (schedule_end_time + remaining_minutes) as \" ~ dbt_utils.type_int() ~ \" )\",\n        \"\" ~ dbt_utils.date_trunc('week', 'sla_applied_at') ~ \"\" ) }} as sla_breach_at\n  from intercepted_periods_with_breach_flag\n\n), reply_time_business_hours_sla as (\n\n  select\n    ticket_id,\n    sla_policy_name,\n    metric,\n    sla_applied_at,\n    target,\n    in_business_hours,\n    sla_breach_at,\n    is_breached_during_schedule\n  from intercepted_periods_with_breach_flag_calculated\n\n) \n\nselect * \nfrom reply_time_business_hours_sla", "compiled": true, "resource_type": "model", "depends_on": {"macros": ["macro.dbt_utils.date_trunc", "macro.fivetran_utils.timestamp_diff", "macro.fivetran_utils.timestamp_add", "macro.dbt_utils.generate_series", "macro.fivetran_utils.ceiling", "macro.dbt_utils.type_timestamp", "macro.dbt_utils.type_int"], "nodes": ["model.zendesk.int_zendesk__ticket_schedules", "model.zendesk.int_zendesk__schedule_spine", "model.zendesk.int_zendesk__sla_policy_applied", "model.zendesk_source.stg_zendesk__schedule"]}, "config": {"enabled": true, "alias": null, "schema": "zendesk_docs", "database": null, "tags": [], "meta": {}, "materialized": "table", "persist_docs": {}, "quoting": {}, "column_types": {}, "full_refresh": null, "on_schema_change": "ignore", "post-hook": [], "pre-hook": []}, "database": "bq-project", "schema": "dbt_joe_zendesk_docs", "fqn": ["zendesk", "sla_policy", "reply_time", "int_zendesk__reply_time_business_hours"], "unique_id": "model.zendesk.int_zendesk__reply_time_business_hours", "package_name": "zendesk", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/zendesk", "path": "sla_policy/reply_time/int_zendesk__reply_time_business_hours.sql", "original_file_path": "models/sla_policy/reply_time/int_zendesk__reply_time_business_hours.sql", "name": "int_zendesk__reply_time_business_hours", "alias": "int_zendesk__reply_time_business_hours", "checksum": {"name": "sha256", "checksum": "87eceff2982df3af12b5d36eb097db7f6d950c21fbf489c624b83885e65f0434"}, "tags": [], "refs": [["int_zendesk__ticket_schedules"], ["int_zendesk__schedule_spine"], ["int_zendesk__sla_policy_applied"], ["stg_zendesk__schedule"]], "sources": [], "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "compiled_path": "target/compiled/zendesk/models/sla_policy/reply_time/int_zendesk__reply_time_business_hours.sql", "build_path": null, "deferred": false, "unrendered_config": {"schema": "zendesk_docs", "materialized": "table", "enabled": true}, "created_at": 1647014737.063242, "compiled_sql": "\n\n-- step 3, determine when an SLA will breach for SLAs that are in business hours\n\nwith ticket_schedules as (\n \n  select *\n  from `bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__ticket_schedules`\n\n), schedule as (\n \n  select *\n  from `bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__schedule_spine`\n\n), sla_policy_applied as (\n \n  select *\n  from `bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__sla_policy_applied`\n\n\n), schedule_business_hours as (\n\n  select \n    schedule_id,\n    sum(end_time - start_time) as total_schedule_weekly_business_minutes\n  -- referrinng to stg_zendesk__schedule instead of int_zendesk__schedule_spine just to calculcate total minutes\n  from `bq-project`.`dbt_joe_zendesk_docs`.`stg_zendesk__schedule`\n  group by 1\n\n), ticket_sla_applied_with_schedules as (\n\n  select \n    sla_policy_applied.*,\n    ticket_schedules.schedule_id,\n    (\n      \n  \n\n    timestamp_diff(\n        sla_policy_applied.sla_applied_at,\n        \n    timestamp_trunc(\n        cast(sla_policy_applied.sla_applied_at as timestamp),\n        week\n    )\n\n,\n        second\n    )\n\n\n /60\n      ) as start_time_in_minutes_from_week,\n      schedule_business_hours.total_schedule_weekly_business_minutes\n  from sla_policy_applied\n  left join ticket_schedules on sla_policy_applied.ticket_id = ticket_schedules.ticket_id\n    and \n\n        timestamp_add(ticket_schedules.schedule_created_at, interval  -1 second)\n\n <= sla_policy_applied.sla_applied_at\n    and \n\n        timestamp_add(ticket_schedules.schedule_invalidated_at, interval  -1 second)\n\n > sla_policy_applied.sla_applied_at\n  left join schedule_business_hours \n    on ticket_schedules.schedule_id = schedule_business_hours.schedule_id\n  where sla_policy_applied.in_business_hours\n    and metric in ('next_reply_time', 'first_reply_time')\n  \n), weeks as (\n\n    \n\n    \n\n    with p as (\n        select 0 as generated_number union all select 1\n    ), unioned as (\n\n    select\n\n    \n    p0.generated_number * power(2, 0)\n     + \n    \n    p1.generated_number * power(2, 1)\n     + \n    \n    p2.generated_number * power(2, 2)\n     + \n    \n    p3.generated_number * power(2, 3)\n     + \n    \n    p4.generated_number * power(2, 4)\n     + \n    \n    p5.generated_number * power(2, 5)\n     + \n    \n    p6.generated_number * power(2, 6)\n     + \n    \n    p7.generated_number * power(2, 7)\n    \n    \n    + 1\n    as generated_number\n\n    from\n\n    \n    p as p0\n     cross join \n    \n    p as p1\n     cross join \n    \n    p as p2\n     cross join \n    \n    p as p3\n     cross join \n    \n    p as p4\n     cross join \n    \n    p as p5\n     cross join \n    \n    p as p6\n     cross join \n    \n    p as p7\n    \n    \n\n    )\n\n    select *\n    from unioned\n    where generated_number <= 208\n    order by generated_number\n\n\n\n), weeks_cross_ticket_sla_applied as (\n    -- because time is reported in minutes since the beginning of the week, we have to split up time spent on the ticket into calendar weeks\n    select \n\n      ticket_sla_applied_with_schedules.*,\n      generated_number - 1 as week_number\n\n    from ticket_sla_applied_with_schedules\n    cross join weeks\n    where \n    ceiling(target/total_schedule_weekly_business_minutes)\n\n >= generated_number - 1\n\n), weekly_periods as (\n  \n  select \n    weeks_cross_ticket_sla_applied.*,\n    greatest(0, start_time_in_minutes_from_week - week_number * (7*24*60)) as ticket_week_start_time,\n    (7*24*60) as ticket_week_end_time\n  from weeks_cross_ticket_sla_applied\n\n), intercepted_periods as (\n\n  select \n    weekly_periods.*,\n    schedule.start_time_utc as schedule_start_time,\n    schedule.end_time_utc as schedule_end_time,\n    (schedule.end_time_utc - greatest(ticket_week_start_time,schedule.start_time_utc)) as lapsed_business_minutes,\n    sum(schedule.end_time_utc - greatest(ticket_week_start_time,schedule.start_time_utc)) over \n      (partition by ticket_id, metric, sla_applied_at \n        order by week_number, schedule.start_time_utc\n        rows between unbounded preceding and current row) as sum_lapsed_business_minutes\n  from weekly_periods\n  join schedule on ticket_week_start_time <= schedule.end_time_utc \n    and ticket_week_end_time >= schedule.start_time_utc\n    and weekly_periods.schedule_id = schedule.schedule_id\n    -- this chooses the Daylight Savings Time or Standard Time version of the schedule\n    and weekly_periods.sla_applied_at >= cast(schedule.valid_from as \n    timestamp\n)\n    and weekly_periods.sla_applied_at < cast(schedule.valid_until as \n    timestamp\n)\n  \n), intercepted_periods_with_breach_flag as (\n  \n  select \n    *,\n    target - sum_lapsed_business_minutes as remaining_minutes,\n    case when (target - sum_lapsed_business_minutes) < 0 \n      and \n        (lag(target - sum_lapsed_business_minutes) over\n        (partition by ticket_id, metric, sla_applied_at order by week_number, schedule_start_time) >= 0 \n        or \n        lag(target - sum_lapsed_business_minutes) over\n        (partition by ticket_id, metric, sla_applied_at order by week_number, schedule_start_time) is null) \n        then true else false end as is_breached_during_schedule -- this flags the scheduled period on which the breach took place\n  from intercepted_periods\n\n), intercepted_periods_with_breach_flag_calculated as (\n\n  select\n    *,\n    schedule_end_time + remaining_minutes as breached_at_minutes,\n    \n    timestamp_trunc(\n        cast(sla_applied_at as timestamp),\n        week\n    )\n\n as starting_point,\n    \n\n        timestamp_add(\n    timestamp_trunc(\n        cast(sla_applied_at as timestamp),\n        week\n    )\n\n, interval  cast(((7*24*60) * week_number) + (schedule_end_time + remaining_minutes) as \n    int64\n ) minute)\n\n as sla_breach_at\n  from intercepted_periods_with_breach_flag\n\n), reply_time_business_hours_sla as (\n\n  select\n    ticket_id,\n    sla_policy_name,\n    metric,\n    sla_applied_at,\n    target,\n    in_business_hours,\n    sla_breach_at,\n    is_breached_during_schedule\n  from intercepted_periods_with_breach_flag_calculated\n\n) \n\nselect * \nfrom reply_time_business_hours_sla", "extra_ctes_injected": true, "extra_ctes": [], "relation_name": "`bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__reply_time_business_hours`"}, "model.zendesk.int_zendesk__reply_time_calendar_hours": {"raw_sql": "--REPLY TIME SLA\n-- step 2, figure out when the sla will breach for sla's in calendar hours. The calculation is relatively straightforward.\n\nwith sla_policy_applied as (\n\n  select *\n  from {{ ref('int_zendesk__sla_policy_applied') }}\n\n), final as (\n  select\n    *,\n    {{ fivetran_utils.timestamp_add(\n        \"minute\",\n        \"cast(target as \" ~ dbt_utils.type_int() ~ \" )\",\n        \"sla_applied_at\" ) }} as sla_breach_at\n  from sla_policy_applied\n  where not in_business_hours\n    and metric in ('next_reply_time', 'first_reply_time')\n\n)\n\nselect *\nfrom final", "compiled": true, "resource_type": "model", "depends_on": {"macros": ["macro.dbt_utils.type_int", "macro.fivetran_utils.timestamp_add"], "nodes": ["model.zendesk.int_zendesk__sla_policy_applied"]}, "config": {"enabled": true, "alias": null, "schema": "zendesk_docs", "database": null, "tags": [], "meta": {}, "materialized": "table", "persist_docs": {}, "quoting": {}, "column_types": {}, "full_refresh": null, "on_schema_change": "ignore", "post-hook": [], "pre-hook": []}, "database": "bq-project", "schema": "dbt_joe_zendesk_docs", "fqn": ["zendesk", "sla_policy", "reply_time", "int_zendesk__reply_time_calendar_hours"], "unique_id": "model.zendesk.int_zendesk__reply_time_calendar_hours", "package_name": "zendesk", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/zendesk", "path": "sla_policy/reply_time/int_zendesk__reply_time_calendar_hours.sql", "original_file_path": "models/sla_policy/reply_time/int_zendesk__reply_time_calendar_hours.sql", "name": "int_zendesk__reply_time_calendar_hours", "alias": "int_zendesk__reply_time_calendar_hours", "checksum": {"name": "sha256", "checksum": "c870f34e14c4245c2a43c5403ef7b9948d776e99dbe703e7fdcba4acc6f2f505"}, "tags": [], "refs": [["int_zendesk__sla_policy_applied"]], "sources": [], "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "compiled_path": "target/compiled/zendesk/models/sla_policy/reply_time/int_zendesk__reply_time_calendar_hours.sql", "build_path": null, "deferred": false, "unrendered_config": {"schema": "zendesk_docs", "materialized": "table"}, "created_at": 1647014737.077785, "compiled_sql": "--REPLY TIME SLA\n-- step 2, figure out when the sla will breach for sla's in calendar hours. The calculation is relatively straightforward.\n\nwith sla_policy_applied as (\n\n  select *\n  from `bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__sla_policy_applied`\n\n), final as (\n  select\n    *,\n    \n\n        timestamp_add(sla_applied_at, interval  cast(target as \n    int64\n ) minute)\n\n as sla_breach_at\n  from sla_policy_applied\n  where not in_business_hours\n    and metric in ('next_reply_time', 'first_reply_time')\n\n)\n\nselect *\nfrom final", "extra_ctes_injected": true, "extra_ctes": [], "relation_name": "`bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__reply_time_calendar_hours`"}, "model.zendesk.int_zendesk__reply_time_combined": {"raw_sql": "with reply_time_calendar_hours_sla as (\n  \n  select *\n  from {{ ref('int_zendesk__reply_time_calendar_hours') }}\n\n{% if var('using_schedules', True) %}\n\n), reply_time_business_hours_sla as (\n \n  select *\n  from {{ ref('int_zendesk__reply_time_business_hours') }}\n\n{% endif %}\n\n), ticket_updates as (\n  select *\n  from {{ ref('int_zendesk__updates') }}\n\n), users as (\n \n  select *\n  from {{ ref('int_zendesk__user_aggregates') }}\n\n), reply_time_breached_at as (\n\n  select \n    ticket_id,\n    sla_policy_name,\n    metric,\n    sla_applied_at,\n    target,\n    in_business_hours,\n    sla_breach_at\n  from reply_time_calendar_hours_sla\n\n{% if var('using_schedules', True) %}\n\n  union all\n\n  select \n    ticket_id,\n    sla_policy_name,\n    metric,\n    sla_applied_at,\n    target,\n    in_business_hours,\n    sla_breach_at\n  from reply_time_business_hours_sla\n{% endif %}\n\n-- Now that we have the breach time, see when the first reply after the sla policy was applied took place.\n), ticket_solved_times as (\n  select\n    ticket_id,\n    valid_starting_at as solved_at\n  from ticket_updates\n  where field_name = 'status'\n  and value in ('solved','closed')\n\n), reply_time as (\n    select \n      ticket_comment.ticket_id,\n      ticket_comment.valid_starting_at as reply_at,\n      commenter.role\n    from ticket_updates as ticket_comment\n    join users as commenter\n      on commenter.user_id = ticket_comment.user_id\n    where field_name = 'comment' \n      and ticket_comment.is_public\n      and commenter.role in ('agent','admin')\n\n), reply_time_breached_at_with_next_reply_timestamp as (\n\n  select \n    reply_time_breached_at.ticket_id,\n    reply_time_breached_at.sla_policy_name,\n    reply_time_breached_at.metric,\n    reply_time_breached_at.sla_applied_at,\n    reply_time_breached_at.target,\n    reply_time_breached_at.in_business_hours,\n    min(sla_breach_at) as sla_breach_at,\n    min(reply_at) as agent_reply_at,\n    min(solved_at) as next_solved_at\n  from reply_time_breached_at\n  left join reply_time\n    on reply_time.ticket_id = reply_time_breached_at.ticket_id\n    and reply_time.reply_at > reply_time_breached_at.sla_applied_at\n  left join ticket_solved_times\n    on reply_time_breached_at.ticket_id = ticket_solved_times.ticket_id\n    and ticket_solved_times.solved_at > reply_time_breached_at.sla_applied_at\n  {{ dbt_utils.group_by(n=6) }}\n\n), reply_time_breached_at_remove_old_sla as (\n  select \n    *,\n    lead(sla_applied_at) over (partition by ticket_id, metric, in_business_hours order by sla_applied_at) as updated_sla_policy_starts_at,\n    case when \n      lead(sla_applied_at) over (partition by ticket_id, metric, in_business_hours order by sla_applied_at) --updated sla policy start at time\n      < sla_breach_at then true else false end as is_stale_sla_policy,\n    case when (sla_breach_at < agent_reply_at and sla_breach_at < next_solved_at)\n                or (sla_breach_at < agent_reply_at and next_solved_at is null)\n                or (agent_reply_at is null and sla_breach_at < next_solved_at)\n                or (agent_reply_at is null and next_solved_at is null)\n      then true\n      else false\n        end as is_sla_breached\n  from reply_time_breached_at_with_next_reply_timestamp\n  \n), reply_time_breach as (\n  select \n    *,\n    {{ dbt_utils.datediff(\"sla_applied_at\", \"agent_reply_at\", 'minute') }} as sla_elapsed_time\n  from reply_time_breached_at_remove_old_sla\n)\n\nselect *\nfrom reply_time_breach", "compiled": true, "resource_type": "model", "depends_on": {"macros": ["macro.dbt_utils.group_by", "macro.dbt_utils.datediff"], "nodes": ["model.zendesk.int_zendesk__reply_time_calendar_hours", "model.zendesk.int_zendesk__reply_time_business_hours", "model.zendesk.int_zendesk__updates", "model.zendesk.int_zendesk__user_aggregates"]}, "config": {"enabled": true, "alias": null, "schema": "zendesk_docs", "database": null, "tags": [], "meta": {}, "materialized": "table", "persist_docs": {}, "quoting": {}, "column_types": {}, "full_refresh": null, "on_schema_change": "ignore", "post-hook": [], "pre-hook": []}, "database": "bq-project", "schema": "dbt_joe_zendesk_docs", "fqn": ["zendesk", "sla_policy", "reply_time", "int_zendesk__reply_time_combined"], "unique_id": "model.zendesk.int_zendesk__reply_time_combined", "package_name": "zendesk", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/zendesk", "path": "sla_policy/reply_time/int_zendesk__reply_time_combined.sql", "original_file_path": "models/sla_policy/reply_time/int_zendesk__reply_time_combined.sql", "name": "int_zendesk__reply_time_combined", "alias": "int_zendesk__reply_time_combined", "checksum": {"name": "sha256", "checksum": "18e90d37086ff809133e4c8f66c024ecb244a80fd8fdc65600a3d81272faaa0f"}, "tags": [], "refs": [["int_zendesk__reply_time_calendar_hours"], ["int_zendesk__reply_time_business_hours"], ["int_zendesk__updates"], ["int_zendesk__user_aggregates"]], "sources": [], "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "compiled_path": "target/compiled/zendesk/models/sla_policy/reply_time/int_zendesk__reply_time_combined.sql", "build_path": null, "deferred": false, "unrendered_config": {"schema": "zendesk_docs", "materialized": "table"}, "created_at": 1647014737.0837991, "compiled_sql": "with reply_time_calendar_hours_sla as (\n  \n  select *\n  from `bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__reply_time_calendar_hours`\n\n\n\n), reply_time_business_hours_sla as (\n \n  select *\n  from `bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__reply_time_business_hours`\n\n\n\n), ticket_updates as (\n  select *\n  from `bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__updates`\n\n), users as (\n \n  select *\n  from `bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__user_aggregates`\n\n), reply_time_breached_at as (\n\n  select \n    ticket_id,\n    sla_policy_name,\n    metric,\n    sla_applied_at,\n    target,\n    in_business_hours,\n    sla_breach_at\n  from reply_time_calendar_hours_sla\n\n\n\n  union all\n\n  select \n    ticket_id,\n    sla_policy_name,\n    metric,\n    sla_applied_at,\n    target,\n    in_business_hours,\n    sla_breach_at\n  from reply_time_business_hours_sla\n\n\n-- Now that we have the breach time, see when the first reply after the sla policy was applied took place.\n), ticket_solved_times as (\n  select\n    ticket_id,\n    valid_starting_at as solved_at\n  from ticket_updates\n  where field_name = 'status'\n  and value in ('solved','closed')\n\n), reply_time as (\n    select \n      ticket_comment.ticket_id,\n      ticket_comment.valid_starting_at as reply_at,\n      commenter.role\n    from ticket_updates as ticket_comment\n    join users as commenter\n      on commenter.user_id = ticket_comment.user_id\n    where field_name = 'comment' \n      and ticket_comment.is_public\n      and commenter.role in ('agent','admin')\n\n), reply_time_breached_at_with_next_reply_timestamp as (\n\n  select \n    reply_time_breached_at.ticket_id,\n    reply_time_breached_at.sla_policy_name,\n    reply_time_breached_at.metric,\n    reply_time_breached_at.sla_applied_at,\n    reply_time_breached_at.target,\n    reply_time_breached_at.in_business_hours,\n    min(sla_breach_at) as sla_breach_at,\n    min(reply_at) as agent_reply_at,\n    min(solved_at) as next_solved_at\n  from reply_time_breached_at\n  left join reply_time\n    on reply_time.ticket_id = reply_time_breached_at.ticket_id\n    and reply_time.reply_at > reply_time_breached_at.sla_applied_at\n  left join ticket_solved_times\n    on reply_time_breached_at.ticket_id = ticket_solved_times.ticket_id\n    and ticket_solved_times.solved_at > reply_time_breached_at.sla_applied_at\n  group by 1,2,3,4,5,6\n\n), reply_time_breached_at_remove_old_sla as (\n  select \n    *,\n    lead(sla_applied_at) over (partition by ticket_id, metric, in_business_hours order by sla_applied_at) as updated_sla_policy_starts_at,\n    case when \n      lead(sla_applied_at) over (partition by ticket_id, metric, in_business_hours order by sla_applied_at) --updated sla policy start at time\n      < sla_breach_at then true else false end as is_stale_sla_policy,\n    case when (sla_breach_at < agent_reply_at and sla_breach_at < next_solved_at)\n                or (sla_breach_at < agent_reply_at and next_solved_at is null)\n                or (agent_reply_at is null and sla_breach_at < next_solved_at)\n                or (agent_reply_at is null and next_solved_at is null)\n      then true\n      else false\n        end as is_sla_breached\n  from reply_time_breached_at_with_next_reply_timestamp\n  \n), reply_time_breach as (\n  select \n    *,\n    \n\n    datetime_diff(\n        cast(agent_reply_at as datetime),\n        cast(sla_applied_at as datetime),\n        minute\n    )\n\n as sla_elapsed_time\n  from reply_time_breached_at_remove_old_sla\n)\n\nselect *\nfrom reply_time_breach", "extra_ctes_injected": true, "extra_ctes": [], "relation_name": "`bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__reply_time_combined`"}, "model.zendesk.int_zendesk__requester_wait_time_calendar_hours": {"raw_sql": "-- Calculate breach time for requester wait time, calendar hours\nwith requester_wait_time_filtered_statuses as (\n\n  select *\n  from {{ ref('int_zendesk__requester_wait_time_filtered_statuses') }}\n  where not in_business_hours\n\n), requester_wait_time_calendar_minutes as (\n\n  select \n    *,\n    {{ fivetran_utils.timestamp_diff(\n        'valid_starting_at',\n        'valid_ending_at',\n        'minute' )}} as calendar_minutes,\n    sum({{ fivetran_utils.timestamp_diff(\n            'valid_starting_at', \n            'valid_ending_at', \n            'minute') }} ) \n      over (partition by ticket_id, sla_applied_at order by valid_starting_at rows between unbounded preceding and current row) as running_total_calendar_minutes\n  from requester_wait_time_filtered_statuses\n\n), requester_wait_time_calendar_minutes_flagged as (\n\nselect \n  requester_wait_time_calendar_minutes.*,\n  target - running_total_calendar_minutes as remaining_target_minutes,\n  case when (target - running_total_calendar_minutes) < 0 \n      and \n        (lag(target - running_total_calendar_minutes) over\n        (partition by ticket_id, sla_applied_at order by valid_starting_at) >= 0 \n        or \n        lag(target - running_total_calendar_minutes) over\n        (partition by ticket_id, sla_applied_at order by valid_starting_at) is null) \n        then true else false end as is_breached_during_schedule\n        \nfrom  requester_wait_time_calendar_minutes\n\n), final as (\n  select\n    *,\n    (remaining_target_minutes + calendar_minutes) as breach_minutes,\n    {{ fivetran_utils.timestamp_add(\n      'minute',\n      '(remaining_target_minutes + calendar_minutes)',\n      'valid_starting_at', \n      ) }} as sla_breach_at\n  from requester_wait_time_calendar_minutes_flagged\n\n)\n\nselect *\nfrom final", "compiled": true, "resource_type": "model", "depends_on": {"macros": ["macro.fivetran_utils.timestamp_diff", "macro.fivetran_utils.timestamp_add"], "nodes": ["model.zendesk.int_zendesk__requester_wait_time_filtered_statuses"]}, "config": {"enabled": true, "alias": null, "schema": "zendesk_docs", "database": null, "tags": [], "meta": {}, "materialized": "table", "persist_docs": {}, "quoting": {}, "column_types": {}, "full_refresh": null, "on_schema_change": "ignore", "post-hook": [], "pre-hook": []}, "database": "bq-project", "schema": "dbt_joe_zendesk_docs", "fqn": ["zendesk", "sla_policy", "requester_wait_time", "int_zendesk__requester_wait_time_calendar_hours"], "unique_id": "model.zendesk.int_zendesk__requester_wait_time_calendar_hours", "package_name": "zendesk", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/zendesk", "path": "sla_policy/requester_wait_time/int_zendesk__requester_wait_time_calendar_hours.sql", "original_file_path": "models/sla_policy/requester_wait_time/int_zendesk__requester_wait_time_calendar_hours.sql", "name": "int_zendesk__requester_wait_time_calendar_hours", "alias": "int_zendesk__requester_wait_time_calendar_hours", "checksum": {"name": "sha256", "checksum": "d470116638c80eb24b44bb55e08f6feb8fb676924af4782e65125cac40a004dd"}, "tags": [], "refs": [["int_zendesk__requester_wait_time_filtered_statuses"]], "sources": [], "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "compiled_path": "target/compiled/zendesk/models/sla_policy/requester_wait_time/int_zendesk__requester_wait_time_calendar_hours.sql", "build_path": null, "deferred": false, "unrendered_config": {"schema": "zendesk_docs", "materialized": "table"}, "created_at": 1647014737.091695, "compiled_sql": "-- Calculate breach time for requester wait time, calendar hours\nwith requester_wait_time_filtered_statuses as (\n\n  select *\n  from `bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__requester_wait_time_filtered_statuses`\n  where not in_business_hours\n\n), requester_wait_time_calendar_minutes as (\n\n  select \n    *,\n    \n  \n\n    timestamp_diff(\n        valid_ending_at,\n        valid_starting_at,\n        minute\n    )\n\n\n as calendar_minutes,\n    sum(\n  \n\n    timestamp_diff(\n        valid_ending_at,\n        valid_starting_at,\n        minute\n    )\n\n\n ) \n      over (partition by ticket_id, sla_applied_at order by valid_starting_at rows between unbounded preceding and current row) as running_total_calendar_minutes\n  from requester_wait_time_filtered_statuses\n\n), requester_wait_time_calendar_minutes_flagged as (\n\nselect \n  requester_wait_time_calendar_minutes.*,\n  target - running_total_calendar_minutes as remaining_target_minutes,\n  case when (target - running_total_calendar_minutes) < 0 \n      and \n        (lag(target - running_total_calendar_minutes) over\n        (partition by ticket_id, sla_applied_at order by valid_starting_at) >= 0 \n        or \n        lag(target - running_total_calendar_minutes) over\n        (partition by ticket_id, sla_applied_at order by valid_starting_at) is null) \n        then true else false end as is_breached_during_schedule\n        \nfrom  requester_wait_time_calendar_minutes\n\n), final as (\n  select\n    *,\n    (remaining_target_minutes + calendar_minutes) as breach_minutes,\n    \n\n        timestamp_add(valid_starting_at, interval  (remaining_target_minutes + calendar_minutes) minute)\n\n as sla_breach_at\n  from requester_wait_time_calendar_minutes_flagged\n\n)\n\nselect *\nfrom final", "extra_ctes_injected": true, "extra_ctes": [], "relation_name": "`bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__requester_wait_time_calendar_hours`"}, "model.zendesk.int_zendesk__requester_wait_time_business_hours": {"raw_sql": "{{ config(enabled=var('using_schedules', True)) }}\n\n-- REQUESTER WAIT TIME\n-- This is complicated, as SLAs minutes are only counted while the ticket is in 'new', 'open', and 'on-hold' status.\n\n-- Additionally, for business hours, only 'new', 'open', and 'on-hold' status hours are counted if they are also during business hours\nwith requester_wait_time_filtered_statuses as (\n\n  select *\n  from {{ ref('int_zendesk__requester_wait_time_filtered_statuses') }}\n  where in_business_hours\n\n), schedule as (\n\n  select * \n  from {{ ref('int_zendesk__schedule_spine') }}\n\n), ticket_schedules as (\n\n  select * \n  from {{ ref('int_zendesk__ticket_schedules') }}\n  \n-- cross schedules with work time\n), ticket_status_crossed_with_schedule as (\n  \n    select\n      requester_wait_time_filtered_statuses.ticket_id,\n      requester_wait_time_filtered_statuses.sla_applied_at,\n      requester_wait_time_filtered_statuses.target,\n      requester_wait_time_filtered_statuses.sla_policy_name,\n      ticket_schedules.schedule_id,\n\n      -- take the intersection of the intervals in which the status and the schedule were both active, for calculating the business minutes spent working on the ticket\n      greatest(valid_starting_at, schedule_created_at) as valid_starting_at,\n      least(valid_ending_at, schedule_invalidated_at) as valid_ending_at,\n\n      -- bringing the following in the determine which schedule (Daylight Savings vs Standard time) to use\n      valid_starting_at as status_valid_starting_at,\n      valid_ending_at as status_valid_ending_at\n\n    from requester_wait_time_filtered_statuses\n    left join ticket_schedules\n      on requester_wait_time_filtered_statuses.ticket_id = ticket_schedules.ticket_id\n    where {{ fivetran_utils.timestamp_diff(\n              'greatest(valid_starting_at, schedule_created_at)', \n              'least(valid_ending_at, schedule_invalidated_at)', \n              'second') }} > 0\n\n), ticket_full_solved_time as (\n\n    select \n      ticket_status_crossed_with_schedule.*,\n      ({{ fivetran_utils.timestamp_diff(\n              \"\" ~ dbt_utils.date_trunc(\n                  'week',\n                  'ticket_status_crossed_with_schedule.valid_starting_at') ~ \"\", \n              'ticket_status_crossed_with_schedule.valid_starting_at', \n              'second') }} /60\n            ) as valid_starting_at_in_minutes_from_week,\n      ({{ fivetran_utils.timestamp_diff(\n              'ticket_status_crossed_with_schedule.valid_starting_at', \n              'ticket_status_crossed_with_schedule.valid_ending_at',\n              'second') }} /60\n            ) as raw_delta_in_minutes\n    from ticket_status_crossed_with_schedule\n    {{ dbt_utils.group_by(n=10) }}\n\n), weeks as (\n\n    {{ dbt_utils.generate_series(208) }}\n\n), weeks_cross_ticket_full_solved_time as (\n    -- because time is reported in minutes since the beginning of the week, we have to split up time spent on the ticket into calendar weeks\n    select \n      ticket_full_solved_time.*,\n      generated_number - 1 as week_number\n    from ticket_full_solved_time\n    cross join weeks\n    where floor((valid_starting_at_in_minutes_from_week + raw_delta_in_minutes) / (7*24*60)) >= generated_number -1\n\n), weekly_period_requester_wait_time as (\n\n    select \n\n      ticket_id,\n      sla_applied_at,\n      valid_starting_at,\n      valid_ending_at,\n      status_valid_starting_at,\n      status_valid_ending_at,\n      target,\n      sla_policy_name,\n      valid_starting_at_in_minutes_from_week,\n      raw_delta_in_minutes,\n      week_number,\n      schedule_id,\n      greatest(0, valid_starting_at_in_minutes_from_week - week_number * (7*24*60)) as ticket_week_start_time_minute,\n      least(valid_starting_at_in_minutes_from_week + raw_delta_in_minutes - week_number * (7*24*60), (7*24*60)) as ticket_week_end_time_minute\n    \n    from weeks_cross_ticket_full_solved_time\n\n), intercepted_periods_agent as (\n  \n    select \n      weekly_period_requester_wait_time.ticket_id,\n      weekly_period_requester_wait_time.sla_applied_at,\n      weekly_period_requester_wait_time.target,\n      weekly_period_requester_wait_time.sla_policy_name,\n      weekly_period_requester_wait_time.valid_starting_at,\n      weekly_period_requester_wait_time.valid_ending_at,\n      weekly_period_requester_wait_time.week_number,\n      weekly_period_requester_wait_time.ticket_week_start_time_minute,\n      weekly_period_requester_wait_time.ticket_week_end_time_minute,\n      schedule.start_time_utc as schedule_start_time,\n      schedule.end_time_utc as schedule_end_time,\n      least(ticket_week_end_time_minute, schedule.end_time_utc) - greatest(weekly_period_requester_wait_time.ticket_week_start_time_minute, schedule.start_time_utc) as scheduled_minutes\n    from weekly_period_requester_wait_time\n    join schedule on ticket_week_start_time_minute <= schedule.end_time_utc \n      and ticket_week_end_time_minute >= schedule.start_time_utc\n      and weekly_period_requester_wait_time.schedule_id = schedule.schedule_id\n      -- this chooses the Daylight Savings Time or Standard Time version of the schedule\n      and weekly_period_requester_wait_time.status_valid_ending_at >= cast(schedule.valid_from as {{ dbt_utils.type_timestamp() }})\n      and weekly_period_requester_wait_time.status_valid_starting_at < cast(schedule.valid_until as {{ dbt_utils.type_timestamp() }}) \n\n), intercepted_periods_with_running_total as (\n  \n    select \n      *,\n      sum(scheduled_minutes) over \n        (partition by ticket_id, sla_applied_at \n          order by valid_starting_at, week_number, schedule_end_time\n          rows between unbounded preceding and current row)\n        as running_total_scheduled_minutes\n\n    from intercepted_periods_agent\n\n\n), intercepted_periods_agent_with_breach_flag as (\n  select \n    intercepted_periods_with_running_total.*,\n    target - running_total_scheduled_minutes as remaining_target_minutes,\n    lag(target - running_total_scheduled_minutes) over\n          (partition by ticket_id, sla_applied_at order by valid_starting_at, week_number, schedule_end_time) as lag_check,\n    case when (target - running_total_scheduled_minutes) = 0 then true\n       when (target - running_total_scheduled_minutes) < 0 \n        and \n          (lag(target - running_total_scheduled_minutes) over\n          (partition by ticket_id, sla_applied_at order by valid_starting_at, week_number, schedule_end_time) > 0 \n          or \n          lag(target - running_total_scheduled_minutes) over\n          (partition by ticket_id, sla_applied_at order by valid_starting_at, week_number, schedule_end_time) is null) \n          then true else false end as is_breached_during_schedule\n          \n  from  intercepted_periods_with_running_total\n\n), intercepted_periods_agent_filtered as (\n\n  select\n    *,\n    (remaining_target_minutes + scheduled_minutes) as breach_minutes,\n    greatest(ticket_week_start_time_minute, schedule_start_time) + (remaining_target_minutes + scheduled_minutes) as breach_minutes_from_week\n  from intercepted_periods_agent_with_breach_flag\n\n), requester_wait_business_breach as (\n  \n  select \n    *,\n    {{ fivetran_utils.timestamp_add(\n      \"minute\",\n      \"cast(((7*24*60) * week_number) + breach_minutes_from_week as \" ~ dbt_utils.type_int() ~ \" )\",\n      \"\" ~ dbt_utils.date_trunc('week', 'valid_starting_at') ~ \"\",\n      ) }} as sla_breach_at\n  from intercepted_periods_agent_filtered\n\n)\n\nselect * \nfrom requester_wait_business_breach", "compiled": true, "resource_type": "model", "depends_on": {"macros": ["macro.fivetran_utils.timestamp_diff", "macro.dbt_utils.date_trunc", "macro.dbt_utils.group_by", "macro.dbt_utils.generate_series", "macro.dbt_utils.type_timestamp", "macro.dbt_utils.type_int", "macro.fivetran_utils.timestamp_add"], "nodes": ["model.zendesk.int_zendesk__requester_wait_time_filtered_statuses", "model.zendesk.int_zendesk__schedule_spine", "model.zendesk.int_zendesk__ticket_schedules"]}, "config": {"enabled": true, "alias": null, "schema": "zendesk_docs", "database": null, "tags": [], "meta": {}, "materialized": "table", "persist_docs": {}, "quoting": {}, "column_types": {}, "full_refresh": null, "on_schema_change": "ignore", "post-hook": [], "pre-hook": []}, "database": "bq-project", "schema": "dbt_joe_zendesk_docs", "fqn": ["zendesk", "sla_policy", "requester_wait_time", "int_zendesk__requester_wait_time_business_hours"], "unique_id": "model.zendesk.int_zendesk__requester_wait_time_business_hours", "package_name": "zendesk", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/zendesk", "path": "sla_policy/requester_wait_time/int_zendesk__requester_wait_time_business_hours.sql", "original_file_path": "models/sla_policy/requester_wait_time/int_zendesk__requester_wait_time_business_hours.sql", "name": "int_zendesk__requester_wait_time_business_hours", "alias": "int_zendesk__requester_wait_time_business_hours", "checksum": {"name": "sha256", "checksum": "15a77731ce46c1a5f50006a1ec174efcda1a248182029006b9a4a117da3c38fa"}, "tags": [], "refs": [["int_zendesk__requester_wait_time_filtered_statuses"], ["int_zendesk__schedule_spine"], ["int_zendesk__ticket_schedules"]], "sources": [], "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "compiled_path": "target/compiled/zendesk/models/sla_policy/requester_wait_time/int_zendesk__requester_wait_time_business_hours.sql", "build_path": null, "deferred": false, "unrendered_config": {"schema": "zendesk_docs", "materialized": "table", "enabled": true}, "created_at": 1647014737.097878, "compiled_sql": "\n\n-- REQUESTER WAIT TIME\n-- This is complicated, as SLAs minutes are only counted while the ticket is in 'new', 'open', and 'on-hold' status.\n\n-- Additionally, for business hours, only 'new', 'open', and 'on-hold' status hours are counted if they are also during business hours\nwith requester_wait_time_filtered_statuses as (\n\n  select *\n  from `bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__requester_wait_time_filtered_statuses`\n  where in_business_hours\n\n), schedule as (\n\n  select * \n  from `bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__schedule_spine`\n\n), ticket_schedules as (\n\n  select * \n  from `bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__ticket_schedules`\n  \n-- cross schedules with work time\n), ticket_status_crossed_with_schedule as (\n  \n    select\n      requester_wait_time_filtered_statuses.ticket_id,\n      requester_wait_time_filtered_statuses.sla_applied_at,\n      requester_wait_time_filtered_statuses.target,\n      requester_wait_time_filtered_statuses.sla_policy_name,\n      ticket_schedules.schedule_id,\n\n      -- take the intersection of the intervals in which the status and the schedule were both active, for calculating the business minutes spent working on the ticket\n      greatest(valid_starting_at, schedule_created_at) as valid_starting_at,\n      least(valid_ending_at, schedule_invalidated_at) as valid_ending_at,\n\n      -- bringing the following in the determine which schedule (Daylight Savings vs Standard time) to use\n      valid_starting_at as status_valid_starting_at,\n      valid_ending_at as status_valid_ending_at\n\n    from requester_wait_time_filtered_statuses\n    left join ticket_schedules\n      on requester_wait_time_filtered_statuses.ticket_id = ticket_schedules.ticket_id\n    where \n  \n\n    timestamp_diff(\n        least(valid_ending_at, schedule_invalidated_at),\n        greatest(valid_starting_at, schedule_created_at),\n        second\n    )\n\n\n > 0\n\n), ticket_full_solved_time as (\n\n    select \n      ticket_status_crossed_with_schedule.*,\n      (\n  \n\n    timestamp_diff(\n        ticket_status_crossed_with_schedule.valid_starting_at,\n        \n    timestamp_trunc(\n        cast(ticket_status_crossed_with_schedule.valid_starting_at as timestamp),\n        week\n    )\n\n,\n        second\n    )\n\n\n /60\n            ) as valid_starting_at_in_minutes_from_week,\n      (\n  \n\n    timestamp_diff(\n        ticket_status_crossed_with_schedule.valid_ending_at,\n        ticket_status_crossed_with_schedule.valid_starting_at,\n        second\n    )\n\n\n /60\n            ) as raw_delta_in_minutes\n    from ticket_status_crossed_with_schedule\n    group by 1,2,3,4,5,6,7,8,9,10\n\n), weeks as (\n\n    \n\n    \n\n    with p as (\n        select 0 as generated_number union all select 1\n    ), unioned as (\n\n    select\n\n    \n    p0.generated_number * power(2, 0)\n     + \n    \n    p1.generated_number * power(2, 1)\n     + \n    \n    p2.generated_number * power(2, 2)\n     + \n    \n    p3.generated_number * power(2, 3)\n     + \n    \n    p4.generated_number * power(2, 4)\n     + \n    \n    p5.generated_number * power(2, 5)\n     + \n    \n    p6.generated_number * power(2, 6)\n     + \n    \n    p7.generated_number * power(2, 7)\n    \n    \n    + 1\n    as generated_number\n\n    from\n\n    \n    p as p0\n     cross join \n    \n    p as p1\n     cross join \n    \n    p as p2\n     cross join \n    \n    p as p3\n     cross join \n    \n    p as p4\n     cross join \n    \n    p as p5\n     cross join \n    \n    p as p6\n     cross join \n    \n    p as p7\n    \n    \n\n    )\n\n    select *\n    from unioned\n    where generated_number <= 208\n    order by generated_number\n\n\n\n), weeks_cross_ticket_full_solved_time as (\n    -- because time is reported in minutes since the beginning of the week, we have to split up time spent on the ticket into calendar weeks\n    select \n      ticket_full_solved_time.*,\n      generated_number - 1 as week_number\n    from ticket_full_solved_time\n    cross join weeks\n    where floor((valid_starting_at_in_minutes_from_week + raw_delta_in_minutes) / (7*24*60)) >= generated_number -1\n\n), weekly_period_requester_wait_time as (\n\n    select \n\n      ticket_id,\n      sla_applied_at,\n      valid_starting_at,\n      valid_ending_at,\n      status_valid_starting_at,\n      status_valid_ending_at,\n      target,\n      sla_policy_name,\n      valid_starting_at_in_minutes_from_week,\n      raw_delta_in_minutes,\n      week_number,\n      schedule_id,\n      greatest(0, valid_starting_at_in_minutes_from_week - week_number * (7*24*60)) as ticket_week_start_time_minute,\n      least(valid_starting_at_in_minutes_from_week + raw_delta_in_minutes - week_number * (7*24*60), (7*24*60)) as ticket_week_end_time_minute\n    \n    from weeks_cross_ticket_full_solved_time\n\n), intercepted_periods_agent as (\n  \n    select \n      weekly_period_requester_wait_time.ticket_id,\n      weekly_period_requester_wait_time.sla_applied_at,\n      weekly_period_requester_wait_time.target,\n      weekly_period_requester_wait_time.sla_policy_name,\n      weekly_period_requester_wait_time.valid_starting_at,\n      weekly_period_requester_wait_time.valid_ending_at,\n      weekly_period_requester_wait_time.week_number,\n      weekly_period_requester_wait_time.ticket_week_start_time_minute,\n      weekly_period_requester_wait_time.ticket_week_end_time_minute,\n      schedule.start_time_utc as schedule_start_time,\n      schedule.end_time_utc as schedule_end_time,\n      least(ticket_week_end_time_minute, schedule.end_time_utc) - greatest(weekly_period_requester_wait_time.ticket_week_start_time_minute, schedule.start_time_utc) as scheduled_minutes\n    from weekly_period_requester_wait_time\n    join schedule on ticket_week_start_time_minute <= schedule.end_time_utc \n      and ticket_week_end_time_minute >= schedule.start_time_utc\n      and weekly_period_requester_wait_time.schedule_id = schedule.schedule_id\n      -- this chooses the Daylight Savings Time or Standard Time version of the schedule\n      and weekly_period_requester_wait_time.status_valid_ending_at >= cast(schedule.valid_from as \n    timestamp\n)\n      and weekly_period_requester_wait_time.status_valid_starting_at < cast(schedule.valid_until as \n    timestamp\n) \n\n), intercepted_periods_with_running_total as (\n  \n    select \n      *,\n      sum(scheduled_minutes) over \n        (partition by ticket_id, sla_applied_at \n          order by valid_starting_at, week_number, schedule_end_time\n          rows between unbounded preceding and current row)\n        as running_total_scheduled_minutes\n\n    from intercepted_periods_agent\n\n\n), intercepted_periods_agent_with_breach_flag as (\n  select \n    intercepted_periods_with_running_total.*,\n    target - running_total_scheduled_minutes as remaining_target_minutes,\n    lag(target - running_total_scheduled_minutes) over\n          (partition by ticket_id, sla_applied_at order by valid_starting_at, week_number, schedule_end_time) as lag_check,\n    case when (target - running_total_scheduled_minutes) = 0 then true\n       when (target - running_total_scheduled_minutes) < 0 \n        and \n          (lag(target - running_total_scheduled_minutes) over\n          (partition by ticket_id, sla_applied_at order by valid_starting_at, week_number, schedule_end_time) > 0 \n          or \n          lag(target - running_total_scheduled_minutes) over\n          (partition by ticket_id, sla_applied_at order by valid_starting_at, week_number, schedule_end_time) is null) \n          then true else false end as is_breached_during_schedule\n          \n  from  intercepted_periods_with_running_total\n\n), intercepted_periods_agent_filtered as (\n\n  select\n    *,\n    (remaining_target_minutes + scheduled_minutes) as breach_minutes,\n    greatest(ticket_week_start_time_minute, schedule_start_time) + (remaining_target_minutes + scheduled_minutes) as breach_minutes_from_week\n  from intercepted_periods_agent_with_breach_flag\n\n), requester_wait_business_breach as (\n  \n  select \n    *,\n    \n\n        timestamp_add(\n    timestamp_trunc(\n        cast(valid_starting_at as timestamp),\n        week\n    )\n\n, interval  cast(((7*24*60) * week_number) + breach_minutes_from_week as \n    int64\n ) minute)\n\n as sla_breach_at\n  from intercepted_periods_agent_filtered\n\n)\n\nselect * \nfrom requester_wait_business_breach", "extra_ctes_injected": true, "extra_ctes": [], "relation_name": "`bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__requester_wait_time_business_hours`"}, "model.zendesk.int_zendesk__requester_wait_time_filtered_statuses": {"raw_sql": "with requester_wait_time_sla as (\n\n  select *\n  from {{ ref('int_zendesk__sla_policy_applied') }}\n  where metric = 'requester_wait_time'\n\n), ticket_historical_status as (\n\n  select *\n  from {{ ref('int_zendesk__ticket_historical_status') }}\n    \n--This captures the statuses of the ticket while the requester wait time sla was active for the ticket.\n), requester_wait_time_filtered_statuses as (\n\n  select  \n    ticket_historical_status.ticket_id,\n    greatest(ticket_historical_status.valid_starting_at, requester_wait_time_sla.sla_applied_at) as valid_starting_at,\n    coalesce(\n      ticket_historical_status.valid_ending_at, \n      {{ fivetran_utils.timestamp_add('day', 30, \"\" ~ dbt_utils.current_timestamp() ~ \"\") }} ) as valid_ending_at, --assumes current status continues into the future. This is necessary to predict future SLA breaches (not just past).\n    ticket_historical_status.status as ticket_status,\n    requester_wait_time_sla.sla_applied_at,\n    requester_wait_time_sla.target,\n    requester_wait_time_sla.sla_policy_name,\n    requester_wait_time_sla.ticket_created_at,\n    requester_wait_time_sla.in_business_hours\n  from ticket_historical_status\n  join requester_wait_time_sla\n    on ticket_historical_status.ticket_id = requester_wait_time_sla.ticket_id\n  where ticket_historical_status.status in ('new', 'open', 'on-hold') -- these are the only statuses that count as \"requester wait time\"\n  and sla_applied_at < valid_ending_at\n\n)\nselect *\nfrom requester_wait_time_filtered_statuses", "compiled": true, "resource_type": "model", "depends_on": {"macros": ["macro.dbt_utils.current_timestamp", "macro.fivetran_utils.timestamp_add"], "nodes": ["model.zendesk.int_zendesk__sla_policy_applied", "model.zendesk.int_zendesk__ticket_historical_status"]}, "config": {"enabled": true, "alias": null, "schema": "zendesk_docs", "database": null, "tags": [], "meta": {}, "materialized": "table", "persist_docs": {}, "quoting": {}, "column_types": {}, "full_refresh": null, "on_schema_change": "ignore", "post-hook": [], "pre-hook": []}, "database": "bq-project", "schema": "dbt_joe_zendesk_docs", "fqn": ["zendesk", "sla_policy", "requester_wait_time", "int_zendesk__requester_wait_time_filtered_statuses"], "unique_id": "model.zendesk.int_zendesk__requester_wait_time_filtered_statuses", "package_name": "zendesk", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/zendesk", "path": "sla_policy/requester_wait_time/int_zendesk__requester_wait_time_filtered_statuses.sql", "original_file_path": "models/sla_policy/requester_wait_time/int_zendesk__requester_wait_time_filtered_statuses.sql", "name": "int_zendesk__requester_wait_time_filtered_statuses", "alias": "int_zendesk__requester_wait_time_filtered_statuses", "checksum": {"name": "sha256", "checksum": "7304fc3acc9d562799a1c4799a0a30e013c58f4fe2f8305c95d18abd6d603a18"}, "tags": [], "refs": [["int_zendesk__sla_policy_applied"], ["int_zendesk__ticket_historical_status"]], "sources": [], "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "compiled_path": "target/compiled/zendesk/models/sla_policy/requester_wait_time/int_zendesk__requester_wait_time_filtered_statuses.sql", "build_path": null, "deferred": false, "unrendered_config": {"schema": "zendesk_docs", "materialized": "table"}, "created_at": 1647014737.109441, "compiled_sql": "with requester_wait_time_sla as (\n\n  select *\n  from `bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__sla_policy_applied`\n  where metric = 'requester_wait_time'\n\n), ticket_historical_status as (\n\n  select *\n  from `bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__ticket_historical_status`\n    \n--This captures the statuses of the ticket while the requester wait time sla was active for the ticket.\n), requester_wait_time_filtered_statuses as (\n\n  select  \n    ticket_historical_status.ticket_id,\n    greatest(ticket_historical_status.valid_starting_at, requester_wait_time_sla.sla_applied_at) as valid_starting_at,\n    coalesce(\n      ticket_historical_status.valid_ending_at, \n      \n\n        timestamp_add(\n    current_timestamp\n, interval  30 day)\n\n ) as valid_ending_at, --assumes current status continues into the future. This is necessary to predict future SLA breaches (not just past).\n    ticket_historical_status.status as ticket_status,\n    requester_wait_time_sla.sla_applied_at,\n    requester_wait_time_sla.target,\n    requester_wait_time_sla.sla_policy_name,\n    requester_wait_time_sla.ticket_created_at,\n    requester_wait_time_sla.in_business_hours\n  from ticket_historical_status\n  join requester_wait_time_sla\n    on ticket_historical_status.ticket_id = requester_wait_time_sla.ticket_id\n  where ticket_historical_status.status in ('new', 'open', 'on-hold') -- these are the only statuses that count as \"requester wait time\"\n  and sla_applied_at < valid_ending_at\n\n)\nselect *\nfrom requester_wait_time_filtered_statuses", "extra_ctes_injected": true, "extra_ctes": [], "relation_name": "`bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__requester_wait_time_filtered_statuses`"}, "model.zendesk.int_zendesk__ticket_reply_times": {"raw_sql": "with ticket_public_comments as (\n\n    select *\n    from {{ ref('int_zendesk__comments_enriched') }}\n    where is_public\n\n), end_user_comments as (\n  \n  select \n    ticket_id,\n    valid_starting_at as end_user_comment_created_at,\n    ticket_created_date,\n    commenter_role,\n    previous_internal_comment_count,\n    previous_commenter_role = 'first_comment' as is_first_comment\n  from ticket_public_comments \n  where (commenter_role = 'external_comment'\n    and ticket_public_comments.previous_commenter_role != 'external_comment') -- we only care about net new end user comments\n    or previous_commenter_role = 'first_comment' -- We also want to take into consideration internal first comment replies\n\n), reply_timestamps as (  \n\n  select\n    end_user_comments.ticket_id,\n    -- If the commentor was internal, a first comment, and had previous non public internal comments then we want the ticket created date to be the end user comment created date\n    -- Otherwise we will want to end user comment created date\n    case when is_first_comment then end_user_comments.ticket_created_date else end_user_comments.end_user_comment_created_at end as end_user_comment_created_at,\n    end_user_comments.is_first_comment,\n    min(case when is_first_comment \n        and end_user_comments.commenter_role != 'external_comment' \n        and (end_user_comments.previous_internal_comment_count > 0)\n          then end_user_comments.end_user_comment_created_at \n        else agent_comments.valid_starting_at end) as agent_responded_at\n  from end_user_comments\n  left join ticket_public_comments as agent_comments\n    on agent_comments.ticket_id = end_user_comments.ticket_id\n    and agent_comments.commenter_role = 'internal_comment'\n    and agent_comments.valid_starting_at > end_user_comments.end_user_comment_created_at\n  group by 1,2,3\n\n)\n\n  select\n    *,\n    ({{ fivetran_utils.timestamp_diff(\n      'end_user_comment_created_at',\n      'agent_responded_at',\n      'second') }} / 60) as reply_time_calendar_minutes\n  from reply_timestamps\n  order by 1,2", "compiled": true, "resource_type": "model", "depends_on": {"macros": ["macro.fivetran_utils.timestamp_diff"], "nodes": ["model.zendesk.int_zendesk__comments_enriched"]}, "config": {"enabled": true, "alias": null, "schema": "zendesk_docs", "database": null, "tags": [], "meta": {}, "materialized": "ephemeral", "persist_docs": {}, "quoting": {}, "column_types": {}, "full_refresh": null, "on_schema_change": "ignore", "post-hook": [], "pre-hook": []}, "database": "bq-project", "schema": "dbt_joe_zendesk_docs", "fqn": ["zendesk", "reply_times", "int_zendesk__ticket_reply_times"], "unique_id": "model.zendesk.int_zendesk__ticket_reply_times", "package_name": "zendesk", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/zendesk", "path": "reply_times/int_zendesk__ticket_reply_times.sql", "original_file_path": "models/reply_times/int_zendesk__ticket_reply_times.sql", "name": "int_zendesk__ticket_reply_times", "alias": "int_zendesk__ticket_reply_times", "checksum": {"name": "sha256", "checksum": "9abb69760f62f7fb8b36f7061a22a4a4bd80c08e2465a459b893942528195198"}, "tags": [], "refs": [["int_zendesk__comments_enriched"]], "sources": [], "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "compiled_path": "target/compiled/zendesk/models/reply_times/int_zendesk__ticket_reply_times.sql", "build_path": null, "deferred": false, "unrendered_config": {"schema": "zendesk_docs", "materialized": "ephemeral"}, "created_at": 1647014737.116197, "compiled_sql": "with  __dbt__cte__int_zendesk__comments_enriched as (\nwith ticket_comment as (\n\n    select *\n    from `bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__updates`\n    where field_name = 'comment'\n\n), users as (\n\n    select *\n    from `bq-project`.`dbt_joe_zendesk_docs`.`stg_zendesk__user`\n\n), joined as (\n\n    select \n\n        ticket_comment.*,\n        case when commenter.role = 'end-user' then 'external_comment'\n            when commenter.role in ('agent','admin') then 'internal_comment'\n            else 'unknown' end as commenter_role\n    \n    from ticket_comment\n    \n    join users as commenter\n        on commenter.user_id = ticket_comment.user_id\n\n), add_previous_commenter_role as (\n    /*\n    In int_zendesk__ticket_reply_times we will only be focusing on reply times between public tickets.\n    The below union explicitly identifies the previous commentor roles of public and not public comments.\n    */\n    select\n        *,\n        coalesce(\n            lag(commenter_role) over (partition by ticket_id order by valid_starting_at)\n            , 'first_comment') \n            as previous_commenter_role\n    from joined\n    where is_public\n\n    union all\n\n    select\n        *,\n        'non_public_comment' as previous_commenter_role\n    from joined\n    where not is_public\n)\n\nselect \n    *,\n    first_value(valid_starting_at) over (partition by ticket_id order by valid_starting_at desc, ticket_id rows unbounded preceding) as last_comment_added_at,\n    sum(case when not is_public then 1 else 0 end) over (partition by ticket_id order by valid_starting_at rows between unbounded preceding and current row) as previous_internal_comment_count\nfrom add_previous_commenter_role\n),ticket_public_comments as (\n\n    select *\n    from __dbt__cte__int_zendesk__comments_enriched\n    where is_public\n\n), end_user_comments as (\n  \n  select \n    ticket_id,\n    valid_starting_at as end_user_comment_created_at,\n    ticket_created_date,\n    commenter_role,\n    previous_internal_comment_count,\n    previous_commenter_role = 'first_comment' as is_first_comment\n  from ticket_public_comments \n  where (commenter_role = 'external_comment'\n    and ticket_public_comments.previous_commenter_role != 'external_comment') -- we only care about net new end user comments\n    or previous_commenter_role = 'first_comment' -- We also want to take into consideration internal first comment replies\n\n), reply_timestamps as (  \n\n  select\n    end_user_comments.ticket_id,\n    -- If the commentor was internal, a first comment, and had previous non public internal comments then we want the ticket created date to be the end user comment created date\n    -- Otherwise we will want to end user comment created date\n    case when is_first_comment then end_user_comments.ticket_created_date else end_user_comments.end_user_comment_created_at end as end_user_comment_created_at,\n    end_user_comments.is_first_comment,\n    min(case when is_first_comment \n        and end_user_comments.commenter_role != 'external_comment' \n        and (end_user_comments.previous_internal_comment_count > 0)\n          then end_user_comments.end_user_comment_created_at \n        else agent_comments.valid_starting_at end) as agent_responded_at\n  from end_user_comments\n  left join ticket_public_comments as agent_comments\n    on agent_comments.ticket_id = end_user_comments.ticket_id\n    and agent_comments.commenter_role = 'internal_comment'\n    and agent_comments.valid_starting_at > end_user_comments.end_user_comment_created_at\n  group by 1,2,3\n\n)\n\n  select\n    *,\n    (\n  \n\n    timestamp_diff(\n        agent_responded_at,\n        end_user_comment_created_at,\n        second\n    )\n\n\n / 60) as reply_time_calendar_minutes\n  from reply_timestamps\n  order by 1,2", "extra_ctes_injected": true, "extra_ctes": [{"id": "model.zendesk.int_zendesk__comments_enriched", "sql": " __dbt__cte__int_zendesk__comments_enriched as (\nwith ticket_comment as (\n\n    select *\n    from `bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__updates`\n    where field_name = 'comment'\n\n), users as (\n\n    select *\n    from `bq-project`.`dbt_joe_zendesk_docs`.`stg_zendesk__user`\n\n), joined as (\n\n    select \n\n        ticket_comment.*,\n        case when commenter.role = 'end-user' then 'external_comment'\n            when commenter.role in ('agent','admin') then 'internal_comment'\n            else 'unknown' end as commenter_role\n    \n    from ticket_comment\n    \n    join users as commenter\n        on commenter.user_id = ticket_comment.user_id\n\n), add_previous_commenter_role as (\n    /*\n    In int_zendesk__ticket_reply_times we will only be focusing on reply times between public tickets.\n    The below union explicitly identifies the previous commentor roles of public and not public comments.\n    */\n    select\n        *,\n        coalesce(\n            lag(commenter_role) over (partition by ticket_id order by valid_starting_at)\n            , 'first_comment') \n            as previous_commenter_role\n    from joined\n    where is_public\n\n    union all\n\n    select\n        *,\n        'non_public_comment' as previous_commenter_role\n    from joined\n    where not is_public\n)\n\nselect \n    *,\n    first_value(valid_starting_at) over (partition by ticket_id order by valid_starting_at desc, ticket_id rows unbounded preceding) as last_comment_added_at,\n    sum(case when not is_public then 1 else 0 end) over (partition by ticket_id order by valid_starting_at rows between unbounded preceding and current row) as previous_internal_comment_count\nfrom add_previous_commenter_role\n)"}], "relation_name": null}, "model.zendesk.int_zendesk__ticket_reply_times_calendar": {"raw_sql": "with ticket as (\n\n  select *\n  from {{ ref('stg_zendesk__ticket') }}\n\n), ticket_reply_times as (\n\n  select *\n  from {{ ref('int_zendesk__ticket_reply_times') }}\n\n)\n\nselect\n\n  ticket.ticket_id,\n  sum(case when is_first_comment then reply_time_calendar_minutes\n    else null end) as first_reply_time_calendar_minutes,\n  sum(reply_time_calendar_minutes) as total_reply_time_calendar_minutes --total combined time the customer waits for internal response\n  \nfrom ticket\nleft join ticket_reply_times\n  using (ticket_id)\n\ngroup by 1", "compiled": true, "resource_type": "model", "depends_on": {"macros": [], "nodes": ["model.zendesk_source.stg_zendesk__ticket", "model.zendesk.int_zendesk__ticket_reply_times"]}, "config": {"enabled": true, "alias": null, "schema": "zendesk_docs", "database": null, "tags": [], "meta": {}, "materialized": "ephemeral", "persist_docs": {}, "quoting": {}, "column_types": {}, "full_refresh": null, "on_schema_change": "ignore", "post-hook": [], "pre-hook": []}, "database": "bq-project", "schema": "dbt_joe_zendesk_docs", "fqn": ["zendesk", "reply_times", "int_zendesk__ticket_reply_times_calendar"], "unique_id": "model.zendesk.int_zendesk__ticket_reply_times_calendar", "package_name": "zendesk", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/zendesk", "path": "reply_times/int_zendesk__ticket_reply_times_calendar.sql", "original_file_path": "models/reply_times/int_zendesk__ticket_reply_times_calendar.sql", "name": "int_zendesk__ticket_reply_times_calendar", "alias": "int_zendesk__ticket_reply_times_calendar", "checksum": {"name": "sha256", "checksum": "6fb6a60134019d78fcfc8c135b4a7887b3ce52ec53d8db463194f7824d2c71c2"}, "tags": [], "refs": [["stg_zendesk__ticket"], ["int_zendesk__ticket_reply_times"]], "sources": [], "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "compiled_path": "target/compiled/zendesk/models/reply_times/int_zendesk__ticket_reply_times_calendar.sql", "build_path": null, "deferred": false, "unrendered_config": {"schema": "zendesk_docs", "materialized": "ephemeral"}, "created_at": 1647014737.1213691, "compiled_sql": "with  __dbt__cte__int_zendesk__comments_enriched as (\nwith ticket_comment as (\n\n    select *\n    from `bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__updates`\n    where field_name = 'comment'\n\n), users as (\n\n    select *\n    from `bq-project`.`dbt_joe_zendesk_docs`.`stg_zendesk__user`\n\n), joined as (\n\n    select \n\n        ticket_comment.*,\n        case when commenter.role = 'end-user' then 'external_comment'\n            when commenter.role in ('agent','admin') then 'internal_comment'\n            else 'unknown' end as commenter_role\n    \n    from ticket_comment\n    \n    join users as commenter\n        on commenter.user_id = ticket_comment.user_id\n\n), add_previous_commenter_role as (\n    /*\n    In int_zendesk__ticket_reply_times we will only be focusing on reply times between public tickets.\n    The below union explicitly identifies the previous commentor roles of public and not public comments.\n    */\n    select\n        *,\n        coalesce(\n            lag(commenter_role) over (partition by ticket_id order by valid_starting_at)\n            , 'first_comment') \n            as previous_commenter_role\n    from joined\n    where is_public\n\n    union all\n\n    select\n        *,\n        'non_public_comment' as previous_commenter_role\n    from joined\n    where not is_public\n)\n\nselect \n    *,\n    first_value(valid_starting_at) over (partition by ticket_id order by valid_starting_at desc, ticket_id rows unbounded preceding) as last_comment_added_at,\n    sum(case when not is_public then 1 else 0 end) over (partition by ticket_id order by valid_starting_at rows between unbounded preceding and current row) as previous_internal_comment_count\nfrom add_previous_commenter_role\n),  __dbt__cte__int_zendesk__ticket_reply_times as (\nwith ticket_public_comments as (\n\n    select *\n    from __dbt__cte__int_zendesk__comments_enriched\n    where is_public\n\n), end_user_comments as (\n  \n  select \n    ticket_id,\n    valid_starting_at as end_user_comment_created_at,\n    ticket_created_date,\n    commenter_role,\n    previous_internal_comment_count,\n    previous_commenter_role = 'first_comment' as is_first_comment\n  from ticket_public_comments \n  where (commenter_role = 'external_comment'\n    and ticket_public_comments.previous_commenter_role != 'external_comment') -- we only care about net new end user comments\n    or previous_commenter_role = 'first_comment' -- We also want to take into consideration internal first comment replies\n\n), reply_timestamps as (  \n\n  select\n    end_user_comments.ticket_id,\n    -- If the commentor was internal, a first comment, and had previous non public internal comments then we want the ticket created date to be the end user comment created date\n    -- Otherwise we will want to end user comment created date\n    case when is_first_comment then end_user_comments.ticket_created_date else end_user_comments.end_user_comment_created_at end as end_user_comment_created_at,\n    end_user_comments.is_first_comment,\n    min(case when is_first_comment \n        and end_user_comments.commenter_role != 'external_comment' \n        and (end_user_comments.previous_internal_comment_count > 0)\n          then end_user_comments.end_user_comment_created_at \n        else agent_comments.valid_starting_at end) as agent_responded_at\n  from end_user_comments\n  left join ticket_public_comments as agent_comments\n    on agent_comments.ticket_id = end_user_comments.ticket_id\n    and agent_comments.commenter_role = 'internal_comment'\n    and agent_comments.valid_starting_at > end_user_comments.end_user_comment_created_at\n  group by 1,2,3\n\n)\n\n  select\n    *,\n    (\n  \n\n    timestamp_diff(\n        agent_responded_at,\n        end_user_comment_created_at,\n        second\n    )\n\n\n / 60) as reply_time_calendar_minutes\n  from reply_timestamps\n  order by 1,2\n),ticket as (\n\n  select *\n  from `bq-project`.`dbt_joe_zendesk_docs`.`stg_zendesk__ticket`\n\n), ticket_reply_times as (\n\n  select *\n  from __dbt__cte__int_zendesk__ticket_reply_times\n\n)\n\nselect\n\n  ticket.ticket_id,\n  sum(case when is_first_comment then reply_time_calendar_minutes\n    else null end) as first_reply_time_calendar_minutes,\n  sum(reply_time_calendar_minutes) as total_reply_time_calendar_minutes --total combined time the customer waits for internal response\n  \nfrom ticket\nleft join ticket_reply_times\n  using (ticket_id)\n\ngroup by 1", "extra_ctes_injected": true, "extra_ctes": [{"id": "model.zendesk.int_zendesk__comments_enriched", "sql": " __dbt__cte__int_zendesk__comments_enriched as (\nwith ticket_comment as (\n\n    select *\n    from `bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__updates`\n    where field_name = 'comment'\n\n), users as (\n\n    select *\n    from `bq-project`.`dbt_joe_zendesk_docs`.`stg_zendesk__user`\n\n), joined as (\n\n    select \n\n        ticket_comment.*,\n        case when commenter.role = 'end-user' then 'external_comment'\n            when commenter.role in ('agent','admin') then 'internal_comment'\n            else 'unknown' end as commenter_role\n    \n    from ticket_comment\n    \n    join users as commenter\n        on commenter.user_id = ticket_comment.user_id\n\n), add_previous_commenter_role as (\n    /*\n    In int_zendesk__ticket_reply_times we will only be focusing on reply times between public tickets.\n    The below union explicitly identifies the previous commentor roles of public and not public comments.\n    */\n    select\n        *,\n        coalesce(\n            lag(commenter_role) over (partition by ticket_id order by valid_starting_at)\n            , 'first_comment') \n            as previous_commenter_role\n    from joined\n    where is_public\n\n    union all\n\n    select\n        *,\n        'non_public_comment' as previous_commenter_role\n    from joined\n    where not is_public\n)\n\nselect \n    *,\n    first_value(valid_starting_at) over (partition by ticket_id order by valid_starting_at desc, ticket_id rows unbounded preceding) as last_comment_added_at,\n    sum(case when not is_public then 1 else 0 end) over (partition by ticket_id order by valid_starting_at rows between unbounded preceding and current row) as previous_internal_comment_count\nfrom add_previous_commenter_role\n)"}, {"id": "model.zendesk.int_zendesk__ticket_reply_times", "sql": " __dbt__cte__int_zendesk__ticket_reply_times as (\nwith ticket_public_comments as (\n\n    select *\n    from __dbt__cte__int_zendesk__comments_enriched\n    where is_public\n\n), end_user_comments as (\n  \n  select \n    ticket_id,\n    valid_starting_at as end_user_comment_created_at,\n    ticket_created_date,\n    commenter_role,\n    previous_internal_comment_count,\n    previous_commenter_role = 'first_comment' as is_first_comment\n  from ticket_public_comments \n  where (commenter_role = 'external_comment'\n    and ticket_public_comments.previous_commenter_role != 'external_comment') -- we only care about net new end user comments\n    or previous_commenter_role = 'first_comment' -- We also want to take into consideration internal first comment replies\n\n), reply_timestamps as (  \n\n  select\n    end_user_comments.ticket_id,\n    -- If the commentor was internal, a first comment, and had previous non public internal comments then we want the ticket created date to be the end user comment created date\n    -- Otherwise we will want to end user comment created date\n    case when is_first_comment then end_user_comments.ticket_created_date else end_user_comments.end_user_comment_created_at end as end_user_comment_created_at,\n    end_user_comments.is_first_comment,\n    min(case when is_first_comment \n        and end_user_comments.commenter_role != 'external_comment' \n        and (end_user_comments.previous_internal_comment_count > 0)\n          then end_user_comments.end_user_comment_created_at \n        else agent_comments.valid_starting_at end) as agent_responded_at\n  from end_user_comments\n  left join ticket_public_comments as agent_comments\n    on agent_comments.ticket_id = end_user_comments.ticket_id\n    and agent_comments.commenter_role = 'internal_comment'\n    and agent_comments.valid_starting_at > end_user_comments.end_user_comment_created_at\n  group by 1,2,3\n\n)\n\n  select\n    *,\n    (\n  \n\n    timestamp_diff(\n        agent_responded_at,\n        end_user_comment_created_at,\n        second\n    )\n\n\n / 60) as reply_time_calendar_minutes\n  from reply_timestamps\n  order by 1,2\n)"}], "relation_name": null}, "model.zendesk.int_zendesk__comments_enriched": {"raw_sql": "with ticket_comment as (\n\n    select *\n    from {{ ref('int_zendesk__updates') }}\n    where field_name = 'comment'\n\n), users as (\n\n    select *\n    from {{ ref('stg_zendesk__user') }}\n\n), joined as (\n\n    select \n\n        ticket_comment.*,\n        case when commenter.role = 'end-user' then 'external_comment'\n            when commenter.role in ('agent','admin') then 'internal_comment'\n            else 'unknown' end as commenter_role\n    \n    from ticket_comment\n    \n    join users as commenter\n        on commenter.user_id = ticket_comment.user_id\n\n), add_previous_commenter_role as (\n    /*\n    In int_zendesk__ticket_reply_times we will only be focusing on reply times between public tickets.\n    The below union explicitly identifies the previous commentor roles of public and not public comments.\n    */\n    select\n        *,\n        coalesce(\n            lag(commenter_role) over (partition by ticket_id order by valid_starting_at)\n            , 'first_comment') \n            as previous_commenter_role\n    from joined\n    where is_public\n\n    union all\n\n    select\n        *,\n        'non_public_comment' as previous_commenter_role\n    from joined\n    where not is_public\n)\n\nselect \n    *,\n    first_value(valid_starting_at) over (partition by ticket_id order by valid_starting_at desc, ticket_id rows unbounded preceding) as last_comment_added_at,\n    sum(case when not is_public then 1 else 0 end) over (partition by ticket_id order by valid_starting_at rows between unbounded preceding and current row) as previous_internal_comment_count\nfrom add_previous_commenter_role", "compiled": true, "resource_type": "model", "depends_on": {"macros": [], "nodes": ["model.zendesk.int_zendesk__updates", "model.zendesk_source.stg_zendesk__user"]}, "config": {"enabled": true, "alias": null, "schema": "zendesk_docs", "database": null, "tags": [], "meta": {}, "materialized": "ephemeral", "persist_docs": {}, "quoting": {}, "column_types": {}, "full_refresh": null, "on_schema_change": "ignore", "post-hook": [], "pre-hook": []}, "database": "bq-project", "schema": "dbt_joe_zendesk_docs", "fqn": ["zendesk", "reply_times", "int_zendesk__comments_enriched"], "unique_id": "model.zendesk.int_zendesk__comments_enriched", "package_name": "zendesk", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/zendesk", "path": "reply_times/int_zendesk__comments_enriched.sql", "original_file_path": "models/reply_times/int_zendesk__comments_enriched.sql", "name": "int_zendesk__comments_enriched", "alias": "int_zendesk__comments_enriched", "checksum": {"name": "sha256", "checksum": "7716c6da8ac9047a98ce8298e20246da0f623ae86212d92d4d61c7cc3b6cbbd9"}, "tags": [], "refs": [["int_zendesk__updates"], ["stg_zendesk__user"]], "sources": [], "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "compiled_path": "target/compiled/zendesk/models/reply_times/int_zendesk__comments_enriched.sql", "build_path": null, "deferred": false, "unrendered_config": {"schema": "zendesk_docs", "materialized": "ephemeral"}, "created_at": 1647014737.124346, "compiled_sql": "with ticket_comment as (\n\n    select *\n    from `bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__updates`\n    where field_name = 'comment'\n\n), users as (\n\n    select *\n    from `bq-project`.`dbt_joe_zendesk_docs`.`stg_zendesk__user`\n\n), joined as (\n\n    select \n\n        ticket_comment.*,\n        case when commenter.role = 'end-user' then 'external_comment'\n            when commenter.role in ('agent','admin') then 'internal_comment'\n            else 'unknown' end as commenter_role\n    \n    from ticket_comment\n    \n    join users as commenter\n        on commenter.user_id = ticket_comment.user_id\n\n), add_previous_commenter_role as (\n    /*\n    In int_zendesk__ticket_reply_times we will only be focusing on reply times between public tickets.\n    The below union explicitly identifies the previous commentor roles of public and not public comments.\n    */\n    select\n        *,\n        coalesce(\n            lag(commenter_role) over (partition by ticket_id order by valid_starting_at)\n            , 'first_comment') \n            as previous_commenter_role\n    from joined\n    where is_public\n\n    union all\n\n    select\n        *,\n        'non_public_comment' as previous_commenter_role\n    from joined\n    where not is_public\n)\n\nselect \n    *,\n    first_value(valid_starting_at) over (partition by ticket_id order by valid_starting_at desc, ticket_id rows unbounded preceding) as last_comment_added_at,\n    sum(case when not is_public then 1 else 0 end) over (partition by ticket_id order by valid_starting_at rows between unbounded preceding and current row) as previous_internal_comment_count\nfrom add_previous_commenter_role", "extra_ctes_injected": true, "extra_ctes": [], "relation_name": null}, "model.zendesk.int_zendesk__ticket_first_reply_time_business": {"raw_sql": "{{ config(enabled=var('using_schedules', True)) }}\n\nwith ticket_reply_times as (\n\n    select *\n    from {{ ref('int_zendesk__ticket_reply_times') }}\n\n), ticket_schedules as (\n\n    select *\n    from {{ ref('int_zendesk__ticket_schedules') }}\n\n), schedule as (\n\n    select *\n    from {{ ref('int_zendesk__schedule_spine') }}\n\n), first_reply_time as (\n\n    select\n      ticket_id,\n      end_user_comment_created_at,\n      agent_responded_at\n\n    from ticket_reply_times\n    where is_first_comment\n\n), ticket_first_reply_time as (\n\n  select \n    first_reply_time.ticket_id,\n    ticket_schedules.schedule_created_at,\n    ticket_schedules.schedule_invalidated_at,\n    ticket_schedules.schedule_id,\n\n    -- bringing this in the determine which schedule (Daylight Savings vs Standard time) to use\n    min(first_reply_time.agent_responded_at) as agent_responded_at,\n\n    ({{ fivetran_utils.timestamp_diff(\n            \"\" ~ dbt_utils.date_trunc('week', 'ticket_schedules.schedule_created_at') ~ \"\", \n            'ticket_schedules.schedule_created_at',\n            'second') }} /60\n          ) as start_time_in_minutes_from_week,\n    greatest(0,\n      (\n        {{ fivetran_utils.timestamp_diff(\n          'ticket_schedules.schedule_created_at',\n          'least(ticket_schedules.schedule_invalidated_at, min(first_reply_time.agent_responded_at))',\n          'second') }}/60\n        )) as raw_delta_in_minutes\n  \n  from first_reply_time\n  join ticket_schedules on first_reply_time.ticket_id = ticket_schedules.ticket_id\n  group by 1, 2, 3, 4\n\n), weeks as (\n\n    {{ dbt_utils.generate_series(208) }}\n\n), weeks_cross_ticket_first_reply as (\n    -- because time is reported in minutes since the beginning of the week, we have to split up time spent on the ticket into calendar weeks\n    select \n\n      ticket_first_reply_time.*,\n      generated_number - 1 as week_number\n\n    from ticket_first_reply_time\n    cross join weeks\n    where floor((start_time_in_minutes_from_week + raw_delta_in_minutes) / (7*24*60)) >= generated_number - 1\n\n), weekly_periods as (\n  \n    select \n      weeks_cross_ticket_first_reply.*, \n      greatest(0, start_time_in_minutes_from_week - week_number * (7*24*60)) as ticket_week_start_time,\n      least(start_time_in_minutes_from_week + raw_delta_in_minutes - week_number * (7*24*60), (7*24*60)) as ticket_week_end_time\n    from weeks_cross_ticket_first_reply\n\n), intercepted_periods as (\n\n  select ticket_id,\n      week_number,\n      weekly_periods.schedule_id,\n      ticket_week_start_time,\n      ticket_week_end_time,\n      schedule.start_time_utc as schedule_start_time,\n      schedule.end_time_utc as schedule_end_time,\n      least(ticket_week_end_time, schedule.end_time_utc) - greatest(ticket_week_start_time, schedule.start_time_utc) as scheduled_minutes\n  from weekly_periods\n  join schedule on ticket_week_start_time <= schedule.end_time_utc \n    and ticket_week_end_time >= schedule.start_time_utc\n    and weekly_periods.schedule_id = schedule.schedule_id\n    -- this chooses the Daylight Savings Time or Standard Time version of the schedule\n    and weekly_periods.agent_responded_at >= cast(schedule.valid_from as {{ dbt_utils.type_timestamp() }})\n    and weekly_periods.agent_responded_at < cast(schedule.valid_until as {{ dbt_utils.type_timestamp() }}) \n\n)\n\n  select ticket_id,\n         sum(scheduled_minutes) as first_reply_time_business_minutes\n  from intercepted_periods\n  group by 1", "compiled": true, "resource_type": "model", "depends_on": {"macros": ["macro.dbt_utils.date_trunc", "macro.fivetran_utils.timestamp_diff", "macro.dbt_utils.generate_series", "macro.dbt_utils.type_timestamp"], "nodes": ["model.zendesk.int_zendesk__ticket_reply_times", "model.zendesk.int_zendesk__ticket_schedules", "model.zendesk.int_zendesk__schedule_spine"]}, "config": {"enabled": true, "alias": null, "schema": "zendesk_docs", "database": null, "tags": [], "meta": {}, "materialized": "ephemeral", "persist_docs": {}, "quoting": {}, "column_types": {}, "full_refresh": null, "on_schema_change": "ignore", "post-hook": [], "pre-hook": []}, "database": "bq-project", "schema": "dbt_joe_zendesk_docs", "fqn": ["zendesk", "reply_times", "int_zendesk__ticket_first_reply_time_business"], "unique_id": "model.zendesk.int_zendesk__ticket_first_reply_time_business", "package_name": "zendesk", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/zendesk", "path": "reply_times/int_zendesk__ticket_first_reply_time_business.sql", "original_file_path": "models/reply_times/int_zendesk__ticket_first_reply_time_business.sql", "name": "int_zendesk__ticket_first_reply_time_business", "alias": "int_zendesk__ticket_first_reply_time_business", "checksum": {"name": "sha256", "checksum": "36546b8ae430a9dc5cc09b5330e0d2232fa12cc7f639e42521abb68a9bb60e26"}, "tags": [], "refs": [["int_zendesk__ticket_reply_times"], ["int_zendesk__ticket_schedules"], ["int_zendesk__schedule_spine"]], "sources": [], "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "compiled_path": "target/compiled/zendesk/models/reply_times/int_zendesk__ticket_first_reply_time_business.sql", "build_path": null, "deferred": false, "unrendered_config": {"schema": "zendesk_docs", "materialized": "ephemeral", "enabled": true}, "created_at": 1647014737.1267571, "compiled_sql": "\n\nwith  __dbt__cte__int_zendesk__comments_enriched as (\nwith ticket_comment as (\n\n    select *\n    from `bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__updates`\n    where field_name = 'comment'\n\n), users as (\n\n    select *\n    from `bq-project`.`dbt_joe_zendesk_docs`.`stg_zendesk__user`\n\n), joined as (\n\n    select \n\n        ticket_comment.*,\n        case when commenter.role = 'end-user' then 'external_comment'\n            when commenter.role in ('agent','admin') then 'internal_comment'\n            else 'unknown' end as commenter_role\n    \n    from ticket_comment\n    \n    join users as commenter\n        on commenter.user_id = ticket_comment.user_id\n\n), add_previous_commenter_role as (\n    /*\n    In int_zendesk__ticket_reply_times we will only be focusing on reply times between public tickets.\n    The below union explicitly identifies the previous commentor roles of public and not public comments.\n    */\n    select\n        *,\n        coalesce(\n            lag(commenter_role) over (partition by ticket_id order by valid_starting_at)\n            , 'first_comment') \n            as previous_commenter_role\n    from joined\n    where is_public\n\n    union all\n\n    select\n        *,\n        'non_public_comment' as previous_commenter_role\n    from joined\n    where not is_public\n)\n\nselect \n    *,\n    first_value(valid_starting_at) over (partition by ticket_id order by valid_starting_at desc, ticket_id rows unbounded preceding) as last_comment_added_at,\n    sum(case when not is_public then 1 else 0 end) over (partition by ticket_id order by valid_starting_at rows between unbounded preceding and current row) as previous_internal_comment_count\nfrom add_previous_commenter_role\n),  __dbt__cte__int_zendesk__ticket_reply_times as (\nwith ticket_public_comments as (\n\n    select *\n    from __dbt__cte__int_zendesk__comments_enriched\n    where is_public\n\n), end_user_comments as (\n  \n  select \n    ticket_id,\n    valid_starting_at as end_user_comment_created_at,\n    ticket_created_date,\n    commenter_role,\n    previous_internal_comment_count,\n    previous_commenter_role = 'first_comment' as is_first_comment\n  from ticket_public_comments \n  where (commenter_role = 'external_comment'\n    and ticket_public_comments.previous_commenter_role != 'external_comment') -- we only care about net new end user comments\n    or previous_commenter_role = 'first_comment' -- We also want to take into consideration internal first comment replies\n\n), reply_timestamps as (  \n\n  select\n    end_user_comments.ticket_id,\n    -- If the commentor was internal, a first comment, and had previous non public internal comments then we want the ticket created date to be the end user comment created date\n    -- Otherwise we will want to end user comment created date\n    case when is_first_comment then end_user_comments.ticket_created_date else end_user_comments.end_user_comment_created_at end as end_user_comment_created_at,\n    end_user_comments.is_first_comment,\n    min(case when is_first_comment \n        and end_user_comments.commenter_role != 'external_comment' \n        and (end_user_comments.previous_internal_comment_count > 0)\n          then end_user_comments.end_user_comment_created_at \n        else agent_comments.valid_starting_at end) as agent_responded_at\n  from end_user_comments\n  left join ticket_public_comments as agent_comments\n    on agent_comments.ticket_id = end_user_comments.ticket_id\n    and agent_comments.commenter_role = 'internal_comment'\n    and agent_comments.valid_starting_at > end_user_comments.end_user_comment_created_at\n  group by 1,2,3\n\n)\n\n  select\n    *,\n    (\n  \n\n    timestamp_diff(\n        agent_responded_at,\n        end_user_comment_created_at,\n        second\n    )\n\n\n / 60) as reply_time_calendar_minutes\n  from reply_timestamps\n  order by 1,2\n),ticket_reply_times as (\n\n    select *\n    from __dbt__cte__int_zendesk__ticket_reply_times\n\n), ticket_schedules as (\n\n    select *\n    from `bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__ticket_schedules`\n\n), schedule as (\n\n    select *\n    from `bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__schedule_spine`\n\n), first_reply_time as (\n\n    select\n      ticket_id,\n      end_user_comment_created_at,\n      agent_responded_at\n\n    from ticket_reply_times\n    where is_first_comment\n\n), ticket_first_reply_time as (\n\n  select \n    first_reply_time.ticket_id,\n    ticket_schedules.schedule_created_at,\n    ticket_schedules.schedule_invalidated_at,\n    ticket_schedules.schedule_id,\n\n    -- bringing this in the determine which schedule (Daylight Savings vs Standard time) to use\n    min(first_reply_time.agent_responded_at) as agent_responded_at,\n\n    (\n  \n\n    timestamp_diff(\n        ticket_schedules.schedule_created_at,\n        \n    timestamp_trunc(\n        cast(ticket_schedules.schedule_created_at as timestamp),\n        week\n    )\n\n,\n        second\n    )\n\n\n /60\n          ) as start_time_in_minutes_from_week,\n    greatest(0,\n      (\n        \n  \n\n    timestamp_diff(\n        least(ticket_schedules.schedule_invalidated_at, min(first_reply_time.agent_responded_at)),\n        ticket_schedules.schedule_created_at,\n        second\n    )\n\n\n/60\n        )) as raw_delta_in_minutes\n  \n  from first_reply_time\n  join ticket_schedules on first_reply_time.ticket_id = ticket_schedules.ticket_id\n  group by 1, 2, 3, 4\n\n), weeks as (\n\n    \n\n    \n\n    with p as (\n        select 0 as generated_number union all select 1\n    ), unioned as (\n\n    select\n\n    \n    p0.generated_number * power(2, 0)\n     + \n    \n    p1.generated_number * power(2, 1)\n     + \n    \n    p2.generated_number * power(2, 2)\n     + \n    \n    p3.generated_number * power(2, 3)\n     + \n    \n    p4.generated_number * power(2, 4)\n     + \n    \n    p5.generated_number * power(2, 5)\n     + \n    \n    p6.generated_number * power(2, 6)\n     + \n    \n    p7.generated_number * power(2, 7)\n    \n    \n    + 1\n    as generated_number\n\n    from\n\n    \n    p as p0\n     cross join \n    \n    p as p1\n     cross join \n    \n    p as p2\n     cross join \n    \n    p as p3\n     cross join \n    \n    p as p4\n     cross join \n    \n    p as p5\n     cross join \n    \n    p as p6\n     cross join \n    \n    p as p7\n    \n    \n\n    )\n\n    select *\n    from unioned\n    where generated_number <= 208\n    order by generated_number\n\n\n\n), weeks_cross_ticket_first_reply as (\n    -- because time is reported in minutes since the beginning of the week, we have to split up time spent on the ticket into calendar weeks\n    select \n\n      ticket_first_reply_time.*,\n      generated_number - 1 as week_number\n\n    from ticket_first_reply_time\n    cross join weeks\n    where floor((start_time_in_minutes_from_week + raw_delta_in_minutes) / (7*24*60)) >= generated_number - 1\n\n), weekly_periods as (\n  \n    select \n      weeks_cross_ticket_first_reply.*, \n      greatest(0, start_time_in_minutes_from_week - week_number * (7*24*60)) as ticket_week_start_time,\n      least(start_time_in_minutes_from_week + raw_delta_in_minutes - week_number * (7*24*60), (7*24*60)) as ticket_week_end_time\n    from weeks_cross_ticket_first_reply\n\n), intercepted_periods as (\n\n  select ticket_id,\n      week_number,\n      weekly_periods.schedule_id,\n      ticket_week_start_time,\n      ticket_week_end_time,\n      schedule.start_time_utc as schedule_start_time,\n      schedule.end_time_utc as schedule_end_time,\n      least(ticket_week_end_time, schedule.end_time_utc) - greatest(ticket_week_start_time, schedule.start_time_utc) as scheduled_minutes\n  from weekly_periods\n  join schedule on ticket_week_start_time <= schedule.end_time_utc \n    and ticket_week_end_time >= schedule.start_time_utc\n    and weekly_periods.schedule_id = schedule.schedule_id\n    -- this chooses the Daylight Savings Time or Standard Time version of the schedule\n    and weekly_periods.agent_responded_at >= cast(schedule.valid_from as \n    timestamp\n)\n    and weekly_periods.agent_responded_at < cast(schedule.valid_until as \n    timestamp\n) \n\n)\n\n  select ticket_id,\n         sum(scheduled_minutes) as first_reply_time_business_minutes\n  from intercepted_periods\n  group by 1", "extra_ctes_injected": true, "extra_ctes": [{"id": "model.zendesk.int_zendesk__comments_enriched", "sql": " __dbt__cte__int_zendesk__comments_enriched as (\nwith ticket_comment as (\n\n    select *\n    from `bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__updates`\n    where field_name = 'comment'\n\n), users as (\n\n    select *\n    from `bq-project`.`dbt_joe_zendesk_docs`.`stg_zendesk__user`\n\n), joined as (\n\n    select \n\n        ticket_comment.*,\n        case when commenter.role = 'end-user' then 'external_comment'\n            when commenter.role in ('agent','admin') then 'internal_comment'\n            else 'unknown' end as commenter_role\n    \n    from ticket_comment\n    \n    join users as commenter\n        on commenter.user_id = ticket_comment.user_id\n\n), add_previous_commenter_role as (\n    /*\n    In int_zendesk__ticket_reply_times we will only be focusing on reply times between public tickets.\n    The below union explicitly identifies the previous commentor roles of public and not public comments.\n    */\n    select\n        *,\n        coalesce(\n            lag(commenter_role) over (partition by ticket_id order by valid_starting_at)\n            , 'first_comment') \n            as previous_commenter_role\n    from joined\n    where is_public\n\n    union all\n\n    select\n        *,\n        'non_public_comment' as previous_commenter_role\n    from joined\n    where not is_public\n)\n\nselect \n    *,\n    first_value(valid_starting_at) over (partition by ticket_id order by valid_starting_at desc, ticket_id rows unbounded preceding) as last_comment_added_at,\n    sum(case when not is_public then 1 else 0 end) over (partition by ticket_id order by valid_starting_at rows between unbounded preceding and current row) as previous_internal_comment_count\nfrom add_previous_commenter_role\n)"}, {"id": "model.zendesk.int_zendesk__ticket_reply_times", "sql": " __dbt__cte__int_zendesk__ticket_reply_times as (\nwith ticket_public_comments as (\n\n    select *\n    from __dbt__cte__int_zendesk__comments_enriched\n    where is_public\n\n), end_user_comments as (\n  \n  select \n    ticket_id,\n    valid_starting_at as end_user_comment_created_at,\n    ticket_created_date,\n    commenter_role,\n    previous_internal_comment_count,\n    previous_commenter_role = 'first_comment' as is_first_comment\n  from ticket_public_comments \n  where (commenter_role = 'external_comment'\n    and ticket_public_comments.previous_commenter_role != 'external_comment') -- we only care about net new end user comments\n    or previous_commenter_role = 'first_comment' -- We also want to take into consideration internal first comment replies\n\n), reply_timestamps as (  \n\n  select\n    end_user_comments.ticket_id,\n    -- If the commentor was internal, a first comment, and had previous non public internal comments then we want the ticket created date to be the end user comment created date\n    -- Otherwise we will want to end user comment created date\n    case when is_first_comment then end_user_comments.ticket_created_date else end_user_comments.end_user_comment_created_at end as end_user_comment_created_at,\n    end_user_comments.is_first_comment,\n    min(case when is_first_comment \n        and end_user_comments.commenter_role != 'external_comment' \n        and (end_user_comments.previous_internal_comment_count > 0)\n          then end_user_comments.end_user_comment_created_at \n        else agent_comments.valid_starting_at end) as agent_responded_at\n  from end_user_comments\n  left join ticket_public_comments as agent_comments\n    on agent_comments.ticket_id = end_user_comments.ticket_id\n    and agent_comments.commenter_role = 'internal_comment'\n    and agent_comments.valid_starting_at > end_user_comments.end_user_comment_created_at\n  group by 1,2,3\n\n)\n\n  select\n    *,\n    (\n  \n\n    timestamp_diff(\n        agent_responded_at,\n        end_user_comment_created_at,\n        second\n    )\n\n\n / 60) as reply_time_calendar_minutes\n  from reply_timestamps\n  order by 1,2\n)"}], "relation_name": null}, "model.zendesk.int_zendesk__field_history_enriched": {"raw_sql": "with ticket_field_history as (\n\n    select *\n    from {{ ref('stg_zendesk__ticket_field_history') }}\n\n), updater_info as (\n    select *\n    from {{ ref('int_zendesk__updater_information') }}\n\n), final as (\n    select\n        ticket_field_history.*\n\n        {% if var('ticket_field_history_updater_columns')%} --The below will be run if any fields are included in the variable within the dbt_project.yml.\n            {% for col in var('ticket_field_history_updater_columns') %} --Iterating through the updater fields included in the variable.\n\n                --The below statements are needed to populate Zendesk automated fields for when the zendesk triggers automatically change fields based on user defined triggers.\n                {% if col in ['updater_is_active'] %}\n                    ,coalesce(updater_info.{{ col|lower }}, true) as {{ col }}\n\n                {% elif col in ['updater_user_id','updater_organization_id'] %}\n                    ,coalesce(updater_info.{{ col|lower }}, -1) as {{ col }}\n                \n                {% elif col in ['updater_last_login_at'] %}\n                    ,coalesce(updater_info.{{ col|lower }}, current_timestamp) as {{ col }}\n                \n                {% else %}\n                    ,coalesce(updater_info.{{ col|lower }}, concat('zendesk_trigger_change_', '{{ col }}' )) as {{ col }}\n  \n                {% endif %}\n            {% endfor %}\n        {% endif %}  \n\n    from ticket_field_history\n\n    left join updater_info\n        on ticket_field_history.user_id = updater_info.updater_user_id\n)\nselect *\nfrom final", "compiled": true, "resource_type": "model", "depends_on": {"macros": [], "nodes": ["model.zendesk_source.stg_zendesk__ticket_field_history", "model.zendesk.int_zendesk__updater_information"]}, "config": {"enabled": true, "alias": null, "schema": "zendesk_docs", "database": null, "tags": [], "meta": {}, "materialized": "ephemeral", "persist_docs": {}, "quoting": {}, "column_types": {}, "full_refresh": null, "on_schema_change": "ignore", "post-hook": [], "pre-hook": []}, "database": "bq-project", "schema": "dbt_joe_zendesk_docs", "fqn": ["zendesk", "ticket_history", "int_zendesk__field_history_enriched"], "unique_id": "model.zendesk.int_zendesk__field_history_enriched", "package_name": "zendesk", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/zendesk", "path": "ticket_history/int_zendesk__field_history_enriched.sql", "original_file_path": "models/ticket_history/int_zendesk__field_history_enriched.sql", "name": "int_zendesk__field_history_enriched", "alias": "int_zendesk__field_history_enriched", "checksum": {"name": "sha256", "checksum": "ed29d2cf5bae22db49bfe045b4d8de74d14621182514e1fb8c47c28733c74b14"}, "tags": [], "refs": [["stg_zendesk__ticket_field_history"], ["int_zendesk__updater_information"]], "sources": [], "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "compiled_path": "target/compiled/zendesk/models/ticket_history/int_zendesk__field_history_enriched.sql", "build_path": null, "deferred": false, "unrendered_config": {"schema": "zendesk_docs", "materialized": "ephemeral"}, "created_at": 1647014737.135647, "compiled_sql": "with  __dbt__cte__int_zendesk__updater_information as (\nwith users as (\n    select *\n    from `bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__user_aggregates`\n\n), organizations as (\n    select *\n    from `bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__organization_aggregates`\n\n), final as (\n    select\n        users.user_id as updater_user_id\n        ,users.name as updater_name\n        ,users.role as updater_role\n        ,users.email as updater_email\n        ,users.external_id as updater_external_id\n        ,users.locale as updater_locale\n        ,users.is_active as updater_is_active\n\n        --If you use user tags this will be included, if not it will be ignored.\n        \n\n        ,users.last_login_at as updater_last_login_at\n        ,users.time_zone as updater_time_zone\n        ,organizations.organization_id as updater_organization_id\n\n        --If you use using_domain_names tags this will be included, if not it will be ignored.\n        \n\n        --If you use organization tags this will be included, if not it will be ignored.\n        \n    from users\n\n    left join organizations\n        using(organization_id)\n)\n\nselect * \nfrom final\n),ticket_field_history as (\n\n    select *\n    from `bq-project`.`dbt_joe_zendesk_docs`.`stg_zendesk__ticket_field_history`\n\n), updater_info as (\n    select *\n    from __dbt__cte__int_zendesk__updater_information\n\n), final as (\n    select\n        ticket_field_history.*\n\n          \n\n    from ticket_field_history\n\n    left join updater_info\n        on ticket_field_history.user_id = updater_info.updater_user_id\n)\nselect *\nfrom final", "extra_ctes_injected": true, "extra_ctes": [{"id": "model.zendesk.int_zendesk__updater_information", "sql": " __dbt__cte__int_zendesk__updater_information as (\nwith users as (\n    select *\n    from `bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__user_aggregates`\n\n), organizations as (\n    select *\n    from `bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__organization_aggregates`\n\n), final as (\n    select\n        users.user_id as updater_user_id\n        ,users.name as updater_name\n        ,users.role as updater_role\n        ,users.email as updater_email\n        ,users.external_id as updater_external_id\n        ,users.locale as updater_locale\n        ,users.is_active as updater_is_active\n\n        --If you use user tags this will be included, if not it will be ignored.\n        \n\n        ,users.last_login_at as updater_last_login_at\n        ,users.time_zone as updater_time_zone\n        ,organizations.organization_id as updater_organization_id\n\n        --If you use using_domain_names tags this will be included, if not it will be ignored.\n        \n\n        --If you use organization tags this will be included, if not it will be ignored.\n        \n    from users\n\n    left join organizations\n        using(organization_id)\n)\n\nselect * \nfrom final\n)"}], "relation_name": null}, "model.zendesk.int_zendesk__field_history_pivot": {"raw_sql": "-- depends_on: {{ ref('stg_zendesk__ticket_field_history') }}\n\n{{ \n    config(\n        materialized='incremental',\n        partition_by = {'field': 'date_day', 'data_type': 'date'},\n        unique_key='ticket_day_id'\n        ) \n}}\n\n{% if execute -%}\n    {% set results = run_query('select distinct field_name from ' ~ var('field_history')) %}\n    {% set results_list = results.columns[0].values() %}\n{% endif -%}\n\nwith field_history as (\n\n    select\n        ticket_id,\n        field_name,\n        valid_ending_at,\n        valid_starting_at\n\n        --Only runs if the user passes updater fields through the final ticket field history model\n        {% if var('ticket_field_history_updater_columns') %}\n        ,\n        {{ var('ticket_field_history_updater_columns') | join (\", \")}}\n\n        {% endif %}\n\n        -- doing this to figure out what values are actually null and what needs to be backfilled in zendesk__ticket_field_history\n        ,case when value is null then 'is_null' else value end as value\n\n    from {{ ref('int_zendesk__field_history_enriched') }}\n    {% if is_incremental() %}\n    where cast( {{ dbt_utils.date_trunc('day', 'valid_starting_at') }} as date) >= (select max(date_day) from {{ this }})\n    {% endif %}\n\n), event_order as (\n\n    select \n        *,\n        row_number() over (\n            partition by cast(valid_starting_at as date), ticket_id, field_name\n            order by valid_starting_at desc\n            ) as row_num\n    from field_history\n\n), filtered as (\n\n    -- Find the last event that occurs on each day for each ticket\n\n    select *\n    from event_order\n    where row_num = 1\n\n), pivots as (\n\n    -- For each column that is in both the ticket_field_history_columns variable and the field_history table,\n    -- pivot out the value into it's own column. This will feed the daily slowly changing dimension model.\n\n    select \n        ticket_id,\n        cast({{ dbt_utils.date_trunc('day', 'valid_starting_at') }} as date) as date_day\n\n        {% for col in results_list if col in var('ticket_field_history_columns') %}\n            {% set col_xf = col|lower %}\n            ,min(case when lower(field_name) = '{{ col|lower }}' then filtered.value end) as {{ col_xf }}\n\n            --Only runs if the user passes updater fields through the final ticket field history model\n            {% if var('ticket_field_history_updater_columns') %}\n\n                {% for upd in var('ticket_field_history_updater_columns') %}\n\n                    {% set upd_xf = (col|lower + '_' + upd ) %} --Creating the appropriate column name based on the history field + update field names.\n\n                    {% if upd == 'updater_is_active' and target.type in ('postgres', 'redshift') %}\n\n                        ,bool_or(case when lower(field_name) = '{{ col|lower }}' then filtered.{{ upd }} end) as {{ upd_xf }}\n\n                    {% else %}\n\n                        ,min(case when lower(field_name) = '{{ col|lower }}' then filtered.{{ upd }} end) as {{ upd_xf }}\n\n                    {% endif %}\n                {% endfor %}\n            {% endif %}\n        {% endfor %}\n    \n    from filtered\n    group by 1,2\n\n), surrogate_key as (\n\n    select \n        *,\n        {{ dbt_utils.surrogate_key(['ticket_id','date_day'])}} as ticket_day_id\n    from pivots\n\n)\n\nselect *\nfrom surrogate_key", "compiled": true, "resource_type": "model", "depends_on": {"macros": ["macro.dbt.is_incremental", "macro.dbt_utils.date_trunc", "macro.dbt_utils.surrogate_key", "macro.dbt.run_query"], "nodes": ["model.zendesk_source.stg_zendesk__ticket_field_history", "model.zendesk.int_zendesk__field_history_enriched"]}, "config": {"enabled": true, "alias": null, "schema": "zendesk_docs", "database": null, "tags": [], "meta": {}, "materialized": "incremental", "persist_docs": {}, "quoting": {}, "column_types": {}, "full_refresh": null, "on_schema_change": "ignore", "partition_by": {"field": "date_day", "data_type": "date"}, "unique_key": "ticket_day_id", "post-hook": [], "pre-hook": []}, "database": "bq-project", "schema": "dbt_joe_zendesk_docs", "fqn": ["zendesk", "ticket_history", "int_zendesk__field_history_pivot"], "unique_id": "model.zendesk.int_zendesk__field_history_pivot", "package_name": "zendesk", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/zendesk", "path": "ticket_history/int_zendesk__field_history_pivot.sql", "original_file_path": "models/ticket_history/int_zendesk__field_history_pivot.sql", "name": "int_zendesk__field_history_pivot", "alias": "int_zendesk__field_history_pivot", "checksum": {"name": "sha256", "checksum": "640f34352b199f132f1a862410be816d881428fb40d299f0d57554ff1c431119"}, "tags": [], "refs": [["stg_zendesk__ticket_field_history"], ["int_zendesk__field_history_enriched"]], "sources": [], "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "compiled_path": "target/compiled/zendesk/models/ticket_history/int_zendesk__field_history_pivot.sql", "build_path": null, "deferred": false, "unrendered_config": {"schema": "zendesk_docs", "materialized": "incremental", "partition_by": {"field": "date_day", "data_type": "date"}, "unique_key": "ticket_day_id"}, "created_at": 1647014737.1440508, "compiled_sql": "-- depends_on: `bq-project`.`dbt_joe_zendesk_docs`.`stg_zendesk__ticket_field_history`\n\n\n\n\n    \nwith  __dbt__cte__int_zendesk__updater_information as (\nwith users as (\n    select *\n    from `bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__user_aggregates`\n\n), organizations as (\n    select *\n    from `bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__organization_aggregates`\n\n), final as (\n    select\n        users.user_id as updater_user_id\n        ,users.name as updater_name\n        ,users.role as updater_role\n        ,users.email as updater_email\n        ,users.external_id as updater_external_id\n        ,users.locale as updater_locale\n        ,users.is_active as updater_is_active\n\n        --If you use user tags this will be included, if not it will be ignored.\n        \n\n        ,users.last_login_at as updater_last_login_at\n        ,users.time_zone as updater_time_zone\n        ,organizations.organization_id as updater_organization_id\n\n        --If you use using_domain_names tags this will be included, if not it will be ignored.\n        \n\n        --If you use organization tags this will be included, if not it will be ignored.\n        \n    from users\n\n    left join organizations\n        using(organization_id)\n)\n\nselect * \nfrom final\n),  __dbt__cte__int_zendesk__field_history_enriched as (\nwith ticket_field_history as (\n\n    select *\n    from `bq-project`.`dbt_joe_zendesk_docs`.`stg_zendesk__ticket_field_history`\n\n), updater_info as (\n    select *\n    from __dbt__cte__int_zendesk__updater_information\n\n), final as (\n    select\n        ticket_field_history.*\n\n          \n\n    from ticket_field_history\n\n    left join updater_info\n        on ticket_field_history.user_id = updater_info.updater_user_id\n)\nselect *\nfrom final\n),field_history as (\n\n    select\n        ticket_id,\n        field_name,\n        valid_ending_at,\n        valid_starting_at\n\n        --Only runs if the user passes updater fields through the final ticket field history model\n        \n\n        -- doing this to figure out what values are actually null and what needs to be backfilled in zendesk__ticket_field_history\n        ,case when value is null then 'is_null' else value end as value\n\n    from __dbt__cte__int_zendesk__field_history_enriched\n    \n    where cast( \n    timestamp_trunc(\n        cast(valid_starting_at as timestamp),\n        day\n    )\n\n as date) >= (select max(date_day) from `bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__field_history_pivot`)\n    \n\n), event_order as (\n\n    select \n        *,\n        row_number() over (\n            partition by cast(valid_starting_at as date), ticket_id, field_name\n            order by valid_starting_at desc\n            ) as row_num\n    from field_history\n\n), filtered as (\n\n    -- Find the last event that occurs on each day for each ticket\n\n    select *\n    from event_order\n    where row_num = 1\n\n), pivots as (\n\n    -- For each column that is in both the ticket_field_history_columns variable and the field_history table,\n    -- pivot out the value into it's own column. This will feed the daily slowly changing dimension model.\n\n    select \n        ticket_id,\n        cast(\n    timestamp_trunc(\n        cast(valid_starting_at as timestamp),\n        day\n    )\n\n as date) as date_day\n\n        \n            \n            ,min(case when lower(field_name) = 'assignee_id' then filtered.value end) as assignee_id\n\n            --Only runs if the user passes updater fields through the final ticket field history model\n            \n        \n            \n            ,min(case when lower(field_name) = 'status' then filtered.value end) as status\n\n            --Only runs if the user passes updater fields through the final ticket field history model\n            \n        \n            \n            ,min(case when lower(field_name) = 'priority' then filtered.value end) as priority\n\n            --Only runs if the user passes updater fields through the final ticket field history model\n            \n        \n    \n    from filtered\n    group by 1,2\n\n), surrogate_key as (\n\n    select \n        *,\n        to_hex(md5(cast(coalesce(cast(ticket_id as \n    string\n), '') || '-' || coalesce(cast(date_day as \n    string\n), '') as \n    string\n))) as ticket_day_id\n    from pivots\n\n)\n\nselect *\nfrom surrogate_key", "extra_ctes_injected": true, "extra_ctes": [{"id": "model.zendesk.int_zendesk__updater_information", "sql": " __dbt__cte__int_zendesk__updater_information as (\nwith users as (\n    select *\n    from `bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__user_aggregates`\n\n), organizations as (\n    select *\n    from `bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__organization_aggregates`\n\n), final as (\n    select\n        users.user_id as updater_user_id\n        ,users.name as updater_name\n        ,users.role as updater_role\n        ,users.email as updater_email\n        ,users.external_id as updater_external_id\n        ,users.locale as updater_locale\n        ,users.is_active as updater_is_active\n\n        --If you use user tags this will be included, if not it will be ignored.\n        \n\n        ,users.last_login_at as updater_last_login_at\n        ,users.time_zone as updater_time_zone\n        ,organizations.organization_id as updater_organization_id\n\n        --If you use using_domain_names tags this will be included, if not it will be ignored.\n        \n\n        --If you use organization tags this will be included, if not it will be ignored.\n        \n    from users\n\n    left join organizations\n        using(organization_id)\n)\n\nselect * \nfrom final\n)"}, {"id": "model.zendesk.int_zendesk__field_history_enriched", "sql": " __dbt__cte__int_zendesk__field_history_enriched as (\nwith ticket_field_history as (\n\n    select *\n    from `bq-project`.`dbt_joe_zendesk_docs`.`stg_zendesk__ticket_field_history`\n\n), updater_info as (\n    select *\n    from __dbt__cte__int_zendesk__updater_information\n\n), final as (\n    select\n        ticket_field_history.*\n\n          \n\n    from ticket_field_history\n\n    left join updater_info\n        on ticket_field_history.user_id = updater_info.updater_user_id\n)\nselect *\nfrom final\n)"}], "relation_name": "`bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__field_history_pivot`"}, "model.zendesk.int_zendesk__updater_information": {"raw_sql": "with users as (\n    select *\n    from {{ ref('int_zendesk__user_aggregates') }}\n\n), organizations as (\n    select *\n    from {{ ref('int_zendesk__organization_aggregates') }}\n\n), final as (\n    select\n        users.user_id as updater_user_id\n        ,users.name as updater_name\n        ,users.role as updater_role\n        ,users.email as updater_email\n        ,users.external_id as updater_external_id\n        ,users.locale as updater_locale\n        ,users.is_active as updater_is_active\n\n        --If you use user tags this will be included, if not it will be ignored.\n        {% if var('using_user_tags', True) %}\n        ,users.user_tags as updater_user_tags\n        {% endif %}\n\n        ,users.last_login_at as updater_last_login_at\n        ,users.time_zone as updater_time_zone\n        ,organizations.organization_id as updater_organization_id\n\n        --If you use using_domain_names tags this will be included, if not it will be ignored.\n        {% if var('using_domain_names', True) %}\n        ,organizations.domain_names as updater_organization_domain_names\n        {% endif %}\n\n        --If you use organization tags this will be included, if not it will be ignored.\n        {% if var('using_organization_tags', True) %}\n        ,organizations.organization_tags as updater_organization_organization_tags\n        {% endif %}\n    from users\n\n    left join organizations\n        using(organization_id)\n)\n\nselect * \nfrom final", "compiled": true, "resource_type": "model", "depends_on": {"macros": [], "nodes": ["model.zendesk.int_zendesk__user_aggregates", "model.zendesk.int_zendesk__organization_aggregates"]}, "config": {"enabled": true, "alias": null, "schema": "zendesk_docs", "database": null, "tags": [], "meta": {}, "materialized": "ephemeral", "persist_docs": {}, "quoting": {}, "column_types": {}, "full_refresh": null, "on_schema_change": "ignore", "post-hook": [], "pre-hook": []}, "database": "bq-project", "schema": "dbt_joe_zendesk_docs", "fqn": ["zendesk", "ticket_history", "int_zendesk__updater_information"], "unique_id": "model.zendesk.int_zendesk__updater_information", "package_name": "zendesk", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/zendesk", "path": "ticket_history/int_zendesk__updater_information.sql", "original_file_path": "models/ticket_history/int_zendesk__updater_information.sql", "name": "int_zendesk__updater_information", "alias": "int_zendesk__updater_information", "checksum": {"name": "sha256", "checksum": "62a690646cff991c0e0b6e205440a070bb44aab8d4d9286714710c52a4c6677a"}, "tags": [], "refs": [["int_zendesk__user_aggregates"], ["int_zendesk__organization_aggregates"]], "sources": [], "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "compiled_path": "target/compiled/zendesk/models/ticket_history/int_zendesk__updater_information.sql", "build_path": null, "deferred": false, "unrendered_config": {"schema": "zendesk_docs", "materialized": "ephemeral"}, "created_at": 1647014737.159039, "compiled_sql": "with users as (\n    select *\n    from `bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__user_aggregates`\n\n), organizations as (\n    select *\n    from `bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__organization_aggregates`\n\n), final as (\n    select\n        users.user_id as updater_user_id\n        ,users.name as updater_name\n        ,users.role as updater_role\n        ,users.email as updater_email\n        ,users.external_id as updater_external_id\n        ,users.locale as updater_locale\n        ,users.is_active as updater_is_active\n\n        --If you use user tags this will be included, if not it will be ignored.\n        \n\n        ,users.last_login_at as updater_last_login_at\n        ,users.time_zone as updater_time_zone\n        ,organizations.organization_id as updater_organization_id\n\n        --If you use using_domain_names tags this will be included, if not it will be ignored.\n        \n\n        --If you use organization tags this will be included, if not it will be ignored.\n        \n    from users\n\n    left join organizations\n        using(organization_id)\n)\n\nselect * \nfrom final", "extra_ctes_injected": true, "extra_ctes": [], "relation_name": null}, "model.zendesk.int_zendesk__field_history_scd": {"raw_sql": "-- model needs to materialize as a table to avoid erroneous null values\n{{ config( materialized='table') }} \n\n{%- set ticket_columns = adapter.get_columns_in_relation(ref('int_zendesk__field_history_pivot')) -%}\n\nwith change_data as (\n\n    select *\n    from {{ ref('int_zendesk__field_history_pivot') }}\n\n), set_values as (\n\n-- each row of the pivoted table includes field values if that field was updated on that day\n-- we need to backfill to persist values that have been previously updated and are still valid \n    select \n        date_day as valid_from,\n        ticket_id,\n        ticket_day_id\n\n        {% for col in ticket_columns if col.name|lower not in ['date_day','ending_day','ticket_id','ticket_day_id'] %} \n\n        ,{{ col.name }}\n        ,sum(case when {{ col.name }} is null \n                then 0 \n                else 1 \n                    end) over (order by ticket_id, date_day rows unbounded preceding) as {{ col.name }}_field_partition\n        {% endfor %}\n\n    from change_data\n\n), fill_values as (\n    select\n        valid_from, \n        ticket_id,\n        ticket_day_id\n\n        {% for col in ticket_columns if col.name|lower not in ['date_day','ending_day','ticket_id','ticket_day_id'] %} \n\n        ,first_value( {{ col.name }} ) over (partition by {{ col.name }}_field_partition, ticket_id order by valid_from asc rows between unbounded preceding and current row) as {{ col.name }}\n        \n        {% endfor %}\n    from set_values\n) \n\nselect *\nfrom fill_values", "compiled": true, "resource_type": "model", "depends_on": {"macros": [], "nodes": ["model.zendesk.int_zendesk__field_history_pivot", "model.zendesk.int_zendesk__field_history_pivot"]}, "config": {"enabled": true, "alias": null, "schema": "zendesk_docs", "database": null, "tags": [], "meta": {}, "materialized": "table", "persist_docs": {}, "quoting": {}, "column_types": {}, "full_refresh": null, "on_schema_change": "ignore", "post-hook": [], "pre-hook": []}, "database": "bq-project", "schema": "dbt_joe_zendesk_docs", "fqn": ["zendesk", "ticket_history", "int_zendesk__field_history_scd"], "unique_id": "model.zendesk.int_zendesk__field_history_scd", "package_name": "zendesk", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/zendesk", "path": "ticket_history/int_zendesk__field_history_scd.sql", "original_file_path": "models/ticket_history/int_zendesk__field_history_scd.sql", "name": "int_zendesk__field_history_scd", "alias": "int_zendesk__field_history_scd", "checksum": {"name": "sha256", "checksum": "fdd5efc378f074d13e0294db9d45581bd8dadb6b77657c96dca6cb656303935e"}, "tags": [], "refs": [["int_zendesk__field_history_pivot"], ["int_zendesk__field_history_pivot"]], "sources": [], "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "compiled_path": "target/compiled/zendesk/models/ticket_history/int_zendesk__field_history_scd.sql", "build_path": null, "deferred": false, "unrendered_config": {"schema": "zendesk_docs", "materialized": "table"}, "created_at": 1647014737.165153, "compiled_sql": "-- model needs to materialize as a table to avoid erroneous null values\nwith change_data as (\n\n    select *\n    from `bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__field_history_pivot`\n\n), set_values as (\n\n-- each row of the pivoted table includes field values if that field was updated on that day\n-- we need to backfill to persist values that have been previously updated and are still valid \n    select \n        date_day as valid_from,\n        ticket_id,\n        ticket_day_id\n\n         \n\n        ,assignee_id\n        ,sum(case when assignee_id is null \n                then 0 \n                else 1 \n                    end) over (order by ticket_id, date_day rows unbounded preceding) as assignee_id_field_partition\n         \n\n        ,status\n        ,sum(case when status is null \n                then 0 \n                else 1 \n                    end) over (order by ticket_id, date_day rows unbounded preceding) as status_field_partition\n         \n\n        ,priority\n        ,sum(case when priority is null \n                then 0 \n                else 1 \n                    end) over (order by ticket_id, date_day rows unbounded preceding) as priority_field_partition\n        \n\n    from change_data\n\n), fill_values as (\n    select\n        valid_from, \n        ticket_id,\n        ticket_day_id\n\n         \n\n        ,first_value( assignee_id ) over (partition by assignee_id_field_partition, ticket_id order by valid_from asc rows between unbounded preceding and current row) as assignee_id\n        \n         \n\n        ,first_value( status ) over (partition by status_field_partition, ticket_id order by valid_from asc rows between unbounded preceding and current row) as status\n        \n         \n\n        ,first_value( priority ) over (partition by priority_field_partition, ticket_id order by valid_from asc rows between unbounded preceding and current row) as priority\n        \n        \n    from set_values\n) \n\nselect *\nfrom fill_values", "extra_ctes_injected": true, "extra_ctes": [], "relation_name": "`bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__field_history_scd`"}, "model.zendesk.int_zendesk__field_calendar_spine": {"raw_sql": "{{\n    config(\n        materialized='incremental',\n        partition_by = {'field': 'date_day', 'data_type': 'date'},\n        unique_key='ticket_day_id'\n    )\n}}\n\nwith calendar as (\n\n    select *\n    from {{ ref('int_zendesk__calendar_spine') }}\n    {% if is_incremental() %}\n    where date_day >= (select max(date_day) from {{ this }})\n    {% endif %}\n\n), ticket as (\n\n    select \n        *,\n        -- closed tickets cannot be re-opened or updated, and solved tickets are automatically closed after a pre-defined number of days configured in your Zendesk settings\n        cast( {{ dbt_utils.date_trunc('day', \"case when status != 'closed' then \" ~ dbt_utils.current_timestamp() ~ \" else updated_at end\") }} as date) as open_until\n    from {{ var('ticket') }}\n    \n), joined as (\n\n    select \n        calendar.date_day,\n        ticket.ticket_id\n    from calendar\n    inner join ticket\n        on calendar.date_day >= cast(ticket.created_at as date)\n        -- use this variable to extend the ticket's history past its close date (for reporting/data viz purposes :-)\n        and {{ dbt_utils.dateadd('month', var('ticket_field_history_extension_months', 0), 'ticket.open_until') }} >= calendar.date_day\n\n), surrogate_key as (\n\n    select\n        *,\n        {{ dbt_utils.surrogate_key(['date_day','ticket_id']) }} as ticket_day_id\n    from joined\n\n)\n\nselect *\nfrom surrogate_key", "compiled": true, "resource_type": "model", "depends_on": {"macros": ["macro.dbt.is_incremental", "macro.dbt_utils.current_timestamp", "macro.dbt_utils.date_trunc", "macro.dbt_utils.dateadd", "macro.dbt_utils.surrogate_key"], "nodes": ["model.zendesk.int_zendesk__calendar_spine", "model.zendesk_source.stg_zendesk__ticket"]}, "config": {"enabled": true, "alias": null, "schema": "zendesk_docs", "database": null, "tags": [], "meta": {}, "materialized": "incremental", "persist_docs": {}, "quoting": {}, "column_types": {}, "full_refresh": null, "on_schema_change": "ignore", "partition_by": {"field": "date_day", "data_type": "date"}, "unique_key": "ticket_day_id", "post-hook": [], "pre-hook": []}, "database": "bq-project", "schema": "dbt_joe_zendesk_docs", "fqn": ["zendesk", "ticket_history", "int_zendesk__field_calendar_spine"], "unique_id": "model.zendesk.int_zendesk__field_calendar_spine", "package_name": "zendesk", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/zendesk", "path": "ticket_history/int_zendesk__field_calendar_spine.sql", "original_file_path": "models/ticket_history/int_zendesk__field_calendar_spine.sql", "name": "int_zendesk__field_calendar_spine", "alias": "int_zendesk__field_calendar_spine", "checksum": {"name": "sha256", "checksum": "b0ea1607b99a53a9e02cdeec7699a20cea85981a56d8fa8f39bed2e65dac39a5"}, "tags": [], "refs": [["int_zendesk__calendar_spine"], ["stg_zendesk__ticket"]], "sources": [], "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "compiled_path": "target/compiled/zendesk/models/ticket_history/int_zendesk__field_calendar_spine.sql", "build_path": null, "deferred": false, "unrendered_config": {"schema": "zendesk_docs", "materialized": "incremental", "partition_by": {"field": "date_day", "data_type": "date"}, "unique_key": "ticket_day_id"}, "created_at": 1647014737.17424, "compiled_sql": "\n\nwith  __dbt__cte__int_zendesk__calendar_spine as (\n-- depends_on: `bq-project`.`dbt_joe_zendesk_docs`.`stg_zendesk__ticket`\n\nwith spine as (\n\n    \n    \n\n    \n    \n        \n            \n\n        \n\n    \n\n    \n\n\n\n\n\n\nwith rawdata as (\n\n    \n\n    \n\n    with p as (\n        select 0 as generated_number union all select 1\n    ), unioned as (\n\n    select\n\n    \n    p0.generated_number * power(2, 0)\n     + \n    \n    p1.generated_number * power(2, 1)\n     + \n    \n    p2.generated_number * power(2, 2)\n     + \n    \n    p3.generated_number * power(2, 3)\n     + \n    \n    p4.generated_number * power(2, 4)\n     + \n    \n    p5.generated_number * power(2, 5)\n     + \n    \n    p6.generated_number * power(2, 6)\n     + \n    \n    p7.generated_number * power(2, 7)\n     + \n    \n    p8.generated_number * power(2, 8)\n     + \n    \n    p9.generated_number * power(2, 9)\n     + \n    \n    p10.generated_number * power(2, 10)\n    \n    \n    + 1\n    as generated_number\n\n    from\n\n    \n    p as p0\n     cross join \n    \n    p as p1\n     cross join \n    \n    p as p2\n     cross join \n    \n    p as p3\n     cross join \n    \n    p as p4\n     cross join \n    \n    p as p5\n     cross join \n    \n    p as p6\n     cross join \n    \n    p as p7\n     cross join \n    \n    p as p8\n     cross join \n    \n    p as p9\n     cross join \n    \n    p as p10\n    \n    \n\n    )\n\n    select *\n    from unioned\n    where generated_number <= 1270\n    order by generated_number\n\n\n\n),\n\nall_periods as (\n\n    select (\n        \n\n        datetime_add(\n            cast( '2018-09-25' as datetime),\n        interval row_number() over (order by 1) - 1 day\n        )\n\n\n    ) as date_day\n    from rawdata\n\n),\n\nfiltered as (\n\n    select *\n    from all_periods\n    where date_day <= \n\n        datetime_add(\n            cast( current_date as datetime),\n        interval 1 week\n        )\n\n\n\n)\n\nselect * from filtered\n\n\n\n), recast as (\n\n    select cast(date_day as date) as date_day\n    from spine\n\n)\n\nselect *\nfrom recast\n),calendar as (\n\n    select *\n    from __dbt__cte__int_zendesk__calendar_spine\n    \n    where date_day >= (select max(date_day) from `bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__field_calendar_spine`)\n    \n\n), ticket as (\n\n    select \n        *,\n        -- closed tickets cannot be re-opened or updated, and solved tickets are automatically closed after a pre-defined number of days configured in your Zendesk settings\n        cast( \n    timestamp_trunc(\n        cast(case when status != 'closed' then \n    current_timestamp\n else updated_at end as timestamp),\n        day\n    )\n\n as date) as open_until\n    from `bq-project`.`dbt_joe_zendesk_docs`.`stg_zendesk__ticket`\n    \n), joined as (\n\n    select \n        calendar.date_day,\n        ticket.ticket_id\n    from calendar\n    inner join ticket\n        on calendar.date_day >= cast(ticket.created_at as date)\n        -- use this variable to extend the ticket's history past its close date (for reporting/data viz purposes :-)\n        and \n\n        datetime_add(\n            cast( ticket.open_until as datetime),\n        interval 0 month\n        )\n\n >= calendar.date_day\n\n), surrogate_key as (\n\n    select\n        *,\n        to_hex(md5(cast(coalesce(cast(date_day as \n    string\n), '') || '-' || coalesce(cast(ticket_id as \n    string\n), '') as \n    string\n))) as ticket_day_id\n    from joined\n\n)\n\nselect *\nfrom surrogate_key", "extra_ctes_injected": true, "extra_ctes": [{"id": "model.zendesk.int_zendesk__calendar_spine", "sql": " __dbt__cte__int_zendesk__calendar_spine as (\n-- depends_on: `bq-project`.`dbt_joe_zendesk_docs`.`stg_zendesk__ticket`\n\nwith spine as (\n\n    \n    \n\n    \n    \n        \n            \n\n        \n\n    \n\n    \n\n\n\n\n\n\nwith rawdata as (\n\n    \n\n    \n\n    with p as (\n        select 0 as generated_number union all select 1\n    ), unioned as (\n\n    select\n\n    \n    p0.generated_number * power(2, 0)\n     + \n    \n    p1.generated_number * power(2, 1)\n     + \n    \n    p2.generated_number * power(2, 2)\n     + \n    \n    p3.generated_number * power(2, 3)\n     + \n    \n    p4.generated_number * power(2, 4)\n     + \n    \n    p5.generated_number * power(2, 5)\n     + \n    \n    p6.generated_number * power(2, 6)\n     + \n    \n    p7.generated_number * power(2, 7)\n     + \n    \n    p8.generated_number * power(2, 8)\n     + \n    \n    p9.generated_number * power(2, 9)\n     + \n    \n    p10.generated_number * power(2, 10)\n    \n    \n    + 1\n    as generated_number\n\n    from\n\n    \n    p as p0\n     cross join \n    \n    p as p1\n     cross join \n    \n    p as p2\n     cross join \n    \n    p as p3\n     cross join \n    \n    p as p4\n     cross join \n    \n    p as p5\n     cross join \n    \n    p as p6\n     cross join \n    \n    p as p7\n     cross join \n    \n    p as p8\n     cross join \n    \n    p as p9\n     cross join \n    \n    p as p10\n    \n    \n\n    )\n\n    select *\n    from unioned\n    where generated_number <= 1270\n    order by generated_number\n\n\n\n),\n\nall_periods as (\n\n    select (\n        \n\n        datetime_add(\n            cast( '2018-09-25' as datetime),\n        interval row_number() over (order by 1) - 1 day\n        )\n\n\n    ) as date_day\n    from rawdata\n\n),\n\nfiltered as (\n\n    select *\n    from all_periods\n    where date_day <= \n\n        datetime_add(\n            cast( current_date as datetime),\n        interval 1 week\n        )\n\n\n\n)\n\nselect * from filtered\n\n\n\n), recast as (\n\n    select cast(date_day as date) as date_day\n    from spine\n\n)\n\nselect *\nfrom recast\n)"}], "relation_name": "`bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__field_calendar_spine`"}, "model.zendesk.int_zendesk__ticket_work_time_calendar": {"raw_sql": "with ticket_historical_status as (\n\n    select *\n    from {{ ref('int_zendesk__ticket_historical_status') }}\n\n), calendar_minutes as (\n  \n    select \n        ticket_id,\n        status,\n        case when status in ('pending') then status_duration_calendar_minutes\n            else 0 end as agent_wait_time_in_minutes,\n        case when status in ('new', 'open', 'hold') then status_duration_calendar_minutes\n            else 0 end as requester_wait_time_in_minutes,\n        case when status in ('new', 'open') then status_duration_calendar_minutes\n            else 0 end as agent_work_time_in_minutes,\n        case when status in ('hold') then status_duration_calendar_minutes\n            else 0 end as on_hold_time_in_minutes,\n        case when status = 'new' then status_duration_calendar_minutes\n            else 0 end as new_status_duration_minutes,\n        case when status = 'open' then status_duration_calendar_minutes\n            else 0 end as open_status_duration_minutes,\n        case when status = 'deleted' then 1\n            else 0 end as ticket_deleted,\n        first_value(valid_starting_at) over (partition by ticket_id order by valid_starting_at desc, ticket_id rows unbounded preceding) as last_status_assignment_date,\n        case when lag(status) over (partition by ticket_id order by valid_starting_at) = 'deleted' and status != 'deleted'\n            then 1\n            else 0\n                end as ticket_recoveries\n\n    from ticket_historical_status\n\n)\n\nselect \n  ticket_id,\n  last_status_assignment_date,\n  sum(ticket_deleted) as ticket_deleted_count,\n  sum(agent_wait_time_in_minutes) as agent_wait_time_in_calendar_minutes,\n  sum(requester_wait_time_in_minutes) as requester_wait_time_in_calendar_minutes,\n  sum(agent_work_time_in_minutes) as agent_work_time_in_calendar_minutes,\n  sum(on_hold_time_in_minutes) as on_hold_time_in_calendar_minutes,\n  sum(new_status_duration_minutes) as new_status_duration_in_calendar_minutes,\n  sum(open_status_duration_minutes) as open_status_duration_in_calendar_minutes,\n  sum(ticket_recoveries) as total_ticket_recoveries\nfrom calendar_minutes\ngroup by 1, 2", "compiled": true, "resource_type": "model", "depends_on": {"macros": [], "nodes": ["model.zendesk.int_zendesk__ticket_historical_status"]}, "config": {"enabled": true, "alias": null, "schema": "zendesk_docs", "database": null, "tags": [], "meta": {}, "materialized": "ephemeral", "persist_docs": {}, "quoting": {}, "column_types": {}, "full_refresh": null, "on_schema_change": "ignore", "post-hook": [], "pre-hook": []}, "database": "bq-project", "schema": "dbt_joe_zendesk_docs", "fqn": ["zendesk", "agent_work_time", "int_zendesk__ticket_work_time_calendar"], "unique_id": "model.zendesk.int_zendesk__ticket_work_time_calendar", "package_name": "zendesk", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/zendesk", "path": "agent_work_time/int_zendesk__ticket_work_time_calendar.sql", "original_file_path": "models/agent_work_time/int_zendesk__ticket_work_time_calendar.sql", "name": "int_zendesk__ticket_work_time_calendar", "alias": "int_zendesk__ticket_work_time_calendar", "checksum": {"name": "sha256", "checksum": "cf3556742d3de31832862939ef3e9ef76e09762949db514b4a8e125953460c10"}, "tags": [], "refs": [["int_zendesk__ticket_historical_status"]], "sources": [], "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "compiled_path": "target/compiled/zendesk/models/agent_work_time/int_zendesk__ticket_work_time_calendar.sql", "build_path": null, "deferred": false, "unrendered_config": {"schema": "zendesk_docs", "materialized": "ephemeral"}, "created_at": 1647014737.186788, "compiled_sql": "with ticket_historical_status as (\n\n    select *\n    from `bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__ticket_historical_status`\n\n), calendar_minutes as (\n  \n    select \n        ticket_id,\n        status,\n        case when status in ('pending') then status_duration_calendar_minutes\n            else 0 end as agent_wait_time_in_minutes,\n        case when status in ('new', 'open', 'hold') then status_duration_calendar_minutes\n            else 0 end as requester_wait_time_in_minutes,\n        case when status in ('new', 'open') then status_duration_calendar_minutes\n            else 0 end as agent_work_time_in_minutes,\n        case when status in ('hold') then status_duration_calendar_minutes\n            else 0 end as on_hold_time_in_minutes,\n        case when status = 'new' then status_duration_calendar_minutes\n            else 0 end as new_status_duration_minutes,\n        case when status = 'open' then status_duration_calendar_minutes\n            else 0 end as open_status_duration_minutes,\n        case when status = 'deleted' then 1\n            else 0 end as ticket_deleted,\n        first_value(valid_starting_at) over (partition by ticket_id order by valid_starting_at desc, ticket_id rows unbounded preceding) as last_status_assignment_date,\n        case when lag(status) over (partition by ticket_id order by valid_starting_at) = 'deleted' and status != 'deleted'\n            then 1\n            else 0\n                end as ticket_recoveries\n\n    from ticket_historical_status\n\n)\n\nselect \n  ticket_id,\n  last_status_assignment_date,\n  sum(ticket_deleted) as ticket_deleted_count,\n  sum(agent_wait_time_in_minutes) as agent_wait_time_in_calendar_minutes,\n  sum(requester_wait_time_in_minutes) as requester_wait_time_in_calendar_minutes,\n  sum(agent_work_time_in_minutes) as agent_work_time_in_calendar_minutes,\n  sum(on_hold_time_in_minutes) as on_hold_time_in_calendar_minutes,\n  sum(new_status_duration_minutes) as new_status_duration_in_calendar_minutes,\n  sum(open_status_duration_minutes) as open_status_duration_in_calendar_minutes,\n  sum(ticket_recoveries) as total_ticket_recoveries\nfrom calendar_minutes\ngroup by 1, 2", "extra_ctes_injected": true, "extra_ctes": [], "relation_name": null}, "model.zendesk.int_zendesk__ticket_work_time_business": {"raw_sql": "{{ config(enabled=var('using_schedules', True)) }}\n\nwith ticket_historical_status as (\n\n    select *\n    from {{ ref('int_zendesk__ticket_historical_status') }}\n\n), ticket_schedules as (\n\n    select *\n    from {{ ref('int_zendesk__ticket_schedules') }}\n\n), schedule as (\n\n    select *\n    from {{ ref('int_zendesk__schedule_spine') }}\n\n), ticket_status_crossed_with_schedule as (\n  \n    select\n      ticket_historical_status.ticket_id,\n      ticket_historical_status.status as ticket_status,\n      ticket_schedules.schedule_id,\n\n      -- take the intersection of the intervals in which the status and the schedule were both active, for calculating the business minutes spent working on the ticket\n      greatest(valid_starting_at, schedule_created_at) as status_schedule_start,\n      least(valid_ending_at, schedule_invalidated_at) as status_schedule_end,\n\n      -- bringing the following in the determine which schedule (Daylight Savings vs Standard time) to use\n      ticket_historical_status.valid_starting_at as status_valid_starting_at,\n      ticket_historical_status.valid_ending_at as status_valid_ending_at\n\n    from ticket_historical_status\n    left join ticket_schedules\n      on ticket_historical_status.ticket_id = ticket_schedules.ticket_id\n      where {{ fivetran_utils.timestamp_diff('greatest(valid_starting_at, schedule_created_at)', 'least(valid_ending_at, schedule_invalidated_at)', 'second') }} > 0\n\n), ticket_full_solved_time as (\n\n    select \n      ticket_status_crossed_with_schedule.*,\n      ({{ fivetran_utils.timestamp_diff(\n              \"\" ~ dbt_utils.date_trunc('week', 'ticket_status_crossed_with_schedule.status_schedule_start') ~ \"\", \n              'ticket_status_crossed_with_schedule.status_schedule_start',\n              'second') }} /60\n            ) as start_time_in_minutes_from_week,\n      ({{ fivetran_utils.timestamp_diff(\n              'ticket_status_crossed_with_schedule.status_schedule_start',\n              'ticket_status_crossed_with_schedule.status_schedule_end',\n              'second') }} /60\n            ) as raw_delta_in_minutes\n    from ticket_status_crossed_with_schedule\n    {{ dbt_utils.group_by(n=7) }}\n\n), weeks as (\n\n    {{ dbt_utils.generate_series(208) }}\n\n), weeks_cross_ticket_full_solved_time as (\n    -- because time is reported in minutes since the beginning of the week, we have to split up time spent on the ticket into calendar weeks\n    select \n      ticket_full_solved_time.*,\n      generated_number - 1 as week_number\n    from ticket_full_solved_time\n    cross join weeks\n    where floor((start_time_in_minutes_from_week + raw_delta_in_minutes) / (7*24*60)) >= generated_number -1\n\n), weekly_periods as (\n\n    select\n\n      weeks_cross_ticket_full_solved_time.*,\n      greatest(0, start_time_in_minutes_from_week - week_number * (7*24*60)) as ticket_week_start_time,\n      least(start_time_in_minutes_from_week + raw_delta_in_minutes - week_number * (7*24*60), (7*24*60)) as ticket_week_end_time\n    \n    from weeks_cross_ticket_full_solved_time\n\n), intercepted_periods as (\n  \n    select \n      weekly_periods.ticket_id,\n      weekly_periods.week_number,\n      weekly_periods.schedule_id,\n      weekly_periods.ticket_status,\n      weekly_periods.ticket_week_start_time,\n      weekly_periods.ticket_week_end_time,\n      schedule.start_time_utc as schedule_start_time,\n      schedule.end_time_utc as schedule_end_time,\n      least(ticket_week_end_time, schedule.end_time_utc) - greatest(weekly_periods.ticket_week_start_time, schedule.start_time_utc) as scheduled_minutes\n    from weekly_periods\n    join schedule on ticket_week_start_time <= schedule.end_time_utc \n      and ticket_week_end_time >= schedule.start_time_utc\n      and weekly_periods.schedule_id = schedule.schedule_id\n      -- this chooses the Daylight Savings Time or Standard Time version of the schedule\n      and weekly_periods.status_valid_ending_at >= cast(schedule.valid_from as {{ dbt_utils.type_timestamp() }})\n      and weekly_periods.status_valid_starting_at < cast(schedule.valid_until as {{ dbt_utils.type_timestamp() }}) \n  \n), business_minutes as (\n  \n    select \n      ticket_id,\n      ticket_status,\n      case when ticket_status in ('pending') then scheduled_minutes\n          else 0 end as agent_wait_time_in_minutes,\n      case when ticket_status in ('new', 'open', 'hold') then scheduled_minutes\n          else 0 end as requester_wait_time_in_minutes,\n      case when ticket_status in ('new', 'open') then scheduled_minutes\n          else 0 end as agent_work_time_in_minutes,\n      case when ticket_status in ('hold') then scheduled_minutes\n          else 0 end as on_hold_time_in_minutes\n    from intercepted_periods\n\n)\n  \n    select \n      ticket_id,\n      sum(agent_wait_time_in_minutes) as agent_wait_time_in_business_minutes,\n      sum(requester_wait_time_in_minutes) as requester_wait_time_in_business_minutes,\n      sum(agent_work_time_in_minutes) as agent_work_time_in_business_minutes,\n      sum(on_hold_time_in_minutes) as on_hold_time_in_business_minutes\n    from business_minutes\n    group by 1", "compiled": true, "resource_type": "model", "depends_on": {"macros": ["macro.fivetran_utils.timestamp_diff", "macro.dbt_utils.date_trunc", "macro.dbt_utils.group_by", "macro.dbt_utils.generate_series", "macro.dbt_utils.type_timestamp"], "nodes": ["model.zendesk.int_zendesk__ticket_historical_status", "model.zendesk.int_zendesk__ticket_schedules", "model.zendesk.int_zendesk__schedule_spine"]}, "config": {"enabled": true, "alias": null, "schema": "zendesk_docs", "database": null, "tags": [], "meta": {}, "materialized": "ephemeral", "persist_docs": {}, "quoting": {}, "column_types": {}, "full_refresh": null, "on_schema_change": "ignore", "post-hook": [], "pre-hook": []}, "database": "bq-project", "schema": "dbt_joe_zendesk_docs", "fqn": ["zendesk", "agent_work_time", "int_zendesk__ticket_work_time_business"], "unique_id": "model.zendesk.int_zendesk__ticket_work_time_business", "package_name": "zendesk", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/zendesk", "path": "agent_work_time/int_zendesk__ticket_work_time_business.sql", "original_file_path": "models/agent_work_time/int_zendesk__ticket_work_time_business.sql", "name": "int_zendesk__ticket_work_time_business", "alias": "int_zendesk__ticket_work_time_business", "checksum": {"name": "sha256", "checksum": "935476f79b31640eed9ed45ca9fd63ab77fd683467c0268f6caa231416e9738a"}, "tags": [], "refs": [["int_zendesk__ticket_historical_status"], ["int_zendesk__ticket_schedules"], ["int_zendesk__schedule_spine"]], "sources": [], "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "compiled_path": "target/compiled/zendesk/models/agent_work_time/int_zendesk__ticket_work_time_business.sql", "build_path": null, "deferred": false, "unrendered_config": {"schema": "zendesk_docs", "materialized": "ephemeral", "enabled": true}, "created_at": 1647014737.1890812, "compiled_sql": "\n\nwith ticket_historical_status as (\n\n    select *\n    from `bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__ticket_historical_status`\n\n), ticket_schedules as (\n\n    select *\n    from `bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__ticket_schedules`\n\n), schedule as (\n\n    select *\n    from `bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__schedule_spine`\n\n), ticket_status_crossed_with_schedule as (\n  \n    select\n      ticket_historical_status.ticket_id,\n      ticket_historical_status.status as ticket_status,\n      ticket_schedules.schedule_id,\n\n      -- take the intersection of the intervals in which the status and the schedule were both active, for calculating the business minutes spent working on the ticket\n      greatest(valid_starting_at, schedule_created_at) as status_schedule_start,\n      least(valid_ending_at, schedule_invalidated_at) as status_schedule_end,\n\n      -- bringing the following in the determine which schedule (Daylight Savings vs Standard time) to use\n      ticket_historical_status.valid_starting_at as status_valid_starting_at,\n      ticket_historical_status.valid_ending_at as status_valid_ending_at\n\n    from ticket_historical_status\n    left join ticket_schedules\n      on ticket_historical_status.ticket_id = ticket_schedules.ticket_id\n      where \n  \n\n    timestamp_diff(\n        least(valid_ending_at, schedule_invalidated_at),\n        greatest(valid_starting_at, schedule_created_at),\n        second\n    )\n\n\n > 0\n\n), ticket_full_solved_time as (\n\n    select \n      ticket_status_crossed_with_schedule.*,\n      (\n  \n\n    timestamp_diff(\n        ticket_status_crossed_with_schedule.status_schedule_start,\n        \n    timestamp_trunc(\n        cast(ticket_status_crossed_with_schedule.status_schedule_start as timestamp),\n        week\n    )\n\n,\n        second\n    )\n\n\n /60\n            ) as start_time_in_minutes_from_week,\n      (\n  \n\n    timestamp_diff(\n        ticket_status_crossed_with_schedule.status_schedule_end,\n        ticket_status_crossed_with_schedule.status_schedule_start,\n        second\n    )\n\n\n /60\n            ) as raw_delta_in_minutes\n    from ticket_status_crossed_with_schedule\n    group by 1,2,3,4,5,6,7\n\n), weeks as (\n\n    \n\n    \n\n    with p as (\n        select 0 as generated_number union all select 1\n    ), unioned as (\n\n    select\n\n    \n    p0.generated_number * power(2, 0)\n     + \n    \n    p1.generated_number * power(2, 1)\n     + \n    \n    p2.generated_number * power(2, 2)\n     + \n    \n    p3.generated_number * power(2, 3)\n     + \n    \n    p4.generated_number * power(2, 4)\n     + \n    \n    p5.generated_number * power(2, 5)\n     + \n    \n    p6.generated_number * power(2, 6)\n     + \n    \n    p7.generated_number * power(2, 7)\n    \n    \n    + 1\n    as generated_number\n\n    from\n\n    \n    p as p0\n     cross join \n    \n    p as p1\n     cross join \n    \n    p as p2\n     cross join \n    \n    p as p3\n     cross join \n    \n    p as p4\n     cross join \n    \n    p as p5\n     cross join \n    \n    p as p6\n     cross join \n    \n    p as p7\n    \n    \n\n    )\n\n    select *\n    from unioned\n    where generated_number <= 208\n    order by generated_number\n\n\n\n), weeks_cross_ticket_full_solved_time as (\n    -- because time is reported in minutes since the beginning of the week, we have to split up time spent on the ticket into calendar weeks\n    select \n      ticket_full_solved_time.*,\n      generated_number - 1 as week_number\n    from ticket_full_solved_time\n    cross join weeks\n    where floor((start_time_in_minutes_from_week + raw_delta_in_minutes) / (7*24*60)) >= generated_number -1\n\n), weekly_periods as (\n\n    select\n\n      weeks_cross_ticket_full_solved_time.*,\n      greatest(0, start_time_in_minutes_from_week - week_number * (7*24*60)) as ticket_week_start_time,\n      least(start_time_in_minutes_from_week + raw_delta_in_minutes - week_number * (7*24*60), (7*24*60)) as ticket_week_end_time\n    \n    from weeks_cross_ticket_full_solved_time\n\n), intercepted_periods as (\n  \n    select \n      weekly_periods.ticket_id,\n      weekly_periods.week_number,\n      weekly_periods.schedule_id,\n      weekly_periods.ticket_status,\n      weekly_periods.ticket_week_start_time,\n      weekly_periods.ticket_week_end_time,\n      schedule.start_time_utc as schedule_start_time,\n      schedule.end_time_utc as schedule_end_time,\n      least(ticket_week_end_time, schedule.end_time_utc) - greatest(weekly_periods.ticket_week_start_time, schedule.start_time_utc) as scheduled_minutes\n    from weekly_periods\n    join schedule on ticket_week_start_time <= schedule.end_time_utc \n      and ticket_week_end_time >= schedule.start_time_utc\n      and weekly_periods.schedule_id = schedule.schedule_id\n      -- this chooses the Daylight Savings Time or Standard Time version of the schedule\n      and weekly_periods.status_valid_ending_at >= cast(schedule.valid_from as \n    timestamp\n)\n      and weekly_periods.status_valid_starting_at < cast(schedule.valid_until as \n    timestamp\n) \n  \n), business_minutes as (\n  \n    select \n      ticket_id,\n      ticket_status,\n      case when ticket_status in ('pending') then scheduled_minutes\n          else 0 end as agent_wait_time_in_minutes,\n      case when ticket_status in ('new', 'open', 'hold') then scheduled_minutes\n          else 0 end as requester_wait_time_in_minutes,\n      case when ticket_status in ('new', 'open') then scheduled_minutes\n          else 0 end as agent_work_time_in_minutes,\n      case when ticket_status in ('hold') then scheduled_minutes\n          else 0 end as on_hold_time_in_minutes\n    from intercepted_periods\n\n)\n  \n    select \n      ticket_id,\n      sum(agent_wait_time_in_minutes) as agent_wait_time_in_business_minutes,\n      sum(requester_wait_time_in_minutes) as requester_wait_time_in_business_minutes,\n      sum(agent_work_time_in_minutes) as agent_work_time_in_business_minutes,\n      sum(on_hold_time_in_minutes) as on_hold_time_in_business_minutes\n    from business_minutes\n    group by 1", "extra_ctes_injected": true, "extra_ctes": [], "relation_name": null}, "model.zendesk.int_zendesk__calendar_spine": {"raw_sql": "-- depends_on: {{ ref('stg_zendesk__ticket') }}\n\nwith spine as (\n\n    {% if execute %}\n    {% set first_date_query %}\n        select  min( created_at ) as min_date from {{ ref('stg_zendesk__ticket') }}\n        -- by default take all the data \n        where cast(created_at as date) >= {{ dbt_utils.dateadd('year', - var('ticket_field_history_timeframe_years', 50), dbt_utils.current_timestamp() ) }}\n    {% endset %}\n\n    {% set first_date = run_query(first_date_query).columns[0][0]|string %}\n    \n        {% if target.type == 'postgres' %}\n            {% set first_date_adjust = \"cast('\" ~ first_date[0:10] ~ \"' as date)\" %}\n\n        {% else %}\n            {% set first_date_adjust = \"'\" ~ first_date[0:10] ~ \"'\" %}\n\n        {% endif %}\n\n    {% else %} {% set first_date_adjust = \"2016-01-01\" %}\n    {% endif %}\n\n    \n{{\n    dbt_utils.date_spine(\n        datepart = \"day\", \n        start_date = first_date_adjust,\n        end_date = dbt_utils.dateadd(\"week\", 1, \"current_date\")\n    )   \n}}\n\n), recast as (\n\n    select cast(date_day as date) as date_day\n    from spine\n\n)\n\nselect *\nfrom recast", "compiled": true, "resource_type": "model", "depends_on": {"macros": ["macro.dbt_utils.dateadd", "macro.dbt_utils.date_spine", "macro.dbt_utils.current_timestamp", "macro.dbt.run_query"], "nodes": ["model.zendesk_source.stg_zendesk__ticket"]}, "config": {"enabled": true, "alias": null, "schema": "zendesk_docs", "database": null, "tags": [], "meta": {}, "materialized": "ephemeral", "persist_docs": {}, "quoting": {}, "column_types": {}, "full_refresh": null, "on_schema_change": "ignore", "post-hook": [], "pre-hook": []}, "database": "bq-project", "schema": "dbt_joe_zendesk_docs", "fqn": ["zendesk", "utils", "int_zendesk__calendar_spine"], "unique_id": "model.zendesk.int_zendesk__calendar_spine", "package_name": "zendesk", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/zendesk", "path": "utils/int_zendesk__calendar_spine.sql", "original_file_path": "models/utils/int_zendesk__calendar_spine.sql", "name": "int_zendesk__calendar_spine", "alias": "int_zendesk__calendar_spine", "checksum": {"name": "sha256", "checksum": "2600ddadf1743eabb6489d5d09180101c182662e7fd7e2f72807dabfae5fd546"}, "tags": [], "refs": [["stg_zendesk__ticket"]], "sources": [], "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "compiled_path": "target/compiled/zendesk/models/utils/int_zendesk__calendar_spine.sql", "build_path": null, "deferred": false, "unrendered_config": {"schema": "zendesk_docs", "materialized": "ephemeral"}, "created_at": 1647014737.199008, "compiled_sql": "-- depends_on: `bq-project`.`dbt_joe_zendesk_docs`.`stg_zendesk__ticket`\n\nwith spine as (\n\n    \n    \n\n    \n    \n        \n            \n\n        \n\n    \n\n    \n\n\n\n\n\n\nwith rawdata as (\n\n    \n\n    \n\n    with p as (\n        select 0 as generated_number union all select 1\n    ), unioned as (\n\n    select\n\n    \n    p0.generated_number * power(2, 0)\n     + \n    \n    p1.generated_number * power(2, 1)\n     + \n    \n    p2.generated_number * power(2, 2)\n     + \n    \n    p3.generated_number * power(2, 3)\n     + \n    \n    p4.generated_number * power(2, 4)\n     + \n    \n    p5.generated_number * power(2, 5)\n     + \n    \n    p6.generated_number * power(2, 6)\n     + \n    \n    p7.generated_number * power(2, 7)\n     + \n    \n    p8.generated_number * power(2, 8)\n     + \n    \n    p9.generated_number * power(2, 9)\n     + \n    \n    p10.generated_number * power(2, 10)\n    \n    \n    + 1\n    as generated_number\n\n    from\n\n    \n    p as p0\n     cross join \n    \n    p as p1\n     cross join \n    \n    p as p2\n     cross join \n    \n    p as p3\n     cross join \n    \n    p as p4\n     cross join \n    \n    p as p5\n     cross join \n    \n    p as p6\n     cross join \n    \n    p as p7\n     cross join \n    \n    p as p8\n     cross join \n    \n    p as p9\n     cross join \n    \n    p as p10\n    \n    \n\n    )\n\n    select *\n    from unioned\n    where generated_number <= 1270\n    order by generated_number\n\n\n\n),\n\nall_periods as (\n\n    select (\n        \n\n        datetime_add(\n            cast( '2018-09-25' as datetime),\n        interval row_number() over (order by 1) - 1 day\n        )\n\n\n    ) as date_day\n    from rawdata\n\n),\n\nfiltered as (\n\n    select *\n    from all_periods\n    where date_day <= \n\n        datetime_add(\n            cast( current_date as datetime),\n        interval 1 week\n        )\n\n\n\n)\n\nselect * from filtered\n\n\n\n), recast as (\n\n    select cast(date_day as date) as date_day\n    from spine\n\n)\n\nselect *\nfrom recast", "extra_ctes_injected": true, "extra_ctes": [], "relation_name": null}, "model.zendesk.int_zendesk__ticket_resolution_times_calendar": {"raw_sql": "with historical_solved_status as (\n\n    select *\n    from {{ ref('int_zendesk__ticket_historical_status') }}\n    where status = 'solved'\n\n), ticket as (\n\n    select *\n    from {{ ref('stg_zendesk__ticket') }}\n\n), ticket_historical_assignee as (\n\n    select *\n    from {{ ref('int_zendesk__ticket_historical_assignee') }}\n\n), ticket_historical_group as (\n\n  select *\n  from {{ ref('int_zendesk__ticket_historical_group') }}\n\n), solved_times as (\n  \n  select\n  \n    ticket_id,\n    min(valid_starting_at) as first_solved_at,\n    max(valid_starting_at) as last_solved_at,\n    count(status) as solved_count \n\n  from historical_solved_status\n  group by 1\n\n)\n\n  select\n\n    ticket.ticket_id,\n    ticket.created_at,\n    solved_times.first_solved_at,\n    solved_times.last_solved_at,\n    ticket_historical_assignee.unique_assignee_count,\n    ticket_historical_assignee.assignee_stations_count,\n    ticket_historical_group.group_stations_count,\n    ticket_historical_assignee.first_assignee_id,\n    ticket_historical_assignee.last_assignee_id,\n    ticket_historical_assignee.first_agent_assignment_date,\n    ticket_historical_assignee.last_agent_assignment_date,\n    ticket_historical_assignee.ticket_unassigned_duration_calendar_minutes,\n    solved_times.solved_count as total_resolutions,\n    case when solved_times.solved_count <= 1\n      then 0\n      else solved_times.solved_count - 1 --subtracting one as the first solve is not a reopen.\n        end as count_reopens,\n\n    {{ fivetran_utils.timestamp_diff(\n        'ticket_historical_assignee.first_agent_assignment_date', \n        'solved_times.last_solved_at',\n        'minute' ) }} as first_assignment_to_resolution_calendar_minutes,\n    {{ fivetran_utils.timestamp_diff(\n        'ticket_historical_assignee.last_agent_assignment_date', \n        'solved_times.last_solved_at',\n        'minute' ) }} as last_assignment_to_resolution_calendar_minutes,\n    {{ fivetran_utils.timestamp_diff(\n        'ticket.created_at', \n        'solved_times.first_solved_at',\n        'minute' ) }} as first_resolution_calendar_minutes,\n    {{ fivetran_utils.timestamp_diff(\n        'ticket.created_at', \n        'solved_times.last_solved_at',\n        'minute') }} as final_resolution_calendar_minutes\n\n  from ticket\n\n  left join ticket_historical_assignee\n    using(ticket_id)\n\n  left join ticket_historical_group\n    using(ticket_id)\n\n  left join solved_times\n    using(ticket_id)", "compiled": true, "resource_type": "model", "depends_on": {"macros": ["macro.fivetran_utils.timestamp_diff"], "nodes": ["model.zendesk.int_zendesk__ticket_historical_status", "model.zendesk_source.stg_zendesk__ticket", "model.zendesk.int_zendesk__ticket_historical_assignee", "model.zendesk.int_zendesk__ticket_historical_group"]}, "config": {"enabled": true, "alias": null, "schema": "zendesk_docs", "database": null, "tags": [], "meta": {}, "materialized": "ephemeral", "persist_docs": {}, "quoting": {}, "column_types": {}, "full_refresh": null, "on_schema_change": "ignore", "post-hook": [], "pre-hook": []}, "database": "bq-project", "schema": "dbt_joe_zendesk_docs", "fqn": ["zendesk", "resolution_times", "int_zendesk__ticket_resolution_times_calendar"], "unique_id": "model.zendesk.int_zendesk__ticket_resolution_times_calendar", "package_name": "zendesk", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/zendesk", "path": "resolution_times/int_zendesk__ticket_resolution_times_calendar.sql", "original_file_path": "models/resolution_times/int_zendesk__ticket_resolution_times_calendar.sql", "name": "int_zendesk__ticket_resolution_times_calendar", "alias": "int_zendesk__ticket_resolution_times_calendar", "checksum": {"name": "sha256", "checksum": "90d50bebce7af1d1d1967f33841dc63db404136ab9f81998f380dd53943b660c"}, "tags": [], "refs": [["int_zendesk__ticket_historical_status"], ["stg_zendesk__ticket"], ["int_zendesk__ticket_historical_assignee"], ["int_zendesk__ticket_historical_group"]], "sources": [], "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "compiled_path": "target/compiled/zendesk/models/resolution_times/int_zendesk__ticket_resolution_times_calendar.sql", "build_path": null, "deferred": false, "unrendered_config": {"schema": "zendesk_docs", "materialized": "ephemeral"}, "created_at": 1647014737.222666, "compiled_sql": "with historical_solved_status as (\n\n    select *\n    from `bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__ticket_historical_status`\n    where status = 'solved'\n\n), ticket as (\n\n    select *\n    from `bq-project`.`dbt_joe_zendesk_docs`.`stg_zendesk__ticket`\n\n), ticket_historical_assignee as (\n\n    select *\n    from `bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__ticket_historical_assignee`\n\n), ticket_historical_group as (\n\n  select *\n  from `bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__ticket_historical_group`\n\n), solved_times as (\n  \n  select\n  \n    ticket_id,\n    min(valid_starting_at) as first_solved_at,\n    max(valid_starting_at) as last_solved_at,\n    count(status) as solved_count \n\n  from historical_solved_status\n  group by 1\n\n)\n\n  select\n\n    ticket.ticket_id,\n    ticket.created_at,\n    solved_times.first_solved_at,\n    solved_times.last_solved_at,\n    ticket_historical_assignee.unique_assignee_count,\n    ticket_historical_assignee.assignee_stations_count,\n    ticket_historical_group.group_stations_count,\n    ticket_historical_assignee.first_assignee_id,\n    ticket_historical_assignee.last_assignee_id,\n    ticket_historical_assignee.first_agent_assignment_date,\n    ticket_historical_assignee.last_agent_assignment_date,\n    ticket_historical_assignee.ticket_unassigned_duration_calendar_minutes,\n    solved_times.solved_count as total_resolutions,\n    case when solved_times.solved_count <= 1\n      then 0\n      else solved_times.solved_count - 1 --subtracting one as the first solve is not a reopen.\n        end as count_reopens,\n\n    \n  \n\n    timestamp_diff(\n        solved_times.last_solved_at,\n        ticket_historical_assignee.first_agent_assignment_date,\n        minute\n    )\n\n\n as first_assignment_to_resolution_calendar_minutes,\n    \n  \n\n    timestamp_diff(\n        solved_times.last_solved_at,\n        ticket_historical_assignee.last_agent_assignment_date,\n        minute\n    )\n\n\n as last_assignment_to_resolution_calendar_minutes,\n    \n  \n\n    timestamp_diff(\n        solved_times.first_solved_at,\n        ticket.created_at,\n        minute\n    )\n\n\n as first_resolution_calendar_minutes,\n    \n  \n\n    timestamp_diff(\n        solved_times.last_solved_at,\n        ticket.created_at,\n        minute\n    )\n\n\n as final_resolution_calendar_minutes\n\n  from ticket\n\n  left join ticket_historical_assignee\n    using(ticket_id)\n\n  left join ticket_historical_group\n    using(ticket_id)\n\n  left join solved_times\n    using(ticket_id)", "extra_ctes_injected": true, "extra_ctes": [], "relation_name": null}, "model.zendesk.int_zendesk__ticket_first_resolution_time_business": {"raw_sql": "{{ config(enabled=var('using_schedules', True)) }}\n\nwith ticket_resolution_times_calendar as (\n\n    select *\n    from {{ ref('int_zendesk__ticket_resolution_times_calendar') }}\n\n), ticket_schedules as (\n\n    select *\n    from {{ ref('int_zendesk__ticket_schedules') }}\n\n), schedule as (\n\n    select *\n    from {{ ref('int_zendesk__schedule_spine') }}\n\n), ticket_first_resolution_time as (\n\n  select \n    ticket_resolution_times_calendar.ticket_id,\n    ticket_schedules.schedule_created_at,\n    ticket_schedules.schedule_invalidated_at,\n    ticket_schedules.schedule_id,\n\n    -- bringing this in the determine which schedule (Daylight Savings vs Standard time) to use\n    min(ticket_resolution_times_calendar.first_solved_at) as first_solved_at,\n    \n    ({{ fivetran_utils.timestamp_diff(\n            \"\" ~ dbt_utils.date_trunc('week', 'ticket_schedules.schedule_created_at') ~ \"\", \n            'ticket_schedules.schedule_created_at',\n            'second') }} /60\n          ) as start_time_in_minutes_from_week,\n    greatest(0,\n      (\n        {{ fivetran_utils.timestamp_diff(\n          'ticket_schedules.schedule_created_at',\n          'least(ticket_schedules.schedule_invalidated_at, min(ticket_resolution_times_calendar.first_solved_at))',\n          'second') }}/60\n        )) as raw_delta_in_minutes\n      \n  from ticket_resolution_times_calendar\n  join ticket_schedules on ticket_resolution_times_calendar.ticket_id = ticket_schedules.ticket_id\n  group by 1, 2, 3, 4\n\n), weeks as (\n\n    {{ dbt_utils.generate_series(208) }}\n\n), weeks_cross_ticket_first_resolution_time as (\n    -- because time is reported in minutes since the beginning of the week, we have to split up time spent on the ticket into calendar weeks\n    select \n\n      ticket_first_resolution_time.*,\n      generated_number - 1 as week_number\n\n    from ticket_first_resolution_time\n    cross join weeks\n    where floor((start_time_in_minutes_from_week + raw_delta_in_minutes) / (7*24*60)) >= generated_number - 1\n\n\n), weekly_periods as (\n  \n    select \n\n      weeks_cross_ticket_first_resolution_time.*,\n      greatest(0, start_time_in_minutes_from_week - week_number * (7*24*60)) as ticket_week_start_time,\n      least(start_time_in_minutes_from_week + raw_delta_in_minutes - week_number * (7*24*60), (7*24*60)) as ticket_week_end_time\n    \n    from weeks_cross_ticket_first_resolution_time\n\n), intercepted_periods as (\n\n  select ticket_id,\n         week_number,\n         weekly_periods.schedule_id,\n         ticket_week_start_time,\n         ticket_week_end_time,\n         schedule.start_time_utc as schedule_start_time,\n         schedule.end_time_utc as schedule_end_time,\n         least(ticket_week_end_time, schedule.end_time_utc) - greatest(ticket_week_start_time, schedule.start_time_utc) as scheduled_minutes\n  from weekly_periods\n  join schedule on ticket_week_start_time <= schedule.end_time_utc \n    and ticket_week_end_time >= schedule.start_time_utc\n    and weekly_periods.schedule_id = schedule.schedule_id\n    -- this chooses the Daylight Savings Time or Standard Time version of the schedule\n    and weekly_periods.first_solved_at >= cast(schedule.valid_from as {{ dbt_utils.type_timestamp() }})\n    and weekly_periods.first_solved_at < cast(schedule.valid_until as {{ dbt_utils.type_timestamp() }}) \n    \n)\n\n  select \n    ticket_id,\n    sum(scheduled_minutes) as first_resolution_business_minutes\n  from intercepted_periods\n  group by 1", "compiled": true, "resource_type": "model", "depends_on": {"macros": ["macro.dbt_utils.date_trunc", "macro.fivetran_utils.timestamp_diff", "macro.dbt_utils.generate_series", "macro.dbt_utils.type_timestamp"], "nodes": ["model.zendesk.int_zendesk__ticket_resolution_times_calendar", "model.zendesk.int_zendesk__ticket_schedules", "model.zendesk.int_zendesk__schedule_spine"]}, "config": {"enabled": true, "alias": null, "schema": "zendesk_docs", "database": null, "tags": [], "meta": {}, "materialized": "ephemeral", "persist_docs": {}, "quoting": {}, "column_types": {}, "full_refresh": null, "on_schema_change": "ignore", "post-hook": [], "pre-hook": []}, "database": "bq-project", "schema": "dbt_joe_zendesk_docs", "fqn": ["zendesk", "resolution_times", "int_zendesk__ticket_first_resolution_time_business"], "unique_id": "model.zendesk.int_zendesk__ticket_first_resolution_time_business", "package_name": "zendesk", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/zendesk", "path": "resolution_times/int_zendesk__ticket_first_resolution_time_business.sql", "original_file_path": "models/resolution_times/int_zendesk__ticket_first_resolution_time_business.sql", "name": "int_zendesk__ticket_first_resolution_time_business", "alias": "int_zendesk__ticket_first_resolution_time_business", "checksum": {"name": "sha256", "checksum": "24d91fed60b2d0fe813a393ed776697899a0e956d4b9db03e999d516502ef7a4"}, "tags": [], "refs": [["int_zendesk__ticket_resolution_times_calendar"], ["int_zendesk__ticket_schedules"], ["int_zendesk__schedule_spine"]], "sources": [], "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "compiled_path": "target/compiled/zendesk/models/resolution_times/int_zendesk__ticket_first_resolution_time_business.sql", "build_path": null, "deferred": false, "unrendered_config": {"schema": "zendesk_docs", "materialized": "ephemeral", "enabled": true}, "created_at": 1647014737.230138, "compiled_sql": "\n\nwith  __dbt__cte__int_zendesk__ticket_resolution_times_calendar as (\nwith historical_solved_status as (\n\n    select *\n    from `bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__ticket_historical_status`\n    where status = 'solved'\n\n), ticket as (\n\n    select *\n    from `bq-project`.`dbt_joe_zendesk_docs`.`stg_zendesk__ticket`\n\n), ticket_historical_assignee as (\n\n    select *\n    from `bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__ticket_historical_assignee`\n\n), ticket_historical_group as (\n\n  select *\n  from `bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__ticket_historical_group`\n\n), solved_times as (\n  \n  select\n  \n    ticket_id,\n    min(valid_starting_at) as first_solved_at,\n    max(valid_starting_at) as last_solved_at,\n    count(status) as solved_count \n\n  from historical_solved_status\n  group by 1\n\n)\n\n  select\n\n    ticket.ticket_id,\n    ticket.created_at,\n    solved_times.first_solved_at,\n    solved_times.last_solved_at,\n    ticket_historical_assignee.unique_assignee_count,\n    ticket_historical_assignee.assignee_stations_count,\n    ticket_historical_group.group_stations_count,\n    ticket_historical_assignee.first_assignee_id,\n    ticket_historical_assignee.last_assignee_id,\n    ticket_historical_assignee.first_agent_assignment_date,\n    ticket_historical_assignee.last_agent_assignment_date,\n    ticket_historical_assignee.ticket_unassigned_duration_calendar_minutes,\n    solved_times.solved_count as total_resolutions,\n    case when solved_times.solved_count <= 1\n      then 0\n      else solved_times.solved_count - 1 --subtracting one as the first solve is not a reopen.\n        end as count_reopens,\n\n    \n  \n\n    timestamp_diff(\n        solved_times.last_solved_at,\n        ticket_historical_assignee.first_agent_assignment_date,\n        minute\n    )\n\n\n as first_assignment_to_resolution_calendar_minutes,\n    \n  \n\n    timestamp_diff(\n        solved_times.last_solved_at,\n        ticket_historical_assignee.last_agent_assignment_date,\n        minute\n    )\n\n\n as last_assignment_to_resolution_calendar_minutes,\n    \n  \n\n    timestamp_diff(\n        solved_times.first_solved_at,\n        ticket.created_at,\n        minute\n    )\n\n\n as first_resolution_calendar_minutes,\n    \n  \n\n    timestamp_diff(\n        solved_times.last_solved_at,\n        ticket.created_at,\n        minute\n    )\n\n\n as final_resolution_calendar_minutes\n\n  from ticket\n\n  left join ticket_historical_assignee\n    using(ticket_id)\n\n  left join ticket_historical_group\n    using(ticket_id)\n\n  left join solved_times\n    using(ticket_id)\n),ticket_resolution_times_calendar as (\n\n    select *\n    from __dbt__cte__int_zendesk__ticket_resolution_times_calendar\n\n), ticket_schedules as (\n\n    select *\n    from `bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__ticket_schedules`\n\n), schedule as (\n\n    select *\n    from `bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__schedule_spine`\n\n), ticket_first_resolution_time as (\n\n  select \n    ticket_resolution_times_calendar.ticket_id,\n    ticket_schedules.schedule_created_at,\n    ticket_schedules.schedule_invalidated_at,\n    ticket_schedules.schedule_id,\n\n    -- bringing this in the determine which schedule (Daylight Savings vs Standard time) to use\n    min(ticket_resolution_times_calendar.first_solved_at) as first_solved_at,\n    \n    (\n  \n\n    timestamp_diff(\n        ticket_schedules.schedule_created_at,\n        \n    timestamp_trunc(\n        cast(ticket_schedules.schedule_created_at as timestamp),\n        week\n    )\n\n,\n        second\n    )\n\n\n /60\n          ) as start_time_in_minutes_from_week,\n    greatest(0,\n      (\n        \n  \n\n    timestamp_diff(\n        least(ticket_schedules.schedule_invalidated_at, min(ticket_resolution_times_calendar.first_solved_at)),\n        ticket_schedules.schedule_created_at,\n        second\n    )\n\n\n/60\n        )) as raw_delta_in_minutes\n      \n  from ticket_resolution_times_calendar\n  join ticket_schedules on ticket_resolution_times_calendar.ticket_id = ticket_schedules.ticket_id\n  group by 1, 2, 3, 4\n\n), weeks as (\n\n    \n\n    \n\n    with p as (\n        select 0 as generated_number union all select 1\n    ), unioned as (\n\n    select\n\n    \n    p0.generated_number * power(2, 0)\n     + \n    \n    p1.generated_number * power(2, 1)\n     + \n    \n    p2.generated_number * power(2, 2)\n     + \n    \n    p3.generated_number * power(2, 3)\n     + \n    \n    p4.generated_number * power(2, 4)\n     + \n    \n    p5.generated_number * power(2, 5)\n     + \n    \n    p6.generated_number * power(2, 6)\n     + \n    \n    p7.generated_number * power(2, 7)\n    \n    \n    + 1\n    as generated_number\n\n    from\n\n    \n    p as p0\n     cross join \n    \n    p as p1\n     cross join \n    \n    p as p2\n     cross join \n    \n    p as p3\n     cross join \n    \n    p as p4\n     cross join \n    \n    p as p5\n     cross join \n    \n    p as p6\n     cross join \n    \n    p as p7\n    \n    \n\n    )\n\n    select *\n    from unioned\n    where generated_number <= 208\n    order by generated_number\n\n\n\n), weeks_cross_ticket_first_resolution_time as (\n    -- because time is reported in minutes since the beginning of the week, we have to split up time spent on the ticket into calendar weeks\n    select \n\n      ticket_first_resolution_time.*,\n      generated_number - 1 as week_number\n\n    from ticket_first_resolution_time\n    cross join weeks\n    where floor((start_time_in_minutes_from_week + raw_delta_in_minutes) / (7*24*60)) >= generated_number - 1\n\n\n), weekly_periods as (\n  \n    select \n\n      weeks_cross_ticket_first_resolution_time.*,\n      greatest(0, start_time_in_minutes_from_week - week_number * (7*24*60)) as ticket_week_start_time,\n      least(start_time_in_minutes_from_week + raw_delta_in_minutes - week_number * (7*24*60), (7*24*60)) as ticket_week_end_time\n    \n    from weeks_cross_ticket_first_resolution_time\n\n), intercepted_periods as (\n\n  select ticket_id,\n         week_number,\n         weekly_periods.schedule_id,\n         ticket_week_start_time,\n         ticket_week_end_time,\n         schedule.start_time_utc as schedule_start_time,\n         schedule.end_time_utc as schedule_end_time,\n         least(ticket_week_end_time, schedule.end_time_utc) - greatest(ticket_week_start_time, schedule.start_time_utc) as scheduled_minutes\n  from weekly_periods\n  join schedule on ticket_week_start_time <= schedule.end_time_utc \n    and ticket_week_end_time >= schedule.start_time_utc\n    and weekly_periods.schedule_id = schedule.schedule_id\n    -- this chooses the Daylight Savings Time or Standard Time version of the schedule\n    and weekly_periods.first_solved_at >= cast(schedule.valid_from as \n    timestamp\n)\n    and weekly_periods.first_solved_at < cast(schedule.valid_until as \n    timestamp\n) \n    \n)\n\n  select \n    ticket_id,\n    sum(scheduled_minutes) as first_resolution_business_minutes\n  from intercepted_periods\n  group by 1", "extra_ctes_injected": true, "extra_ctes": [{"id": "model.zendesk.int_zendesk__ticket_resolution_times_calendar", "sql": " __dbt__cte__int_zendesk__ticket_resolution_times_calendar as (\nwith historical_solved_status as (\n\n    select *\n    from `bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__ticket_historical_status`\n    where status = 'solved'\n\n), ticket as (\n\n    select *\n    from `bq-project`.`dbt_joe_zendesk_docs`.`stg_zendesk__ticket`\n\n), ticket_historical_assignee as (\n\n    select *\n    from `bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__ticket_historical_assignee`\n\n), ticket_historical_group as (\n\n  select *\n  from `bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__ticket_historical_group`\n\n), solved_times as (\n  \n  select\n  \n    ticket_id,\n    min(valid_starting_at) as first_solved_at,\n    max(valid_starting_at) as last_solved_at,\n    count(status) as solved_count \n\n  from historical_solved_status\n  group by 1\n\n)\n\n  select\n\n    ticket.ticket_id,\n    ticket.created_at,\n    solved_times.first_solved_at,\n    solved_times.last_solved_at,\n    ticket_historical_assignee.unique_assignee_count,\n    ticket_historical_assignee.assignee_stations_count,\n    ticket_historical_group.group_stations_count,\n    ticket_historical_assignee.first_assignee_id,\n    ticket_historical_assignee.last_assignee_id,\n    ticket_historical_assignee.first_agent_assignment_date,\n    ticket_historical_assignee.last_agent_assignment_date,\n    ticket_historical_assignee.ticket_unassigned_duration_calendar_minutes,\n    solved_times.solved_count as total_resolutions,\n    case when solved_times.solved_count <= 1\n      then 0\n      else solved_times.solved_count - 1 --subtracting one as the first solve is not a reopen.\n        end as count_reopens,\n\n    \n  \n\n    timestamp_diff(\n        solved_times.last_solved_at,\n        ticket_historical_assignee.first_agent_assignment_date,\n        minute\n    )\n\n\n as first_assignment_to_resolution_calendar_minutes,\n    \n  \n\n    timestamp_diff(\n        solved_times.last_solved_at,\n        ticket_historical_assignee.last_agent_assignment_date,\n        minute\n    )\n\n\n as last_assignment_to_resolution_calendar_minutes,\n    \n  \n\n    timestamp_diff(\n        solved_times.first_solved_at,\n        ticket.created_at,\n        minute\n    )\n\n\n as first_resolution_calendar_minutes,\n    \n  \n\n    timestamp_diff(\n        solved_times.last_solved_at,\n        ticket.created_at,\n        minute\n    )\n\n\n as final_resolution_calendar_minutes\n\n  from ticket\n\n  left join ticket_historical_assignee\n    using(ticket_id)\n\n  left join ticket_historical_group\n    using(ticket_id)\n\n  left join solved_times\n    using(ticket_id)\n)"}], "relation_name": null}, "model.zendesk.int_zendesk__ticket_full_resolution_time_business": {"raw_sql": "{{ config(enabled=var('using_schedules', True)) }}\n\nwith ticket_resolution_times_calendar as (\n\n    select *\n    from {{ ref('int_zendesk__ticket_resolution_times_calendar') }}\n\n), ticket_schedules as (\n\n    select *\n    from {{ ref('int_zendesk__ticket_schedules') }}\n\n), schedule as (\n\n    select *\n    from {{ ref('int_zendesk__schedule_spine') }}\n\n), ticket_full_resolution_time as (\n\n  select \n    ticket_resolution_times_calendar.ticket_id,\n    ticket_schedules.schedule_created_at,\n    ticket_schedules.schedule_invalidated_at,\n    ticket_schedules.schedule_id,\n\n    -- bringing this in the determine which schedule (Daylight Savings vs Standard time) to use\n    min(ticket_resolution_times_calendar.last_solved_at) as last_solved_at,\n    \n    ({{ fivetran_utils.timestamp_diff(\n            \"\" ~ dbt_utils.date_trunc('week', 'ticket_schedules.schedule_created_at') ~ \"\", \n            'ticket_schedules.schedule_created_at',\n            'second') }} /60\n          ) as start_time_in_minutes_from_week,\n    greatest(0,\n      (\n        {{ fivetran_utils.timestamp_diff(\n          'ticket_schedules.schedule_created_at',\n          'least(ticket_schedules.schedule_invalidated_at, min(ticket_resolution_times_calendar.last_solved_at))',\n          'second') }}/60\n        )) as raw_delta_in_minutes\n      \n  from ticket_resolution_times_calendar\n  join ticket_schedules on ticket_resolution_times_calendar.ticket_id = ticket_schedules.ticket_id\n  group by 1, 2, 3, 4\n\n), weeks as (\n\n    {{ dbt_utils.generate_series(208) }}\n\n), weeks_cross_ticket_full_resolution_time as (\n    -- because time is reported in minutes since the beginning of the week, we have to split up time spent on the ticket into calendar weeks\n    select \n\n      ticket_full_resolution_time.*,\n      generated_number - 1 as week_number\n\n    from ticket_full_resolution_time\n    cross join weeks\n    where floor((start_time_in_minutes_from_week + raw_delta_in_minutes) / (7*24*60)) >= generated_number - 1\n\n), weekly_periods as (\n  \n  select \n\n    weeks_cross_ticket_full_resolution_time.*,\n    greatest(0, start_time_in_minutes_from_week - week_number * (7*24*60)) as ticket_week_start_time,\n    least(start_time_in_minutes_from_week + raw_delta_in_minutes - week_number * (7*24*60), (7*24*60)) as ticket_week_end_time\n  \n  from weeks_cross_ticket_full_resolution_time\n\n), intercepted_periods as (\n\n  select \n    ticket_id,\n    week_number,\n    weekly_periods.schedule_id,\n    ticket_week_start_time,\n    ticket_week_end_time,\n    schedule.start_time_utc as schedule_start_time,\n    schedule.end_time_utc as schedule_end_time,\n    least(ticket_week_end_time, schedule.end_time_utc) - greatest(ticket_week_start_time, schedule.start_time_utc) as scheduled_minutes\n  from weekly_periods\n  join schedule on ticket_week_start_time <= schedule.end_time_utc \n    and ticket_week_end_time >= schedule.start_time_utc\n    and weekly_periods.schedule_id = schedule.schedule_id\n    -- this chooses the Daylight Savings Time or Standard Time version of the schedule\n    and weekly_periods.last_solved_at >= cast(schedule.valid_from as {{ dbt_utils.type_timestamp() }})\n    and weekly_periods.last_solved_at < cast(schedule.valid_until as {{ dbt_utils.type_timestamp() }}) \n    \n)\n\n  select \n    ticket_id,\n    sum(scheduled_minutes) as full_resolution_business_minutes\n  from intercepted_periods\n  group by 1", "compiled": true, "resource_type": "model", "depends_on": {"macros": ["macro.dbt_utils.date_trunc", "macro.fivetran_utils.timestamp_diff", "macro.dbt_utils.generate_series", "macro.dbt_utils.type_timestamp"], "nodes": ["model.zendesk.int_zendesk__ticket_resolution_times_calendar", "model.zendesk.int_zendesk__ticket_schedules", "model.zendesk.int_zendesk__schedule_spine"]}, "config": {"enabled": true, "alias": null, "schema": "zendesk_docs", "database": null, "tags": [], "meta": {}, "materialized": "ephemeral", "persist_docs": {}, "quoting": {}, "column_types": {}, "full_refresh": null, "on_schema_change": "ignore", "post-hook": [], "pre-hook": []}, "database": "bq-project", "schema": "dbt_joe_zendesk_docs", "fqn": ["zendesk", "resolution_times", "int_zendesk__ticket_full_resolution_time_business"], "unique_id": "model.zendesk.int_zendesk__ticket_full_resolution_time_business", "package_name": "zendesk", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/zendesk", "path": "resolution_times/int_zendesk__ticket_full_resolution_time_business.sql", "original_file_path": "models/resolution_times/int_zendesk__ticket_full_resolution_time_business.sql", "name": "int_zendesk__ticket_full_resolution_time_business", "alias": "int_zendesk__ticket_full_resolution_time_business", "checksum": {"name": "sha256", "checksum": "a8876067e37145975bcc8b732b1174600adf32453b4fecfd51673a61acabe06a"}, "tags": [], "refs": [["int_zendesk__ticket_resolution_times_calendar"], ["int_zendesk__ticket_schedules"], ["int_zendesk__schedule_spine"]], "sources": [], "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "compiled_path": "target/compiled/zendesk/models/resolution_times/int_zendesk__ticket_full_resolution_time_business.sql", "build_path": null, "deferred": false, "unrendered_config": {"schema": "zendesk_docs", "materialized": "ephemeral", "enabled": true}, "created_at": 1647014737.239146, "compiled_sql": "\n\nwith  __dbt__cte__int_zendesk__ticket_resolution_times_calendar as (\nwith historical_solved_status as (\n\n    select *\n    from `bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__ticket_historical_status`\n    where status = 'solved'\n\n), ticket as (\n\n    select *\n    from `bq-project`.`dbt_joe_zendesk_docs`.`stg_zendesk__ticket`\n\n), ticket_historical_assignee as (\n\n    select *\n    from `bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__ticket_historical_assignee`\n\n), ticket_historical_group as (\n\n  select *\n  from `bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__ticket_historical_group`\n\n), solved_times as (\n  \n  select\n  \n    ticket_id,\n    min(valid_starting_at) as first_solved_at,\n    max(valid_starting_at) as last_solved_at,\n    count(status) as solved_count \n\n  from historical_solved_status\n  group by 1\n\n)\n\n  select\n\n    ticket.ticket_id,\n    ticket.created_at,\n    solved_times.first_solved_at,\n    solved_times.last_solved_at,\n    ticket_historical_assignee.unique_assignee_count,\n    ticket_historical_assignee.assignee_stations_count,\n    ticket_historical_group.group_stations_count,\n    ticket_historical_assignee.first_assignee_id,\n    ticket_historical_assignee.last_assignee_id,\n    ticket_historical_assignee.first_agent_assignment_date,\n    ticket_historical_assignee.last_agent_assignment_date,\n    ticket_historical_assignee.ticket_unassigned_duration_calendar_minutes,\n    solved_times.solved_count as total_resolutions,\n    case when solved_times.solved_count <= 1\n      then 0\n      else solved_times.solved_count - 1 --subtracting one as the first solve is not a reopen.\n        end as count_reopens,\n\n    \n  \n\n    timestamp_diff(\n        solved_times.last_solved_at,\n        ticket_historical_assignee.first_agent_assignment_date,\n        minute\n    )\n\n\n as first_assignment_to_resolution_calendar_minutes,\n    \n  \n\n    timestamp_diff(\n        solved_times.last_solved_at,\n        ticket_historical_assignee.last_agent_assignment_date,\n        minute\n    )\n\n\n as last_assignment_to_resolution_calendar_minutes,\n    \n  \n\n    timestamp_diff(\n        solved_times.first_solved_at,\n        ticket.created_at,\n        minute\n    )\n\n\n as first_resolution_calendar_minutes,\n    \n  \n\n    timestamp_diff(\n        solved_times.last_solved_at,\n        ticket.created_at,\n        minute\n    )\n\n\n as final_resolution_calendar_minutes\n\n  from ticket\n\n  left join ticket_historical_assignee\n    using(ticket_id)\n\n  left join ticket_historical_group\n    using(ticket_id)\n\n  left join solved_times\n    using(ticket_id)\n),ticket_resolution_times_calendar as (\n\n    select *\n    from __dbt__cte__int_zendesk__ticket_resolution_times_calendar\n\n), ticket_schedules as (\n\n    select *\n    from `bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__ticket_schedules`\n\n), schedule as (\n\n    select *\n    from `bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__schedule_spine`\n\n), ticket_full_resolution_time as (\n\n  select \n    ticket_resolution_times_calendar.ticket_id,\n    ticket_schedules.schedule_created_at,\n    ticket_schedules.schedule_invalidated_at,\n    ticket_schedules.schedule_id,\n\n    -- bringing this in the determine which schedule (Daylight Savings vs Standard time) to use\n    min(ticket_resolution_times_calendar.last_solved_at) as last_solved_at,\n    \n    (\n  \n\n    timestamp_diff(\n        ticket_schedules.schedule_created_at,\n        \n    timestamp_trunc(\n        cast(ticket_schedules.schedule_created_at as timestamp),\n        week\n    )\n\n,\n        second\n    )\n\n\n /60\n          ) as start_time_in_minutes_from_week,\n    greatest(0,\n      (\n        \n  \n\n    timestamp_diff(\n        least(ticket_schedules.schedule_invalidated_at, min(ticket_resolution_times_calendar.last_solved_at)),\n        ticket_schedules.schedule_created_at,\n        second\n    )\n\n\n/60\n        )) as raw_delta_in_minutes\n      \n  from ticket_resolution_times_calendar\n  join ticket_schedules on ticket_resolution_times_calendar.ticket_id = ticket_schedules.ticket_id\n  group by 1, 2, 3, 4\n\n), weeks as (\n\n    \n\n    \n\n    with p as (\n        select 0 as generated_number union all select 1\n    ), unioned as (\n\n    select\n\n    \n    p0.generated_number * power(2, 0)\n     + \n    \n    p1.generated_number * power(2, 1)\n     + \n    \n    p2.generated_number * power(2, 2)\n     + \n    \n    p3.generated_number * power(2, 3)\n     + \n    \n    p4.generated_number * power(2, 4)\n     + \n    \n    p5.generated_number * power(2, 5)\n     + \n    \n    p6.generated_number * power(2, 6)\n     + \n    \n    p7.generated_number * power(2, 7)\n    \n    \n    + 1\n    as generated_number\n\n    from\n\n    \n    p as p0\n     cross join \n    \n    p as p1\n     cross join \n    \n    p as p2\n     cross join \n    \n    p as p3\n     cross join \n    \n    p as p4\n     cross join \n    \n    p as p5\n     cross join \n    \n    p as p6\n     cross join \n    \n    p as p7\n    \n    \n\n    )\n\n    select *\n    from unioned\n    where generated_number <= 208\n    order by generated_number\n\n\n\n), weeks_cross_ticket_full_resolution_time as (\n    -- because time is reported in minutes since the beginning of the week, we have to split up time spent on the ticket into calendar weeks\n    select \n\n      ticket_full_resolution_time.*,\n      generated_number - 1 as week_number\n\n    from ticket_full_resolution_time\n    cross join weeks\n    where floor((start_time_in_minutes_from_week + raw_delta_in_minutes) / (7*24*60)) >= generated_number - 1\n\n), weekly_periods as (\n  \n  select \n\n    weeks_cross_ticket_full_resolution_time.*,\n    greatest(0, start_time_in_minutes_from_week - week_number * (7*24*60)) as ticket_week_start_time,\n    least(start_time_in_minutes_from_week + raw_delta_in_minutes - week_number * (7*24*60), (7*24*60)) as ticket_week_end_time\n  \n  from weeks_cross_ticket_full_resolution_time\n\n), intercepted_periods as (\n\n  select \n    ticket_id,\n    week_number,\n    weekly_periods.schedule_id,\n    ticket_week_start_time,\n    ticket_week_end_time,\n    schedule.start_time_utc as schedule_start_time,\n    schedule.end_time_utc as schedule_end_time,\n    least(ticket_week_end_time, schedule.end_time_utc) - greatest(ticket_week_start_time, schedule.start_time_utc) as scheduled_minutes\n  from weekly_periods\n  join schedule on ticket_week_start_time <= schedule.end_time_utc \n    and ticket_week_end_time >= schedule.start_time_utc\n    and weekly_periods.schedule_id = schedule.schedule_id\n    -- this chooses the Daylight Savings Time or Standard Time version of the schedule\n    and weekly_periods.last_solved_at >= cast(schedule.valid_from as \n    timestamp\n)\n    and weekly_periods.last_solved_at < cast(schedule.valid_until as \n    timestamp\n) \n    \n)\n\n  select \n    ticket_id,\n    sum(scheduled_minutes) as full_resolution_business_minutes\n  from intercepted_periods\n  group by 1", "extra_ctes_injected": true, "extra_ctes": [{"id": "model.zendesk.int_zendesk__ticket_resolution_times_calendar", "sql": " __dbt__cte__int_zendesk__ticket_resolution_times_calendar as (\nwith historical_solved_status as (\n\n    select *\n    from `bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__ticket_historical_status`\n    where status = 'solved'\n\n), ticket as (\n\n    select *\n    from `bq-project`.`dbt_joe_zendesk_docs`.`stg_zendesk__ticket`\n\n), ticket_historical_assignee as (\n\n    select *\n    from `bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__ticket_historical_assignee`\n\n), ticket_historical_group as (\n\n  select *\n  from `bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__ticket_historical_group`\n\n), solved_times as (\n  \n  select\n  \n    ticket_id,\n    min(valid_starting_at) as first_solved_at,\n    max(valid_starting_at) as last_solved_at,\n    count(status) as solved_count \n\n  from historical_solved_status\n  group by 1\n\n)\n\n  select\n\n    ticket.ticket_id,\n    ticket.created_at,\n    solved_times.first_solved_at,\n    solved_times.last_solved_at,\n    ticket_historical_assignee.unique_assignee_count,\n    ticket_historical_assignee.assignee_stations_count,\n    ticket_historical_group.group_stations_count,\n    ticket_historical_assignee.first_assignee_id,\n    ticket_historical_assignee.last_assignee_id,\n    ticket_historical_assignee.first_agent_assignment_date,\n    ticket_historical_assignee.last_agent_assignment_date,\n    ticket_historical_assignee.ticket_unassigned_duration_calendar_minutes,\n    solved_times.solved_count as total_resolutions,\n    case when solved_times.solved_count <= 1\n      then 0\n      else solved_times.solved_count - 1 --subtracting one as the first solve is not a reopen.\n        end as count_reopens,\n\n    \n  \n\n    timestamp_diff(\n        solved_times.last_solved_at,\n        ticket_historical_assignee.first_agent_assignment_date,\n        minute\n    )\n\n\n as first_assignment_to_resolution_calendar_minutes,\n    \n  \n\n    timestamp_diff(\n        solved_times.last_solved_at,\n        ticket_historical_assignee.last_agent_assignment_date,\n        minute\n    )\n\n\n as last_assignment_to_resolution_calendar_minutes,\n    \n  \n\n    timestamp_diff(\n        solved_times.first_solved_at,\n        ticket.created_at,\n        minute\n    )\n\n\n as first_resolution_calendar_minutes,\n    \n  \n\n    timestamp_diff(\n        solved_times.last_solved_at,\n        ticket.created_at,\n        minute\n    )\n\n\n as final_resolution_calendar_minutes\n\n  from ticket\n\n  left join ticket_historical_assignee\n    using(ticket_id)\n\n  left join ticket_historical_group\n    using(ticket_id)\n\n  left join solved_times\n    using(ticket_id)\n)"}], "relation_name": null}, "model.zendesk.int_zendesk__updates": {"raw_sql": "with ticket_history as (\n    select *\n    from {{ ref('stg_zendesk__ticket_field_history') }}\n\n), ticket_comment as (\n    select *\n    from {{ ref('stg_zendesk__ticket_comment') }}\n\n), tickets as (\n    select *\n    from {{ ref('stg_zendesk__ticket') }}\n\n), updates_union as (\n    select \n        ticket_id,\n        field_name,\n        value,\n        null as is_public,\n        user_id,\n        valid_starting_at,\n        valid_ending_at\n    from ticket_history\n\n    union all\n\n    select\n        ticket_id,\n        cast('comment' as {{ dbt_utils.type_string() }}) as field_name,\n        body as value,\n        is_public,\n        user_id,\n        created_at as valid_starting_at,\n        lead(created_at) over (partition by ticket_id order by created_at) as valid_ending_at\n    from ticket_comment\n\n), final as (\n    select\n        updates_union.*,\n        tickets.created_at as ticket_created_date\n    from updates_union\n\n    left join tickets\n        on tickets.ticket_id = updates_union.ticket_id\n)\n\nselect *\nfrom final", "compiled": true, "resource_type": "model", "depends_on": {"macros": ["macro.dbt_utils.type_string"], "nodes": ["model.zendesk_source.stg_zendesk__ticket_field_history", "model.zendesk_source.stg_zendesk__ticket_comment", "model.zendesk_source.stg_zendesk__ticket"]}, "config": {"enabled": true, "alias": null, "schema": "zendesk_docs", "database": null, "tags": [], "meta": {}, "materialized": "table", "persist_docs": {}, "quoting": {}, "column_types": {}, "full_refresh": null, "on_schema_change": "ignore", "post-hook": [], "pre-hook": []}, "database": "bq-project", "schema": "dbt_joe_zendesk_docs", "fqn": ["zendesk", "intermediate", "int_zendesk__updates"], "unique_id": "model.zendesk.int_zendesk__updates", "package_name": "zendesk", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/zendesk", "path": "intermediate/int_zendesk__updates.sql", "original_file_path": "models/intermediate/int_zendesk__updates.sql", "name": "int_zendesk__updates", "alias": "int_zendesk__updates", "checksum": {"name": "sha256", "checksum": "f5f81cb1ebdd577a17ff4985bac5f824985e9af7d5ae67cd7f20cdcb7eaf8726"}, "tags": [], "refs": [["stg_zendesk__ticket_field_history"], ["stg_zendesk__ticket_comment"], ["stg_zendesk__ticket"]], "sources": [], "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "compiled_path": "target/compiled/zendesk/models/intermediate/int_zendesk__updates.sql", "build_path": null, "deferred": false, "unrendered_config": {"schema": "zendesk_docs", "materialized": "table"}, "created_at": 1647014737.2486799, "compiled_sql": "with ticket_history as (\n    select *\n    from `bq-project`.`dbt_joe_zendesk_docs`.`stg_zendesk__ticket_field_history`\n\n), ticket_comment as (\n    select *\n    from `bq-project`.`dbt_joe_zendesk_docs`.`stg_zendesk__ticket_comment`\n\n), tickets as (\n    select *\n    from `bq-project`.`dbt_joe_zendesk_docs`.`stg_zendesk__ticket`\n\n), updates_union as (\n    select \n        ticket_id,\n        field_name,\n        value,\n        null as is_public,\n        user_id,\n        valid_starting_at,\n        valid_ending_at\n    from ticket_history\n\n    union all\n\n    select\n        ticket_id,\n        cast('comment' as \n    string\n) as field_name,\n        body as value,\n        is_public,\n        user_id,\n        created_at as valid_starting_at,\n        lead(created_at) over (partition by ticket_id order by created_at) as valid_ending_at\n    from ticket_comment\n\n), final as (\n    select\n        updates_union.*,\n        tickets.created_at as ticket_created_date\n    from updates_union\n\n    left join tickets\n        on tickets.ticket_id = updates_union.ticket_id\n)\n\nselect *\nfrom final", "extra_ctes_injected": true, "extra_ctes": [], "relation_name": "`bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__updates`"}, "model.zendesk.int_zendesk__ticket_historical_assignee": {"raw_sql": "with assignee_updates as (\n\n    select *\n    from {{ ref('int_zendesk__updates') }}\n    where field_name = 'assignee_id'\n\n), calculate_metrics as (\n    select\n        ticket_id,\n        field_name as assignee_id,\n        value,\n        ticket_created_date,\n        valid_starting_at,\n        lag(valid_starting_at) over (partition by ticket_id order by valid_starting_at) as previous_update,\n        lag(value) over (partition by ticket_id order by valid_starting_at) as previous_assignee,\n        first_value(valid_starting_at) over (partition by ticket_id order by valid_starting_at, ticket_id rows unbounded preceding) as first_agent_assignment_date,\n        first_value(value) over (partition by ticket_id order by valid_starting_at, ticket_id rows unbounded preceding) as first_assignee_id,\n        first_value(valid_starting_at) over (partition by ticket_id order by valid_starting_at desc, ticket_id rows unbounded preceding) as last_agent_assignment_date,\n        first_value(value) over (partition by ticket_id order by valid_starting_at desc, ticket_id rows unbounded preceding) as last_assignee_id,\n        count(value) over (partition by ticket_id) as assignee_stations_count\n    from assignee_updates\n\n), unassigned_time as (\n    select\n        ticket_id,\n        sum(case when assignee_id is not null and previous_assignee is null \n            then {{ dbt_utils.datediff(\"coalesce(previous_update, ticket_created_date)\", \"valid_starting_at\", 'second') }} / 60\n            else 0\n                end) as ticket_unassigned_duration_calendar_minutes,\n        count(distinct value) as unique_assignee_count\n    from calculate_metrics\n\n    group by 1\n\n), window_group as (\n    select\n        calculate_metrics.ticket_id,\n        calculate_metrics.first_agent_assignment_date,\n        calculate_metrics.first_assignee_id,\n        calculate_metrics.last_agent_assignment_date,\n        calculate_metrics.last_assignee_id,\n        calculate_metrics.assignee_stations_count\n    from calculate_metrics\n\n    {{ dbt_utils.group_by(n=6) }}\n\n), final as (\n    select\n        window_group.*,\n        unassigned_time.unique_assignee_count,\n        unassigned_time.ticket_unassigned_duration_calendar_minutes\n    from window_group\n\n    left join unassigned_time\n        using(ticket_id)\n)\n\nselect *\nfrom final", "compiled": true, "resource_type": "model", "depends_on": {"macros": ["macro.dbt_utils.datediff", "macro.dbt_utils.group_by"], "nodes": ["model.zendesk.int_zendesk__updates"]}, "config": {"enabled": true, "alias": null, "schema": "zendesk_docs", "database": null, "tags": [], "meta": {}, "materialized": "table", "persist_docs": {}, "quoting": {}, "column_types": {}, "full_refresh": null, "on_schema_change": "ignore", "post-hook": [], "pre-hook": []}, "database": "bq-project", "schema": "dbt_joe_zendesk_docs", "fqn": ["zendesk", "intermediate", "int_zendesk__ticket_historical_assignee"], "unique_id": "model.zendesk.int_zendesk__ticket_historical_assignee", "package_name": "zendesk", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/zendesk", "path": "intermediate/int_zendesk__ticket_historical_assignee.sql", "original_file_path": "models/intermediate/int_zendesk__ticket_historical_assignee.sql", "name": "int_zendesk__ticket_historical_assignee", "alias": "int_zendesk__ticket_historical_assignee", "checksum": {"name": "sha256", "checksum": "fd6ca90f7cf23ac0a680a93517897efc44534572059a953621b5b8757a0c7c9e"}, "tags": [], "refs": [["int_zendesk__updates"]], "sources": [], "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "compiled_path": "target/compiled/zendesk/models/intermediate/int_zendesk__ticket_historical_assignee.sql", "build_path": null, "deferred": false, "unrendered_config": {"schema": "zendesk_docs", "materialized": "table"}, "created_at": 1647014737.2541409, "compiled_sql": "with assignee_updates as (\n\n    select *\n    from `bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__updates`\n    where field_name = 'assignee_id'\n\n), calculate_metrics as (\n    select\n        ticket_id,\n        field_name as assignee_id,\n        value,\n        ticket_created_date,\n        valid_starting_at,\n        lag(valid_starting_at) over (partition by ticket_id order by valid_starting_at) as previous_update,\n        lag(value) over (partition by ticket_id order by valid_starting_at) as previous_assignee,\n        first_value(valid_starting_at) over (partition by ticket_id order by valid_starting_at, ticket_id rows unbounded preceding) as first_agent_assignment_date,\n        first_value(value) over (partition by ticket_id order by valid_starting_at, ticket_id rows unbounded preceding) as first_assignee_id,\n        first_value(valid_starting_at) over (partition by ticket_id order by valid_starting_at desc, ticket_id rows unbounded preceding) as last_agent_assignment_date,\n        first_value(value) over (partition by ticket_id order by valid_starting_at desc, ticket_id rows unbounded preceding) as last_assignee_id,\n        count(value) over (partition by ticket_id) as assignee_stations_count\n    from assignee_updates\n\n), unassigned_time as (\n    select\n        ticket_id,\n        sum(case when assignee_id is not null and previous_assignee is null \n            then \n\n    datetime_diff(\n        cast(valid_starting_at as datetime),\n        cast(coalesce(previous_update, ticket_created_date) as datetime),\n        second\n    )\n\n / 60\n            else 0\n                end) as ticket_unassigned_duration_calendar_minutes,\n        count(distinct value) as unique_assignee_count\n    from calculate_metrics\n\n    group by 1\n\n), window_group as (\n    select\n        calculate_metrics.ticket_id,\n        calculate_metrics.first_agent_assignment_date,\n        calculate_metrics.first_assignee_id,\n        calculate_metrics.last_agent_assignment_date,\n        calculate_metrics.last_assignee_id,\n        calculate_metrics.assignee_stations_count\n    from calculate_metrics\n\n    group by 1,2,3,4,5,6\n\n), final as (\n    select\n        window_group.*,\n        unassigned_time.unique_assignee_count,\n        unassigned_time.ticket_unassigned_duration_calendar_minutes\n    from window_group\n\n    left join unassigned_time\n        using(ticket_id)\n)\n\nselect *\nfrom final", "extra_ctes_injected": true, "extra_ctes": [], "relation_name": "`bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__ticket_historical_assignee`"}, "model.zendesk.int_zendesk__ticket_historical_status": {"raw_sql": "-- To do -- can we delete ticket_status_counter and unique_status_counter?\n\nwith ticket_status_history as (\n\n    select *\n    from {{ ref('int_zendesk__updates') }}\n    where field_name = 'status'\n\n)\n\n  select\n  \n    ticket_id,\n    valid_starting_at,\n    valid_ending_at,\n    {{ fivetran_utils.timestamp_diff(\n        'valid_starting_at',\n        \"coalesce(valid_ending_at, \" ~ dbt_utils.current_timestamp() ~ \")\",\n        'minute') }} as status_duration_calendar_minutes,\n    value as status,\n    -- MIGHT BE ABLE TO DELETE ROWS BELOW\n    row_number() over (partition by ticket_id order by valid_starting_at) as ticket_status_counter,\n    row_number() over (partition by ticket_id, value order by valid_starting_at) as unique_status_counter\n\n  from ticket_status_history", "compiled": true, "resource_type": "model", "depends_on": {"macros": ["macro.dbt_utils.current_timestamp", "macro.fivetran_utils.timestamp_diff"], "nodes": ["model.zendesk.int_zendesk__updates"]}, "config": {"enabled": true, "alias": null, "schema": "zendesk_docs", "database": null, "tags": [], "meta": {}, "materialized": "table", "persist_docs": {}, "quoting": {}, "column_types": {}, "full_refresh": null, "on_schema_change": "ignore", "post-hook": [], "pre-hook": []}, "database": "bq-project", "schema": "dbt_joe_zendesk_docs", "fqn": ["zendesk", "intermediate", "int_zendesk__ticket_historical_status"], "unique_id": "model.zendesk.int_zendesk__ticket_historical_status", "package_name": "zendesk", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/zendesk", "path": "intermediate/int_zendesk__ticket_historical_status.sql", "original_file_path": "models/intermediate/int_zendesk__ticket_historical_status.sql", "name": "int_zendesk__ticket_historical_status", "alias": "int_zendesk__ticket_historical_status", "checksum": {"name": "sha256", "checksum": "bcf2649d98ed04b05faa03779cab67203f4fa62c95cf78759e75d2f6183320be"}, "tags": [], "refs": [["int_zendesk__updates"]], "sources": [], "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "compiled_path": "target/compiled/zendesk/models/intermediate/int_zendesk__ticket_historical_status.sql", "build_path": null, "deferred": false, "unrendered_config": {"schema": "zendesk_docs", "materialized": "table"}, "created_at": 1647014737.26001, "compiled_sql": "-- To do -- can we delete ticket_status_counter and unique_status_counter?\n\nwith ticket_status_history as (\n\n    select *\n    from `bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__updates`\n    where field_name = 'status'\n\n)\n\n  select\n  \n    ticket_id,\n    valid_starting_at,\n    valid_ending_at,\n    \n  \n\n    timestamp_diff(\n        coalesce(valid_ending_at, \n    current_timestamp\n),\n        valid_starting_at,\n        minute\n    )\n\n\n as status_duration_calendar_minutes,\n    value as status,\n    -- MIGHT BE ABLE TO DELETE ROWS BELOW\n    row_number() over (partition by ticket_id order by valid_starting_at) as ticket_status_counter,\n    row_number() over (partition by ticket_id, value order by valid_starting_at) as unique_status_counter\n\n  from ticket_status_history", "extra_ctes_injected": true, "extra_ctes": [], "relation_name": "`bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__ticket_historical_status`"}, "model.zendesk.int_zendesk__user_aggregates": {"raw_sql": "with users as (\n  select *\n  from {{ ref('stg_zendesk__user') }}\n\n--If you use user tags this will be included, if not it will be ignored.\n{% if var('using_user_tags', True) %}\n), user_tags as (\n\n  select *\n  from {{ ref('stg_zendesk__user_tag') }}\n  \n), user_tag_aggregate as (\n  select\n    user_tags.user_id,\n    {{ fivetran_utils.string_agg( 'user_tags.tags', \"', '\" )}} as user_tags\n  from user_tags\n  group by 1\n\n{% endif %}\n\n), final as (\n  select \n    users.*\n\n    --If you use user tags this will be included, if not it will be ignored.\n    {% if var('using_user_tags', True) %}\n    ,user_tag_aggregate.user_tags\n    {% endif %}\n  from users\n\n  --If you use user tags this will be included, if not it will be ignored.\n  {% if var('using_user_tags', True) %}\n  left join user_tag_aggregate\n    using(user_id)\n  {% endif %}\n)\n\nselect *\nfrom final", "compiled": true, "resource_type": "model", "depends_on": {"macros": [], "nodes": ["model.zendesk_source.stg_zendesk__user"]}, "config": {"enabled": true, "alias": null, "schema": "zendesk_docs", "database": null, "tags": [], "meta": {}, "materialized": "table", "persist_docs": {}, "quoting": {}, "column_types": {}, "full_refresh": null, "on_schema_change": "ignore", "post-hook": [], "pre-hook": []}, "database": "bq-project", "schema": "dbt_joe_zendesk_docs", "fqn": ["zendesk", "intermediate", "int_zendesk__user_aggregates"], "unique_id": "model.zendesk.int_zendesk__user_aggregates", "package_name": "zendesk", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/zendesk", "path": "intermediate/int_zendesk__user_aggregates.sql", "original_file_path": "models/intermediate/int_zendesk__user_aggregates.sql", "name": "int_zendesk__user_aggregates", "alias": "int_zendesk__user_aggregates", "checksum": {"name": "sha256", "checksum": "ae23565fdc62d13c33ddb03f3b25a5e288ec6e6ffe6b57cb01496be6ecd2b73f"}, "tags": [], "refs": [["stg_zendesk__user"]], "sources": [], "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "compiled_path": "target/compiled/zendesk/models/intermediate/int_zendesk__user_aggregates.sql", "build_path": null, "deferred": false, "unrendered_config": {"schema": "zendesk_docs", "materialized": "table"}, "created_at": 1647014737.265604, "compiled_sql": "with users as (\n  select *\n  from `bq-project`.`dbt_joe_zendesk_docs`.`stg_zendesk__user`\n\n--If you use user tags this will be included, if not it will be ignored.\n\n\n), final as (\n  select \n    users.*\n\n    --If you use user tags this will be included, if not it will be ignored.\n    \n  from users\n\n  --If you use user tags this will be included, if not it will be ignored.\n  \n)\n\nselect *\nfrom final", "extra_ctes_injected": true, "extra_ctes": [], "relation_name": "`bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__user_aggregates`"}, "model.zendesk.int_zendesk__schedule_spine": {"raw_sql": "{{ config(enabled=var('using_schedules', True)) }}\n\n/*\n    The purpose of this model is to create a spine of appropriate timezone offsets to use for schedules, as offsets may change due to Daylight Savings.\n    End result will include `valid_from` and `valid_until` columns which we will use downstream to determine which schedule-offset to associate with each ticket (ie standard time vs daylight time)\n*/\n\nwith timezone as (\n\n    select *\n    from {{ var('time_zone') }}\n\n), daylight_time as (\n\n    select *\n    from {{ var('daylight_time') }}\n\n), schedule as (\n\n    select *\n    from {{ var('schedule') }}   \n\n), timezone_with_dt as (\n\n    select \n        timezone.*,\n        daylight_time.daylight_start_utc,\n        daylight_time.daylight_end_utc,\n        daylight_time.daylight_offset_minutes\n\n    from timezone \n    left join daylight_time \n        on timezone.time_zone = daylight_time.time_zone\n\n), order_timezone_dt as (\n\n    select \n        *,\n        -- will be null for timezones without any daylight savings records (and the first entry)\n        -- we will coalesce the first entry date with .... the X years ago\n        lag(daylight_end_utc, 1) over (partition by time_zone order by daylight_end_utc asc) as last_daylight_end_utc,\n        -- will be null for timezones without any daylight savings records (and the last entry)\n        -- we will coalesce the last entry date with the current date \n        lead(daylight_start_utc, 1) over (partition by time_zone order by daylight_start_utc asc) as next_daylight_start_utc\n\n    from timezone_with_dt\n\n), split_timezones as (\n\n    -- standard schedule (includes timezones without DT)\n    -- starts: when the last Daylight Savings ended\n    -- ends: when the next Daylight Savings starts\n    select \n        time_zone,\n        standard_offset_minutes as offset_minutes,\n\n        -- last_daylight_end_utc is null for the first record of the time_zone's daylight time, or if the TZ doesn't use DT\n        coalesce(last_daylight_end_utc, cast('1970-01-01' as date)) as valid_from,\n\n        -- daylight_start_utc is null for timezones that don't use DT\n        coalesce(daylight_start_utc, cast( {{ dbt_utils.dateadd('year', 1, dbt_utils.current_timestamp()) }} as date)) as valid_until\n\n    from order_timezone_dt\n\n    union all \n\n    -- DT schedule (excludes timezones without it)\n    -- starts: when this Daylight Savings started\n    -- ends: when this Daylight Savings ends\n    select \n        time_zone,\n        -- Pacific Time is -8h during standard time and -7h during DT\n        standard_offset_minutes + daylight_offset_minutes as offset_minutes,\n        daylight_start_utc as valid_from,\n        daylight_end_utc as valid_until\n\n    from order_timezone_dt\n    where daylight_offset_minutes is not null\n\n), calculate_schedules as (\n\n    select \n        schedule.schedule_id,\n        schedule.time_zone,\n        schedule.start_time,\n        schedule.end_time,\n        schedule.created_at,\n        schedule.schedule_name,\n        schedule.start_time - coalesce(split_timezones.offset_minutes, 0) as start_time_utc,\n        schedule.end_time - coalesce(split_timezones.offset_minutes, 0) as end_time_utc,\n\n        -- we'll use these to determine which schedule version to associate tickets with\n        split_timezones.valid_from,\n        split_timezones.valid_until\n\n    from schedule\n    left join split_timezones\n        on split_timezones.time_zone = schedule.time_zone\n\n), final as (\n\n    select \n        *,\n        -- might remove this but for testing this is nice to have\n        {{ dbt_utils.surrogate_key(['schedule_id', 'time_zone','start_time', 'valid_from']) }} as unqiue_schedule_spine_key\n    \n    from calculate_schedules\n)\n\nselect *\nfrom final", "compiled": true, "resource_type": "model", "depends_on": {"macros": ["macro.dbt_utils.current_timestamp", "macro.dbt_utils.dateadd", "macro.dbt_utils.surrogate_key"], "nodes": ["model.zendesk_source.stg_zendesk__time_zone", "model.zendesk_source.stg_zendesk__daylight_time", "model.zendesk_source.stg_zendesk__schedule"]}, "config": {"enabled": true, "alias": null, "schema": "zendesk_docs", "database": null, "tags": [], "meta": {}, "materialized": "table", "persist_docs": {}, "quoting": {}, "column_types": {}, "full_refresh": null, "on_schema_change": "ignore", "post-hook": [], "pre-hook": []}, "database": "bq-project", "schema": "dbt_joe_zendesk_docs", "fqn": ["zendesk", "intermediate", "int_zendesk__schedule_spine"], "unique_id": "model.zendesk.int_zendesk__schedule_spine", "package_name": "zendesk", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/zendesk", "path": "intermediate/int_zendesk__schedule_spine.sql", "original_file_path": "models/intermediate/int_zendesk__schedule_spine.sql", "name": "int_zendesk__schedule_spine", "alias": "int_zendesk__schedule_spine", "checksum": {"name": "sha256", "checksum": "78c270560181b9fb01ce7c29a21aa53cba615d293eac2cab56eacf7a7d6259bb"}, "tags": [], "refs": [["stg_zendesk__time_zone"], ["stg_zendesk__daylight_time"], ["stg_zendesk__schedule"]], "sources": [], "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "compiled_path": "target/compiled/zendesk/models/intermediate/int_zendesk__schedule_spine.sql", "build_path": null, "deferred": false, "unrendered_config": {"schema": "zendesk_docs", "materialized": "table", "enabled": true}, "created_at": 1647014737.2720718, "compiled_sql": "\n\n/*\n    The purpose of this model is to create a spine of appropriate timezone offsets to use for schedules, as offsets may change due to Daylight Savings.\n    End result will include `valid_from` and `valid_until` columns which we will use downstream to determine which schedule-offset to associate with each ticket (ie standard time vs daylight time)\n*/\n\nwith timezone as (\n\n    select *\n    from `bq-project`.`dbt_joe_zendesk_docs`.`stg_zendesk__time_zone`\n\n), daylight_time as (\n\n    select *\n    from `bq-project`.`dbt_joe_zendesk_docs`.`stg_zendesk__daylight_time`\n\n), schedule as (\n\n    select *\n    from `bq-project`.`dbt_joe_zendesk_docs`.`stg_zendesk__schedule`   \n\n), timezone_with_dt as (\n\n    select \n        timezone.*,\n        daylight_time.daylight_start_utc,\n        daylight_time.daylight_end_utc,\n        daylight_time.daylight_offset_minutes\n\n    from timezone \n    left join daylight_time \n        on timezone.time_zone = daylight_time.time_zone\n\n), order_timezone_dt as (\n\n    select \n        *,\n        -- will be null for timezones without any daylight savings records (and the first entry)\n        -- we will coalesce the first entry date with .... the X years ago\n        lag(daylight_end_utc, 1) over (partition by time_zone order by daylight_end_utc asc) as last_daylight_end_utc,\n        -- will be null for timezones without any daylight savings records (and the last entry)\n        -- we will coalesce the last entry date with the current date \n        lead(daylight_start_utc, 1) over (partition by time_zone order by daylight_start_utc asc) as next_daylight_start_utc\n\n    from timezone_with_dt\n\n), split_timezones as (\n\n    -- standard schedule (includes timezones without DT)\n    -- starts: when the last Daylight Savings ended\n    -- ends: when the next Daylight Savings starts\n    select \n        time_zone,\n        standard_offset_minutes as offset_minutes,\n\n        -- last_daylight_end_utc is null for the first record of the time_zone's daylight time, or if the TZ doesn't use DT\n        coalesce(last_daylight_end_utc, cast('1970-01-01' as date)) as valid_from,\n\n        -- daylight_start_utc is null for timezones that don't use DT\n        coalesce(daylight_start_utc, cast( \n\n        datetime_add(\n            cast( \n    current_timestamp\n as datetime),\n        interval 1 year\n        )\n\n as date)) as valid_until\n\n    from order_timezone_dt\n\n    union all \n\n    -- DT schedule (excludes timezones without it)\n    -- starts: when this Daylight Savings started\n    -- ends: when this Daylight Savings ends\n    select \n        time_zone,\n        -- Pacific Time is -8h during standard time and -7h during DT\n        standard_offset_minutes + daylight_offset_minutes as offset_minutes,\n        daylight_start_utc as valid_from,\n        daylight_end_utc as valid_until\n\n    from order_timezone_dt\n    where daylight_offset_minutes is not null\n\n), calculate_schedules as (\n\n    select \n        schedule.schedule_id,\n        schedule.time_zone,\n        schedule.start_time,\n        schedule.end_time,\n        schedule.created_at,\n        schedule.schedule_name,\n        schedule.start_time - coalesce(split_timezones.offset_minutes, 0) as start_time_utc,\n        schedule.end_time - coalesce(split_timezones.offset_minutes, 0) as end_time_utc,\n\n        -- we'll use these to determine which schedule version to associate tickets with\n        split_timezones.valid_from,\n        split_timezones.valid_until\n\n    from schedule\n    left join split_timezones\n        on split_timezones.time_zone = schedule.time_zone\n\n), final as (\n\n    select \n        *,\n        -- might remove this but for testing this is nice to have\n        to_hex(md5(cast(coalesce(cast(schedule_id as \n    string\n), '') || '-' || coalesce(cast(time_zone as \n    string\n), '') || '-' || coalesce(cast(start_time as \n    string\n), '') || '-' || coalesce(cast(valid_from as \n    string\n), '') as \n    string\n))) as unqiue_schedule_spine_key\n    \n    from calculate_schedules\n)\n\nselect *\nfrom final", "extra_ctes_injected": true, "extra_ctes": [], "relation_name": "`bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__schedule_spine`"}, "model.zendesk.int_zendesk__ticket_schedules": {"raw_sql": "{{ config(enabled=var('using_schedules', True)) }}\n\nwith ticket as (\n  \n  select *\n  from {{ ref('stg_zendesk__ticket') }}\n\n), ticket_schedule as (\n \n  select *\n  from {{ ref('stg_zendesk__ticket_schedule') }}\n\n), schedule as (\n \n  select *\n  from {{ ref('stg_zendesk__schedule') }}\n\n\n), default_schedule_events as (\n-- Goal: understand the working schedules applied to tickets, so that we can then determine the applicable business hours/schedule.\n-- Your default schedule is used for all tickets, unless you set up a trigger to apply a specific schedule to specific tickets.\n\n-- This portion of the query creates ticket_schedules for these \"default\" schedules, as the ticket_schedule table only includes\n-- trigger schedules\n\n{% if execute %}\n\n    {% set default_schedule_id_query %}\n        with set_default_schedule_flag as (\n          select \n            row_number() over (order by created_at) = 1 as is_default_schedule,\n            schedule_id\n          from {{ ref('stg_zendesk__schedule') }}\n        )\n        select \n          schedule_id\n        from set_default_schedule_flag\n        where is_default_schedule\n\n    {% endset %}\n\n    {% set default_schedule_id = run_query(default_schedule_id_query).columns[0][0]|string %}\n\n    {% endif %}\n\n  select\n    ticket.ticket_id,\n    ticket.created_at as schedule_created_at,\n    '{{default_schedule_id}}' as schedule_id\n  from ticket\n  left join ticket_schedule as first_schedule\n    on first_schedule.ticket_id = ticket.ticket_id\n    and {{ fivetran_utils.timestamp_add('second', -5, 'first_schedule.created_at') }} <= ticket.created_at\n    and first_schedule.created_at >= ticket.created_at    \n  where first_schedule.ticket_id is null\n\n), schedule_events as (\n  \n  select\n    *\n  from default_schedule_events\n  \n  union all\n  \n  select \n    ticket_id,\n    created_at as schedule_created_at,\n    schedule_id\n  from ticket_schedule\n\n), ticket_schedules as (\n  \n  select \n    ticket_id,\n    schedule_id,\n    schedule_created_at,\n    coalesce(lead(schedule_created_at) over (partition by ticket_id order by schedule_created_at)\n            , {{ fivetran_utils.timestamp_add(\"hour\", 1000, \"\" ~ dbt_utils.current_timestamp() ~ \"\") }} ) as schedule_invalidated_at\n  from schedule_events\n\n)\nselect\n  *\nfrom ticket_schedules", "compiled": true, "resource_type": "model", "depends_on": {"macros": ["macro.fivetran_utils.timestamp_add", "macro.dbt_utils.current_timestamp", "macro.dbt.run_query"], "nodes": ["model.zendesk_source.stg_zendesk__ticket", "model.zendesk_source.stg_zendesk__ticket_schedule", "model.zendesk_source.stg_zendesk__schedule"]}, "config": {"enabled": true, "alias": null, "schema": "zendesk_docs", "database": null, "tags": [], "meta": {}, "materialized": "table", "persist_docs": {}, "quoting": {}, "column_types": {}, "full_refresh": null, "on_schema_change": "ignore", "post-hook": [], "pre-hook": []}, "database": "bq-project", "schema": "dbt_joe_zendesk_docs", "fqn": ["zendesk", "intermediate", "int_zendesk__ticket_schedules"], "unique_id": "model.zendesk.int_zendesk__ticket_schedules", "package_name": "zendesk", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/zendesk", "path": "intermediate/int_zendesk__ticket_schedules.sql", "original_file_path": "models/intermediate/int_zendesk__ticket_schedules.sql", "name": "int_zendesk__ticket_schedules", "alias": "int_zendesk__ticket_schedules", "checksum": {"name": "sha256", "checksum": "f20eb27db92f2d3622124552b20757e7e1a03e972e5e0bc261c74573ae8123df"}, "tags": [], "refs": [["stg_zendesk__ticket"], ["stg_zendesk__ticket_schedule"], ["stg_zendesk__schedule"]], "sources": [], "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "compiled_path": "target/compiled/zendesk/models/intermediate/int_zendesk__ticket_schedules.sql", "build_path": null, "deferred": false, "unrendered_config": {"schema": "zendesk_docs", "materialized": "table", "enabled": true}, "created_at": 1647014737.282927, "compiled_sql": "\n\nwith ticket as (\n  \n  select *\n  from `bq-project`.`dbt_joe_zendesk_docs`.`stg_zendesk__ticket`\n\n), ticket_schedule as (\n \n  select *\n  from `bq-project`.`dbt_joe_zendesk_docs`.`stg_zendesk__ticket_schedule`\n\n), schedule as (\n \n  select *\n  from `bq-project`.`dbt_joe_zendesk_docs`.`stg_zendesk__schedule`\n\n\n), default_schedule_events as (\n-- Goal: understand the working schedules applied to tickets, so that we can then determine the applicable business hours/schedule.\n-- Your default schedule is used for all tickets, unless you set up a trigger to apply a specific schedule to specific tickets.\n\n-- This portion of the query creates ticket_schedules for these \"default\" schedules, as the ticket_schedule table only includes\n-- trigger schedules\n\n\n\n    \n\n    \n\n    \n\n  select\n    ticket.ticket_id,\n    ticket.created_at as schedule_created_at,\n    '360000389531' as schedule_id\n  from ticket\n  left join ticket_schedule as first_schedule\n    on first_schedule.ticket_id = ticket.ticket_id\n    and \n\n        timestamp_add(first_schedule.created_at, interval  -5 second)\n\n <= ticket.created_at\n    and first_schedule.created_at >= ticket.created_at    \n  where first_schedule.ticket_id is null\n\n), schedule_events as (\n  \n  select\n    *\n  from default_schedule_events\n  \n  union all\n  \n  select \n    ticket_id,\n    created_at as schedule_created_at,\n    schedule_id\n  from ticket_schedule\n\n), ticket_schedules as (\n  \n  select \n    ticket_id,\n    schedule_id,\n    schedule_created_at,\n    coalesce(lead(schedule_created_at) over (partition by ticket_id order by schedule_created_at)\n            , \n\n        timestamp_add(\n    current_timestamp\n, interval  1000 hour)\n\n ) as schedule_invalidated_at\n  from schedule_events\n\n)\nselect\n  *\nfrom ticket_schedules", "extra_ctes_injected": true, "extra_ctes": [], "relation_name": "`bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__ticket_schedules`"}, "model.zendesk.int_zendesk__assignee_updates": {"raw_sql": "with ticket_updates as (\n    select *\n    from {{ ref('int_zendesk__updates') }}\n\n), ticket as (\n    select *\n    from {{ ref('stg_zendesk__ticket') }}\n\n), ticket_requester as (\n    select\n        ticket.ticket_id,\n        ticket.assignee_id,\n        ticket_updates.valid_starting_at\n\n    from ticket\n\n    left join ticket_updates\n        on ticket_updates.ticket_id = ticket.ticket_id\n            and ticket_updates.user_id = ticket.assignee_id\n\n), final as (\n    select \n        ticket_id,\n        assignee_id,\n        max(valid_starting_at) as last_updated,\n        count(*) as total_updates\n    from ticket_requester\n\n    group by 1, 2\n)\n\nselect * \nfrom final", "compiled": true, "resource_type": "model", "depends_on": {"macros": [], "nodes": ["model.zendesk.int_zendesk__updates", "model.zendesk_source.stg_zendesk__ticket"]}, "config": {"enabled": true, "alias": null, "schema": "zendesk_docs", "database": null, "tags": [], "meta": {}, "materialized": "table", "persist_docs": {}, "quoting": {}, "column_types": {}, "full_refresh": null, "on_schema_change": "ignore", "post-hook": [], "pre-hook": []}, "database": "bq-project", "schema": "dbt_joe_zendesk_docs", "fqn": ["zendesk", "intermediate", "int_zendesk__assignee_updates"], "unique_id": "model.zendesk.int_zendesk__assignee_updates", "package_name": "zendesk", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/zendesk", "path": "intermediate/int_zendesk__assignee_updates.sql", "original_file_path": "models/intermediate/int_zendesk__assignee_updates.sql", "name": "int_zendesk__assignee_updates", "alias": "int_zendesk__assignee_updates", "checksum": {"name": "sha256", "checksum": "951ec2d4f8c9a7470a50cfc6e01838a090472a9f18fccd2dd65097d309d43aed"}, "tags": [], "refs": [["int_zendesk__updates"], ["stg_zendesk__ticket"]], "sources": [], "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "compiled_path": "target/compiled/zendesk/models/intermediate/int_zendesk__assignee_updates.sql", "build_path": null, "deferred": false, "unrendered_config": {"schema": "zendesk_docs", "materialized": "table"}, "created_at": 1647014737.2928169, "compiled_sql": "with ticket_updates as (\n    select *\n    from `bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__updates`\n\n), ticket as (\n    select *\n    from `bq-project`.`dbt_joe_zendesk_docs`.`stg_zendesk__ticket`\n\n), ticket_requester as (\n    select\n        ticket.ticket_id,\n        ticket.assignee_id,\n        ticket_updates.valid_starting_at\n\n    from ticket\n\n    left join ticket_updates\n        on ticket_updates.ticket_id = ticket.ticket_id\n            and ticket_updates.user_id = ticket.assignee_id\n\n), final as (\n    select \n        ticket_id,\n        assignee_id,\n        max(valid_starting_at) as last_updated,\n        count(*) as total_updates\n    from ticket_requester\n\n    group by 1, 2\n)\n\nselect * \nfrom final", "extra_ctes_injected": true, "extra_ctes": [], "relation_name": "`bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__assignee_updates`"}, "model.zendesk.int_zendesk__comment_metrics": {"raw_sql": "with ticket_comments as (\n\n    select *\n    from {{ ref('int_zendesk__comments_enriched') }}\n),\n\ncomment_counts as (\n    select\n        ticket_id,\n        last_comment_added_at,\n        sum(case when commenter_role = 'internal_comment' and is_public = true\n            then 1\n            else 0\n                end) as count_public_agent_comments,\n        sum(case when commenter_role = 'internal_comment'\n            then 1\n            else 0\n                end) as count_agent_comments,\n        sum(case when commenter_role = 'external_comment'\n            then 1\n            else 0\n                end) as count_end_user_comments,\n        sum(case when is_public = true\n            then 1\n            else 0\n                end) as count_public_comments,\n        sum(case when is_public = false\n            then 1\n            else 0\n                end) as count_internal_comments,\n        count(*) as total_comments,\n        count(distinct case when commenter_role = 'internal_comment'\n            then user_id\n                end) as count_ticket_handoffs\n    from ticket_comments\n\n    group by 1, 2\n),\n\nfinal as (\n    select\n        *,\n        count_public_agent_comments = 1 as is_one_touch_resolution,\n        count_public_agent_comments = 2 as is_two_touch_resolution\n    from comment_counts\n)\n\nselect * \nfrom final", "compiled": true, "resource_type": "model", "depends_on": {"macros": [], "nodes": ["model.zendesk.int_zendesk__comments_enriched"]}, "config": {"enabled": true, "alias": null, "schema": "zendesk_docs", "database": null, "tags": [], "meta": {}, "materialized": "table", "persist_docs": {}, "quoting": {}, "column_types": {}, "full_refresh": null, "on_schema_change": "ignore", "post-hook": [], "pre-hook": []}, "database": "bq-project", "schema": "dbt_joe_zendesk_docs", "fqn": ["zendesk", "intermediate", "int_zendesk__comment_metrics"], "unique_id": "model.zendesk.int_zendesk__comment_metrics", "package_name": "zendesk", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/zendesk", "path": "intermediate/int_zendesk__comment_metrics.sql", "original_file_path": "models/intermediate/int_zendesk__comment_metrics.sql", "name": "int_zendesk__comment_metrics", "alias": "int_zendesk__comment_metrics", "checksum": {"name": "sha256", "checksum": "55c61cb79adcf74f427896f7e3c61dc3cae6f12ef2e61736b17efd913e232e4c"}, "tags": [], "refs": [["int_zendesk__comments_enriched"]], "sources": [], "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "compiled_path": "target/compiled/zendesk/models/intermediate/int_zendesk__comment_metrics.sql", "build_path": null, "deferred": false, "unrendered_config": {"schema": "zendesk_docs", "materialized": "table"}, "created_at": 1647014737.295253, "compiled_sql": "with  __dbt__cte__int_zendesk__comments_enriched as (\nwith ticket_comment as (\n\n    select *\n    from `bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__updates`\n    where field_name = 'comment'\n\n), users as (\n\n    select *\n    from `bq-project`.`dbt_joe_zendesk_docs`.`stg_zendesk__user`\n\n), joined as (\n\n    select \n\n        ticket_comment.*,\n        case when commenter.role = 'end-user' then 'external_comment'\n            when commenter.role in ('agent','admin') then 'internal_comment'\n            else 'unknown' end as commenter_role\n    \n    from ticket_comment\n    \n    join users as commenter\n        on commenter.user_id = ticket_comment.user_id\n\n), add_previous_commenter_role as (\n    /*\n    In int_zendesk__ticket_reply_times we will only be focusing on reply times between public tickets.\n    The below union explicitly identifies the previous commentor roles of public and not public comments.\n    */\n    select\n        *,\n        coalesce(\n            lag(commenter_role) over (partition by ticket_id order by valid_starting_at)\n            , 'first_comment') \n            as previous_commenter_role\n    from joined\n    where is_public\n\n    union all\n\n    select\n        *,\n        'non_public_comment' as previous_commenter_role\n    from joined\n    where not is_public\n)\n\nselect \n    *,\n    first_value(valid_starting_at) over (partition by ticket_id order by valid_starting_at desc, ticket_id rows unbounded preceding) as last_comment_added_at,\n    sum(case when not is_public then 1 else 0 end) over (partition by ticket_id order by valid_starting_at rows between unbounded preceding and current row) as previous_internal_comment_count\nfrom add_previous_commenter_role\n),ticket_comments as (\n\n    select *\n    from __dbt__cte__int_zendesk__comments_enriched\n),\n\ncomment_counts as (\n    select\n        ticket_id,\n        last_comment_added_at,\n        sum(case when commenter_role = 'internal_comment' and is_public = true\n            then 1\n            else 0\n                end) as count_public_agent_comments,\n        sum(case when commenter_role = 'internal_comment'\n            then 1\n            else 0\n                end) as count_agent_comments,\n        sum(case when commenter_role = 'external_comment'\n            then 1\n            else 0\n                end) as count_end_user_comments,\n        sum(case when is_public = true\n            then 1\n            else 0\n                end) as count_public_comments,\n        sum(case when is_public = false\n            then 1\n            else 0\n                end) as count_internal_comments,\n        count(*) as total_comments,\n        count(distinct case when commenter_role = 'internal_comment'\n            then user_id\n                end) as count_ticket_handoffs\n    from ticket_comments\n\n    group by 1, 2\n),\n\nfinal as (\n    select\n        *,\n        count_public_agent_comments = 1 as is_one_touch_resolution,\n        count_public_agent_comments = 2 as is_two_touch_resolution\n    from comment_counts\n)\n\nselect * \nfrom final", "extra_ctes_injected": true, "extra_ctes": [{"id": "model.zendesk.int_zendesk__comments_enriched", "sql": " __dbt__cte__int_zendesk__comments_enriched as (\nwith ticket_comment as (\n\n    select *\n    from `bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__updates`\n    where field_name = 'comment'\n\n), users as (\n\n    select *\n    from `bq-project`.`dbt_joe_zendesk_docs`.`stg_zendesk__user`\n\n), joined as (\n\n    select \n\n        ticket_comment.*,\n        case when commenter.role = 'end-user' then 'external_comment'\n            when commenter.role in ('agent','admin') then 'internal_comment'\n            else 'unknown' end as commenter_role\n    \n    from ticket_comment\n    \n    join users as commenter\n        on commenter.user_id = ticket_comment.user_id\n\n), add_previous_commenter_role as (\n    /*\n    In int_zendesk__ticket_reply_times we will only be focusing on reply times between public tickets.\n    The below union explicitly identifies the previous commentor roles of public and not public comments.\n    */\n    select\n        *,\n        coalesce(\n            lag(commenter_role) over (partition by ticket_id order by valid_starting_at)\n            , 'first_comment') \n            as previous_commenter_role\n    from joined\n    where is_public\n\n    union all\n\n    select\n        *,\n        'non_public_comment' as previous_commenter_role\n    from joined\n    where not is_public\n)\n\nselect \n    *,\n    first_value(valid_starting_at) over (partition by ticket_id order by valid_starting_at desc, ticket_id rows unbounded preceding) as last_comment_added_at,\n    sum(case when not is_public then 1 else 0 end) over (partition by ticket_id order by valid_starting_at rows between unbounded preceding and current row) as previous_internal_comment_count\nfrom add_previous_commenter_role\n)"}], "relation_name": "`bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__comment_metrics`"}, "model.zendesk.int_zendesk__ticket_historical_group": {"raw_sql": "with ticket_group_history as (\n\n    select *\n    from {{ ref('int_zendesk__updates') }}\n    where field_name = 'group_id'\n\n), group_breakdown as (\n    select\n  \n        ticket_id,\n        valid_starting_at,\n        valid_ending_at,\n        value as group_id\n    from ticket_group_history\n\n), final as (\n    select\n        ticket_id,\n        count(group_id) as group_stations_count\n    from group_breakdown\n\n    group by 1\n)\n\nselect *\nfrom final", "compiled": true, "resource_type": "model", "depends_on": {"macros": [], "nodes": ["model.zendesk.int_zendesk__updates"]}, "config": {"enabled": true, "alias": null, "schema": "zendesk_docs", "database": null, "tags": [], "meta": {}, "materialized": "table", "persist_docs": {}, "quoting": {}, "column_types": {}, "full_refresh": null, "on_schema_change": "ignore", "post-hook": [], "pre-hook": []}, "database": "bq-project", "schema": "dbt_joe_zendesk_docs", "fqn": ["zendesk", "intermediate", "int_zendesk__ticket_historical_group"], "unique_id": "model.zendesk.int_zendesk__ticket_historical_group", "package_name": "zendesk", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/zendesk", "path": "intermediate/int_zendesk__ticket_historical_group.sql", "original_file_path": "models/intermediate/int_zendesk__ticket_historical_group.sql", "name": "int_zendesk__ticket_historical_group", "alias": "int_zendesk__ticket_historical_group", "checksum": {"name": "sha256", "checksum": "7d4d72f5d6a7ef73a23ad4be966b00683532fe2a11c9729a8d640752ebee1adc"}, "tags": [], "refs": [["int_zendesk__updates"]], "sources": [], "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "compiled_path": "target/compiled/zendesk/models/intermediate/int_zendesk__ticket_historical_group.sql", "build_path": null, "deferred": false, "unrendered_config": {"schema": "zendesk_docs", "materialized": "table"}, "created_at": 1647014737.297614, "compiled_sql": "with ticket_group_history as (\n\n    select *\n    from `bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__updates`\n    where field_name = 'group_id'\n\n), group_breakdown as (\n    select\n  \n        ticket_id,\n        valid_starting_at,\n        valid_ending_at,\n        value as group_id\n    from ticket_group_history\n\n), final as (\n    select\n        ticket_id,\n        count(group_id) as group_stations_count\n    from group_breakdown\n\n    group by 1\n)\n\nselect *\nfrom final", "extra_ctes_injected": true, "extra_ctes": [], "relation_name": "`bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__ticket_historical_group`"}, "model.zendesk.int_zendesk__requester_updates": {"raw_sql": "with ticket_updates as (\n    select *\n    from {{ ref('int_zendesk__updates') }}\n\n), ticket as (\n    select *\n    from {{ ref('stg_zendesk__ticket') }}\n\n), ticket_requester as (\n    select\n        ticket.ticket_id,\n        ticket.requester_id,\n        ticket_updates.valid_starting_at\n\n    from ticket\n\n    left join ticket_updates\n        on ticket_updates.ticket_id = ticket.ticket_id\n            and ticket_updates.user_id = ticket.requester_id\n\n), final as (\n    select \n        ticket_id,\n        requester_id,\n        max(valid_starting_at) as last_updated,\n        count(*) as total_updates\n    from ticket_requester\n\n    group by 1, 2\n)\n\nselect * \nfrom final", "compiled": true, "resource_type": "model", "depends_on": {"macros": [], "nodes": ["model.zendesk.int_zendesk__updates", "model.zendesk_source.stg_zendesk__ticket"]}, "config": {"enabled": true, "alias": null, "schema": "zendesk_docs", "database": null, "tags": [], "meta": {}, "materialized": "table", "persist_docs": {}, "quoting": {}, "column_types": {}, "full_refresh": null, "on_schema_change": "ignore", "post-hook": [], "pre-hook": []}, "database": "bq-project", "schema": "dbt_joe_zendesk_docs", "fqn": ["zendesk", "intermediate", "int_zendesk__requester_updates"], "unique_id": "model.zendesk.int_zendesk__requester_updates", "package_name": "zendesk", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/zendesk", "path": "intermediate/int_zendesk__requester_updates.sql", "original_file_path": "models/intermediate/int_zendesk__requester_updates.sql", "name": "int_zendesk__requester_updates", "alias": "int_zendesk__requester_updates", "checksum": {"name": "sha256", "checksum": "b2d14b09db3cadfb56e4b3dcb55c4f9000e670e3c7c29ef89b249e626e8ba103"}, "tags": [], "refs": [["int_zendesk__updates"], ["stg_zendesk__ticket"]], "sources": [], "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "compiled_path": "target/compiled/zendesk/models/intermediate/int_zendesk__requester_updates.sql", "build_path": null, "deferred": false, "unrendered_config": {"schema": "zendesk_docs", "materialized": "table"}, "created_at": 1647014737.2999601, "compiled_sql": "with ticket_updates as (\n    select *\n    from `bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__updates`\n\n), ticket as (\n    select *\n    from `bq-project`.`dbt_joe_zendesk_docs`.`stg_zendesk__ticket`\n\n), ticket_requester as (\n    select\n        ticket.ticket_id,\n        ticket.requester_id,\n        ticket_updates.valid_starting_at\n\n    from ticket\n\n    left join ticket_updates\n        on ticket_updates.ticket_id = ticket.ticket_id\n            and ticket_updates.user_id = ticket.requester_id\n\n), final as (\n    select \n        ticket_id,\n        requester_id,\n        max(valid_starting_at) as last_updated,\n        count(*) as total_updates\n    from ticket_requester\n\n    group by 1, 2\n)\n\nselect * \nfrom final", "extra_ctes_injected": true, "extra_ctes": [], "relation_name": "`bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__requester_updates`"}, "model.zendesk.int_zendesk__ticket_historical_satisfaction": {"raw_sql": "with satisfaction_updates as (\n\n    select *\n    from {{ ref('int_zendesk__updates') }}\n    where field_name in ('satisfaction_score', 'satisfaction_comment', 'satisfaction_reason_code') \n\n), latest_reason as (\n    select\n        ticket_id,\n        first_value(value) over (partition by ticket_id order by valid_starting_at desc, ticket_id rows unbounded preceding) as latest_satisfaction_reason\n    from satisfaction_updates\n\n    where field_name = 'satisfaction_reason_code'\n\n), latest_comment as (\n    select\n        ticket_id,\n        first_value(value) over (partition by ticket_id order by valid_starting_at desc, ticket_id rows unbounded preceding) as latest_satisfaction_comment\n    from satisfaction_updates\n\n    where field_name = 'satisfaction_comment'\n\n), first_and_latest_score as (\n    select\n        ticket_id,\n        first_value(value) over (partition by ticket_id order by valid_starting_at, ticket_id rows unbounded preceding) as first_satisfaction_score,\n        first_value(value) over (partition by ticket_id order by valid_starting_at desc, ticket_id rows unbounded preceding) as latest_satisfaction_score\n    from satisfaction_updates\n\n    where field_name = 'satisfaction_score' and value != 'offered'\n\n), satisfaction_scores as (\n    select\n        ticket_id,\n        count(value) over (partition by ticket_id) as count_satisfaction_scores,\n        case when lag(value) over (partition by ticket_id order by valid_starting_at desc) = 'good' and value = 'bad'\n            then 1\n            else 0\n                end as good_to_bad_score,\n        case when lag(value) over (partition by ticket_id order by valid_starting_at desc) = 'bad' and value = 'good'\n            then 1\n            else 0\n                end as bad_to_good_score\n    from satisfaction_updates\n    where field_name = 'satisfaction_score'\n\n), score_group as (\n    select\n        ticket_id,\n        count_satisfaction_scores,\n        sum(good_to_bad_score) as total_good_to_bad_score,\n        sum(bad_to_good_score) as total_bad_to_good_score\n    from satisfaction_scores\n\n    group by 1, 2\n\n), window_group as (\n    select\n        satisfaction_updates.ticket_id,\n        latest_reason.latest_satisfaction_reason,\n        latest_comment.latest_satisfaction_comment,\n        first_and_latest_score.first_satisfaction_score,\n        first_and_latest_score.latest_satisfaction_score,\n        score_group.count_satisfaction_scores,\n        score_group.total_good_to_bad_score,\n        score_group.total_bad_to_good_score\n\n    from satisfaction_updates\n\n    left join latest_reason\n        on satisfaction_updates.ticket_id = latest_reason.ticket_id\n\n    left join latest_comment\n        on satisfaction_updates.ticket_id = latest_comment.ticket_id\n\n    left join first_and_latest_score\n        on satisfaction_updates.ticket_id = first_and_latest_score.ticket_id\n\n    left join score_group\n        on satisfaction_updates.ticket_id = score_group.ticket_id\n\n    group by 1, 2, 3, 4, 5, 6, 7, 8\n\n), final as (\n    select\n        ticket_id,\n        latest_satisfaction_reason,\n        latest_satisfaction_comment,\n        first_satisfaction_score,\n        latest_satisfaction_score,\n        case when count_satisfaction_scores > 0\n            then (count_satisfaction_scores - 1) --Subtracting one as the first score is always \"offered\".\n            else count_satisfaction_scores\n                end as count_satisfaction_scores,\n        case when total_good_to_bad_score > 0\n            then true\n            else false\n                end as is_good_to_bad_satisfaction_score,\n        case when total_bad_to_good_score > 0\n            then true\n            else false\n                end as is_bad_to_good_satisfaction_score\n    from window_group\n)\n\nselect *\nfrom final", "compiled": true, "resource_type": "model", "depends_on": {"macros": [], "nodes": ["model.zendesk.int_zendesk__updates"]}, "config": {"enabled": true, "alias": null, "schema": "zendesk_docs", "database": null, "tags": [], "meta": {}, "materialized": "table", "persist_docs": {}, "quoting": {}, "column_types": {}, "full_refresh": null, "on_schema_change": "ignore", "post-hook": [], "pre-hook": []}, "database": "bq-project", "schema": "dbt_joe_zendesk_docs", "fqn": ["zendesk", "intermediate", "int_zendesk__ticket_historical_satisfaction"], "unique_id": "model.zendesk.int_zendesk__ticket_historical_satisfaction", "package_name": "zendesk", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/zendesk", "path": "intermediate/int_zendesk__ticket_historical_satisfaction.sql", "original_file_path": "models/intermediate/int_zendesk__ticket_historical_satisfaction.sql", "name": "int_zendesk__ticket_historical_satisfaction", "alias": "int_zendesk__ticket_historical_satisfaction", "checksum": {"name": "sha256", "checksum": "dce9b5b8705d72688802f99250a8f8a34b8791c3cb440f85efa11f09ebfe3e1d"}, "tags": [], "refs": [["int_zendesk__updates"]], "sources": [], "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "compiled_path": "target/compiled/zendesk/models/intermediate/int_zendesk__ticket_historical_satisfaction.sql", "build_path": null, "deferred": false, "unrendered_config": {"schema": "zendesk_docs", "materialized": "table"}, "created_at": 1647014737.302361, "compiled_sql": "with satisfaction_updates as (\n\n    select *\n    from `bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__updates`\n    where field_name in ('satisfaction_score', 'satisfaction_comment', 'satisfaction_reason_code') \n\n), latest_reason as (\n    select\n        ticket_id,\n        first_value(value) over (partition by ticket_id order by valid_starting_at desc, ticket_id rows unbounded preceding) as latest_satisfaction_reason\n    from satisfaction_updates\n\n    where field_name = 'satisfaction_reason_code'\n\n), latest_comment as (\n    select\n        ticket_id,\n        first_value(value) over (partition by ticket_id order by valid_starting_at desc, ticket_id rows unbounded preceding) as latest_satisfaction_comment\n    from satisfaction_updates\n\n    where field_name = 'satisfaction_comment'\n\n), first_and_latest_score as (\n    select\n        ticket_id,\n        first_value(value) over (partition by ticket_id order by valid_starting_at, ticket_id rows unbounded preceding) as first_satisfaction_score,\n        first_value(value) over (partition by ticket_id order by valid_starting_at desc, ticket_id rows unbounded preceding) as latest_satisfaction_score\n    from satisfaction_updates\n\n    where field_name = 'satisfaction_score' and value != 'offered'\n\n), satisfaction_scores as (\n    select\n        ticket_id,\n        count(value) over (partition by ticket_id) as count_satisfaction_scores,\n        case when lag(value) over (partition by ticket_id order by valid_starting_at desc) = 'good' and value = 'bad'\n            then 1\n            else 0\n                end as good_to_bad_score,\n        case when lag(value) over (partition by ticket_id order by valid_starting_at desc) = 'bad' and value = 'good'\n            then 1\n            else 0\n                end as bad_to_good_score\n    from satisfaction_updates\n    where field_name = 'satisfaction_score'\n\n), score_group as (\n    select\n        ticket_id,\n        count_satisfaction_scores,\n        sum(good_to_bad_score) as total_good_to_bad_score,\n        sum(bad_to_good_score) as total_bad_to_good_score\n    from satisfaction_scores\n\n    group by 1, 2\n\n), window_group as (\n    select\n        satisfaction_updates.ticket_id,\n        latest_reason.latest_satisfaction_reason,\n        latest_comment.latest_satisfaction_comment,\n        first_and_latest_score.first_satisfaction_score,\n        first_and_latest_score.latest_satisfaction_score,\n        score_group.count_satisfaction_scores,\n        score_group.total_good_to_bad_score,\n        score_group.total_bad_to_good_score\n\n    from satisfaction_updates\n\n    left join latest_reason\n        on satisfaction_updates.ticket_id = latest_reason.ticket_id\n\n    left join latest_comment\n        on satisfaction_updates.ticket_id = latest_comment.ticket_id\n\n    left join first_and_latest_score\n        on satisfaction_updates.ticket_id = first_and_latest_score.ticket_id\n\n    left join score_group\n        on satisfaction_updates.ticket_id = score_group.ticket_id\n\n    group by 1, 2, 3, 4, 5, 6, 7, 8\n\n), final as (\n    select\n        ticket_id,\n        latest_satisfaction_reason,\n        latest_satisfaction_comment,\n        first_satisfaction_score,\n        latest_satisfaction_score,\n        case when count_satisfaction_scores > 0\n            then (count_satisfaction_scores - 1) --Subtracting one as the first score is always \"offered\".\n            else count_satisfaction_scores\n                end as count_satisfaction_scores,\n        case when total_good_to_bad_score > 0\n            then true\n            else false\n                end as is_good_to_bad_satisfaction_score,\n        case when total_bad_to_good_score > 0\n            then true\n            else false\n                end as is_bad_to_good_satisfaction_score\n    from window_group\n)\n\nselect *\nfrom final", "extra_ctes_injected": true, "extra_ctes": [], "relation_name": "`bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__ticket_historical_satisfaction`"}, "model.zendesk.int_zendesk__latest_ticket_form": {"raw_sql": "--To disable this model, set the using_ticket_form_history variable within your dbt_project.yml file to False.\n{{ config(enabled=var('using_ticket_form_history', True)) }}\n\nwith ticket_form_history as (\n  select *\n  from {{ ref('stg_zendesk__ticket_form_history') }}\n),\n\nlatest_ticket_form as (\n    select\n      *,\n      row_number() over(partition by ticket_form_id order by updated_at desc) as latest_form_index\n    from ticket_form_history\n),\n\nfinal as (\n    select \n        ticket_form_id,\n        created_at,\n        updated_at,\n        display_name,\n        is_active,\n        name,\n        latest_form_index\n    from latest_ticket_form\n\n    where latest_form_index = 1\n)\n\nselect *\nfrom final", "compiled": true, "resource_type": "model", "depends_on": {"macros": [], "nodes": ["model.zendesk_source.stg_zendesk__ticket_form_history"]}, "config": {"enabled": true, "alias": null, "schema": "zendesk_docs", "database": null, "tags": [], "meta": {}, "materialized": "table", "persist_docs": {}, "quoting": {}, "column_types": {}, "full_refresh": null, "on_schema_change": "ignore", "post-hook": [], "pre-hook": []}, "database": "bq-project", "schema": "dbt_joe_zendesk_docs", "fqn": ["zendesk", "intermediate", "int_zendesk__latest_ticket_form"], "unique_id": "model.zendesk.int_zendesk__latest_ticket_form", "package_name": "zendesk", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/zendesk", "path": "intermediate/int_zendesk__latest_ticket_form.sql", "original_file_path": "models/intermediate/int_zendesk__latest_ticket_form.sql", "name": "int_zendesk__latest_ticket_form", "alias": "int_zendesk__latest_ticket_form", "checksum": {"name": "sha256", "checksum": "906a97576bff9f4fead3b0ed4632aa8a04b94f523e62b0e05425770213f78ea5"}, "tags": [], "refs": [["stg_zendesk__ticket_form_history"]], "sources": [], "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "compiled_path": "target/compiled/zendesk/models/intermediate/int_zendesk__latest_ticket_form.sql", "build_path": null, "deferred": false, "unrendered_config": {"schema": "zendesk_docs", "materialized": "table", "enabled": true}, "created_at": 1647014737.304682, "compiled_sql": "--To disable this model, set the using_ticket_form_history variable within your dbt_project.yml file to False.\n\n\nwith ticket_form_history as (\n  select *\n  from `bq-project`.`dbt_joe_zendesk_docs`.`stg_zendesk__ticket_form_history`\n),\n\nlatest_ticket_form as (\n    select\n      *,\n      row_number() over(partition by ticket_form_id order by updated_at desc) as latest_form_index\n    from ticket_form_history\n),\n\nfinal as (\n    select \n        ticket_form_id,\n        created_at,\n        updated_at,\n        display_name,\n        is_active,\n        name,\n        latest_form_index\n    from latest_ticket_form\n\n    where latest_form_index = 1\n)\n\nselect *\nfrom final", "extra_ctes_injected": true, "extra_ctes": [], "relation_name": "`bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__latest_ticket_form`"}, "model.zendesk.int_zendesk__ticket_aggregates": {"raw_sql": "with tickets as (\n  select *\n  from {{ ref('stg_zendesk__ticket') }}\n\n), ticket_tags as (\n\n  select *\n  from {{ ref('stg_zendesk__ticket_tag') }}\n\n), brands as (\n\n  select *\n  from {{ ref('stg_zendesk__brand') }}\n  \n), ticket_tag_aggregate as (\n  select\n    ticket_tags.ticket_id,\n    {{ fivetran_utils.string_agg( 'ticket_tags.tags', \"', '\" )}} as ticket_tags\n  from ticket_tags\n  group by 1\n\n), final as (\n  select \n    tickets.*,\n    case when lower(tickets.type) = 'incident'\n      then true\n      else false\n        end as is_incident,\n    brands.name as ticket_brand_name,\n    ticket_tag_aggregate.ticket_tags\n  from tickets\n\n  left join ticket_tag_aggregate\n    using(ticket_id)\n\n  left join brands\n    on brands.brand_id = tickets.brand_id\n)\n\nselect *\nfrom final", "compiled": true, "resource_type": "model", "depends_on": {"macros": ["macro.fivetran_utils.string_agg"], "nodes": ["model.zendesk_source.stg_zendesk__ticket", "model.zendesk_source.stg_zendesk__ticket_tag", "model.zendesk_source.stg_zendesk__brand"]}, "config": {"enabled": true, "alias": null, "schema": "zendesk_docs", "database": null, "tags": [], "meta": {}, "materialized": "table", "persist_docs": {}, "quoting": {}, "column_types": {}, "full_refresh": null, "on_schema_change": "ignore", "post-hook": [], "pre-hook": []}, "database": "bq-project", "schema": "dbt_joe_zendesk_docs", "fqn": ["zendesk", "intermediate", "int_zendesk__ticket_aggregates"], "unique_id": "model.zendesk.int_zendesk__ticket_aggregates", "package_name": "zendesk", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/zendesk", "path": "intermediate/int_zendesk__ticket_aggregates.sql", "original_file_path": "models/intermediate/int_zendesk__ticket_aggregates.sql", "name": "int_zendesk__ticket_aggregates", "alias": "int_zendesk__ticket_aggregates", "checksum": {"name": "sha256", "checksum": "cef0c080fae7a2b361b077473aa1ccfd4bfa472469b9006038aa3866a5bf8b50"}, "tags": [], "refs": [["stg_zendesk__ticket"], ["stg_zendesk__ticket_tag"], ["stg_zendesk__brand"]], "sources": [], "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "compiled_path": "target/compiled/zendesk/models/intermediate/int_zendesk__ticket_aggregates.sql", "build_path": null, "deferred": false, "unrendered_config": {"schema": "zendesk_docs", "materialized": "table"}, "created_at": 1647014737.309983, "compiled_sql": "with tickets as (\n  select *\n  from `bq-project`.`dbt_joe_zendesk_docs`.`stg_zendesk__ticket`\n\n), ticket_tags as (\n\n  select *\n  from `bq-project`.`dbt_joe_zendesk_docs`.`stg_zendesk__ticket_tag`\n\n), brands as (\n\n  select *\n  from `bq-project`.`dbt_joe_zendesk_docs`.`stg_zendesk__brand`\n  \n), ticket_tag_aggregate as (\n  select\n    ticket_tags.ticket_id,\n    \n    string_agg(ticket_tags.tags, ', ')\n\n as ticket_tags\n  from ticket_tags\n  group by 1\n\n), final as (\n  select \n    tickets.*,\n    case when lower(tickets.type) = 'incident'\n      then true\n      else false\n        end as is_incident,\n    brands.name as ticket_brand_name,\n    ticket_tag_aggregate.ticket_tags\n  from tickets\n\n  left join ticket_tag_aggregate\n    using(ticket_id)\n\n  left join brands\n    on brands.brand_id = tickets.brand_id\n)\n\nselect *\nfrom final", "extra_ctes_injected": true, "extra_ctes": [], "relation_name": "`bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__ticket_aggregates`"}, "model.zendesk.int_zendesk__organization_aggregates": {"raw_sql": "with organizations as (\n    select * \n    from {{ ref('stg_zendesk__organization') }}\n\n--If you use organization tags this will be included, if not it will be ignored.\n{% if var('using_organization_tags', True) %}\n), organization_tags as (\n    select * \n    from {{ ref('stg_zendesk__organization_tag') }}\n\n), tag_aggregates as (\n    select\n        organizations.organization_id,\n        {{ fivetran_utils.string_agg('organization_tags.tags', \"', '\" ) }} as organization_tags\n    from organizations\n\n    left join organization_tags\n        using (organization_id)\n\n    group by 1\n{% endif %}\n\n--If you use using_domain_names tags this will be included, if not it will be ignored.\n{% if var('using_domain_names', True) %}\n), domain_names as (\n\n    select *\n    from {{ ref('stg_zendesk__domain_name') }}\n\n), domain_aggregates as (\n    select\n        organizations.organization_id,\n        {{ fivetran_utils.string_agg('domain_names.domain_name', \"', '\" ) }} as domain_names\n    from organizations\n\n    left join domain_names\n        using(organization_id)\n    \n    group by 1\n{% endif %}\n\n\n), final as (\n    select\n        organizations.*\n\n        --If you use organization tags this will be included, if not it will be ignored.\n        {% if var('using_organization_tags', True) %}\n        ,tag_aggregates.organization_tags\n        {% endif %}\n\n        --If you use using_domain_names tags this will be included, if not it will be ignored.\n        {% if var('using_domain_names', True) %}\n        ,domain_aggregates.domain_names\n        {% endif %}\n\n    from organizations\n\n    --If you use using_domain_names tags this will be included, if not it will be ignored.\n    {% if var('using_domain_names', True) %}\n    left join domain_aggregates\n        using(organization_id)\n    {% endif %}\n\n    --If you use organization tags this will be included, if not it will be ignored.\n    {% if var('using_organization_tags', True) %}\n    left join tag_aggregates\n        using(organization_id)\n    {% endif %}\n)\n\nselect *\nfrom final", "compiled": true, "resource_type": "model", "depends_on": {"macros": [], "nodes": ["model.zendesk_source.stg_zendesk__organization"]}, "config": {"enabled": true, "alias": null, "schema": "zendesk_docs", "database": null, "tags": [], "meta": {}, "materialized": "table", "persist_docs": {}, "quoting": {}, "column_types": {}, "full_refresh": null, "on_schema_change": "ignore", "post-hook": [], "pre-hook": []}, "database": "bq-project", "schema": "dbt_joe_zendesk_docs", "fqn": ["zendesk", "intermediate", "int_zendesk__organization_aggregates"], "unique_id": "model.zendesk.int_zendesk__organization_aggregates", "package_name": "zendesk", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/zendesk", "path": "intermediate/int_zendesk__organization_aggregates.sql", "original_file_path": "models/intermediate/int_zendesk__organization_aggregates.sql", "name": "int_zendesk__organization_aggregates", "alias": "int_zendesk__organization_aggregates", "checksum": {"name": "sha256", "checksum": "a16300f45d2cb0bd1c26dfec62e967a047095b92f340974bfef56178bfff6cf9"}, "tags": [], "refs": [["stg_zendesk__organization"]], "sources": [], "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "compiled_path": "target/compiled/zendesk/models/intermediate/int_zendesk__organization_aggregates.sql", "build_path": null, "deferred": false, "unrendered_config": {"schema": "zendesk_docs", "materialized": "table"}, "created_at": 1647014737.317665, "compiled_sql": "with organizations as (\n    select * \n    from `bq-project`.`dbt_joe_zendesk_docs`.`stg_zendesk__organization`\n\n--If you use organization tags this will be included, if not it will be ignored.\n\n\n--If you use using_domain_names tags this will be included, if not it will be ignored.\n\n\n\n), final as (\n    select\n        organizations.*\n\n        --If you use organization tags this will be included, if not it will be ignored.\n        \n\n        --If you use using_domain_names tags this will be included, if not it will be ignored.\n        \n\n    from organizations\n\n    --If you use using_domain_names tags this will be included, if not it will be ignored.\n    \n\n    --If you use organization tags this will be included, if not it will be ignored.\n    \n)\n\nselect *\nfrom final", "extra_ctes_injected": true, "extra_ctes": [], "relation_name": "`bq-project`.`dbt_joe_zendesk_docs`.`int_zendesk__organization_aggregates`"}, "operation.zendesk.zendesk-on-run-start-0": {"raw_sql": "{{ fivetran_utils.empty_variable_warning(\"ticket_field_history_columns\", \"zendesk_ticket_field_history\") }}", "compiled": true, "resource_type": "operation", "depends_on": {"macros": ["macro.fivetran_utils.empty_variable_warning"], "nodes": []}, "config": {"enabled": true, "alias": null, "schema": "zendesk_docs", "database": null, "tags": [], "meta": {}, "materialized": "table", "persist_docs": {}, "quoting": {}, "column_types": {}, "full_refresh": null, "on_schema_change": "ignore", "post-hook": [], "pre-hook": []}, "database": "bq-project", "schema": "dbt_joe_zendesk_docs", "fqn": ["zendesk", "hooks", "zendesk-on-run-start-0"], "unique_id": "operation.zendesk.zendesk-on-run-start-0", "package_name": "zendesk", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/zendesk", "path": "hooks/zendesk-on-run-start-0.sql", "original_file_path": "./dbt_project.yml", "name": "zendesk-on-run-start-0", "alias": "zendesk-on-run-start-0", "checksum": {"name": "sha256", "checksum": "059e1edb65397b8635ce88a6c4c8066f7b137f34eeed2127d12dcf3d4e061614"}, "tags": ["on-run-start"], "refs": [], "sources": [], "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "compiled_path": "target/compiled/zendesk/./dbt_project.yml/hooks/zendesk-on-run-start-0.sql", "build_path": null, "deferred": false, "unrendered_config": {"schema": "zendesk_docs", "materialized": "table"}, "created_at": 1647014737.336638, "compiled_sql": "\n\n\n\n", "extra_ctes_injected": true, "extra_ctes": [], "relation_name": null, "index": 0}, "model.zendesk_source.stg_zendesk__ticket_tag": {"raw_sql": "with base as (\n\n    select * \n    from {{ ref('stg_zendesk__ticket_tag_tmp') }}\n\n),\n\nfields as (\n\n    select\n        /*\n        The below macro is used to generate the correct SQL for package staging models. It takes a list of columns \n        that are expected/needed (staging_columns from dbt_zendesk_source/models/tmp/) and compares it with columns \n        in the source (source_columns from dbt_zendesk_source/macros/).\n        For more information refer to our dbt_fivetran_utils documentation (https://github.com/fivetran/dbt_fivetran_utils.git).\n        */\n        {{\n            fivetran_utils.fill_staging_columns(\n                source_columns=adapter.get_columns_in_relation(ref('stg_zendesk__ticket_tag_tmp')),\n                staging_columns=get_ticket_tag_columns()\n            )\n        }}\n        \n    from base\n),\n\nfinal as (\n    \n    select \n        ticket_id,\n        {% if target.type == 'redshift' %}\n        \"tag\" as tags\n        {% else %}\n        tag as tags\n        {% endif %}\n    from fields\n)\n\nselect * \nfrom final", "compiled": true, "resource_type": "model", "depends_on": {"macros": ["macro.zendesk_source.get_ticket_tag_columns", "macro.fivetran_utils.fill_staging_columns"], "nodes": ["model.zendesk_source.stg_zendesk__ticket_tag_tmp", "model.zendesk_source.stg_zendesk__ticket_tag_tmp"]}, "config": {"enabled": true, "alias": null, "schema": "zendesk_docs", "database": null, "tags": [], "meta": {}, "materialized": "table", "persist_docs": {}, "quoting": {}, "column_types": {}, "full_refresh": null, "on_schema_change": "ignore", "post-hook": [], "pre-hook": []}, "database": "bq-project", "schema": "dbt_joe_zendesk_docs", "fqn": ["zendesk_source", "stg_zendesk__ticket_tag"], "unique_id": "model.zendesk_source.stg_zendesk__ticket_tag", "package_name": "zendesk_source", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/zendesk_source", "path": "stg_zendesk__ticket_tag.sql", "original_file_path": "models/stg_zendesk__ticket_tag.sql", "name": "stg_zendesk__ticket_tag", "alias": "stg_zendesk__ticket_tag", "checksum": {"name": "sha256", "checksum": "3428fceccfd804f2317fe4404a74ea365549910b484a567ccf5c10556597037a"}, "tags": [], "refs": [["stg_zendesk__ticket_tag_tmp"], ["stg_zendesk__ticket_tag_tmp"]], "sources": [], "description": "Tags are words, or combinations of words, you can use to add more context to tickets. The table lists all tags currently associated with a ticket.\n", "columns": {"ticket_id": {"name": "ticket_id", "description": "The ID of the ticket associated with the tag", "meta": {}, "data_type": null, "quote": null, "tags": []}, "tags": {"name": "tags", "description": "The tag, or word(s), associated with the ticket", "meta": {}, "data_type": null, "quote": null, "tags": []}}, "meta": {}, "docs": {"show": true}, "patch_path": "zendesk_source://models/stg_zendesk.yml", "compiled_path": "target/compiled/zendesk_source/models/stg_zendesk__ticket_tag.sql", "build_path": null, "deferred": false, "unrendered_config": {"materialized": "table", "schema": "zendesk_docs"}, "created_at": 1647014737.9691882, "compiled_sql": "with base as (\n\n    select * \n    from `bq-project`.`dbt_joe_zendesk_docs`.`stg_zendesk__ticket_tag_tmp`\n\n),\n\nfields as (\n\n    select\n        /*\n        The below macro is used to generate the correct SQL for package staging models. It takes a list of columns \n        that are expected/needed (staging_columns from dbt_zendesk_source/models/tmp/) and compares it with columns \n        in the source (source_columns from dbt_zendesk_source/macros/).\n        For more information refer to our dbt_fivetran_utils documentation (https://github.com/fivetran/dbt_fivetran_utils.git).\n        */\n        \n    \n    \n    _fivetran_synced\n    \n as \n    \n    _fivetran_synced\n    \n, \n    \n    \n    ticket_id\n    \n as \n    \n    ticket_id\n    \n, \n    \n    \n    tag\n    \n as \n    \n    tag\n    \n\n\n\n        \n    from base\n),\n\nfinal as (\n    \n    select \n        ticket_id,\n        \n        tag as tags\n        \n    from fields\n)\n\nselect * \nfrom final", "extra_ctes_injected": true, "extra_ctes": [], "relation_name": "`bq-project`.`dbt_joe_zendesk_docs`.`stg_zendesk__ticket_tag`"}, "model.zendesk_source.stg_zendesk__ticket_field_history": {"raw_sql": "with base as (\n\n    select * \n    from {{ ref('stg_zendesk__ticket_field_history_tmp') }}\n\n),\n\nfields as (\n\n    select\n        /*\n        The below macro is used to generate the correct SQL for package staging models. It takes a list of columns \n        that are expected/needed (staging_columns from dbt_zendesk_source/models/tmp/) and compares it with columns \n        in the source (source_columns from dbt_zendesk_source/macros/).\n        For more information refer to our dbt_fivetran_utils documentation (https://github.com/fivetran/dbt_fivetran_utils.git).\n        */\n        {{\n            fivetran_utils.fill_staging_columns(\n                source_columns=adapter.get_columns_in_relation(ref('stg_zendesk__ticket_field_history_tmp')),\n                staging_columns=get_ticket_field_history_columns()\n            )\n        }}\n        \n    from base\n),\n\nfinal as (\n    \n    select \n        ticket_id,\n        field_name,\n        {% if target.type == 'redshift' -%}\n            cast(updated as timestamp without time zone) as valid_starting_at,\n            cast(lead(updated) over (partition by ticket_id, field_name order by updated) as timestamp without time zone) as valid_ending_at,\n        {% else -%}\n            updated as valid_starting_at,\n            lead(updated) over (partition by ticket_id, field_name order by updated) as valid_ending_at,\n        {% endif %}\n        value,\n        user_id\n    from fields\n)\n\nselect * \nfrom final", "compiled": true, "resource_type": "model", "depends_on": {"macros": ["macro.zendesk_source.get_ticket_field_history_columns", "macro.fivetran_utils.fill_staging_columns"], "nodes": ["model.zendesk_source.stg_zendesk__ticket_field_history_tmp", "model.zendesk_source.stg_zendesk__ticket_field_history_tmp"]}, "config": {"enabled": true, "alias": null, "schema": "zendesk_docs", "database": null, "tags": [], "meta": {}, "materialized": "table", "persist_docs": {}, "quoting": {}, "column_types": {}, "full_refresh": null, "on_schema_change": "ignore", "post-hook": [], "pre-hook": []}, "database": "bq-project", "schema": "dbt_joe_zendesk_docs", "fqn": ["zendesk_source", "stg_zendesk__ticket_field_history"], "unique_id": "model.zendesk_source.stg_zendesk__ticket_field_history", "package_name": "zendesk_source", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/zendesk_source", "path": "stg_zendesk__ticket_field_history.sql", "original_file_path": "models/stg_zendesk__ticket_field_history.sql", "name": "stg_zendesk__ticket_field_history", "alias": "stg_zendesk__ticket_field_history", "checksum": {"name": "sha256", "checksum": "5433bbc70d70fa389d0f5a6aaac37d1d4dbf83206978764b56e553dbc1339da2"}, "tags": [], "refs": [["stg_zendesk__ticket_field_history_tmp"], ["stg_zendesk__ticket_field_history_tmp"]], "sources": [], "description": "All fields and field values associated with tickets.", "columns": {"ticket_id": {"name": "ticket_id", "description": "The ID of the ticket associated with the field", "meta": {}, "data_type": null, "quote": null, "tags": []}, "field_name": {"name": "field_name", "description": "The name of the ticket field", "meta": {}, "data_type": null, "quote": null, "tags": []}, "valid_starting_at": {"name": "valid_starting_at", "description": "The time the ticket field value became valid", "meta": {}, "data_type": null, "quote": null, "tags": []}, "valid_ending_at": {"name": "valid_ending_at", "description": "The time the ticket field value became invalidated", "meta": {}, "data_type": null, "quote": null, "tags": []}, "value": {"name": "value", "description": "The value of the field", "meta": {}, "data_type": null, "quote": null, "tags": []}, "user_id": {"name": "user_id", "description": "The id of the user who made the update", "meta": {}, "data_type": null, "quote": null, "tags": []}}, "meta": {}, "docs": {"show": true}, "patch_path": "zendesk_source://models/stg_zendesk.yml", "compiled_path": "target/compiled/zendesk_source/models/stg_zendesk__ticket_field_history.sql", "build_path": null, "deferred": false, "unrendered_config": {"materialized": "table", "schema": "zendesk_docs"}, "created_at": 1647014737.97176, "compiled_sql": "with base as (\n\n    select * \n    from `bq-project`.`dbt_joe_zendesk_docs`.`stg_zendesk__ticket_field_history_tmp`\n\n),\n\nfields as (\n\n    select\n        /*\n        The below macro is used to generate the correct SQL for package staging models. It takes a list of columns \n        that are expected/needed (staging_columns from dbt_zendesk_source/models/tmp/) and compares it with columns \n        in the source (source_columns from dbt_zendesk_source/macros/).\n        For more information refer to our dbt_fivetran_utils documentation (https://github.com/fivetran/dbt_fivetran_utils.git).\n        */\n        \n    \n    \n    _fivetran_synced\n    \n as \n    \n    _fivetran_synced\n    \n, \n    \n    \n    field_name\n    \n as \n    \n    field_name\n    \n, \n    \n    \n    ticket_id\n    \n as \n    \n    ticket_id\n    \n, \n    \n    \n    updated\n    \n as \n    \n    updated\n    \n, \n    \n    \n    user_id\n    \n as \n    \n    user_id\n    \n, \n    \n    \n    value\n    \n as \n    \n    value\n    \n\n\n\n        \n    from base\n),\n\nfinal as (\n    \n    select \n        ticket_id,\n        field_name,\n        updated as valid_starting_at,\n            lead(updated) over (partition by ticket_id, field_name order by updated) as valid_ending_at,\n        \n        value,\n        user_id\n    from fields\n)\n\nselect * \nfrom final", "extra_ctes_injected": true, "extra_ctes": [], "relation_name": "`bq-project`.`dbt_joe_zendesk_docs`.`stg_zendesk__ticket_field_history`"}, "model.zendesk_source.stg_zendesk__daylight_time": {"raw_sql": "--To disable this model, set the using_schedules variable within your dbt_project.yml file to False.\n{{ config(enabled=var('using_schedules', True)) }}\n\nwith base as (\n\n    select * \n    from {{ ref('stg_zendesk__daylight_time_tmp') }}\n\n),\n\nfields as (\n\n    select\n        /*\n        The below macro is used to generate the correct SQL for package staging models. It takes a list of columns \n        that are expected/needed (staging_columns from dbt_zendesk_source/models/tmp/) and compares it with columns \n        in the source (source_columns from dbt_zendesk_source/macros/).\n        For more information refer to our dbt_fivetran_utils documentation (https://github.com/fivetran/dbt_fivetran_utils.git).\n        */\n        {{\n            fivetran_utils.fill_staging_columns(\n                source_columns=adapter.get_columns_in_relation(ref('stg_zendesk__daylight_time_tmp')),\n                staging_columns=get_daylight_time_columns()\n            )\n        }}\n        \n    from base\n),\n\nfinal as (\n    \n    select \n        daylight_end_utc,\n        daylight_offset,\n        daylight_start_utc,\n        time_zone,\n        year,\n        daylight_offset * 60 as daylight_offset_minutes\n        \n    from fields\n)\n\nselect * from final", "compiled": true, "resource_type": "model", "depends_on": {"macros": ["macro.zendesk_source.get_daylight_time_columns", "macro.fivetran_utils.fill_staging_columns"], "nodes": ["model.zendesk_source.stg_zendesk__daylight_time_tmp", "model.zendesk_source.stg_zendesk__daylight_time_tmp"]}, "config": {"enabled": true, "alias": null, "schema": "zendesk_docs", "database": null, "tags": [], "meta": {}, "materialized": "table", "persist_docs": {}, "quoting": {}, "column_types": {}, "full_refresh": null, "on_schema_change": "ignore", "post-hook": [], "pre-hook": []}, "database": "bq-project", "schema": "dbt_joe_zendesk_docs", "fqn": ["zendesk_source", "stg_zendesk__daylight_time"], "unique_id": "model.zendesk_source.stg_zendesk__daylight_time", "package_name": "zendesk_source", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/zendesk_source", "path": "stg_zendesk__daylight_time.sql", "original_file_path": "models/stg_zendesk__daylight_time.sql", "name": "stg_zendesk__daylight_time", "alias": "stg_zendesk__daylight_time", "checksum": {"name": "sha256", "checksum": "6c328b1fb108b9d6dfd251f645e46fe47f819ee6a77ca58952de7ab5bba17dc7"}, "tags": [], "refs": [["stg_zendesk__daylight_time_tmp"], ["stg_zendesk__daylight_time_tmp"]], "sources": [], "description": "Appropriate offsets (from UTC) for timezones that engage or have engaged with Daylight Savings at some point since 1970.\n", "columns": {"daylight_end_utc": {"name": "daylight_end_utc", "description": "UTC timestamp of when Daylight Time ended in this year.", "meta": {}, "data_type": null, "quote": null, "tags": []}, "daylight_offset": {"name": "daylight_offset", "description": "Number of **hours** added during Daylight Savings Time.", "meta": {}, "data_type": null, "quote": null, "tags": []}, "daylight_start_utc": {"name": "daylight_start_utc", "description": "UTC timestamp of when Daylight Time began in this year.", "meta": {}, "data_type": null, "quote": null, "tags": []}, "time_zone": {"name": "time_zone", "description": "Name of the timezone.", "meta": {}, "data_type": null, "quote": null, "tags": []}, "year": {"name": "year", "description": "Year in which daylight savings occurred.", "meta": {}, "data_type": null, "quote": null, "tags": []}, "daylight_offset_minutes": {"name": "daylight_offset_minutes", "description": "Number of **minutes** added during Daylight Savings Time.", "meta": {}, "data_type": null, "quote": null, "tags": []}}, "meta": {}, "docs": {"show": true}, "patch_path": "zendesk_source://models/stg_zendesk.yml", "compiled_path": "target/compiled/zendesk_source/models/stg_zendesk__daylight_time.sql", "build_path": null, "deferred": false, "unrendered_config": {"materialized": "table", "schema": "zendesk_docs", "enabled": true}, "created_at": 1647014737.9744399, "compiled_sql": "--To disable this model, set the using_schedules variable within your dbt_project.yml file to False.\n\n\nwith base as (\n\n    select * \n    from `bq-project`.`dbt_joe_zendesk_docs`.`stg_zendesk__daylight_time_tmp`\n\n),\n\nfields as (\n\n    select\n        /*\n        The below macro is used to generate the correct SQL for package staging models. It takes a list of columns \n        that are expected/needed (staging_columns from dbt_zendesk_source/models/tmp/) and compares it with columns \n        in the source (source_columns from dbt_zendesk_source/macros/).\n        For more information refer to our dbt_fivetran_utils documentation (https://github.com/fivetran/dbt_fivetran_utils.git).\n        */\n        \n    \n    \n    _fivetran_synced\n    \n as \n    \n    _fivetran_synced\n    \n, \n    \n    \n    daylight_end_utc\n    \n as \n    \n    daylight_end_utc\n    \n, \n    \n    \n    daylight_offset\n    \n as \n    \n    daylight_offset\n    \n, \n    \n    \n    daylight_start_utc\n    \n as \n    \n    daylight_start_utc\n    \n, \n    \n    \n    time_zone\n    \n as \n    \n    time_zone\n    \n, \n    \n    \n    year\n    \n as \n    \n    year\n    \n\n\n\n        \n    from base\n),\n\nfinal as (\n    \n    select \n        daylight_end_utc,\n        daylight_offset,\n        daylight_start_utc,\n        time_zone,\n        year,\n        daylight_offset * 60 as daylight_offset_minutes\n        \n    from fields\n)\n\nselect * from final", "extra_ctes_injected": true, "extra_ctes": [], "relation_name": "`bq-project`.`dbt_joe_zendesk_docs`.`stg_zendesk__daylight_time`"}, "model.zendesk_source.stg_zendesk__organization": {"raw_sql": "with base as (\n\n    select * \n    from {{ ref('stg_zendesk__organization_tmp') }}\n\n),\n\nfields as (\n\n    select\n        /*\n        The below macro is used to generate the correct SQL for package staging models. It takes a list of columns \n        that are expected/needed (staging_columns from dbt_zendesk_source/models/tmp/) and compares it with columns \n        in the source (source_columns from dbt_zendesk_source/macros/).\n        For more information refer to our dbt_fivetran_utils documentation (https://github.com/fivetran/dbt_fivetran_utils.git).\n        */\n        {{\n            fivetran_utils.fill_staging_columns(\n                source_columns=adapter.get_columns_in_relation(ref('stg_zendesk__organization_tmp')),\n                staging_columns=get_organization_columns()\n            )\n        }}\n        \n    from base\n),\n\nfinal as (\n    \n    select \n        id as organization_id,\n        created_at,\n        updated_at,\n        details,\n        name,\n        external_id\n\n    from fields\n)\n\nselect * \nfrom final", "compiled": true, "resource_type": "model", "depends_on": {"macros": ["macro.zendesk_source.get_organization_columns", "macro.fivetran_utils.fill_staging_columns"], "nodes": ["model.zendesk_source.stg_zendesk__organization_tmp", "model.zendesk_source.stg_zendesk__organization_tmp"]}, "config": {"enabled": true, "alias": null, "schema": "zendesk_docs", "database": null, "tags": [], "meta": {}, "materialized": "table", "persist_docs": {}, "quoting": {}, "column_types": {}, "full_refresh": null, "on_schema_change": "ignore", "post-hook": [], "pre-hook": []}, "database": "bq-project", "schema": "dbt_joe_zendesk_docs", "fqn": ["zendesk_source", "stg_zendesk__organization"], "unique_id": "model.zendesk_source.stg_zendesk__organization", "package_name": "zendesk_source", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/zendesk_source", "path": "stg_zendesk__organization.sql", "original_file_path": "models/stg_zendesk__organization.sql", "name": "stg_zendesk__organization", "alias": "stg_zendesk__organization", "checksum": {"name": "sha256", "checksum": "5527f691054dd7a01158ae65c9c44881a8f0d6eaa1a9124a912f262b6f4f024c"}, "tags": [], "refs": [["stg_zendesk__organization_tmp"], ["stg_zendesk__organization_tmp"]], "sources": [], "description": "Just as agents can be segmented into groups in Zendesk Support, your customers (end-users) can be segmented into  organizations. You can manually assign customers to an organization or automatically assign them to an organization  by their email address domain. Organizations can be used in business rules to route tickets to groups of agents or  to send email notifications.\n", "columns": {"organization_id": {"name": "organization_id", "description": "Automatically assigned when the organization is created", "meta": {}, "data_type": null, "quote": null, "tags": []}, "name": {"name": "name", "description": "A unique name for the organization", "meta": {}, "data_type": null, "quote": null, "tags": []}, "details": {"name": "details", "description": "Any details obout the organization, such as the address", "meta": {}, "data_type": null, "quote": null, "tags": []}}, "meta": {}, "docs": {"show": true}, "patch_path": "zendesk_source://models/stg_zendesk.yml", "compiled_path": "target/compiled/zendesk_source/models/stg_zendesk__organization.sql", "build_path": null, "deferred": false, "unrendered_config": {"materialized": "table", "schema": "zendesk_docs"}, "created_at": 1647014737.952339, "compiled_sql": "with base as (\n\n    select * \n    from `bq-project`.`dbt_joe_zendesk_docs`.`stg_zendesk__organization_tmp`\n\n),\n\nfields as (\n\n    select\n        /*\n        The below macro is used to generate the correct SQL for package staging models. It takes a list of columns \n        that are expected/needed (staging_columns from dbt_zendesk_source/models/tmp/) and compares it with columns \n        in the source (source_columns from dbt_zendesk_source/macros/).\n        For more information refer to our dbt_fivetran_utils documentation (https://github.com/fivetran/dbt_fivetran_utils.git).\n        */\n        \n    \n    \n    _fivetran_synced\n    \n as \n    \n    _fivetran_synced\n    \n, \n    \n    \n    created_at\n    \n as \n    \n    created_at\n    \n, \n    \n    \n    details\n    \n as \n    \n    details\n    \n, \n    \n    \n    external_id\n    \n as \n    \n    external_id\n    \n, \n    \n    \n    group_id\n    \n as \n    \n    group_id\n    \n, \n    \n    \n    id\n    \n as \n    \n    id\n    \n, \n    \n    \n    name\n    \n as \n    \n    name\n    \n, \n    \n    \n    notes\n    \n as \n    \n    notes\n    \n, \n    \n    \n    shared_comments\n    \n as \n    \n    shared_comments\n    \n, \n    \n    \n    shared_tickets\n    \n as \n    \n    shared_tickets\n    \n, \n    \n    \n    updated_at\n    \n as \n    \n    updated_at\n    \n, \n    \n    \n    url\n    \n as \n    \n    url\n    \n\n\n\n        \n    from base\n),\n\nfinal as (\n    \n    select \n        id as organization_id,\n        created_at,\n        updated_at,\n        details,\n        name,\n        external_id\n\n    from fields\n)\n\nselect * \nfrom final", "extra_ctes_injected": true, "extra_ctes": [], "relation_name": "`bq-project`.`dbt_joe_zendesk_docs`.`stg_zendesk__organization`"}, "model.zendesk_source.stg_zendesk__time_zone": {"raw_sql": "--To disable this model, set the using_schedules variable within your dbt_project.yml file to False.\n{{ config(enabled=var('using_schedules', True)) }}\n\nwith base as (\n\n    select * \n    from {{ ref('stg_zendesk__time_zone_tmp') }}\n\n),\n\nfields as (\n\n    select\n        {{\n            fivetran_utils.fill_staging_columns(\n                source_columns=adapter.get_columns_in_relation(ref('stg_zendesk__time_zone_tmp')),\n                staging_columns=get_time_zone_columns()\n            )\n        }}\n        \n    from base\n),\n\nfinal as (\n    \n    select \n        standard_offset,\n        time_zone,\n        -- the standard_offset is a string written as [+/-]HH:MM\n        -- let's convert it to an integer value of minutes\n        cast( {{ dbt_utils.split_part(string_text='standard_offset', delimiter_text=\"':'\", part_number=1) }} as {{ dbt_utils.type_int() }} ) * 60 +\n            (cast( {{ dbt_utils.split_part(string_text='standard_offset', delimiter_text=\"':'\", part_number=2) }} as {{ dbt_utils.type_int() }} ) *\n                (case when standard_offset like '-%' then -1 else 1 end) ) as standard_offset_minutes\n    \n    from fields\n)\n\nselect * from final", "compiled": true, "resource_type": "model", "depends_on": {"macros": ["macro.zendesk_source.get_time_zone_columns", "macro.fivetran_utils.fill_staging_columns", "macro.dbt_utils.split_part", "macro.dbt_utils.type_int"], "nodes": ["model.zendesk_source.stg_zendesk__time_zone_tmp", "model.zendesk_source.stg_zendesk__time_zone_tmp"]}, "config": {"enabled": true, "alias": null, "schema": "zendesk_docs", "database": null, "tags": [], "meta": {}, "materialized": "table", "persist_docs": {}, "quoting": {}, "column_types": {}, "full_refresh": null, "on_schema_change": "ignore", "post-hook": [], "pre-hook": []}, "database": "bq-project", "schema": "dbt_joe_zendesk_docs", "fqn": ["zendesk_source", "stg_zendesk__time_zone"], "unique_id": "model.zendesk_source.stg_zendesk__time_zone", "package_name": "zendesk_source", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/zendesk_source", "path": "stg_zendesk__time_zone.sql", "original_file_path": "models/stg_zendesk__time_zone.sql", "name": "stg_zendesk__time_zone", "alias": "stg_zendesk__time_zone", "checksum": {"name": "sha256", "checksum": "2e7a20dc3b8cea2cdba6cfa1eb0c7a5e183e32ee26754180477d36259d62daf3"}, "tags": [], "refs": [["stg_zendesk__time_zone_tmp"], ["stg_zendesk__time_zone_tmp"]], "sources": [], "description": "Offsets (from UTC) for each timezone.", "columns": {"time_zone": {"name": "time_zone", "description": "Name of the time zone.", "meta": {}, "data_type": null, "quote": null, "tags": []}, "standard_offset": {"name": "standard_offset", "description": "Standard offset of the timezone (non-daylight savings hours). In `+/-hh:mm` format.", "meta": {}, "data_type": null, "quote": null, "tags": []}, "standard_offset_minutes": {"name": "standard_offset_minutes", "description": "Standard offset of the timezone (non-daylight savings hours) in minutes.", "meta": {}, "data_type": null, "quote": null, "tags": []}}, "meta": {}, "docs": {"show": true}, "patch_path": "zendesk_source://models/stg_zendesk.yml", "compiled_path": "target/compiled/zendesk_source/models/stg_zendesk__time_zone.sql", "build_path": null, "deferred": false, "unrendered_config": {"materialized": "table", "schema": "zendesk_docs", "enabled": true}, "created_at": 1647014737.9761658, "compiled_sql": "--To disable this model, set the using_schedules variable within your dbt_project.yml file to False.\n\n\nwith base as (\n\n    select * \n    from `bq-project`.`dbt_joe_zendesk_docs`.`stg_zendesk__time_zone_tmp`\n\n),\n\nfields as (\n\n    select\n        \n    \n    \n    _fivetran_synced\n    \n as \n    \n    _fivetran_synced\n    \n, \n    \n    \n    standard_offset\n    \n as \n    \n    standard_offset\n    \n, \n    \n    \n    time_zone\n    \n as \n    \n    time_zone\n    \n\n\n\n        \n    from base\n),\n\nfinal as (\n    \n    select \n        standard_offset,\n        time_zone,\n        -- the standard_offset is a string written as [+/-]HH:MM\n        -- let's convert it to an integer value of minutes\n        cast( \n\n    split(\n        standard_offset,\n        ':'\n        )[safe_offset(0)]\n\n as \n    int64\n ) * 60 +\n            (cast( \n\n    split(\n        standard_offset,\n        ':'\n        )[safe_offset(1)]\n\n as \n    int64\n ) *\n                (case when standard_offset like '-%' then -1 else 1 end) ) as standard_offset_minutes\n    \n    from fields\n)\n\nselect * from final", "extra_ctes_injected": true, "extra_ctes": [], "relation_name": "`bq-project`.`dbt_joe_zendesk_docs`.`stg_zendesk__time_zone`"}, "model.zendesk_source.stg_zendesk__group": {"raw_sql": "with base as (\n\n    select * \n    from {{ ref('stg_zendesk__group_tmp') }}\n\n),\n\nfields as (\n\n    select\n        /*\n        The below macro is used to generate the correct SQL for package staging models. It takes a list of columns \n        that are expected/needed (staging_columns from dbt_zendesk_source/models/tmp/) and compares it with columns \n        in the source (source_columns from dbt_zendesk_source/macros/).\n        For more information refer to our dbt_fivetran_utils documentation (https://github.com/fivetran/dbt_fivetran_utils.git).\n        */\n        {{\n            fivetran_utils.fill_staging_columns(\n                source_columns=adapter.get_columns_in_relation(ref('stg_zendesk__group_tmp')),\n                staging_columns=get_group_columns()\n            )\n        }}\n        \n    from base\n),\n\nfinal as (\n    \n    select \n        id as group_id,\n        name\n    from fields\n    \n    where not coalesce(_fivetran_deleted, false)\n)\n\nselect * \nfrom final", "compiled": true, "resource_type": "model", "depends_on": {"macros": ["macro.zendesk_source.get_group_columns", "macro.fivetran_utils.fill_staging_columns"], "nodes": ["model.zendesk_source.stg_zendesk__group_tmp", "model.zendesk_source.stg_zendesk__group_tmp"]}, "config": {"enabled": true, "alias": null, "schema": "zendesk_docs", "database": null, "tags": [], "meta": {}, "materialized": "table", "persist_docs": {}, "quoting": {}, "column_types": {}, "full_refresh": null, "on_schema_change": "ignore", "post-hook": [], "pre-hook": []}, "database": "bq-project", "schema": "dbt_joe_zendesk_docs", "fqn": ["zendesk_source", "stg_zendesk__group"], "unique_id": "model.zendesk_source.stg_zendesk__group", "package_name": "zendesk_source", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/zendesk_source", "path": "stg_zendesk__group.sql", "original_file_path": "models/stg_zendesk__group.sql", "name": "stg_zendesk__group", "alias": "stg_zendesk__group", "checksum": {"name": "sha256", "checksum": "a867fd2d0bab21a736d6ae6bc5306a2f800e2d36518eea6c957736821ffcf099"}, "tags": [], "refs": [["stg_zendesk__group_tmp"], ["stg_zendesk__group_tmp"]], "sources": [], "description": "When support requests arrive in Zendesk Support, they can be assigned to a Group. Groups serve as the core element of ticket workflow; support agents are organized into Groups and tickets can be assigned to a Group only, or to an assigned agent within a Group. A ticket can never be assigned to an agent without also being  assigned to a Group.\n", "columns": {"group_id": {"name": "group_id", "description": "Automatically assigned when creating groups", "meta": {}, "data_type": null, "quote": null, "tags": []}, "name": {"name": "name", "description": "The name of the group", "meta": {}, "data_type": null, "quote": null, "tags": []}}, "meta": {}, "docs": {"show": true}, "patch_path": "zendesk_source://models/stg_zendesk.yml", "compiled_path": "target/compiled/zendesk_source/models/stg_zendesk__group.sql", "build_path": null, "deferred": false, "unrendered_config": {"materialized": "table", "schema": "zendesk_docs"}, "created_at": 1647014737.9493601, "compiled_sql": "with base as (\n\n    select * \n    from `bq-project`.`dbt_joe_zendesk_docs`.`stg_zendesk__group_tmp`\n\n),\n\nfields as (\n\n    select\n        /*\n        The below macro is used to generate the correct SQL for package staging models. It takes a list of columns \n        that are expected/needed (staging_columns from dbt_zendesk_source/models/tmp/) and compares it with columns \n        in the source (source_columns from dbt_zendesk_source/macros/).\n        For more information refer to our dbt_fivetran_utils documentation (https://github.com/fivetran/dbt_fivetran_utils.git).\n        */\n        \n    \n    \n    _fivetran_deleted\n    \n as \n    \n    _fivetran_deleted\n    \n, \n    \n    \n    _fivetran_synced\n    \n as \n    \n    _fivetran_synced\n    \n, \n    \n    \n    created_at\n    \n as \n    \n    created_at\n    \n, \n    \n    \n    id\n    \n as \n    \n    id\n    \n, \n    \n    \n    name\n    \n as \n    \n    name\n    \n, \n    \n    \n    updated_at\n    \n as \n    \n    updated_at\n    \n, \n    \n    \n    url\n    \n as \n    \n    url\n    \n\n\n\n        \n    from base\n),\n\nfinal as (\n    \n    select \n        id as group_id,\n        name\n    from fields\n    \n    where not coalesce(_fivetran_deleted, false)\n)\n\nselect * \nfrom final", "extra_ctes_injected": true, "extra_ctes": [], "relation_name": "`bq-project`.`dbt_joe_zendesk_docs`.`stg_zendesk__group`"}, "model.zendesk_source.stg_zendesk__ticket_comment": {"raw_sql": "with base as (\n\n    select * \n    from {{ ref('stg_zendesk__ticket_comment_tmp') }}\n\n),\n\nfields as (\n\n    select\n        /*\n        The below macro is used to generate the correct SQL for package staging models. It takes a list of columns \n        that are expected/needed (staging_columns from dbt_zendesk_source/models/tmp/) and compares it with columns \n        in the source (source_columns from dbt_zendesk_source/macros/).\n        For more information refer to our dbt_fivetran_utils documentation (https://github.com/fivetran/dbt_fivetran_utils.git).\n        */\n        {{\n            fivetran_utils.fill_staging_columns(\n                source_columns=adapter.get_columns_in_relation(ref('stg_zendesk__ticket_comment_tmp')),\n                staging_columns=get_ticket_comment_columns()\n            )\n        }}\n        \n    from base\n),\n\nfinal as (\n    \n    select \n        id as ticket_comment_id,\n        _fivetran_synced,\n        body,\n        {% if target.type == 'redshift' -%}\n            cast(created as timestamp without time zone) as created_at,\n        {% else -%}\n            created as created_at,\n        {% endif %}\n        public as is_public,\n        ticket_id,\n        user_id,\n        facebook_comment as is_facebook_comment,\n        tweet as is_tweet,\n        voice_comment as is_voice_comment\n    from fields\n)\n\nselect * \nfrom final", "compiled": true, "resource_type": "model", "depends_on": {"macros": ["macro.zendesk_source.get_ticket_comment_columns", "macro.fivetran_utils.fill_staging_columns"], "nodes": ["model.zendesk_source.stg_zendesk__ticket_comment_tmp", "model.zendesk_source.stg_zendesk__ticket_comment_tmp"]}, "config": {"enabled": true, "alias": null, "schema": "zendesk_docs", "database": null, "tags": [], "meta": {}, "materialized": "table", "persist_docs": {}, "quoting": {}, "column_types": {}, "full_refresh": null, "on_schema_change": "ignore", "post-hook": [], "pre-hook": []}, "database": "bq-project", "schema": "dbt_joe_zendesk_docs", "fqn": ["zendesk_source", "stg_zendesk__ticket_comment"], "unique_id": "model.zendesk_source.stg_zendesk__ticket_comment", "package_name": "zendesk_source", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/zendesk_source", "path": "stg_zendesk__ticket_comment.sql", "original_file_path": "models/stg_zendesk__ticket_comment.sql", "name": "stg_zendesk__ticket_comment", "alias": "stg_zendesk__ticket_comment", "checksum": {"name": "sha256", "checksum": "6f8f819c12033476ea5cabae04a88f36b51cfe956b8b514ff1e8216ee22553fe"}, "tags": [], "refs": [["stg_zendesk__ticket_comment_tmp"], ["stg_zendesk__ticket_comment_tmp"]], "sources": [], "description": "Ticket comments represent the conversation between requesters, collaborators, and agents. Comments can be public or private.", "columns": {"ticket_comment_id": {"name": "ticket_comment_id", "description": "Automatically assigned when the comment is created", "meta": {}, "data_type": null, "quote": null, "tags": []}, "body": {"name": "body", "description": "The comment string", "meta": {}, "data_type": null, "quote": null, "tags": []}, "created_at": {"name": "created_at", "description": "The time the comment was created", "meta": {}, "data_type": null, "quote": null, "tags": []}, "is_public": {"name": "is_public", "description": "Boolean field indicating if the comment is public (true), or if it is an internal note (false)", "meta": {}, "data_type": null, "quote": null, "tags": []}, "ticket_id": {"name": "ticket_id", "description": "The ticket id associated with this comment", "meta": {}, "data_type": null, "quote": null, "tags": []}, "user_id": {"name": "user_id", "description": "The id of the comment author", "meta": {}, "data_type": null, "quote": null, "tags": []}, "is_facebook_comment": {"name": "is_facebook_comment", "description": "Boolean field indicating if the comment is a facebook comment", "meta": {}, "data_type": null, "quote": null, "tags": []}, "is_tweet": {"name": "is_tweet", "description": "Boolean field indicating if the comment is a twitter tweet", "meta": {}, "data_type": null, "quote": null, "tags": []}, "is_voice_comment": {"name": "is_voice_comment", "description": "Boolean field indicating if the comment is a voice comment", "meta": {}, "data_type": null, "quote": null, "tags": []}}, "meta": {}, "docs": {"show": true}, "patch_path": "zendesk_source://models/stg_zendesk.yml", "compiled_path": "target/compiled/zendesk_source/models/stg_zendesk__ticket_comment.sql", "build_path": null, "deferred": false, "unrendered_config": {"materialized": "table", "schema": "zendesk_docs"}, "created_at": 1647014737.956094, "compiled_sql": "with base as (\n\n    select * \n    from `bq-project`.`dbt_joe_zendesk_docs`.`stg_zendesk__ticket_comment_tmp`\n\n),\n\nfields as (\n\n    select\n        /*\n        The below macro is used to generate the correct SQL for package staging models. It takes a list of columns \n        that are expected/needed (staging_columns from dbt_zendesk_source/models/tmp/) and compares it with columns \n        in the source (source_columns from dbt_zendesk_source/macros/).\n        For more information refer to our dbt_fivetran_utils documentation (https://github.com/fivetran/dbt_fivetran_utils.git).\n        */\n        \n    \n    \n    _fivetran_synced\n    \n as \n    \n    _fivetran_synced\n    \n, \n    \n    \n    body\n    \n as \n    \n    body\n    \n, \n    \n    \n    call_duration\n    \n as \n    \n    call_duration\n    \n, \n    \n    \n    call_id\n    \n as \n    \n    call_id\n    \n, \n    \n    \n    created\n    \n as \n    \n    created\n    \n, \n    \n    \n    facebook_comment\n    \n as \n    \n    facebook_comment\n    \n, \n    \n    \n    id\n    \n as \n    \n    id\n    \n, \n    \n    \n    location\n    \n as \n    \n    location\n    \n, \n    \n    \n    public\n    \n as \n    \n    public\n    \n, \n    \n    \n    recording_url\n    \n as \n    \n    recording_url\n    \n, \n    \n    \n    started_at\n    \n as \n    \n    started_at\n    \n, \n    \n    \n    ticket_id\n    \n as \n    \n    ticket_id\n    \n, \n    \n    \n    transcription_status\n    \n as \n    \n    transcription_status\n    \n, \n    \n    \n    transcription_text\n    \n as \n    \n    transcription_text\n    \n, \n    \n    \n    trusted\n    \n as \n    \n    trusted\n    \n, \n    \n    \n    tweet\n    \n as \n    \n    tweet\n    \n, \n    \n    \n    user_id\n    \n as \n    \n    user_id\n    \n, \n    \n    \n    voice_comment\n    \n as \n    \n    voice_comment\n    \n, \n    \n    \n    voice_comment_transcription_visible\n    \n as \n    \n    voice_comment_transcription_visible\n    \n\n\n\n        \n    from base\n),\n\nfinal as (\n    \n    select \n        id as ticket_comment_id,\n        _fivetran_synced,\n        body,\n        created as created_at,\n        \n        public as is_public,\n        ticket_id,\n        user_id,\n        facebook_comment as is_facebook_comment,\n        tweet as is_tweet,\n        voice_comment as is_voice_comment\n    from fields\n)\n\nselect * \nfrom final", "extra_ctes_injected": true, "extra_ctes": [], "relation_name": "`bq-project`.`dbt_joe_zendesk_docs`.`stg_zendesk__ticket_comment`"}, "model.zendesk_source.stg_zendesk__ticket_schedule": {"raw_sql": "--To disable this model, set the using_schedules variable within your dbt_project.yml file to False.\n{{ config(enabled=var('using_schedules', True)) }}\n\nwith base as (\n\n    select * \n    from {{ ref('stg_zendesk__ticket_schedule_tmp') }}\n\n),\n\nfields as (\n\n    select\n        /*\n        The below macro is used to generate the correct SQL for package staging models. It takes a list of columns \n        that are expected/needed (staging_columns from dbt_zendesk_source/models/tmp/) and compares it with columns \n        in the source (source_columns from dbt_zendesk_source/macros/).\n        For more information refer to our dbt_fivetran_utils documentation (https://github.com/fivetran/dbt_fivetran_utils.git).\n        */\n        {{\n            fivetran_utils.fill_staging_columns(\n                source_columns=adapter.get_columns_in_relation(ref('stg_zendesk__ticket_schedule_tmp')),\n                staging_columns=get_ticket_schedule_columns()\n            )\n        }}\n        \n    from base\n),\n\nfinal as (\n    \n    select \n        ticket_id,\n        {% if target.type == 'redshift' -%}\n            cast(created_at as timestamp without time zone) as created_at,\n        {% else -%}\n            created_at,\n        {% endif %}\n        cast(schedule_id as {{ dbt_utils.type_string() }}) as schedule_id --need to convert from numeric to string for downstream models to work properly\n    from fields\n)\n\nselect * \nfrom final", "compiled": true, "resource_type": "model", "depends_on": {"macros": ["macro.zendesk_source.get_ticket_schedule_columns", "macro.fivetran_utils.fill_staging_columns", "macro.dbt_utils.type_string"], "nodes": ["model.zendesk_source.stg_zendesk__ticket_schedule_tmp", "model.zendesk_source.stg_zendesk__ticket_schedule_tmp"]}, "config": {"enabled": true, "alias": null, "schema": "zendesk_docs", "database": null, "tags": [], "meta": {}, "materialized": "table", "persist_docs": {}, "quoting": {}, "column_types": {}, "full_refresh": null, "on_schema_change": "ignore", "post-hook": [], "pre-hook": []}, "database": "bq-project", "schema": "dbt_joe_zendesk_docs", "fqn": ["zendesk_source", "stg_zendesk__ticket_schedule"], "unique_id": "model.zendesk_source.stg_zendesk__ticket_schedule", "package_name": "zendesk_source", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/zendesk_source", "path": "stg_zendesk__ticket_schedule.sql", "original_file_path": "models/stg_zendesk__ticket_schedule.sql", "name": "stg_zendesk__ticket_schedule", "alias": "stg_zendesk__ticket_schedule", "checksum": {"name": "sha256", "checksum": "cf8e0d6b95284bb5582258a186d465281b27d4c6a8a9bf137fa7387c404ae0ce"}, "tags": [], "refs": [["stg_zendesk__ticket_schedule_tmp"], ["stg_zendesk__ticket_schedule_tmp"]], "sources": [], "description": "The schedules applied to tickets through a trigger.", "columns": {"ticket_id": {"name": "ticket_id", "description": "The ID of the ticket assigned to the schedule", "meta": {}, "data_type": null, "quote": null, "tags": []}, "created_at": {"name": "created_at", "description": "The time the schedule was assigned to the ticket", "meta": {}, "data_type": null, "quote": null, "tags": []}, "schedule_id": {"name": "schedule_id", "description": "The ID of the schedule applied to the ticket", "meta": {}, "data_type": null, "quote": null, "tags": []}}, "meta": {}, "docs": {"show": true}, "patch_path": "zendesk_source://models/stg_zendesk.yml", "compiled_path": "target/compiled/zendesk_source/models/stg_zendesk__ticket_schedule.sql", "build_path": null, "deferred": false, "unrendered_config": {"materialized": "table", "schema": "zendesk_docs", "enabled": true}, "created_at": 1647014737.9652631, "compiled_sql": "--To disable this model, set the using_schedules variable within your dbt_project.yml file to False.\n\n\nwith base as (\n\n    select * \n    from `bq-project`.`dbt_joe_zendesk_docs`.`stg_zendesk__ticket_schedule_tmp`\n\n),\n\nfields as (\n\n    select\n        /*\n        The below macro is used to generate the correct SQL for package staging models. It takes a list of columns \n        that are expected/needed (staging_columns from dbt_zendesk_source/models/tmp/) and compares it with columns \n        in the source (source_columns from dbt_zendesk_source/macros/).\n        For more information refer to our dbt_fivetran_utils documentation (https://github.com/fivetran/dbt_fivetran_utils.git).\n        */\n        \n    \n    \n    _fivetran_synced\n    \n as \n    \n    _fivetran_synced\n    \n, \n    \n    \n    created_at\n    \n as \n    \n    created_at\n    \n, \n    \n    \n    schedule_id\n    \n as \n    \n    schedule_id\n    \n, \n    \n    \n    ticket_id\n    \n as \n    \n    ticket_id\n    \n\n\n\n        \n    from base\n),\n\nfinal as (\n    \n    select \n        ticket_id,\n        created_at,\n        \n        cast(schedule_id as \n    string\n) as schedule_id --need to convert from numeric to string for downstream models to work properly\n    from fields\n)\n\nselect * \nfrom final", "extra_ctes_injected": true, "extra_ctes": [], "relation_name": "`bq-project`.`dbt_joe_zendesk_docs`.`stg_zendesk__ticket_schedule`"}, "model.zendesk_source.stg_zendesk__schedule": {"raw_sql": "--To disable this model, set the using_schedules variable within your dbt_project.yml file to False.\n{{ config(enabled=var('using_schedules', True)) }}\n\nwith base as (\n\n    select * \n    from {{ ref('stg_zendesk__schedule_tmp') }}\n\n),\n\nfields as (\n\n    select\n        /*\n        The below macro is used to generate the correct SQL for package staging models. It takes a list of columns \n        that are expected/needed (staging_columns from dbt_zendesk_source/models/tmp/) and compares it with columns \n        in the source (source_columns from dbt_zendesk_source/macros/).\n        For more information refer to our dbt_fivetran_utils documentation (https://github.com/fivetran/dbt_fivetran_utils.git).\n        */\n        {{\n            fivetran_utils.fill_staging_columns(\n                source_columns=adapter.get_columns_in_relation(ref('stg_zendesk__schedule_tmp')),\n                staging_columns=get_schedule_columns()\n            )\n        }}\n        \n    from base\n),\n\nfinal as (\n    \n    select \n        cast(id as {{ dbt_utils.type_string() }}) as schedule_id, --need to convert from numeric to string for downstream models to work properly\n        end_time,\n        start_time,\n        name as schedule_name,\n        created_at,\n        time_zone\n        \n    from fields\n    where not coalesce(_fivetran_deleted, false)\n)\n\nselect * \nfrom final", "compiled": true, "resource_type": "model", "depends_on": {"macros": ["macro.zendesk_source.get_schedule_columns", "macro.fivetran_utils.fill_staging_columns", "macro.dbt_utils.type_string"], "nodes": ["model.zendesk_source.stg_zendesk__schedule_tmp", "model.zendesk_source.stg_zendesk__schedule_tmp"]}, "config": {"enabled": true, "alias": null, "schema": "zendesk_docs", "database": null, "tags": [], "meta": {}, "materialized": "table", "persist_docs": {}, "quoting": {}, "column_types": {}, "full_refresh": null, "on_schema_change": "ignore", "post-hook": [], "pre-hook": []}, "database": "bq-project", "schema": "dbt_joe_zendesk_docs", "fqn": ["zendesk_source", "stg_zendesk__schedule"], "unique_id": "model.zendesk_source.stg_zendesk__schedule", "package_name": "zendesk_source", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/zendesk_source", "path": "stg_zendesk__schedule.sql", "original_file_path": "models/stg_zendesk__schedule.sql", "name": "stg_zendesk__schedule", "alias": "stg_zendesk__schedule", "checksum": {"name": "sha256", "checksum": "72cfc5115af4c865b36d49823ac67097bd356dd1eb921226701d6204093f7ad8"}, "tags": [], "refs": [["stg_zendesk__schedule_tmp"], ["stg_zendesk__schedule_tmp"]], "sources": [], "description": "The support schedules created with different business hours and holidays.", "columns": {"schedule_id": {"name": "schedule_id", "description": "ID automatically assigned to the schedule upon creation", "meta": {}, "data_type": null, "quote": null, "tags": []}, "schedule_name": {"name": "schedule_name", "description": "Name of the schedule", "meta": {}, "data_type": null, "quote": null, "tags": []}, "created_at": {"name": "created_at", "description": "Time the schedule was created", "meta": {}, "data_type": null, "quote": null, "tags": []}, "start_time": {"name": "start_time", "description": "Start time of the schedule, in the schedule's time zone.", "meta": {}, "data_type": null, "quote": null, "tags": []}, "end_time": {"name": "end_time", "description": "End time of the schedule, in the schedule's time zone.", "meta": {}, "data_type": null, "quote": null, "tags": []}, "time_zone": {"name": "time_zone", "description": "Timezone in which the schedule operates.", "meta": {}, "data_type": null, "quote": null, "tags": []}}, "meta": {}, "docs": {"show": true}, "patch_path": "zendesk_source://models/stg_zendesk.yml", "compiled_path": "target/compiled/zendesk_source/models/stg_zendesk__schedule.sql", "build_path": null, "deferred": false, "unrendered_config": {"materialized": "table", "schema": "zendesk_docs", "enabled": true}, "created_at": 1647014737.963783, "compiled_sql": "--To disable this model, set the using_schedules variable within your dbt_project.yml file to False.\n\n\nwith base as (\n\n    select * \n    from `bq-project`.`dbt_joe_zendesk_docs`.`stg_zendesk__schedule_tmp`\n\n),\n\nfields as (\n\n    select\n        /*\n        The below macro is used to generate the correct SQL for package staging models. It takes a list of columns \n        that are expected/needed (staging_columns from dbt_zendesk_source/models/tmp/) and compares it with columns \n        in the source (source_columns from dbt_zendesk_source/macros/).\n        For more information refer to our dbt_fivetran_utils documentation (https://github.com/fivetran/dbt_fivetran_utils.git).\n        */\n        \n    \n    \n    _fivetran_deleted\n    \n as \n    \n    _fivetran_deleted\n    \n, \n    \n    \n    _fivetran_synced\n    \n as \n    \n    _fivetran_synced\n    \n, \n    \n    \n    created_at\n    \n as \n    \n    created_at\n    \n, \n    \n    \n    end_time\n    \n as \n    \n    end_time\n    \n, \n    \n    \n    end_time_utc\n    \n as \n    \n    end_time_utc\n    \n, \n    \n    \n    id\n    \n as \n    \n    id\n    \n, \n    \n    \n    name\n    \n as \n    \n    name\n    \n, \n    \n    \n    start_time\n    \n as \n    \n    start_time\n    \n, \n    \n    \n    start_time_utc\n    \n as \n    \n    start_time_utc\n    \n, \n    \n    \n    time_zone\n    \n as \n    \n    time_zone\n    \n\n\n\n        \n    from base\n),\n\nfinal as (\n    \n    select \n        cast(id as \n    string\n) as schedule_id, --need to convert from numeric to string for downstream models to work properly\n        end_time,\n        start_time,\n        name as schedule_name,\n        created_at,\n        time_zone\n        \n    from fields\n    where not coalesce(_fivetran_deleted, false)\n)\n\nselect * \nfrom final", "extra_ctes_injected": true, "extra_ctes": [], "relation_name": "`bq-project`.`dbt_joe_zendesk_docs`.`stg_zendesk__schedule`"}, "model.zendesk_source.stg_zendesk__user": {"raw_sql": "with base as (\n\n    select * \n    from {{ ref('stg_zendesk__user_tmp') }}\n\n),\n\nfields as (\n\n    select\n        /*\n        The below macro is used to generate the correct SQL for package staging models. It takes a list of columns \n        that are expected/needed (staging_columns from dbt_zendesk_source/models/tmp/) and compares it with columns \n        in the source (source_columns from dbt_zendesk_source/macros/).\n        For more information refer to our dbt_fivetran_utils documentation (https://github.com/fivetran/dbt_fivetran_utils.git).\n        */\n        {{\n            fivetran_utils.fill_staging_columns(\n                source_columns=adapter.get_columns_in_relation(ref('stg_zendesk__user_tmp')),\n                staging_columns=get_user_columns()\n            )\n        }}\n        \n    from base\n),\n\nfinal as ( \n    \n    select \n        id as user_id,\n        external_id,\n        _fivetran_synced,\n        {% if target.type == 'redshift' -%}\n            cast(last_login_at as timestamp without time zone) as last_login_at,\n            cast(created_at as timestamp without time zone) as created_at,\n            cast(updated_at as timestamp without time zone) as updated_at,\n        {% else -%}\n            last_login_at,\n            created_at,\n            updated_at,\n        {% endif %}\n        email,\n        name,\n        organization_id,\n        role,\n        ticket_restriction,\n        time_zone,\n        locale,\n        active as is_active,\n        suspended as is_suspended\n    from fields\n)\n\nselect * \nfrom final", "compiled": true, "resource_type": "model", "depends_on": {"macros": ["macro.zendesk_source.get_user_columns", "macro.fivetran_utils.fill_staging_columns"], "nodes": ["model.zendesk_source.stg_zendesk__user_tmp", "model.zendesk_source.stg_zendesk__user_tmp"]}, "config": {"enabled": true, "alias": null, "schema": "zendesk_docs", "database": null, "tags": [], "meta": {}, "materialized": "table", "persist_docs": {}, "quoting": {}, "column_types": {}, "full_refresh": null, "on_schema_change": "ignore", "post-hook": [], "pre-hook": []}, "database": "bq-project", "schema": "dbt_joe_zendesk_docs", "fqn": ["zendesk_source", "stg_zendesk__user"], "unique_id": "model.zendesk_source.stg_zendesk__user", "package_name": "zendesk_source", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/zendesk_source", "path": "stg_zendesk__user.sql", "original_file_path": "models/stg_zendesk__user.sql", "name": "stg_zendesk__user", "alias": "stg_zendesk__user", "checksum": {"name": "sha256", "checksum": "c48fd4bfa305a6b298d08f8295598572f29e533de8d82b9382f39c03c3dc9c6e"}, "tags": [], "refs": [["stg_zendesk__user_tmp"], ["stg_zendesk__user_tmp"]], "sources": [], "description": "Zendesk has three types of users, end-users (your customers), agents, and administrators.", "columns": {"user_id": {"name": "user_id", "description": "Automatically assigned when the user is created", "meta": {}, "data_type": null, "quote": null, "tags": []}, "email": {"name": "email", "description": "The user's primary email address. *Writeable on create only. On update, a secondary email is added. See Email Address", "meta": {}, "data_type": null, "quote": null, "tags": []}, "name": {"name": "name", "description": "The user's name", "meta": {}, "data_type": null, "quote": null, "tags": []}, "is_active": {"name": "is_active", "description": "false if the user has been deleted", "meta": {}, "data_type": null, "quote": null, "tags": []}, "created_at": {"name": "created_at", "description": "The time the user was created", "meta": {}, "data_type": null, "quote": null, "tags": []}, "organization_id": {"name": "organization_id", "description": "The id of the user's organization. If the user has more than one organization memberships, the id of the user's default organization", "meta": {}, "data_type": null, "quote": null, "tags": []}, "role": {"name": "role", "description": "The user's role. Possible values are \"end-user\", \"agent\", or \"admin\"", "meta": {}, "data_type": null, "quote": null, "tags": []}, "time_zone": {"name": "time_zone", "description": "The user's time zone. See Time Zone", "meta": {}, "data_type": null, "quote": null, "tags": []}, "ticket_restriction": {"name": "ticket_restriction", "description": "Specifies which tickets the user has access to. Possible values are organization, groups, assigned, requested and null", "meta": {}, "data_type": null, "quote": null, "tags": []}}, "meta": {}, "docs": {"show": true}, "patch_path": "zendesk_source://models/stg_zendesk.yml", "compiled_path": "target/compiled/zendesk_source/models/stg_zendesk__user.sql", "build_path": null, "deferred": false, "unrendered_config": {"materialized": "table", "schema": "zendesk_docs"}, "created_at": 1647014737.961314, "compiled_sql": "with base as (\n\n    select * \n    from `bq-project`.`dbt_joe_zendesk_docs`.`stg_zendesk__user_tmp`\n\n),\n\nfields as (\n\n    select\n        /*\n        The below macro is used to generate the correct SQL for package staging models. It takes a list of columns \n        that are expected/needed (staging_columns from dbt_zendesk_source/models/tmp/) and compares it with columns \n        in the source (source_columns from dbt_zendesk_source/macros/).\n        For more information refer to our dbt_fivetran_utils documentation (https://github.com/fivetran/dbt_fivetran_utils.git).\n        */\n        \n    \n    \n    _fivetran_synced\n    \n as \n    \n    _fivetran_synced\n    \n, \n    \n    \n    active\n    \n as \n    \n    active\n    \n, \n    \n    \n    alias\n    \n as \n    \n    alias\n    \n, \n    \n    \n    authenticity_token\n    \n as \n    \n    authenticity_token\n    \n, \n    \n    \n    chat_only\n    \n as \n    \n    chat_only\n    \n, \n    \n    \n    created_at\n    \n as \n    \n    created_at\n    \n, \n    \n    \n    details\n    \n as \n    \n    details\n    \n, \n    \n    \n    email\n    \n as \n    \n    email\n    \n, \n    \n    \n    external_id\n    \n as \n    \n    external_id\n    \n, \n    \n    \n    id\n    \n as \n    \n    id\n    \n, \n    \n    \n    last_login_at\n    \n as \n    \n    last_login_at\n    \n, \n    \n    \n    locale\n    \n as \n    \n    locale\n    \n, \n    \n    \n    locale_id\n    \n as \n    \n    locale_id\n    \n, \n    \n    \n    moderator\n    \n as \n    \n    moderator\n    \n, \n    \n    \n    name\n    \n as \n    \n    name\n    \n, \n    \n    \n    notes\n    \n as \n    \n    notes\n    \n, \n    \n    \n    only_private_comments\n    \n as \n    \n    only_private_comments\n    \n, \n    \n    \n    organization_id\n    \n as \n    \n    organization_id\n    \n, \n    \n    \n    phone\n    \n as \n    \n    phone\n    \n, \n    \n    \n    remote_photo_url\n    \n as \n    \n    remote_photo_url\n    \n, \n    \n    \n    restricted_agent\n    \n as \n    \n    restricted_agent\n    \n, \n    \n    \n    role\n    \n as \n    \n    role\n    \n, \n    \n    \n    shared\n    \n as \n    \n    shared\n    \n, \n    \n    \n    shared_agent\n    \n as \n    \n    shared_agent\n    \n, \n    \n    \n    signature\n    \n as \n    \n    signature\n    \n, \n    \n    \n    suspended\n    \n as \n    \n    suspended\n    \n, \n    \n    \n    ticket_restriction\n    \n as \n    \n    ticket_restriction\n    \n, \n    \n    \n    time_zone\n    \n as \n    \n    time_zone\n    \n, \n    \n    \n    two_factor_auth_enabled\n    \n as \n    \n    two_factor_auth_enabled\n    \n, \n    \n    \n    updated_at\n    \n as \n    \n    updated_at\n    \n, \n    \n    \n    url\n    \n as \n    \n    url\n    \n, \n    \n    \n    verified\n    \n as \n    \n    verified\n    \n\n\n\n        \n    from base\n),\n\nfinal as ( \n    \n    select \n        id as user_id,\n        external_id,\n        _fivetran_synced,\n        last_login_at,\n            created_at,\n            updated_at,\n        \n        email,\n        name,\n        organization_id,\n        role,\n        ticket_restriction,\n        time_zone,\n        locale,\n        active as is_active,\n        suspended as is_suspended\n    from fields\n)\n\nselect * \nfrom final", "extra_ctes_injected": true, "extra_ctes": [], "relation_name": "`bq-project`.`dbt_joe_zendesk_docs`.`stg_zendesk__user`"}, "model.zendesk_source.stg_zendesk__brand": {"raw_sql": "with base as (\n\n    select * \n    from {{ ref('stg_zendesk__brand_tmp') }}\n\n),\n\nfields as (\n\n    select\n        /*\n        The below macro is used to generate the correct SQL for package staging models. It takes a list of columns \n        that are expected/needed (staging_columns from dbt_zendesk_source/models/tmp/) and compares it with columns \n        in the source (source_columns from dbt_zendesk_source/macros/).\n        For more information refer to our dbt_fivetran_utils documentation (https://github.com/fivetran/dbt_fivetran_utils.git).\n        */\n        {{\n            fivetran_utils.fill_staging_columns(\n                source_columns=adapter.get_columns_in_relation(ref('stg_zendesk__brand_tmp')),\n                staging_columns=get_brand_columns()\n            )\n        }}\n        \n    from base\n),\n\nfinal as (\n    \n    select \n        id as brand_id,\n        brand_url,\n        name,\n        subdomain,\n        active as is_active\n    from fields\n    where not coalesce(_fivetran_deleted, false)\n)\n\nselect * \nfrom final", "compiled": true, "resource_type": "model", "depends_on": {"macros": ["macro.zendesk_source.get_brand_columns", "macro.fivetran_utils.fill_staging_columns"], "nodes": ["model.zendesk_source.stg_zendesk__brand_tmp", "model.zendesk_source.stg_zendesk__brand_tmp"]}, "config": {"enabled": true, "alias": null, "schema": "zendesk_docs", "database": null, "tags": [], "meta": {}, "materialized": "table", "persist_docs": {}, "quoting": {}, "column_types": {}, "full_refresh": null, "on_schema_change": "ignore", "post-hook": [], "pre-hook": []}, "database": "bq-project", "schema": "dbt_joe_zendesk_docs", "fqn": ["zendesk_source", "stg_zendesk__brand"], "unique_id": "model.zendesk_source.stg_zendesk__brand", "package_name": "zendesk_source", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/zendesk_source", "path": "stg_zendesk__brand.sql", "original_file_path": "models/stg_zendesk__brand.sql", "name": "stg_zendesk__brand", "alias": "stg_zendesk__brand", "checksum": {"name": "sha256", "checksum": "eaf8b6e645dccfcee1bd72d80f1fd5c14fc86df2c084a843dc221c5ecab20fb0"}, "tags": [], "refs": [["stg_zendesk__brand_tmp"], ["stg_zendesk__brand_tmp"]], "sources": [], "description": "Brands are your customer-facing identities. They might represent multiple products or services, or they  might literally be multiple brands owned and represented by your company.\n", "columns": {"brand_id": {"name": "brand_id", "description": "The ID automatically assigned when the brand is created", "meta": {}, "data_type": null, "quote": null, "tags": []}, "brand_url": {"name": "brand_url", "description": "The url of the brand", "meta": {}, "data_type": null, "quote": null, "tags": []}, "name": {"name": "name", "description": "The name of the brand", "meta": {}, "data_type": null, "quote": null, "tags": []}, "subdomain": {"name": "subdomain", "description": "The subdomain of the brand", "meta": {}, "data_type": null, "quote": null, "tags": []}, "active": {"name": "active", "description": "If the brand is set as active", "meta": {}, "data_type": null, "quote": null, "tags": []}}, "meta": {}, "docs": {"show": true}, "patch_path": "zendesk_source://models/stg_zendesk.yml", "compiled_path": "target/compiled/zendesk_source/models/stg_zendesk__brand.sql", "build_path": null, "deferred": false, "unrendered_config": {"materialized": "table", "schema": "zendesk_docs"}, "created_at": 1647014737.946557, "compiled_sql": "with base as (\n\n    select * \n    from `bq-project`.`dbt_joe_zendesk_docs`.`stg_zendesk__brand_tmp`\n\n),\n\nfields as (\n\n    select\n        /*\n        The below macro is used to generate the correct SQL for package staging models. It takes a list of columns \n        that are expected/needed (staging_columns from dbt_zendesk_source/models/tmp/) and compares it with columns \n        in the source (source_columns from dbt_zendesk_source/macros/).\n        For more information refer to our dbt_fivetran_utils documentation (https://github.com/fivetran/dbt_fivetran_utils.git).\n        */\n        \n    \n    \n    _fivetran_deleted\n    \n as \n    \n    _fivetran_deleted\n    \n, \n    \n    \n    _fivetran_synced\n    \n as \n    \n    _fivetran_synced\n    \n, \n    \n    \n    active\n    \n as \n    \n    active\n    \n, \n    \n    \n    brand_url\n    \n as \n    \n    brand_url\n    \n, \n    \n    \n    has_help_center\n    \n as \n    \n    has_help_center\n    \n, \n    \n    \n    help_center_state\n    \n as \n    \n    help_center_state\n    \n, \n    \n    \n    id\n    \n as \n    \n    id\n    \n, \n    \n    \n    logo_content_type\n    \n as \n    \n    logo_content_type\n    \n, \n    \n    \n    logo_content_url\n    \n as \n    \n    logo_content_url\n    \n, \n    cast(null as boolean) as \n    \n    logo_deleted\n    \n , \n    \n    \n    logo_file_name\n    \n as \n    \n    logo_file_name\n    \n, \n    cast(null as \n    int64\n) as \n    \n    logo_height\n    \n , \n    \n    \n    logo_id\n    \n as \n    \n    logo_id\n    \n, \n    cast(null as boolean) as \n    \n    logo_inline\n    \n , \n    \n    \n    logo_mapped_content_url\n    \n as \n    \n    logo_mapped_content_url\n    \n, \n    \n    \n    logo_size\n    \n as \n    \n    logo_size\n    \n, \n    \n    \n    logo_url\n    \n as \n    \n    logo_url\n    \n, \n    cast(null as \n    int64\n) as \n    \n    logo_width\n    \n , \n    \n    \n    name\n    \n as \n    \n    name\n    \n, \n    \n    \n    subdomain\n    \n as \n    \n    subdomain\n    \n, \n    \n    \n    url\n    \n as \n    \n    url\n    \n\n\n\n        \n    from base\n),\n\nfinal as (\n    \n    select \n        id as brand_id,\n        brand_url,\n        name,\n        subdomain,\n        active as is_active\n    from fields\n    where not coalesce(_fivetran_deleted, false)\n)\n\nselect * \nfrom final", "extra_ctes_injected": true, "extra_ctes": [], "relation_name": "`bq-project`.`dbt_joe_zendesk_docs`.`stg_zendesk__brand`"}, "model.zendesk_source.stg_zendesk__ticket_form_history": {"raw_sql": "--To disable this model, set the using_ticket_form_history variable within your dbt_project.yml file to False.\n{{ config(enabled=var('using_ticket_form_history', True)) }}\n\nwith base as (\n\n    select * \n    from {{ ref('stg_zendesk__ticket_form_history_tmp') }}\n\n),\n\nfields as (\n\n    select\n        /*\n        The below macro is used to generate the correct SQL for package staging models. It takes a list of columns \n        that are expected/needed (staging_columns from dbt_zendesk_source/models/tmp/) and compares it with columns \n        in the source (source_columns from dbt_zendesk_source/macros/).\n        For more information refer to our dbt_fivetran_utils documentation (https://github.com/fivetran/dbt_fivetran_utils.git).\n        */\n        {{\n            fivetran_utils.fill_staging_columns(\n                source_columns=adapter.get_columns_in_relation(ref('stg_zendesk__ticket_form_history_tmp')),\n                staging_columns=get_ticket_form_history_columns()\n            )\n        }}\n        \n    from base\n),\n\nfinal as (\n    \n    select \n        id as ticket_form_id,\n        {% if target.type == 'redshift' -%}\n            cast(created_at as timestamp without time zone) as created_at,\n            cast(updated_at as timestamp without time zone) as updated_at,\n        {% else -%}\n            created_at,\n            updated_at,\n        {% endif %}\n        display_name,\n        active as is_active,\n        name\n    from fields\n    where not coalesce(_fivetran_deleted, false)\n    \n)\n\nselect * \nfrom final", "compiled": true, "resource_type": "model", "depends_on": {"macros": ["macro.zendesk_source.get_ticket_form_history_columns", "macro.fivetran_utils.fill_staging_columns"], "nodes": ["model.zendesk_source.stg_zendesk__ticket_form_history_tmp", "model.zendesk_source.stg_zendesk__ticket_form_history_tmp"]}, "config": {"enabled": true, "alias": null, "schema": "zendesk_docs", "database": null, "tags": [], "meta": {}, "materialized": "table", "persist_docs": {}, "quoting": {}, "column_types": {}, "full_refresh": null, "on_schema_change": "ignore", "post-hook": [], "pre-hook": []}, "database": "bq-project", "schema": "dbt_joe_zendesk_docs", "fqn": ["zendesk_source", "stg_zendesk__ticket_form_history"], "unique_id": "model.zendesk_source.stg_zendesk__ticket_form_history", "package_name": "zendesk_source", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/zendesk_source", "path": "stg_zendesk__ticket_form_history.sql", "original_file_path": "models/stg_zendesk__ticket_form_history.sql", "name": "stg_zendesk__ticket_form_history", "alias": "stg_zendesk__ticket_form_history", "checksum": {"name": "sha256", "checksum": "ccfe41a6c79f1263c5905246c2bf4a0c22af12cb4b2181d297fa4b0dc1d0fb0c"}, "tags": [], "refs": [["stg_zendesk__ticket_form_history_tmp"], ["stg_zendesk__ticket_form_history_tmp"]], "sources": [], "description": "Ticket forms allow an admin to define a subset of ticket fields for display to both agents and end users.", "columns": {"ticket_form_id": {"name": "ticket_form_id", "description": "Automatically assigned when creating ticket form", "meta": {}, "data_type": null, "quote": null, "tags": []}, "created_at": {"name": "created_at", "description": "The time the ticket form was created", "meta": {}, "data_type": null, "quote": null, "tags": []}, "updated_at": {"name": "updated_at", "description": "The time of the last update of the ticket form", "meta": {}, "data_type": null, "quote": null, "tags": []}, "display_name": {"name": "display_name", "description": "The name of the form that is displayed to an end user", "meta": {}, "data_type": null, "quote": null, "tags": []}, "active": {"name": "active", "description": "If the form is set as active", "meta": {}, "data_type": null, "quote": null, "tags": []}, "name": {"name": "name", "description": "The name of the form", "meta": {}, "data_type": null, "quote": null, "tags": []}}, "meta": {}, "docs": {"show": true}, "patch_path": "zendesk_source://models/stg_zendesk.yml", "compiled_path": "target/compiled/zendesk_source/models/stg_zendesk__ticket_form_history.sql", "build_path": null, "deferred": false, "unrendered_config": {"materialized": "table", "schema": "zendesk_docs", "enabled": true}, "created_at": 1647014737.967937, "compiled_sql": "--To disable this model, set the using_ticket_form_history variable within your dbt_project.yml file to False.\n\n\nwith base as (\n\n    select * \n    from `bq-project`.`dbt_joe_zendesk_docs`.`stg_zendesk__ticket_form_history_tmp`\n\n),\n\nfields as (\n\n    select\n        /*\n        The below macro is used to generate the correct SQL for package staging models. It takes a list of columns \n        that are expected/needed (staging_columns from dbt_zendesk_source/models/tmp/) and compares it with columns \n        in the source (source_columns from dbt_zendesk_source/macros/).\n        For more information refer to our dbt_fivetran_utils documentation (https://github.com/fivetran/dbt_fivetran_utils.git).\n        */\n        \n    \n    \n    _fivetran_deleted\n    \n as \n    \n    _fivetran_deleted\n    \n, \n    \n    \n    _fivetran_synced\n    \n as \n    \n    _fivetran_synced\n    \n, \n    \n    \n    active\n    \n as \n    \n    active\n    \n, \n    \n    \n    created_at\n    \n as \n    \n    created_at\n    \n, \n    \n    \n    display_name\n    \n as \n    \n    display_name\n    \n, \n    \n    \n    end_user_visible\n    \n as \n    \n    end_user_visible\n    \n, \n    \n    \n    id\n    \n as \n    \n    id\n    \n, \n    \n    \n    name\n    \n as \n    \n    name\n    \n, \n    \n    \n    updated_at\n    \n as \n    \n    updated_at\n    \n\n\n\n        \n    from base\n),\n\nfinal as (\n    \n    select \n        id as ticket_form_id,\n        created_at,\n            updated_at,\n        \n        display_name,\n        active as is_active,\n        name\n    from fields\n    where not coalesce(_fivetran_deleted, false)\n    \n)\n\nselect * \nfrom final", "extra_ctes_injected": true, "extra_ctes": [], "relation_name": "`bq-project`.`dbt_joe_zendesk_docs`.`stg_zendesk__ticket_form_history`"}, "model.zendesk_source.stg_zendesk__ticket": {"raw_sql": "with base as (\n\n    select * \n    from {{ ref('stg_zendesk__ticket_tmp') }}\n\n),\n\nfields as (\n\n    select\n        /*\n        The below macro is used to generate the correct SQL for package staging models. It takes a list of columns \n        that are expected/needed (staging_columns from dbt_zendesk_source/models/tmp/) and compares it with columns \n        in the source (source_columns from dbt_zendesk_source/macros/).\n        For more information refer to our dbt_fivetran_utils documentation (https://github.com/fivetran/dbt_fivetran_utils.git).\n        */\n        {{\n            fivetran_utils.fill_staging_columns(\n                source_columns=adapter.get_columns_in_relation(ref('stg_zendesk__ticket_tmp')),\n                staging_columns=get_ticket_columns()\n            )\n        }}\n        \n    from base\n),\n\nfinal as (\n    \n    select \n        id as ticket_id,\n        _fivetran_synced,\n        assignee_id,\n        brand_id,\n        {% if target.type == 'redshift' -%}\n            cast(created_at as timestamp without time zone) as created_at,\n            cast(updated_at as timestamp without time zone) as updated_at,\n        {% else -%}\n            created_at,\n            updated_at,\n        {% endif %}\n        description,\n        due_at,\n        group_id,\n        external_id,\n        is_public,\n        organization_id,\n        priority,\n        recipient,\n        requester_id,\n        status,\n        subject,\n        problem_id,\n        submitter_id,\n        ticket_form_id,\n        type,\n        url,\n        via_channel as created_channel,\n        via_source_from_id as source_from_id,\n        via_source_from_title as source_from_title,\n        via_source_rel as source_rel,\n        via_source_to_address as source_to_address,\n        via_source_to_name as source_to_name\n    from fields\n)\n\nselect * \nfrom final", "compiled": true, "resource_type": "model", "depends_on": {"macros": ["macro.zendesk_source.get_ticket_columns", "macro.fivetran_utils.fill_staging_columns"], "nodes": ["model.zendesk_source.stg_zendesk__ticket_tmp", "model.zendesk_source.stg_zendesk__ticket_tmp"]}, "config": {"enabled": true, "alias": null, "schema": "zendesk_docs", "database": null, "tags": [], "meta": {}, "materialized": "table", "persist_docs": {}, "quoting": {}, "column_types": {}, "full_refresh": null, "on_schema_change": "ignore", "post-hook": [], "pre-hook": []}, "database": "bq-project", "schema": "dbt_joe_zendesk_docs", "fqn": ["zendesk_source", "stg_zendesk__ticket"], "unique_id": "model.zendesk_source.stg_zendesk__ticket", "package_name": "zendesk_source", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/zendesk_source", "path": "stg_zendesk__ticket.sql", "original_file_path": "models/stg_zendesk__ticket.sql", "name": "stg_zendesk__ticket", "alias": "stg_zendesk__ticket", "checksum": {"name": "sha256", "checksum": "32baaa2d94b739338ccd39b02b5fa94adecc535c8353e73c040cd7d64c399eb2"}, "tags": [], "refs": [["stg_zendesk__ticket_tmp"], ["stg_zendesk__ticket_tmp"]], "sources": [], "description": "Tickets are the means through which your end users (customers) communicate with agents in Zendesk Support. Tickets can  originate from a number of channels, including email, Help Center, chat, phone call, Twitter, Facebook, or the API.\n", "columns": {"ticket_id": {"name": "ticket_id", "description": "Automatically assigned when the ticket is created", "meta": {}, "data_type": null, "quote": null, "tags": []}, "url": {"name": "url", "description": "The API url of this ticket", "meta": {}, "data_type": null, "quote": null, "tags": []}, "assignee_id": {"name": "assignee_id", "description": "The agent currently assigned to the ticket", "meta": {}, "data_type": null, "quote": null, "tags": []}, "brand_id": {"name": "brand_id", "description": "Enterprise only. The id of the brand this ticket is associated with", "meta": {}, "data_type": null, "quote": null, "tags": []}, "created_at": {"name": "created_at", "description": "When this record was created", "meta": {}, "data_type": null, "quote": null, "tags": []}, "type": {"name": "type", "description": "The type of this ticket, possible values are problem, incident, question or task", "meta": {}, "data_type": null, "quote": null, "tags": []}, "subject": {"name": "subject", "description": "The value of the subject field for this ticket", "meta": {}, "data_type": null, "quote": null, "tags": []}, "description": {"name": "description", "description": "Read-only first comment on the ticket", "meta": {}, "data_type": null, "quote": null, "tags": []}, "priority": {"name": "priority", "description": "The urgency with which the ticket should be addressed, possible values are urgent, high, normal and low", "meta": {}, "data_type": null, "quote": null, "tags": []}, "status": {"name": "status", "description": "The state of the ticket, possible values are new, open, pending, hold, solved and closed", "meta": {}, "data_type": null, "quote": null, "tags": []}, "recipient": {"name": "recipient", "description": "The original recipient e-mail address of the ticket", "meta": {}, "data_type": null, "quote": null, "tags": []}, "requester_id": {"name": "requester_id", "description": "The user who requested this ticket", "meta": {}, "data_type": null, "quote": null, "tags": []}, "submitter_id": {"name": "submitter_id", "description": "The user who submitted the ticket. The submitter always becomes the author of the first comment on the ticket", "meta": {}, "data_type": null, "quote": null, "tags": []}, "organization_id": {"name": "organization_id", "description": "The organization of the requester", "meta": {}, "data_type": null, "quote": null, "tags": []}, "group_id": {"name": "group_id", "description": "The group this ticket is assigned to", "meta": {}, "data_type": null, "quote": null, "tags": []}, "due_at": {"name": "due_at", "description": "If this is a ticket of type \"task\" it has a due date. Due date format uses ISO 8601 format.", "meta": {}, "data_type": null, "quote": null, "tags": []}, "ticket_form_id": {"name": "ticket_form_id", "description": "Enterprise only. The id of the ticket form to render for the ticket", "meta": {}, "data_type": null, "quote": null, "tags": []}, "is_public": {"name": "is_public", "description": "Is true if any comments are public, false otherwise", "meta": {}, "data_type": null, "quote": null, "tags": []}, "updated_at": {"name": "updated_at", "description": "When this record last got updated", "meta": {}, "data_type": null, "quote": null, "tags": []}, "created_channel": {"name": "created_channel", "description": "The channel the ticket was created from", "meta": {}, "data_type": null, "quote": null, "tags": []}, "source_from_id": {"name": "source_from_id", "description": "The channel the ticket was created from", "meta": {}, "data_type": null, "quote": null, "tags": []}, "source_from_title": {"name": "source_from_title", "description": "The channel the ticket was created from", "meta": {}, "data_type": null, "quote": null, "tags": []}, "source_rel": {"name": "source_rel", "description": "The rel the ticket was created from", "meta": {}, "data_type": null, "quote": null, "tags": []}, "source_to_address": {"name": "source_to_address", "description": "The address of the source the ticket was created from", "meta": {}, "data_type": null, "quote": null, "tags": []}, "source_to_name": {"name": "source_to_name", "description": "The name of the source the ticket was created from", "meta": {}, "data_type": null, "quote": null, "tags": []}}, "meta": {}, "docs": {"show": true}, "patch_path": "zendesk_source://models/stg_zendesk.yml", "compiled_path": "target/compiled/zendesk_source/models/stg_zendesk__ticket.sql", "build_path": null, "deferred": false, "unrendered_config": {"materialized": "table", "schema": "zendesk_docs"}, "created_at": 1647014737.9442291, "compiled_sql": "with base as (\n\n    select * \n    from `bq-project`.`dbt_joe_zendesk_docs`.`stg_zendesk__ticket_tmp`\n\n),\n\nfields as (\n\n    select\n        /*\n        The below macro is used to generate the correct SQL for package staging models. It takes a list of columns \n        that are expected/needed (staging_columns from dbt_zendesk_source/models/tmp/) and compares it with columns \n        in the source (source_columns from dbt_zendesk_source/macros/).\n        For more information refer to our dbt_fivetran_utils documentation (https://github.com/fivetran/dbt_fivetran_utils.git).\n        */\n        \n    \n    \n    _fivetran_synced\n    \n as \n    \n    _fivetran_synced\n    \n, \n    \n    \n    allow_channelback\n    \n as \n    \n    allow_channelback\n    \n, \n    \n    \n    assignee_id\n    \n as \n    \n    assignee_id\n    \n, \n    \n    \n    brand_id\n    \n as \n    \n    brand_id\n    \n, \n    \n    \n    created_at\n    \n as \n    \n    created_at\n    \n, \n    \n    \n    description\n    \n as \n    \n    description\n    \n, \n    \n    \n    due_at\n    \n as \n    \n    due_at\n    \n, \n    \n    \n    external_id\n    \n as \n    \n    external_id\n    \n, \n    \n    \n    forum_topic_id\n    \n as \n    \n    forum_topic_id\n    \n, \n    \n    \n    group_id\n    \n as \n    \n    group_id\n    \n, \n    \n    \n    has_incidents\n    \n as \n    \n    has_incidents\n    \n, \n    \n    \n    id\n    \n as \n    \n    id\n    \n, \n    \n    \n    is_public\n    \n as \n    \n    is_public\n    \n, \n    \n    \n    merged_ticket_ids\n    \n as \n    \n    merged_ticket_ids\n    \n, \n    \n    \n    organization_id\n    \n as \n    \n    organization_id\n    \n, \n    \n    \n    priority\n    \n as \n    \n    priority\n    \n, \n    \n    \n    problem_id\n    \n as \n    \n    problem_id\n    \n, \n    \n    \n    recipient\n    \n as \n    \n    recipient\n    \n, \n    \n    \n    requester_id\n    \n as \n    \n    requester_id\n    \n, \n    \n    \n    status\n    \n as \n    \n    status\n    \n, \n    \n    \n    subject\n    \n as \n    \n    subject\n    \n, \n    \n    \n    submitter_id\n    \n as \n    \n    submitter_id\n    \n, \n    cast(null as \n    int64\n) as \n    \n    system_ccs\n    \n , \n    \n    \n    system_client\n    \n as \n    \n    system_client\n    \n, \n    \n    \n    system_ip_address\n    \n as \n    \n    system_ip_address\n    \n, \n    cast(null as \n    int64\n) as \n    \n    system_json_email_identifier\n    \n , \n    \n    \n    system_latitude\n    \n as \n    \n    system_latitude\n    \n, \n    \n    \n    system_location\n    \n as \n    \n    system_location\n    \n, \n    \n    \n    system_longitude\n    \n as \n    \n    system_longitude\n    \n, \n    cast(null as \n    int64\n) as \n    \n    system_machine_generated\n    \n , \n    cast(null as \n    int64\n) as \n    \n    system_message_id\n    \n , \n    cast(null as \n    int64\n) as \n    \n    system_raw_email_identifier\n    \n , \n    \n    \n    ticket_form_id\n    \n as \n    \n    ticket_form_id\n    \n, \n    \n    \n    type\n    \n as \n    \n    type\n    \n, \n    \n    \n    updated_at\n    \n as \n    \n    updated_at\n    \n, \n    \n    \n    url\n    \n as \n    \n    url\n    \n, \n    \n    \n    via_channel\n    \n as \n    \n    via_channel\n    \n, \n    \n    \n    via_source_from_address\n    \n as \n    \n    via_source_from_address\n    \n, \n    \n    \n    via_source_from_id\n    \n as \n    \n    via_source_from_id\n    \n, \n    \n    \n    via_source_from_title\n    \n as \n    \n    via_source_from_title\n    \n, \n    \n    \n    via_source_rel\n    \n as \n    \n    via_source_rel\n    \n, \n    \n    \n    via_source_to_address\n    \n as \n    \n    via_source_to_address\n    \n, \n    \n    \n    via_source_to_name\n    \n as \n    \n    via_source_to_name\n    \n\n\n\n        \n    from base\n),\n\nfinal as (\n    \n    select \n        id as ticket_id,\n        _fivetran_synced,\n        assignee_id,\n        brand_id,\n        created_at,\n            updated_at,\n        \n        description,\n        due_at,\n        group_id,\n        external_id,\n        is_public,\n        organization_id,\n        priority,\n        recipient,\n        requester_id,\n        status,\n        subject,\n        problem_id,\n        submitter_id,\n        ticket_form_id,\n        type,\n        url,\n        via_channel as created_channel,\n        via_source_from_id as source_from_id,\n        via_source_from_title as source_from_title,\n        via_source_rel as source_rel,\n        via_source_to_address as source_to_address,\n        via_source_to_name as source_to_name\n    from fields\n)\n\nselect * \nfrom final", "extra_ctes_injected": true, "extra_ctes": [], "relation_name": "`bq-project`.`dbt_joe_zendesk_docs`.`stg_zendesk__ticket`"}, "model.zendesk_source.stg_zendesk__daylight_time_tmp": {"raw_sql": "--To disable this model, set the using_schedules variable within your dbt_project.yml file to False.\n{{ config(enabled=var('using_schedules', True)) }}\n\nselect * \nfrom {{ var('daylight_time') }}", "compiled": true, "resource_type": "model", "depends_on": {"macros": [], "nodes": ["source.zendesk_source.zendesk.daylight_time"]}, "config": {"enabled": true, "alias": null, "schema": "zendesk_docs", "database": null, "tags": [], "meta": {}, "materialized": "view", "persist_docs": {}, "quoting": {}, "column_types": {}, "full_refresh": null, "on_schema_change": "ignore", "post-hook": [], "pre-hook": []}, "database": "bq-project", "schema": "dbt_joe_zendesk_docs", "fqn": ["zendesk_source", "tmp", "stg_zendesk__daylight_time_tmp"], "unique_id": "model.zendesk_source.stg_zendesk__daylight_time_tmp", "package_name": "zendesk_source", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/zendesk_source", "path": "tmp/stg_zendesk__daylight_time_tmp.sql", "original_file_path": "models/tmp/stg_zendesk__daylight_time_tmp.sql", "name": "stg_zendesk__daylight_time_tmp", "alias": "stg_zendesk__daylight_time_tmp", "checksum": {"name": "sha256", "checksum": "1e56b01380e146e42947a9745e7239cde9b56c56744f0b8c79b5ef9a4451aa76"}, "tags": [], "refs": [], "sources": [["zendesk", "daylight_time"]], "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "compiled_path": "target/compiled/zendesk_source/models/tmp/stg_zendesk__daylight_time_tmp.sql", "build_path": null, "deferred": false, "unrendered_config": {"materialized": "view", "schema": "zendesk_docs", "enabled": true}, "created_at": 1647014737.642672, "compiled_sql": "--To disable this model, set the using_schedules variable within your dbt_project.yml file to False.\n\n\nselect * \nfrom `bq-project`.`zendesk`.`daylight_time`", "extra_ctes_injected": true, "extra_ctes": [], "relation_name": "`bq-project`.`dbt_joe_zendesk_docs`.`stg_zendesk__daylight_time_tmp`"}, "model.zendesk_source.stg_zendesk__user_tmp": {"raw_sql": "select * \nfrom {{ var('user') }}", "compiled": true, "resource_type": "model", "depends_on": {"macros": [], "nodes": ["source.zendesk_source.zendesk.user"]}, "config": {"enabled": true, "alias": null, "schema": "zendesk_docs", "database": null, "tags": [], "meta": {}, "materialized": "view", "persist_docs": {}, "quoting": {}, "column_types": {}, "full_refresh": null, "on_schema_change": "ignore", "post-hook": [], "pre-hook": []}, "database": "bq-project", "schema": "dbt_joe_zendesk_docs", "fqn": ["zendesk_source", "tmp", "stg_zendesk__user_tmp"], "unique_id": "model.zendesk_source.stg_zendesk__user_tmp", "package_name": "zendesk_source", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/zendesk_source", "path": "tmp/stg_zendesk__user_tmp.sql", "original_file_path": "models/tmp/stg_zendesk__user_tmp.sql", "name": "stg_zendesk__user_tmp", "alias": "stg_zendesk__user_tmp", "checksum": {"name": "sha256", "checksum": "6a45d1112d3ae79f22784f5fd5723a27b7894d57aea5795a37921842affc0085"}, "tags": [], "refs": [], "sources": [["zendesk", "user"]], "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "compiled_path": "target/compiled/zendesk_source/models/tmp/stg_zendesk__user_tmp.sql", "build_path": null, "deferred": false, "unrendered_config": {"materialized": "view", "schema": "zendesk_docs"}, "created_at": 1647014737.648524, "compiled_sql": "select * \nfrom `bq-project`.`zendesk`.`user`", "extra_ctes_injected": true, "extra_ctes": [], "relation_name": "`bq-project`.`dbt_joe_zendesk_docs`.`stg_zendesk__user_tmp`"}, "model.zendesk_source.stg_zendesk__group_tmp": {"raw_sql": "select * \nfrom {{ var('group') }}", "compiled": true, "resource_type": "model", "depends_on": {"macros": [], "nodes": ["source.zendesk_source.zendesk.group"]}, "config": {"enabled": true, "alias": null, "schema": "zendesk_docs", "database": null, "tags": [], "meta": {}, "materialized": "view", "persist_docs": {}, "quoting": {}, "column_types": {}, "full_refresh": null, "on_schema_change": "ignore", "post-hook": [], "pre-hook": []}, "database": "bq-project", "schema": "dbt_joe_zendesk_docs", "fqn": ["zendesk_source", "tmp", "stg_zendesk__group_tmp"], "unique_id": "model.zendesk_source.stg_zendesk__group_tmp", "package_name": "zendesk_source", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/zendesk_source", "path": "tmp/stg_zendesk__group_tmp.sql", "original_file_path": "models/tmp/stg_zendesk__group_tmp.sql", "name": "stg_zendesk__group_tmp", "alias": "stg_zendesk__group_tmp", "checksum": {"name": "sha256", "checksum": "f8e6c8c86b8fd6cea489c85641677a5ec978e5fa5d7ecd73cdf89eb25a533905"}, "tags": [], "refs": [], "sources": [["zendesk", "group"]], "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "compiled_path": "target/compiled/zendesk_source/models/tmp/stg_zendesk__group_tmp.sql", "build_path": null, "deferred": false, "unrendered_config": {"materialized": "view", "schema": "zendesk_docs"}, "created_at": 1647014737.6535559, "compiled_sql": "select * \nfrom `bq-project`.`zendesk`.`group`", "extra_ctes_injected": true, "extra_ctes": [], "relation_name": "`bq-project`.`dbt_joe_zendesk_docs`.`stg_zendesk__group_tmp`"}, "model.zendesk_source.stg_zendesk__ticket_tmp": {"raw_sql": "select * \nfrom {{ var('ticket') }}", "compiled": true, "resource_type": "model", "depends_on": {"macros": [], "nodes": ["source.zendesk_source.zendesk.ticket"]}, "config": {"enabled": true, "alias": null, "schema": "zendesk_docs", "database": null, "tags": [], "meta": {}, "materialized": "view", "persist_docs": {}, "quoting": {}, "column_types": {}, "full_refresh": null, "on_schema_change": "ignore", "post-hook": [], "pre-hook": []}, "database": "bq-project", "schema": "dbt_joe_zendesk_docs", "fqn": ["zendesk_source", "tmp", "stg_zendesk__ticket_tmp"], "unique_id": "model.zendesk_source.stg_zendesk__ticket_tmp", "package_name": "zendesk_source", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/zendesk_source", "path": "tmp/stg_zendesk__ticket_tmp.sql", "original_file_path": "models/tmp/stg_zendesk__ticket_tmp.sql", "name": "stg_zendesk__ticket_tmp", "alias": "stg_zendesk__ticket_tmp", "checksum": {"name": "sha256", "checksum": "19b2466ae73fd66df0348a3b03e757b40fc5f85bd6d99c893626f55e8c69d2ca"}, "tags": [], "refs": [], "sources": [["zendesk", "ticket"]], "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "compiled_path": "target/compiled/zendesk_source/models/tmp/stg_zendesk__ticket_tmp.sql", "build_path": null, "deferred": false, "unrendered_config": {"materialized": "view", "schema": "zendesk_docs"}, "created_at": 1647014737.658578, "compiled_sql": "select * \nfrom `bq-project`.`zendesk`.`ticket`", "extra_ctes_injected": true, "extra_ctes": [], "relation_name": "`bq-project`.`dbt_joe_zendesk_docs`.`stg_zendesk__ticket_tmp`"}, "model.zendesk_source.stg_zendesk__brand_tmp": {"raw_sql": "select * \nfrom {{ var('brand') }}", "compiled": true, "resource_type": "model", "depends_on": {"macros": [], "nodes": ["source.zendesk_source.zendesk.brand"]}, "config": {"enabled": true, "alias": null, "schema": "zendesk_docs", "database": null, "tags": [], "meta": {}, "materialized": "view", "persist_docs": {}, "quoting": {}, "column_types": {}, "full_refresh": null, "on_schema_change": "ignore", "post-hook": [], "pre-hook": []}, "database": "bq-project", "schema": "dbt_joe_zendesk_docs", "fqn": ["zendesk_source", "tmp", "stg_zendesk__brand_tmp"], "unique_id": "model.zendesk_source.stg_zendesk__brand_tmp", "package_name": "zendesk_source", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/zendesk_source", "path": "tmp/stg_zendesk__brand_tmp.sql", "original_file_path": "models/tmp/stg_zendesk__brand_tmp.sql", "name": "stg_zendesk__brand_tmp", "alias": "stg_zendesk__brand_tmp", "checksum": {"name": "sha256", "checksum": "58555c5a87cdf4ff202901b74ac2e6dbf7e01dd675aa86e8f8937f74685ca8a2"}, "tags": [], "refs": [], "sources": [["zendesk", "brand"]], "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "compiled_path": "target/compiled/zendesk_source/models/tmp/stg_zendesk__brand_tmp.sql", "build_path": null, "deferred": false, "unrendered_config": {"materialized": "view", "schema": "zendesk_docs"}, "created_at": 1647014737.6641831, "compiled_sql": "select * \nfrom `bq-project`.`zendesk`.`brand`", "extra_ctes_injected": true, "extra_ctes": [], "relation_name": "`bq-project`.`dbt_joe_zendesk_docs`.`stg_zendesk__brand_tmp`"}, "model.zendesk_source.stg_zendesk__ticket_tag_tmp": {"raw_sql": "select * \nfrom {{ var('ticket_tag') }}", "compiled": true, "resource_type": "model", "depends_on": {"macros": [], "nodes": ["source.zendesk_source.zendesk.ticket_tag"]}, "config": {"enabled": true, "alias": null, "schema": "zendesk_docs", "database": null, "tags": [], "meta": {}, "materialized": "view", "persist_docs": {}, "quoting": {}, "column_types": {}, "full_refresh": null, "on_schema_change": "ignore", "post-hook": [], "pre-hook": []}, "database": "bq-project", "schema": "dbt_joe_zendesk_docs", "fqn": ["zendesk_source", "tmp", "stg_zendesk__ticket_tag_tmp"], "unique_id": "model.zendesk_source.stg_zendesk__ticket_tag_tmp", "package_name": "zendesk_source", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/zendesk_source", "path": "tmp/stg_zendesk__ticket_tag_tmp.sql", "original_file_path": "models/tmp/stg_zendesk__ticket_tag_tmp.sql", "name": "stg_zendesk__ticket_tag_tmp", "alias": "stg_zendesk__ticket_tag_tmp", "checksum": {"name": "sha256", "checksum": "bd1c6e36c872436d5b0225cc21df29fa2f97864083d67175a6fed09d8b79d5ef"}, "tags": [], "refs": [], "sources": [["zendesk", "ticket_tag"]], "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "compiled_path": "target/compiled/zendesk_source/models/tmp/stg_zendesk__ticket_tag_tmp.sql", "build_path": null, "deferred": false, "unrendered_config": {"materialized": "view", "schema": "zendesk_docs"}, "created_at": 1647014737.669055, "compiled_sql": "select * \nfrom `bq-project`.`zendesk`.`ticket_tag`", "extra_ctes_injected": true, "extra_ctes": [], "relation_name": "`bq-project`.`dbt_joe_zendesk_docs`.`stg_zendesk__ticket_tag_tmp`"}, "model.zendesk_source.stg_zendesk__ticket_field_history_tmp": {"raw_sql": "select * \nfrom {{ var('ticket_field_history') }}", "compiled": true, "resource_type": "model", "depends_on": {"macros": [], "nodes": ["source.zendesk_source.zendesk.ticket_field_history"]}, "config": {"enabled": true, "alias": null, "schema": "zendesk_docs", "database": null, "tags": [], "meta": {}, "materialized": "view", "persist_docs": {}, "quoting": {}, "column_types": {}, "full_refresh": null, "on_schema_change": "ignore", "post-hook": [], "pre-hook": []}, "database": "bq-project", "schema": "dbt_joe_zendesk_docs", "fqn": ["zendesk_source", "tmp", "stg_zendesk__ticket_field_history_tmp"], "unique_id": "model.zendesk_source.stg_zendesk__ticket_field_history_tmp", "package_name": "zendesk_source", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/zendesk_source", "path": "tmp/stg_zendesk__ticket_field_history_tmp.sql", "original_file_path": "models/tmp/stg_zendesk__ticket_field_history_tmp.sql", "name": "stg_zendesk__ticket_field_history_tmp", "alias": "stg_zendesk__ticket_field_history_tmp", "checksum": {"name": "sha256", "checksum": "6f06e6d418e0f6f8b8c02256c24e75add9a1b33d8e0c2515bad04dc6db404ff1"}, "tags": [], "refs": [], "sources": [["zendesk", "ticket_field_history"]], "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "compiled_path": "target/compiled/zendesk_source/models/tmp/stg_zendesk__ticket_field_history_tmp.sql", "build_path": null, "deferred": false, "unrendered_config": {"materialized": "view", "schema": "zendesk_docs"}, "created_at": 1647014737.6800041, "compiled_sql": "select * \nfrom `bq-project`.`zendesk`.`ticket_field_history`", "extra_ctes_injected": true, "extra_ctes": [], "relation_name": "`bq-project`.`dbt_joe_zendesk_docs`.`stg_zendesk__ticket_field_history_tmp`"}, "model.zendesk_source.stg_zendesk__ticket_form_history_tmp": {"raw_sql": "--To disable this model, set the using_ticket_form_history variable within your dbt_project.yml file to False.\n{{ config(enabled=var('using_ticket_form_history', True)) }}\n\nselect * \nfrom {{ var('ticket_form_history') }}", "compiled": true, "resource_type": "model", "depends_on": {"macros": [], "nodes": ["source.zendesk_source.zendesk.ticket_form_history"]}, "config": {"enabled": true, "alias": null, "schema": "zendesk_docs", "database": null, "tags": [], "meta": {}, "materialized": "view", "persist_docs": {}, "quoting": {}, "column_types": {}, "full_refresh": null, "on_schema_change": "ignore", "post-hook": [], "pre-hook": []}, "database": "bq-project", "schema": "dbt_joe_zendesk_docs", "fqn": ["zendesk_source", "tmp", "stg_zendesk__ticket_form_history_tmp"], "unique_id": "model.zendesk_source.stg_zendesk__ticket_form_history_tmp", "package_name": "zendesk_source", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/zendesk_source", "path": "tmp/stg_zendesk__ticket_form_history_tmp.sql", "original_file_path": "models/tmp/stg_zendesk__ticket_form_history_tmp.sql", "name": "stg_zendesk__ticket_form_history_tmp", "alias": "stg_zendesk__ticket_form_history_tmp", "checksum": {"name": "sha256", "checksum": "c982594d09e47ffcf3513e6b8443d208baf26f2df376bfa2e2f9fb95e1a05ec5"}, "tags": [], "refs": [], "sources": [["zendesk", "ticket_form_history"]], "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "compiled_path": "target/compiled/zendesk_source/models/tmp/stg_zendesk__ticket_form_history_tmp.sql", "build_path": null, "deferred": false, "unrendered_config": {"materialized": "view", "schema": "zendesk_docs", "enabled": true}, "created_at": 1647014737.685097, "compiled_sql": "--To disable this model, set the using_ticket_form_history variable within your dbt_project.yml file to False.\n\n\nselect * \nfrom `bq-project`.`zendesk`.`ticket_form_history`", "extra_ctes_injected": true, "extra_ctes": [], "relation_name": "`bq-project`.`dbt_joe_zendesk_docs`.`stg_zendesk__ticket_form_history_tmp`"}, "model.zendesk_source.stg_zendesk__ticket_comment_tmp": {"raw_sql": "select * \nfrom {{ var('ticket_comment') }}", "compiled": true, "resource_type": "model", "depends_on": {"macros": [], "nodes": ["source.zendesk_source.zendesk.ticket_comment"]}, "config": {"enabled": true, "alias": null, "schema": "zendesk_docs", "database": null, "tags": [], "meta": {}, "materialized": "view", "persist_docs": {}, "quoting": {}, "column_types": {}, "full_refresh": null, "on_schema_change": "ignore", "post-hook": [], "pre-hook": []}, "database": "bq-project", "schema": "dbt_joe_zendesk_docs", "fqn": ["zendesk_source", "tmp", "stg_zendesk__ticket_comment_tmp"], "unique_id": "model.zendesk_source.stg_zendesk__ticket_comment_tmp", "package_name": "zendesk_source", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/zendesk_source", "path": "tmp/stg_zendesk__ticket_comment_tmp.sql", "original_file_path": "models/tmp/stg_zendesk__ticket_comment_tmp.sql", "name": "stg_zendesk__ticket_comment_tmp", "alias": "stg_zendesk__ticket_comment_tmp", "checksum": {"name": "sha256", "checksum": "0f14f6e0dc38eac86f58cec21d12d25fcdd916e7f31bceff35cc0766da2ab560"}, "tags": [], "refs": [], "sources": [["zendesk", "ticket_comment"]], "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "compiled_path": "target/compiled/zendesk_source/models/tmp/stg_zendesk__ticket_comment_tmp.sql", "build_path": null, "deferred": false, "unrendered_config": {"materialized": "view", "schema": "zendesk_docs"}, "created_at": 1647014737.691029, "compiled_sql": "select * \nfrom `bq-project`.`zendesk`.`ticket_comment`", "extra_ctes_injected": true, "extra_ctes": [], "relation_name": "`bq-project`.`dbt_joe_zendesk_docs`.`stg_zendesk__ticket_comment_tmp`"}, "model.zendesk_source.stg_zendesk__schedule_tmp": {"raw_sql": "--To disable this model, set the using_schedules variable within your dbt_project.yml file to False.\n{{ config(enabled=var('using_schedules', True)) }}\n\nselect * \nfrom {{ var('schedule') }}", "compiled": true, "resource_type": "model", "depends_on": {"macros": [], "nodes": ["source.zendesk_source.zendesk.schedule"]}, "config": {"enabled": true, "alias": null, "schema": "zendesk_docs", "database": null, "tags": [], "meta": {}, "materialized": "view", "persist_docs": {}, "quoting": {}, "column_types": {}, "full_refresh": null, "on_schema_change": "ignore", "post-hook": [], "pre-hook": []}, "database": "bq-project", "schema": "dbt_joe_zendesk_docs", "fqn": ["zendesk_source", "tmp", "stg_zendesk__schedule_tmp"], "unique_id": "model.zendesk_source.stg_zendesk__schedule_tmp", "package_name": "zendesk_source", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/zendesk_source", "path": "tmp/stg_zendesk__schedule_tmp.sql", "original_file_path": "models/tmp/stg_zendesk__schedule_tmp.sql", "name": "stg_zendesk__schedule_tmp", "alias": "stg_zendesk__schedule_tmp", "checksum": {"name": "sha256", "checksum": "e14f77042a8f64d285a76897176d96cae381a464cc944a5af7e3ec0c91122947"}, "tags": [], "refs": [], "sources": [["zendesk", "schedule"]], "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "compiled_path": "target/compiled/zendesk_source/models/tmp/stg_zendesk__schedule_tmp.sql", "build_path": null, "deferred": false, "unrendered_config": {"materialized": "view", "schema": "zendesk_docs", "enabled": true}, "created_at": 1647014737.702846, "compiled_sql": "--To disable this model, set the using_schedules variable within your dbt_project.yml file to False.\n\n\nselect * \nfrom `bq-project`.`zendesk`.`schedule`", "extra_ctes_injected": true, "extra_ctes": [], "relation_name": "`bq-project`.`dbt_joe_zendesk_docs`.`stg_zendesk__schedule_tmp`"}, "model.zendesk_source.stg_zendesk__organization_tmp": {"raw_sql": "select * \nfrom {{ var('organization') }}", "compiled": true, "resource_type": "model", "depends_on": {"macros": [], "nodes": ["source.zendesk_source.zendesk.organization"]}, "config": {"enabled": true, "alias": null, "schema": "zendesk_docs", "database": null, "tags": [], "meta": {}, "materialized": "view", "persist_docs": {}, "quoting": {}, "column_types": {}, "full_refresh": null, "on_schema_change": "ignore", "post-hook": [], "pre-hook": []}, "database": "bq-project", "schema": "dbt_joe_zendesk_docs", "fqn": ["zendesk_source", "tmp", "stg_zendesk__organization_tmp"], "unique_id": "model.zendesk_source.stg_zendesk__organization_tmp", "package_name": "zendesk_source", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/zendesk_source", "path": "tmp/stg_zendesk__organization_tmp.sql", "original_file_path": "models/tmp/stg_zendesk__organization_tmp.sql", "name": "stg_zendesk__organization_tmp", "alias": "stg_zendesk__organization_tmp", "checksum": {"name": "sha256", "checksum": "2f3e00296ea52db703431b38d4d3f523f83a2a4a2e87607c8c79378b169835f8"}, "tags": [], "refs": [], "sources": [["zendesk", "organization"]], "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "compiled_path": "target/compiled/zendesk_source/models/tmp/stg_zendesk__organization_tmp.sql", "build_path": null, "deferred": false, "unrendered_config": {"materialized": "view", "schema": "zendesk_docs"}, "created_at": 1647014737.7085571, "compiled_sql": "select * \nfrom `bq-project`.`zendesk`.`organization`", "extra_ctes_injected": true, "extra_ctes": [], "relation_name": "`bq-project`.`dbt_joe_zendesk_docs`.`stg_zendesk__organization_tmp`"}, "model.zendesk_source.stg_zendesk__ticket_schedule_tmp": {"raw_sql": "--To disable this model, set the using_schedules variable within your dbt_project.yml file to False.\n{{ config(enabled=var('using_schedules', True)) }}\n\n{%- set source_relation = adapter.get_relation(\n      database=source('zendesk', 'ticket_schedule').database,\n      schema=source('zendesk', 'ticket_schedule').schema,\n      identifier=source('zendesk', 'ticket_schedule').name) -%}\n\n{% set table_exists=source_relation is not none  %}\n\n{% if table_exists %}\n\nselect *\nfrom {{ source('zendesk', 'ticket_schedule') }}\n\n{% else %}\n\nselect\n    cast(null as {{ dbt_utils.type_timestamp() }}) as _fivetran_synced,\n    cast(null as {{ dbt_utils.type_timestamp() }}) as created_at,\n    cast(null as {{ dbt_utils.type_int() }}) as schedule_id,\n    cast(null as {{ dbt_utils.type_int() }}) as ticket_id\n\n{% endif %}", "compiled": true, "resource_type": "model", "depends_on": {"macros": ["macro.dbt_utils.type_timestamp", "macro.dbt_utils.type_int"], "nodes": ["source.zendesk_source.zendesk.ticket_schedule", "source.zendesk_source.zendesk.ticket_schedule", "source.zendesk_source.zendesk.ticket_schedule"]}, "config": {"enabled": true, "alias": null, "schema": "zendesk_docs", "database": null, "tags": [], "meta": {}, "materialized": "view", "persist_docs": {}, "quoting": {}, "column_types": {}, "full_refresh": null, "on_schema_change": "ignore", "post-hook": [], "pre-hook": []}, "database": "bq-project", "schema": "dbt_joe_zendesk_docs", "fqn": ["zendesk_source", "tmp", "stg_zendesk__ticket_schedule_tmp"], "unique_id": "model.zendesk_source.stg_zendesk__ticket_schedule_tmp", "package_name": "zendesk_source", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/zendesk_source", "path": "tmp/stg_zendesk__ticket_schedule_tmp.sql", "original_file_path": "models/tmp/stg_zendesk__ticket_schedule_tmp.sql", "name": "stg_zendesk__ticket_schedule_tmp", "alias": "stg_zendesk__ticket_schedule_tmp", "checksum": {"name": "sha256", "checksum": "15e5b270de6a25bf52311df259a5969b24cb1ce513eaa4a11af74c4d6b854ad0"}, "tags": [], "refs": [], "sources": [["zendesk", "ticket_schedule"], ["zendesk", "ticket_schedule"], ["zendesk", "ticket_schedule"]], "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "compiled_path": "target/compiled/zendesk_source/models/tmp/stg_zendesk__ticket_schedule_tmp.sql", "build_path": null, "deferred": false, "unrendered_config": {"materialized": "view", "schema": "zendesk_docs", "enabled": true}, "created_at": 1647014737.713645, "compiled_sql": "--To disable this model, set the using_schedules variable within your dbt_project.yml file to False.\n\n\n\n\nselect *\nfrom `bq-project`.`zendesk`.`ticket_schedule`\n\n", "extra_ctes_injected": true, "extra_ctes": [], "relation_name": "`bq-project`.`dbt_joe_zendesk_docs`.`stg_zendesk__ticket_schedule_tmp`"}, "model.zendesk_source.stg_zendesk__time_zone_tmp": {"raw_sql": "--To disable this model, set the using_schedules variable within your dbt_project.yml file to False.\n{{ config(enabled=var('using_schedules', True)) }}\n\nselect * \nfrom {{ var('time_zone') }}", "compiled": true, "resource_type": "model", "depends_on": {"macros": [], "nodes": ["source.zendesk_source.zendesk.time_zone"]}, "config": {"enabled": true, "alias": null, "schema": "zendesk_docs", "database": null, "tags": [], "meta": {}, "materialized": "view", "persist_docs": {}, "quoting": {}, "column_types": {}, "full_refresh": null, "on_schema_change": "ignore", "post-hook": [], "pre-hook": []}, "database": "bq-project", "schema": "dbt_joe_zendesk_docs", "fqn": ["zendesk_source", "tmp", "stg_zendesk__time_zone_tmp"], "unique_id": "model.zendesk_source.stg_zendesk__time_zone_tmp", "package_name": "zendesk_source", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/zendesk_source", "path": "tmp/stg_zendesk__time_zone_tmp.sql", "original_file_path": "models/tmp/stg_zendesk__time_zone_tmp.sql", "name": "stg_zendesk__time_zone_tmp", "alias": "stg_zendesk__time_zone_tmp", "checksum": {"name": "sha256", "checksum": "36ffaa731bbe3b27c8677eb200419585dc7416b165acbe2a1c55631e11d54f4c"}, "tags": [], "refs": [], "sources": [["zendesk", "time_zone"]], "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "compiled_path": "target/compiled/zendesk_source/models/tmp/stg_zendesk__time_zone_tmp.sql", "build_path": null, "deferred": false, "unrendered_config": {"materialized": "view", "schema": "zendesk_docs", "enabled": true}, "created_at": 1647014737.728037, "compiled_sql": "--To disable this model, set the using_schedules variable within your dbt_project.yml file to False.\n\n\nselect * \nfrom `bq-project`.`zendesk`.`time_zone`", "extra_ctes_injected": true, "extra_ctes": [], "relation_name": "`bq-project`.`dbt_joe_zendesk_docs`.`stg_zendesk__time_zone_tmp`"}, "test.zendesk.unique_zendesk__ticket_enriched_ticket_id.7c3c6ca9ef": {"raw_sql": "{{ test_unique(**_dbt_generic_test_kwargs) }}", "test_metadata": {"name": "unique", "kwargs": {"column_name": "ticket_id", "model": "{{ get_where_subquery(ref('zendesk__ticket_enriched')) }}"}, "namespace": null}, "compiled": true, "resource_type": "test", "depends_on": {"macros": ["macro.dbt.test_unique", "macro.dbt.get_where_subquery"], "nodes": ["model.zendesk.zendesk__ticket_enriched"]}, "config": {"enabled": true, "alias": null, "schema": "dbt_test__audit", "database": null, "tags": [], "meta": {}, "materialized": "test", "severity": "ERROR", "store_failures": null, "where": null, "limit": null, "fail_calc": "count(*)", "warn_if": "!= 0", "error_if": "!= 0"}, "database": "bq-project", "schema": "dbt_joe_dbt_test__audit", "fqn": ["zendesk", "unique_zendesk__ticket_enriched_ticket_id"], "unique_id": "test.zendesk.unique_zendesk__ticket_enriched_ticket_id.7c3c6ca9ef", "package_name": "zendesk", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/zendesk", "path": "unique_zendesk__ticket_enriched_ticket_id.sql", "original_file_path": "models/zendesk.yml", "name": "unique_zendesk__ticket_enriched_ticket_id", "alias": "unique_zendesk__ticket_enriched_ticket_id", "checksum": {"name": "none", "checksum": ""}, "tags": [], "refs": [["zendesk__ticket_enriched"]], "sources": [], "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "compiled_path": "target/compiled/zendesk/models/zendesk.yml/unique_zendesk__ticket_enriched_ticket_id.sql", "build_path": null, "deferred": false, "unrendered_config": {}, "created_at": 1647014737.920429, "compiled_sql": "\n    \n    \n\nwith dbt_test__target as (\n  \n  select ticket_id as unique_field\n  from `bq-project`.`dbt_joe_zendesk_docs`.`zendesk__ticket_enriched`\n  where ticket_id is not null\n  \n)\n\nselect\n    unique_field,\n    count(*) as n_records\n\nfrom dbt_test__target\ngroup by unique_field\nhaving count(*) > 1\n\n\n", "extra_ctes_injected": true, "extra_ctes": [], "relation_name": null, "column_name": "ticket_id", "file_key_name": "models.zendesk__ticket_enriched"}, "test.zendesk.not_null_zendesk__ticket_enriched_ticket_id.e3efc5bf0a": {"raw_sql": "{{ test_not_null(**_dbt_generic_test_kwargs) }}", "test_metadata": {"name": "not_null", "kwargs": {"column_name": "ticket_id", "model": "{{ get_where_subquery(ref('zendesk__ticket_enriched')) }}"}, "namespace": null}, "compiled": true, "resource_type": "test", "depends_on": {"macros": ["macro.dbt.test_not_null", "macro.dbt.get_where_subquery"], "nodes": ["model.zendesk.zendesk__ticket_enriched"]}, "config": {"enabled": true, "alias": null, "schema": "dbt_test__audit", "database": null, "tags": [], "meta": {}, "materialized": "test", "severity": "ERROR", "store_failures": null, "where": null, "limit": null, "fail_calc": "count(*)", "warn_if": "!= 0", "error_if": "!= 0"}, "database": "bq-project", "schema": "dbt_joe_dbt_test__audit", "fqn": ["zendesk", "not_null_zendesk__ticket_enriched_ticket_id"], "unique_id": "test.zendesk.not_null_zendesk__ticket_enriched_ticket_id.e3efc5bf0a", "package_name": "zendesk", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/zendesk", "path": "not_null_zendesk__ticket_enriched_ticket_id.sql", "original_file_path": "models/zendesk.yml", "name": "not_null_zendesk__ticket_enriched_ticket_id", "alias": "not_null_zendesk__ticket_enriched_ticket_id", "checksum": {"name": "none", "checksum": ""}, "tags": [], "refs": [["zendesk__ticket_enriched"]], "sources": [], "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "compiled_path": "target/compiled/zendesk/models/zendesk.yml/not_null_zendesk__ticket_enriched_ticket_id.sql", "build_path": null, "deferred": false, "unrendered_config": {}, "created_at": 1647014737.92259, "compiled_sql": "\n    \n    \n\nselect *\nfrom `bq-project`.`dbt_joe_zendesk_docs`.`zendesk__ticket_enriched`\nwhere ticket_id is null\n\n\n", "extra_ctes_injected": true, "extra_ctes": [], "relation_name": null, "column_name": "ticket_id", "file_key_name": "models.zendesk__ticket_enriched"}, "test.zendesk.unique_zendesk__sla_policies_sla_event_id.5daff4d2bd": {"raw_sql": "{{ test_unique(**_dbt_generic_test_kwargs) }}", "test_metadata": {"name": "unique", "kwargs": {"column_name": "sla_event_id", "model": "{{ get_where_subquery(ref('zendesk__sla_policies')) }}"}, "namespace": null}, "compiled": true, "resource_type": "test", "depends_on": {"macros": ["macro.dbt.test_unique", "macro.dbt.get_where_subquery"], "nodes": ["model.zendesk.zendesk__sla_policies"]}, "config": {"enabled": true, "alias": null, "schema": "dbt_test__audit", "database": null, "tags": [], "meta": {}, "materialized": "test", "severity": "ERROR", "store_failures": null, "where": null, "limit": null, "fail_calc": "count(*)", "warn_if": "!= 0", "error_if": "!= 0"}, "database": "bq-project", "schema": "dbt_joe_dbt_test__audit", "fqn": ["zendesk", "unique_zendesk__sla_policies_sla_event_id"], "unique_id": "test.zendesk.unique_zendesk__sla_policies_sla_event_id.5daff4d2bd", "package_name": "zendesk", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/zendesk", "path": "unique_zendesk__sla_policies_sla_event_id.sql", "original_file_path": "models/zendesk.yml", "name": "unique_zendesk__sla_policies_sla_event_id", "alias": "unique_zendesk__sla_policies_sla_event_id", "checksum": {"name": "none", "checksum": ""}, "tags": [], "refs": [["zendesk__sla_policies"]], "sources": [], "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "compiled_path": "target/compiled/zendesk/models/zendesk.yml/unique_zendesk__sla_policies_sla_event_id.sql", "build_path": null, "deferred": false, "unrendered_config": {}, "created_at": 1647014737.9244502, "compiled_sql": "\n    \n    \n\nwith dbt_test__target as (\n  \n  select sla_event_id as unique_field\n  from `bq-project`.`dbt_joe_zendesk_docs`.`zendesk__sla_policies`\n  where sla_event_id is not null\n  \n)\n\nselect\n    unique_field,\n    count(*) as n_records\n\nfrom dbt_test__target\ngroup by unique_field\nhaving count(*) > 1\n\n\n", "extra_ctes_injected": true, "extra_ctes": [], "relation_name": null, "column_name": "sla_event_id", "file_key_name": "models.zendesk__sla_policies"}, "test.zendesk.unique_zendesk__ticket_metrics_ticket_id.f3dc8eba5c": {"raw_sql": "{{ test_unique(**_dbt_generic_test_kwargs) }}", "test_metadata": {"name": "unique", "kwargs": {"column_name": "ticket_id", "model": "{{ get_where_subquery(ref('zendesk__ticket_metrics')) }}"}, "namespace": null}, "compiled": true, "resource_type": "test", "depends_on": {"macros": ["macro.dbt.test_unique", "macro.dbt.get_where_subquery"], "nodes": ["model.zendesk.zendesk__ticket_metrics"]}, "config": {"enabled": true, "alias": null, "schema": "dbt_test__audit", "database": null, "tags": [], "meta": {}, "materialized": "test", "severity": "ERROR", "store_failures": null, "where": null, "limit": null, "fail_calc": "count(*)", "warn_if": "!= 0", "error_if": "!= 0"}, "database": "bq-project", "schema": "dbt_joe_dbt_test__audit", "fqn": ["zendesk", "unique_zendesk__ticket_metrics_ticket_id"], "unique_id": "test.zendesk.unique_zendesk__ticket_metrics_ticket_id.f3dc8eba5c", "package_name": "zendesk", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/zendesk", "path": "unique_zendesk__ticket_metrics_ticket_id.sql", "original_file_path": "models/zendesk.yml", "name": "unique_zendesk__ticket_metrics_ticket_id", "alias": "unique_zendesk__ticket_metrics_ticket_id", "checksum": {"name": "none", "checksum": ""}, "tags": [], "refs": [["zendesk__ticket_metrics"]], "sources": [], "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "compiled_path": "target/compiled/zendesk/models/zendesk.yml/unique_zendesk__ticket_metrics_ticket_id.sql", "build_path": null, "deferred": false, "unrendered_config": {}, "created_at": 1647014737.9264178, "compiled_sql": "\n    \n    \n\nwith dbt_test__target as (\n  \n  select ticket_id as unique_field\n  from `bq-project`.`dbt_joe_zendesk_docs`.`zendesk__ticket_metrics`\n  where ticket_id is not null\n  \n)\n\nselect\n    unique_field,\n    count(*) as n_records\n\nfrom dbt_test__target\ngroup by unique_field\nhaving count(*) > 1\n\n\n", "extra_ctes_injected": true, "extra_ctes": [], "relation_name": null, "column_name": "ticket_id", "file_key_name": "models.zendesk__ticket_metrics"}, "test.zendesk.not_null_zendesk__ticket_metrics_ticket_id.3466b76bbd": {"raw_sql": "{{ test_not_null(**_dbt_generic_test_kwargs) }}", "test_metadata": {"name": "not_null", "kwargs": {"column_name": "ticket_id", "model": "{{ get_where_subquery(ref('zendesk__ticket_metrics')) }}"}, "namespace": null}, "compiled": true, "resource_type": "test", "depends_on": {"macros": ["macro.dbt.test_not_null", "macro.dbt.get_where_subquery"], "nodes": ["model.zendesk.zendesk__ticket_metrics"]}, "config": {"enabled": true, "alias": null, "schema": "dbt_test__audit", "database": null, "tags": [], "meta": {}, "materialized": "test", "severity": "ERROR", "store_failures": null, "where": null, "limit": null, "fail_calc": "count(*)", "warn_if": "!= 0", "error_if": "!= 0"}, "database": "bq-project", "schema": "dbt_joe_dbt_test__audit", "fqn": ["zendesk", "not_null_zendesk__ticket_metrics_ticket_id"], "unique_id": "test.zendesk.not_null_zendesk__ticket_metrics_ticket_id.3466b76bbd", "package_name": "zendesk", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/zendesk", "path": "not_null_zendesk__ticket_metrics_ticket_id.sql", "original_file_path": "models/zendesk.yml", "name": "not_null_zendesk__ticket_metrics_ticket_id", "alias": "not_null_zendesk__ticket_metrics_ticket_id", "checksum": {"name": "none", "checksum": ""}, "tags": [], "refs": [["zendesk__ticket_metrics"]], "sources": [], "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "compiled_path": "target/compiled/zendesk/models/zendesk.yml/not_null_zendesk__ticket_metrics_ticket_id.sql", "build_path": null, "deferred": false, "unrendered_config": {}, "created_at": 1647014737.928635, "compiled_sql": "\n    \n    \n\nselect *\nfrom `bq-project`.`dbt_joe_zendesk_docs`.`zendesk__ticket_metrics`\nwhere ticket_id is null\n\n\n", "extra_ctes_injected": true, "extra_ctes": [], "relation_name": null, "column_name": "ticket_id", "file_key_name": "models.zendesk__ticket_metrics"}, "test.zendesk_source.unique_stg_zendesk__ticket_ticket_id.4be7124521": {"raw_sql": "{{ test_unique(**_dbt_generic_test_kwargs) }}", "test_metadata": {"name": "unique", "kwargs": {"column_name": "ticket_id", "model": "{{ get_where_subquery(ref('stg_zendesk__ticket')) }}"}, "namespace": null}, "compiled": true, "resource_type": "test", "depends_on": {"macros": ["macro.dbt.test_unique", "macro.dbt.get_where_subquery"], "nodes": ["model.zendesk_source.stg_zendesk__ticket"]}, "config": {"enabled": true, "alias": null, "schema": "dbt_test__audit", "database": null, "tags": [], "meta": {}, "materialized": "test", "severity": "ERROR", "store_failures": null, "where": null, "limit": null, "fail_calc": "count(*)", "warn_if": "!= 0", "error_if": "!= 0"}, "database": "bq-project", "schema": "dbt_joe_dbt_test__audit", "fqn": ["zendesk_source", "unique_stg_zendesk__ticket_ticket_id"], "unique_id": "test.zendesk_source.unique_stg_zendesk__ticket_ticket_id.4be7124521", "package_name": "zendesk_source", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/zendesk_source", "path": "unique_stg_zendesk__ticket_ticket_id.sql", "original_file_path": "models/stg_zendesk.yml", "name": "unique_stg_zendesk__ticket_ticket_id", "alias": "unique_stg_zendesk__ticket_ticket_id", "checksum": {"name": "none", "checksum": ""}, "tags": [], "refs": [["stg_zendesk__ticket"]], "sources": [], "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "compiled_path": "target/compiled/zendesk_source/models/stg_zendesk.yml/unique_stg_zendesk__ticket_ticket_id.sql", "build_path": null, "deferred": false, "unrendered_config": {}, "created_at": 1647014737.977077, "compiled_sql": "\n    \n    \n\nwith dbt_test__target as (\n  \n  select ticket_id as unique_field\n  from `bq-project`.`dbt_joe_zendesk_docs`.`stg_zendesk__ticket`\n  where ticket_id is not null\n  \n)\n\nselect\n    unique_field,\n    count(*) as n_records\n\nfrom dbt_test__target\ngroup by unique_field\nhaving count(*) > 1\n\n\n", "extra_ctes_injected": true, "extra_ctes": [], "relation_name": null, "column_name": "ticket_id", "file_key_name": "models.stg_zendesk__ticket"}, "test.zendesk_source.not_null_stg_zendesk__ticket_ticket_id.a8229e6981": {"raw_sql": "{{ test_not_null(**_dbt_generic_test_kwargs) }}", "test_metadata": {"name": "not_null", "kwargs": {"column_name": "ticket_id", "model": "{{ get_where_subquery(ref('stg_zendesk__ticket')) }}"}, "namespace": null}, "compiled": true, "resource_type": "test", "depends_on": {"macros": ["macro.dbt.test_not_null", "macro.dbt.get_where_subquery"], "nodes": ["model.zendesk_source.stg_zendesk__ticket"]}, "config": {"enabled": true, "alias": null, "schema": "dbt_test__audit", "database": null, "tags": [], "meta": {}, "materialized": "test", "severity": "ERROR", "store_failures": null, "where": null, "limit": null, "fail_calc": "count(*)", "warn_if": "!= 0", "error_if": "!= 0"}, "database": "bq-project", "schema": "dbt_joe_dbt_test__audit", "fqn": ["zendesk_source", "not_null_stg_zendesk__ticket_ticket_id"], "unique_id": "test.zendesk_source.not_null_stg_zendesk__ticket_ticket_id.a8229e6981", "package_name": "zendesk_source", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/zendesk_source", "path": "not_null_stg_zendesk__ticket_ticket_id.sql", "original_file_path": "models/stg_zendesk.yml", "name": "not_null_stg_zendesk__ticket_ticket_id", "alias": "not_null_stg_zendesk__ticket_ticket_id", "checksum": {"name": "none", "checksum": ""}, "tags": [], "refs": [["stg_zendesk__ticket"]], "sources": [], "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "compiled_path": "target/compiled/zendesk_source/models/stg_zendesk.yml/not_null_stg_zendesk__ticket_ticket_id.sql", "build_path": null, "deferred": false, "unrendered_config": {}, "created_at": 1647014737.9790049, "compiled_sql": "\n    \n    \n\nselect *\nfrom `bq-project`.`dbt_joe_zendesk_docs`.`stg_zendesk__ticket`\nwhere ticket_id is null\n\n\n", "extra_ctes_injected": true, "extra_ctes": [], "relation_name": null, "column_name": "ticket_id", "file_key_name": "models.stg_zendesk__ticket"}, "test.zendesk_source.unique_stg_zendesk__brand_brand_id.fdf8e23c9e": {"raw_sql": "{{ test_unique(**_dbt_generic_test_kwargs) }}", "test_metadata": {"name": "unique", "kwargs": {"column_name": "brand_id", "model": "{{ get_where_subquery(ref('stg_zendesk__brand')) }}"}, "namespace": null}, "compiled": true, "resource_type": "test", "depends_on": {"macros": ["macro.dbt.test_unique", "macro.dbt.get_where_subquery"], "nodes": ["model.zendesk_source.stg_zendesk__brand"]}, "config": {"enabled": true, "alias": null, "schema": "dbt_test__audit", "database": null, "tags": [], "meta": {}, "materialized": "test", "severity": "ERROR", "store_failures": null, "where": null, "limit": null, "fail_calc": "count(*)", "warn_if": "!= 0", "error_if": "!= 0"}, "database": "bq-project", "schema": "dbt_joe_dbt_test__audit", "fqn": ["zendesk_source", "unique_stg_zendesk__brand_brand_id"], "unique_id": "test.zendesk_source.unique_stg_zendesk__brand_brand_id.fdf8e23c9e", "package_name": "zendesk_source", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/zendesk_source", "path": "unique_stg_zendesk__brand_brand_id.sql", "original_file_path": "models/stg_zendesk.yml", "name": "unique_stg_zendesk__brand_brand_id", "alias": "unique_stg_zendesk__brand_brand_id", "checksum": {"name": "none", "checksum": ""}, "tags": [], "refs": [["stg_zendesk__brand"]], "sources": [], "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "compiled_path": "target/compiled/zendesk_source/models/stg_zendesk.yml/unique_stg_zendesk__brand_brand_id.sql", "build_path": null, "deferred": false, "unrendered_config": {}, "created_at": 1647014737.981054, "compiled_sql": "\n    \n    \n\nwith dbt_test__target as (\n  \n  select brand_id as unique_field\n  from `bq-project`.`dbt_joe_zendesk_docs`.`stg_zendesk__brand`\n  where brand_id is not null\n  \n)\n\nselect\n    unique_field,\n    count(*) as n_records\n\nfrom dbt_test__target\ngroup by unique_field\nhaving count(*) > 1\n\n\n", "extra_ctes_injected": true, "extra_ctes": [], "relation_name": null, "column_name": "brand_id", "file_key_name": "models.stg_zendesk__brand"}, "test.zendesk_source.not_null_stg_zendesk__brand_brand_id.a2419e1741": {"raw_sql": "{{ test_not_null(**_dbt_generic_test_kwargs) }}", "test_metadata": {"name": "not_null", "kwargs": {"column_name": "brand_id", "model": "{{ get_where_subquery(ref('stg_zendesk__brand')) }}"}, "namespace": null}, "compiled": true, "resource_type": "test", "depends_on": {"macros": ["macro.dbt.test_not_null", "macro.dbt.get_where_subquery"], "nodes": ["model.zendesk_source.stg_zendesk__brand"]}, "config": {"enabled": true, "alias": null, "schema": "dbt_test__audit", "database": null, "tags": [], "meta": {}, "materialized": "test", "severity": "ERROR", "store_failures": null, "where": null, "limit": null, "fail_calc": "count(*)", "warn_if": "!= 0", "error_if": "!= 0"}, "database": "bq-project", "schema": "dbt_joe_dbt_test__audit", "fqn": ["zendesk_source", "not_null_stg_zendesk__brand_brand_id"], "unique_id": "test.zendesk_source.not_null_stg_zendesk__brand_brand_id.a2419e1741", "package_name": "zendesk_source", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/zendesk_source", "path": "not_null_stg_zendesk__brand_brand_id.sql", "original_file_path": "models/stg_zendesk.yml", "name": "not_null_stg_zendesk__brand_brand_id", "alias": "not_null_stg_zendesk__brand_brand_id", "checksum": {"name": "none", "checksum": ""}, "tags": [], "refs": [["stg_zendesk__brand"]], "sources": [], "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "compiled_path": "target/compiled/zendesk_source/models/stg_zendesk.yml/not_null_stg_zendesk__brand_brand_id.sql", "build_path": null, "deferred": false, "unrendered_config": {}, "created_at": 1647014737.98288, "compiled_sql": "\n    \n    \n\nselect *\nfrom `bq-project`.`dbt_joe_zendesk_docs`.`stg_zendesk__brand`\nwhere brand_id is null\n\n\n", "extra_ctes_injected": true, "extra_ctes": [], "relation_name": null, "column_name": "brand_id", "file_key_name": "models.stg_zendesk__brand"}, "test.zendesk_source.not_null_stg_zendesk__domain_name_organization_id.a2b5ff8fd3": {"raw_sql": "{{ test_not_null(**_dbt_generic_test_kwargs) }}", "test_metadata": {"name": "not_null", "kwargs": {"column_name": "organization_id", "model": "{{ get_where_subquery(ref('stg_zendesk__domain_name')) }}"}, "namespace": null}, "resource_type": "test", "depends_on": {"macros": ["macro.dbt.test_not_null"], "nodes": []}, "config": {"enabled": false, "alias": null, "schema": "dbt_test__audit", "database": null, "tags": [], "meta": {}, "materialized": "test", "severity": "ERROR", "store_failures": null, "where": null, "limit": null, "fail_calc": "count(*)", "warn_if": "!= 0", "error_if": "!= 0"}, "database": "bq-project", "schema": "dbt_joe_dbt_test__audit", "fqn": ["zendesk_source", "not_null_stg_zendesk__domain_name_organization_id"], "unique_id": "test.zendesk_source.not_null_stg_zendesk__domain_name_organization_id.a2b5ff8fd3", "package_name": "zendesk_source", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/zendesk_source", "path": "not_null_stg_zendesk__domain_name_organization_id.sql", "original_file_path": "models/stg_zendesk.yml", "name": "not_null_stg_zendesk__domain_name_organization_id", "alias": "not_null_stg_zendesk__domain_name_organization_id", "checksum": {"name": "none", "checksum": ""}, "tags": [], "refs": [["stg_zendesk__domain_name"]], "sources": [], "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "compiled_path": null, "build_path": null, "deferred": false, "unrendered_config": {}, "created_at": 1647014737.98466, "column_name": "organization_id", "file_key_name": "models.stg_zendesk__domain_name"}, "test.zendesk_source.unique_stg_zendesk__group_group_id.f0658dabcd": {"raw_sql": "{{ test_unique(**_dbt_generic_test_kwargs) }}", "test_metadata": {"name": "unique", "kwargs": {"column_name": "group_id", "model": "{{ get_where_subquery(ref('stg_zendesk__group')) }}"}, "namespace": null}, "compiled": true, "resource_type": "test", "depends_on": {"macros": ["macro.dbt.test_unique", "macro.dbt.get_where_subquery"], "nodes": ["model.zendesk_source.stg_zendesk__group"]}, "config": {"enabled": true, "alias": null, "schema": "dbt_test__audit", "database": null, "tags": [], "meta": {}, "materialized": "test", "severity": "ERROR", "store_failures": null, "where": null, "limit": null, "fail_calc": "count(*)", "warn_if": "!= 0", "error_if": "!= 0"}, "database": "bq-project", "schema": "dbt_joe_dbt_test__audit", "fqn": ["zendesk_source", "unique_stg_zendesk__group_group_id"], "unique_id": "test.zendesk_source.unique_stg_zendesk__group_group_id.f0658dabcd", "package_name": "zendesk_source", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/zendesk_source", "path": "unique_stg_zendesk__group_group_id.sql", "original_file_path": "models/stg_zendesk.yml", "name": "unique_stg_zendesk__group_group_id", "alias": "unique_stg_zendesk__group_group_id", "checksum": {"name": "none", "checksum": ""}, "tags": [], "refs": [["stg_zendesk__group"]], "sources": [], "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "compiled_path": "target/compiled/zendesk_source/models/stg_zendesk.yml/unique_stg_zendesk__group_group_id.sql", "build_path": null, "deferred": false, "unrendered_config": {}, "created_at": 1647014737.986442, "compiled_sql": "\n    \n    \n\nwith dbt_test__target as (\n  \n  select group_id as unique_field\n  from `bq-project`.`dbt_joe_zendesk_docs`.`stg_zendesk__group`\n  where group_id is not null\n  \n)\n\nselect\n    unique_field,\n    count(*) as n_records\n\nfrom dbt_test__target\ngroup by unique_field\nhaving count(*) > 1\n\n\n", "extra_ctes_injected": true, "extra_ctes": [], "relation_name": null, "column_name": "group_id", "file_key_name": "models.stg_zendesk__group"}, "test.zendesk_source.not_null_stg_zendesk__group_group_id.7659ed83ec": {"raw_sql": "{{ test_not_null(**_dbt_generic_test_kwargs) }}", "test_metadata": {"name": "not_null", "kwargs": {"column_name": "group_id", "model": "{{ get_where_subquery(ref('stg_zendesk__group')) }}"}, "namespace": null}, "compiled": true, "resource_type": "test", "depends_on": {"macros": ["macro.dbt.test_not_null", "macro.dbt.get_where_subquery"], "nodes": ["model.zendesk_source.stg_zendesk__group"]}, "config": {"enabled": true, "alias": null, "schema": "dbt_test__audit", "database": null, "tags": [], "meta": {}, "materialized": "test", "severity": "ERROR", "store_failures": null, "where": null, "limit": null, "fail_calc": "count(*)", "warn_if": "!= 0", "error_if": "!= 0"}, "database": "bq-project", "schema": "dbt_joe_dbt_test__audit", "fqn": ["zendesk_source", "not_null_stg_zendesk__group_group_id"], "unique_id": "test.zendesk_source.not_null_stg_zendesk__group_group_id.7659ed83ec", "package_name": "zendesk_source", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/zendesk_source", "path": "not_null_stg_zendesk__group_group_id.sql", "original_file_path": "models/stg_zendesk.yml", "name": "not_null_stg_zendesk__group_group_id", "alias": "not_null_stg_zendesk__group_group_id", "checksum": {"name": "none", "checksum": ""}, "tags": [], "refs": [["stg_zendesk__group"]], "sources": [], "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "compiled_path": "target/compiled/zendesk_source/models/stg_zendesk.yml/not_null_stg_zendesk__group_group_id.sql", "build_path": null, "deferred": false, "unrendered_config": {}, "created_at": 1647014737.988527, "compiled_sql": "\n    \n    \n\nselect *\nfrom `bq-project`.`dbt_joe_zendesk_docs`.`stg_zendesk__group`\nwhere group_id is null\n\n\n", "extra_ctes_injected": true, "extra_ctes": [], "relation_name": null, "column_name": "group_id", "file_key_name": "models.stg_zendesk__group"}, "test.zendesk_source.unique_stg_zendesk__organization_organization_id.152be1ab31": {"raw_sql": "{{ test_unique(**_dbt_generic_test_kwargs) }}", "test_metadata": {"name": "unique", "kwargs": {"column_name": "organization_id", "model": "{{ get_where_subquery(ref('stg_zendesk__organization')) }}"}, "namespace": null}, "compiled": true, "resource_type": "test", "depends_on": {"macros": ["macro.dbt.test_unique", "macro.dbt.get_where_subquery"], "nodes": ["model.zendesk_source.stg_zendesk__organization"]}, "config": {"enabled": true, "alias": null, "schema": "dbt_test__audit", "database": null, "tags": [], "meta": {}, "materialized": "test", "severity": "ERROR", "store_failures": null, "where": null, "limit": null, "fail_calc": "count(*)", "warn_if": "!= 0", "error_if": "!= 0"}, "database": "bq-project", "schema": "dbt_joe_dbt_test__audit", "fqn": ["zendesk_source", "unique_stg_zendesk__organization_organization_id"], "unique_id": "test.zendesk_source.unique_stg_zendesk__organization_organization_id.152be1ab31", "package_name": "zendesk_source", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/zendesk_source", "path": "unique_stg_zendesk__organization_organization_id.sql", "original_file_path": "models/stg_zendesk.yml", "name": "unique_stg_zendesk__organization_organization_id", "alias": "unique_stg_zendesk__organization_organization_id", "checksum": {"name": "none", "checksum": ""}, "tags": [], "refs": [["stg_zendesk__organization"]], "sources": [], "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "compiled_path": "target/compiled/zendesk_source/models/stg_zendesk.yml/unique_stg_zendesk__organization_organization_id.sql", "build_path": null, "deferred": false, "unrendered_config": {}, "created_at": 1647014737.990405, "compiled_sql": "\n    \n    \n\nwith dbt_test__target as (\n  \n  select organization_id as unique_field\n  from `bq-project`.`dbt_joe_zendesk_docs`.`stg_zendesk__organization`\n  where organization_id is not null\n  \n)\n\nselect\n    unique_field,\n    count(*) as n_records\n\nfrom dbt_test__target\ngroup by unique_field\nhaving count(*) > 1\n\n\n", "extra_ctes_injected": true, "extra_ctes": [], "relation_name": null, "column_name": "organization_id", "file_key_name": "models.stg_zendesk__organization"}, "test.zendesk_source.not_null_stg_zendesk__organization_organization_id.de7b98c06a": {"raw_sql": "{{ test_not_null(**_dbt_generic_test_kwargs) }}", "test_metadata": {"name": "not_null", "kwargs": {"column_name": "organization_id", "model": "{{ get_where_subquery(ref('stg_zendesk__organization')) }}"}, "namespace": null}, "compiled": true, "resource_type": "test", "depends_on": {"macros": ["macro.dbt.test_not_null", "macro.dbt.get_where_subquery"], "nodes": ["model.zendesk_source.stg_zendesk__organization"]}, "config": {"enabled": true, "alias": null, "schema": "dbt_test__audit", "database": null, "tags": [], "meta": {}, "materialized": "test", "severity": "ERROR", "store_failures": null, "where": null, "limit": null, "fail_calc": "count(*)", "warn_if": "!= 0", "error_if": "!= 0"}, "database": "bq-project", "schema": "dbt_joe_dbt_test__audit", "fqn": ["zendesk_source", "not_null_stg_zendesk__organization_organization_id"], "unique_id": "test.zendesk_source.not_null_stg_zendesk__organization_organization_id.de7b98c06a", "package_name": "zendesk_source", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/zendesk_source", "path": "not_null_stg_zendesk__organization_organization_id.sql", "original_file_path": "models/stg_zendesk.yml", "name": "not_null_stg_zendesk__organization_organization_id", "alias": "not_null_stg_zendesk__organization_organization_id", "checksum": {"name": "none", "checksum": ""}, "tags": [], "refs": [["stg_zendesk__organization"]], "sources": [], "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "compiled_path": "target/compiled/zendesk_source/models/stg_zendesk.yml/not_null_stg_zendesk__organization_organization_id.sql", "build_path": null, "deferred": false, "unrendered_config": {}, "created_at": 1647014737.992191, "compiled_sql": "\n    \n    \n\nselect *\nfrom `bq-project`.`dbt_joe_zendesk_docs`.`stg_zendesk__organization`\nwhere organization_id is null\n\n\n", "extra_ctes_injected": true, "extra_ctes": [], "relation_name": null, "column_name": "organization_id", "file_key_name": "models.stg_zendesk__organization"}, "test.zendesk_source.unique_stg_zendesk__ticket_comment_ticket_comment_id.ba353330cd": {"raw_sql": "{{ test_unique(**_dbt_generic_test_kwargs) }}", "test_metadata": {"name": "unique", "kwargs": {"column_name": "ticket_comment_id", "model": "{{ get_where_subquery(ref('stg_zendesk__ticket_comment')) }}"}, "namespace": null}, "compiled": true, "resource_type": "test", "depends_on": {"macros": ["macro.dbt.test_unique", "macro.dbt.get_where_subquery"], "nodes": ["model.zendesk_source.stg_zendesk__ticket_comment"]}, "config": {"enabled": true, "alias": null, "schema": "dbt_test__audit", "database": null, "tags": [], "meta": {}, "materialized": "test", "severity": "ERROR", "store_failures": null, "where": null, "limit": null, "fail_calc": "count(*)", "warn_if": "!= 0", "error_if": "!= 0"}, "database": "bq-project", "schema": "dbt_joe_dbt_test__audit", "fqn": ["zendesk_source", "unique_stg_zendesk__ticket_comment_ticket_comment_id"], "unique_id": "test.zendesk_source.unique_stg_zendesk__ticket_comment_ticket_comment_id.ba353330cd", "package_name": "zendesk_source", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/zendesk_source", "path": "unique_stg_zendesk__ticket_comment_ticket_comment_id.sql", "original_file_path": "models/stg_zendesk.yml", "name": "unique_stg_zendesk__ticket_comment_ticket_comment_id", "alias": "unique_stg_zendesk__ticket_comment_ticket_comment_id", "checksum": {"name": "none", "checksum": ""}, "tags": [], "refs": [["stg_zendesk__ticket_comment"]], "sources": [], "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "compiled_path": "target/compiled/zendesk_source/models/stg_zendesk.yml/unique_stg_zendesk__ticket_comment_ticket_comment_id.sql", "build_path": null, "deferred": false, "unrendered_config": {}, "created_at": 1647014737.993973, "compiled_sql": "\n    \n    \n\nwith dbt_test__target as (\n  \n  select ticket_comment_id as unique_field\n  from `bq-project`.`dbt_joe_zendesk_docs`.`stg_zendesk__ticket_comment`\n  where ticket_comment_id is not null\n  \n)\n\nselect\n    unique_field,\n    count(*) as n_records\n\nfrom dbt_test__target\ngroup by unique_field\nhaving count(*) > 1\n\n\n", "extra_ctes_injected": true, "extra_ctes": [], "relation_name": null, "column_name": "ticket_comment_id", "file_key_name": "models.stg_zendesk__ticket_comment"}, "test.zendesk_source.not_null_stg_zendesk__ticket_comment_ticket_comment_id.b821f4a606": {"raw_sql": "{{ test_not_null(**_dbt_generic_test_kwargs) }}", "test_metadata": {"name": "not_null", "kwargs": {"column_name": "ticket_comment_id", "model": "{{ get_where_subquery(ref('stg_zendesk__ticket_comment')) }}"}, "namespace": null}, "compiled": true, "resource_type": "test", "depends_on": {"macros": ["macro.dbt.test_not_null", "macro.dbt.get_where_subquery"], "nodes": ["model.zendesk_source.stg_zendesk__ticket_comment"]}, "config": {"enabled": true, "alias": null, "schema": "dbt_test__audit", "database": null, "tags": [], "meta": {}, "materialized": "test", "severity": "ERROR", "store_failures": null, "where": null, "limit": null, "fail_calc": "count(*)", "warn_if": "!= 0", "error_if": "!= 0"}, "database": "bq-project", "schema": "dbt_joe_dbt_test__audit", "fqn": ["zendesk_source", "not_null_stg_zendesk__ticket_comment_ticket_comment_id"], "unique_id": "test.zendesk_source.not_null_stg_zendesk__ticket_comment_ticket_comment_id.b821f4a606", "package_name": "zendesk_source", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/zendesk_source", "path": "not_null_stg_zendesk__ticket_comment_ticket_comment_id.sql", "original_file_path": "models/stg_zendesk.yml", "name": "not_null_stg_zendesk__ticket_comment_ticket_comment_id", "alias": "not_null_stg_zendesk__ticket_comment_ticket_comment_id", "checksum": {"name": "none", "checksum": ""}, "tags": [], "refs": [["stg_zendesk__ticket_comment"]], "sources": [], "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "compiled_path": "target/compiled/zendesk_source/models/stg_zendesk.yml/not_null_stg_zendesk__ticket_comment_ticket_comment_id.sql", "build_path": null, "deferred": false, "unrendered_config": {}, "created_at": 1647014737.996446, "compiled_sql": "\n    \n    \n\nselect *\nfrom `bq-project`.`dbt_joe_zendesk_docs`.`stg_zendesk__ticket_comment`\nwhere ticket_comment_id is null\n\n\n", "extra_ctes_injected": true, "extra_ctes": [], "relation_name": null, "column_name": "ticket_comment_id", "file_key_name": "models.stg_zendesk__ticket_comment"}, "test.zendesk_source.unique_stg_zendesk__user_user_id.3d3e346b11": {"raw_sql": "{{ test_unique(**_dbt_generic_test_kwargs) }}", "test_metadata": {"name": "unique", "kwargs": {"column_name": "user_id", "model": "{{ get_where_subquery(ref('stg_zendesk__user')) }}"}, "namespace": null}, "compiled": true, "resource_type": "test", "depends_on": {"macros": ["macro.dbt.test_unique", "macro.dbt.get_where_subquery"], "nodes": ["model.zendesk_source.stg_zendesk__user"]}, "config": {"enabled": true, "alias": null, "schema": "dbt_test__audit", "database": null, "tags": [], "meta": {}, "materialized": "test", "severity": "ERROR", "store_failures": null, "where": null, "limit": null, "fail_calc": "count(*)", "warn_if": "!= 0", "error_if": "!= 0"}, "database": "bq-project", "schema": "dbt_joe_dbt_test__audit", "fqn": ["zendesk_source", "unique_stg_zendesk__user_user_id"], "unique_id": "test.zendesk_source.unique_stg_zendesk__user_user_id.3d3e346b11", "package_name": "zendesk_source", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/zendesk_source", "path": "unique_stg_zendesk__user_user_id.sql", "original_file_path": "models/stg_zendesk.yml", "name": "unique_stg_zendesk__user_user_id", "alias": "unique_stg_zendesk__user_user_id", "checksum": {"name": "none", "checksum": ""}, "tags": [], "refs": [["stg_zendesk__user"]], "sources": [], "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "compiled_path": "target/compiled/zendesk_source/models/stg_zendesk.yml/unique_stg_zendesk__user_user_id.sql", "build_path": null, "deferred": false, "unrendered_config": {}, "created_at": 1647014737.998234, "compiled_sql": "\n    \n    \n\nwith dbt_test__target as (\n  \n  select user_id as unique_field\n  from `bq-project`.`dbt_joe_zendesk_docs`.`stg_zendesk__user`\n  where user_id is not null\n  \n)\n\nselect\n    unique_field,\n    count(*) as n_records\n\nfrom dbt_test__target\ngroup by unique_field\nhaving count(*) > 1\n\n\n", "extra_ctes_injected": true, "extra_ctes": [], "relation_name": null, "column_name": "user_id", "file_key_name": "models.stg_zendesk__user"}, "test.zendesk_source.not_null_stg_zendesk__user_user_id.102d572926": {"raw_sql": "{{ test_not_null(**_dbt_generic_test_kwargs) }}", "test_metadata": {"name": "not_null", "kwargs": {"column_name": "user_id", "model": "{{ get_where_subquery(ref('stg_zendesk__user')) }}"}, "namespace": null}, "compiled": true, "resource_type": "test", "depends_on": {"macros": ["macro.dbt.test_not_null", "macro.dbt.get_where_subquery"], "nodes": ["model.zendesk_source.stg_zendesk__user"]}, "config": {"enabled": true, "alias": null, "schema": "dbt_test__audit", "database": null, "tags": [], "meta": {}, "materialized": "test", "severity": "ERROR", "store_failures": null, "where": null, "limit": null, "fail_calc": "count(*)", "warn_if": "!= 0", "error_if": "!= 0"}, "database": "bq-project", "schema": "dbt_joe_dbt_test__audit", "fqn": ["zendesk_source", "not_null_stg_zendesk__user_user_id"], "unique_id": "test.zendesk_source.not_null_stg_zendesk__user_user_id.102d572926", "package_name": "zendesk_source", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/zendesk_source", "path": "not_null_stg_zendesk__user_user_id.sql", "original_file_path": "models/stg_zendesk.yml", "name": "not_null_stg_zendesk__user_user_id", "alias": "not_null_stg_zendesk__user_user_id", "checksum": {"name": "none", "checksum": ""}, "tags": [], "refs": [["stg_zendesk__user"]], "sources": [], "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "compiled_path": "target/compiled/zendesk_source/models/stg_zendesk.yml/not_null_stg_zendesk__user_user_id.sql", "build_path": null, "deferred": false, "unrendered_config": {}, "created_at": 1647014738.0000598, "compiled_sql": "\n    \n    \n\nselect *\nfrom `bq-project`.`dbt_joe_zendesk_docs`.`stg_zendesk__user`\nwhere user_id is null\n\n\n", "extra_ctes_injected": true, "extra_ctes": [], "relation_name": null, "column_name": "user_id", "file_key_name": "models.stg_zendesk__user"}, "test.zendesk_source.not_null_stg_zendesk__ticket_form_history_ticket_form_id.1afe781a17": {"raw_sql": "{{ test_not_null(**_dbt_generic_test_kwargs) }}", "test_metadata": {"name": "not_null", "kwargs": {"column_name": "ticket_form_id", "model": "{{ get_where_subquery(ref('stg_zendesk__ticket_form_history')) }}"}, "namespace": null}, "compiled": true, "resource_type": "test", "depends_on": {"macros": ["macro.dbt.test_not_null", "macro.dbt.get_where_subquery"], "nodes": ["model.zendesk_source.stg_zendesk__ticket_form_history"]}, "config": {"enabled": true, "alias": null, "schema": "dbt_test__audit", "database": null, "tags": [], "meta": {}, "materialized": "test", "severity": "ERROR", "store_failures": null, "where": null, "limit": null, "fail_calc": "count(*)", "warn_if": "!= 0", "error_if": "!= 0"}, "database": "bq-project", "schema": "dbt_joe_dbt_test__audit", "fqn": ["zendesk_source", "not_null_stg_zendesk__ticket_form_history_ticket_form_id"], "unique_id": "test.zendesk_source.not_null_stg_zendesk__ticket_form_history_ticket_form_id.1afe781a17", "package_name": "zendesk_source", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/zendesk_source", "path": "not_null_stg_zendesk__ticket_form_history_ticket_form_id.sql", "original_file_path": "models/stg_zendesk.yml", "name": "not_null_stg_zendesk__ticket_form_history_ticket_form_id", "alias": "not_null_stg_zendesk__ticket_form_history_ticket_form_id", "checksum": {"name": "none", "checksum": ""}, "tags": [], "refs": [["stg_zendesk__ticket_form_history"]], "sources": [], "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "compiled_path": "target/compiled/zendesk_source/models/stg_zendesk.yml/not_null_stg_zendesk__ticket_form_history_ticket_form_id.sql", "build_path": null, "deferred": false, "unrendered_config": {}, "created_at": 1647014738.001837, "compiled_sql": "\n    \n    \n\nselect *\nfrom `bq-project`.`dbt_joe_zendesk_docs`.`stg_zendesk__ticket_form_history`\nwhere ticket_form_id is null\n\n\n", "extra_ctes_injected": true, "extra_ctes": [], "relation_name": null, "column_name": "ticket_form_id", "file_key_name": "models.stg_zendesk__ticket_form_history"}, "test.zendesk_source.dbt_utils_unique_combination_of_columns_stg_zendesk__daylight_time_time_zone__year.88227aef3d": {"raw_sql": "{{ dbt_utils.test_unique_combination_of_columns(**_dbt_generic_test_kwargs) }}{{ config(alias=\"dbt_utils_unique_combination_o_54ab42208165c9c38d3147cec984eab9\") }}", "test_metadata": {"name": "unique_combination_of_columns", "kwargs": {"combination_of_columns": ["time_zone", "year"], "model": "{{ get_where_subquery(ref('stg_zendesk__daylight_time')) }}"}, "namespace": "dbt_utils"}, "compiled": true, "resource_type": "test", "depends_on": {"macros": ["macro.dbt_utils.test_unique_combination_of_columns", "macro.dbt.get_where_subquery"], "nodes": ["model.zendesk_source.stg_zendesk__daylight_time"]}, "config": {"enabled": true, "alias": "dbt_utils_unique_combination_o_54ab42208165c9c38d3147cec984eab9", "schema": "dbt_test__audit", "database": null, "tags": [], "meta": {}, "materialized": "test", "severity": "ERROR", "store_failures": null, "where": null, "limit": null, "fail_calc": "count(*)", "warn_if": "!= 0", "error_if": "!= 0"}, "database": "bq-project", "schema": "dbt_joe_dbt_test__audit", "fqn": ["zendesk_source", "dbt_utils_unique_combination_of_columns_stg_zendesk__daylight_time_time_zone__year"], "unique_id": "test.zendesk_source.dbt_utils_unique_combination_of_columns_stg_zendesk__daylight_time_time_zone__year.88227aef3d", "package_name": "zendesk_source", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/zendesk_source", "path": "dbt_utils_unique_combination_o_54ab42208165c9c38d3147cec984eab9.sql", "original_file_path": "models/stg_zendesk.yml", "name": "dbt_utils_unique_combination_of_columns_stg_zendesk__daylight_time_time_zone__year", "alias": "dbt_utils_unique_combination_o_54ab42208165c9c38d3147cec984eab9", "checksum": {"name": "none", "checksum": ""}, "tags": [], "refs": [["stg_zendesk__daylight_time"]], "sources": [], "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "compiled_path": "target/compiled/zendesk_source/models/stg_zendesk.yml/dbt_utils_unique_combination_o_54ab42208165c9c38d3147cec984eab9.sql", "build_path": null, "deferred": false, "unrendered_config": {"alias": "dbt_utils_unique_combination_o_54ab42208165c9c38d3147cec984eab9"}, "created_at": 1647014738.00384, "compiled_sql": "\n\n\n\n\n\nwith validation_errors as (\n\n    select\n        time_zone, year\n    from `bq-project`.`dbt_joe_zendesk_docs`.`stg_zendesk__daylight_time`\n    group by time_zone, year\n    having count(*) > 1\n\n)\n\nselect *\nfrom validation_errors\n\n\n", "extra_ctes_injected": true, "extra_ctes": [], "relation_name": null, "column_name": null, "file_key_name": "models.stg_zendesk__daylight_time"}, "test.zendesk_source.unique_stg_zendesk__time_zone_time_zone.67995adbaf": {"raw_sql": "{{ test_unique(**_dbt_generic_test_kwargs) }}", "test_metadata": {"name": "unique", "kwargs": {"column_name": "time_zone", "model": "{{ get_where_subquery(ref('stg_zendesk__time_zone')) }}"}, "namespace": null}, "compiled": true, "resource_type": "test", "depends_on": {"macros": ["macro.dbt.test_unique", "macro.dbt.get_where_subquery"], "nodes": ["model.zendesk_source.stg_zendesk__time_zone"]}, "config": {"enabled": true, "alias": null, "schema": "dbt_test__audit", "database": null, "tags": [], "meta": {}, "materialized": "test", "severity": "ERROR", "store_failures": null, "where": null, "limit": null, "fail_calc": "count(*)", "warn_if": "!= 0", "error_if": "!= 0"}, "database": "bq-project", "schema": "dbt_joe_dbt_test__audit", "fqn": ["zendesk_source", "unique_stg_zendesk__time_zone_time_zone"], "unique_id": "test.zendesk_source.unique_stg_zendesk__time_zone_time_zone.67995adbaf", "package_name": "zendesk_source", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/zendesk_source", "path": "unique_stg_zendesk__time_zone_time_zone.sql", "original_file_path": "models/stg_zendesk.yml", "name": "unique_stg_zendesk__time_zone_time_zone", "alias": "unique_stg_zendesk__time_zone_time_zone", "checksum": {"name": "none", "checksum": ""}, "tags": [], "refs": [["stg_zendesk__time_zone"]], "sources": [], "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "compiled_path": "target/compiled/zendesk_source/models/stg_zendesk.yml/unique_stg_zendesk__time_zone_time_zone.sql", "build_path": null, "deferred": false, "unrendered_config": {}, "created_at": 1647014738.017909, "compiled_sql": "\n    \n    \n\nwith dbt_test__target as (\n  \n  select time_zone as unique_field\n  from `bq-project`.`dbt_joe_zendesk_docs`.`stg_zendesk__time_zone`\n  where time_zone is not null\n  \n)\n\nselect\n    unique_field,\n    count(*) as n_records\n\nfrom dbt_test__target\ngroup by unique_field\nhaving count(*) > 1\n\n\n", "extra_ctes_injected": true, "extra_ctes": [], "relation_name": null, "column_name": "time_zone", "file_key_name": "models.stg_zendesk__time_zone"}, "test.zendesk_source.not_null_stg_zendesk__time_zone_time_zone.b25b3452b1": {"raw_sql": "{{ test_not_null(**_dbt_generic_test_kwargs) }}", "test_metadata": {"name": "not_null", "kwargs": {"column_name": "time_zone", "model": "{{ get_where_subquery(ref('stg_zendesk__time_zone')) }}"}, "namespace": null}, "compiled": true, "resource_type": "test", "depends_on": {"macros": ["macro.dbt.test_not_null", "macro.dbt.get_where_subquery"], "nodes": ["model.zendesk_source.stg_zendesk__time_zone"]}, "config": {"enabled": true, "alias": null, "schema": "dbt_test__audit", "database": null, "tags": [], "meta": {}, "materialized": "test", "severity": "ERROR", "store_failures": null, "where": null, "limit": null, "fail_calc": "count(*)", "warn_if": "!= 0", "error_if": "!= 0"}, "database": "bq-project", "schema": "dbt_joe_dbt_test__audit", "fqn": ["zendesk_source", "not_null_stg_zendesk__time_zone_time_zone"], "unique_id": "test.zendesk_source.not_null_stg_zendesk__time_zone_time_zone.b25b3452b1", "package_name": "zendesk_source", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/zendesk_source", "path": "not_null_stg_zendesk__time_zone_time_zone.sql", "original_file_path": "models/stg_zendesk.yml", "name": "not_null_stg_zendesk__time_zone_time_zone", "alias": "not_null_stg_zendesk__time_zone_time_zone", "checksum": {"name": "none", "checksum": ""}, "tags": [], "refs": [["stg_zendesk__time_zone"]], "sources": [], "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "compiled_path": "target/compiled/zendesk_source/models/stg_zendesk.yml/not_null_stg_zendesk__time_zone_time_zone.sql", "build_path": null, "deferred": false, "unrendered_config": {}, "created_at": 1647014738.019721, "compiled_sql": "\n    \n    \n\nselect *\nfrom `bq-project`.`dbt_joe_zendesk_docs`.`stg_zendesk__time_zone`\nwhere time_zone is null\n\n\n", "extra_ctes_injected": true, "extra_ctes": [], "relation_name": null, "column_name": "time_zone", "file_key_name": "models.stg_zendesk__time_zone"}}, "sources": {"source.zendesk_source.zendesk.ticket": {"fqn": ["zendesk_source", "zendesk", "ticket"], "database": "bq-project", "schema": "zendesk", "unique_id": "source.zendesk_source.zendesk.ticket", "package_name": "zendesk_source", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/zendesk_source", "path": "models/src_zendesk.yml", "original_file_path": "models/src_zendesk.yml", "name": "ticket", "source_name": "zendesk", "source_description": "", "loader": "fivetran", "identifier": "ticket", "resource_type": "source", "quoting": {"database": null, "schema": null, "identifier": null, "column": null}, "loaded_at_field": "_fivetran_synced", "freshness": {"warn_after": {"count": 72, "period": "hour"}, "error_after": {"count": 168, "period": "hour"}, "filter": null}, "external": null, "description": "Tickets are the means through which your end users (customers) communicate with agents in Zendesk Support. Tickets can  originate from a number of channels, including email, Help Center, chat, phone call, Twitter, Facebook, or the API.\n", "columns": {"id": {"name": "id", "description": "Automatically assigned when the ticket is created", "meta": {}, "data_type": null, "quote": null, "tags": []}, "url": {"name": "url", "description": "The API url of this ticket", "meta": {}, "data_type": null, "quote": null, "tags": []}, "assignee_id": {"name": "assignee_id", "description": "The agent currently assigned to the ticket", "meta": {}, "data_type": null, "quote": null, "tags": []}, "brand_id": {"name": "brand_id", "description": "Enterprise only. The id of the brand this ticket is associated with", "meta": {}, "data_type": null, "quote": null, "tags": []}, "created_at": {"name": "created_at", "description": "When this record was created", "meta": {}, "data_type": null, "quote": null, "tags": []}, "type": {"name": "type", "description": "The type of this ticket, possible values are problem, incident, question or task", "meta": {}, "data_type": null, "quote": null, "tags": []}, "subject": {"name": "subject", "description": "The value of the subject field for this ticket", "meta": {}, "data_type": null, "quote": null, "tags": []}, "description": {"name": "description", "description": "Read-only first comment on the ticket", "meta": {}, "data_type": null, "quote": null, "tags": []}, "priority": {"name": "priority", "description": "The urgency with which the ticket should be addressed, possible values are urgent, high, normal and low", "meta": {}, "data_type": null, "quote": null, "tags": []}, "status": {"name": "status", "description": "The state of the ticket, possible values are new, open, pending, hold, solved and closed", "meta": {}, "data_type": null, "quote": null, "tags": []}, "recipient": {"name": "recipient", "description": "The original recipient e-mail address of the ticket", "meta": {}, "data_type": null, "quote": null, "tags": []}, "requester_id": {"name": "requester_id", "description": "The user who requested this ticket", "meta": {}, "data_type": null, "quote": null, "tags": []}, "submitter_id": {"name": "submitter_id", "description": "The user who submitted the ticket. The submitter always becomes the author of the first comment on the ticket", "meta": {}, "data_type": null, "quote": null, "tags": []}, "organization_id": {"name": "organization_id", "description": "The organization of the requester", "meta": {}, "data_type": null, "quote": null, "tags": []}, "group_id": {"name": "group_id", "description": "The group this ticket is assigned to", "meta": {}, "data_type": null, "quote": null, "tags": []}, "due_at": {"name": "due_at", "description": "If this is a ticket of type \"task\" it has a due date. Due date format uses ISO 8601 format.", "meta": {}, "data_type": null, "quote": null, "tags": []}, "ticket_form_id": {"name": "ticket_form_id", "description": "Enterprise only. The id of the ticket form to render for the ticket", "meta": {}, "data_type": null, "quote": null, "tags": []}, "is_public": {"name": "is_public", "description": "Is true if any comments are public, false otherwise", "meta": {}, "data_type": null, "quote": null, "tags": []}, "updated_at": {"name": "updated_at", "description": "When this record last got updated", "meta": {}, "data_type": null, "quote": null, "tags": []}, "via_channel": {"name": "via_channel", "description": "The channel the ticket was created from", "meta": {}, "data_type": null, "quote": null, "tags": []}, "via_source_from_id": {"name": "via_source_from_id", "description": "The channel the ticket was created from", "meta": {}, "data_type": null, "quote": null, "tags": []}, "via_source_from_title": {"name": "via_source_from_title", "description": "The channel the ticket was created from", "meta": {}, "data_type": null, "quote": null, "tags": []}, "via_source_rel": {"name": "via_source_rel", "description": "The rel the ticket was created from", "meta": {}, "data_type": null, "quote": null, "tags": []}, "via_source_to_address": {"name": "via_source_to_address", "description": "The address of the source the ticket was created from", "meta": {}, "data_type": null, "quote": null, "tags": []}, "via_source_to_name": {"name": "via_source_to_name", "description": "The name of the source the ticket was created from", "meta": {}, "data_type": null, "quote": null, "tags": []}}, "meta": {}, "source_meta": {}, "tags": [], "config": {"enabled": true}, "patch_path": null, "unrendered_config": {}, "relation_name": "`bq-project`.`zendesk`.`ticket`", "created_at": 1647014738.081254}, "source.zendesk_source.zendesk.brand": {"fqn": ["zendesk_source", "zendesk", "brand"], "database": "bq-project", "schema": "zendesk", "unique_id": "source.zendesk_source.zendesk.brand", "package_name": "zendesk_source", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/zendesk_source", "path": "models/src_zendesk.yml", "original_file_path": "models/src_zendesk.yml", "name": "brand", "source_name": "zendesk", "source_description": "", "loader": "fivetran", "identifier": "brand", "resource_type": "source", "quoting": {"database": null, "schema": null, "identifier": null, "column": null}, "loaded_at_field": "_fivetran_synced", "freshness": {"warn_after": {"count": 72, "period": "hour"}, "error_after": {"count": 168, "period": "hour"}, "filter": null}, "external": null, "description": "Brands are your customer-facing identities. They might represent multiple products or services, or they  might literally be multiple brands owned and represented by your company.\n", "columns": {"id": {"name": "id", "description": "The ID automatically assigned when the brand is created", "meta": {}, "data_type": null, "quote": null, "tags": []}, "brand_url": {"name": "brand_url", "description": "The url of the brand", "meta": {}, "data_type": null, "quote": null, "tags": []}, "name": {"name": "name", "description": "The name of the brand", "meta": {}, "data_type": null, "quote": null, "tags": []}, "subdomain": {"name": "subdomain", "description": "The subdomain of the brand", "meta": {}, "data_type": null, "quote": null, "tags": []}, "active": {"name": "active", "description": "If the brand is set as active", "meta": {}, "data_type": null, "quote": null, "tags": []}}, "meta": {}, "source_meta": {}, "tags": [], "config": {"enabled": true}, "patch_path": null, "unrendered_config": {}, "relation_name": "`bq-project`.`zendesk`.`brand`", "created_at": 1647014738.081438}, "source.zendesk_source.zendesk.domain_name": {"fqn": ["zendesk_source", "zendesk", "domain_name"], "database": "bq-project", "schema": "zendesk", "unique_id": "source.zendesk_source.zendesk.domain_name", "package_name": "zendesk_source", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/zendesk_source", "path": "models/src_zendesk.yml", "original_file_path": "models/src_zendesk.yml", "name": "domain_name", "source_name": "zendesk", "source_description": "", "loader": "fivetran", "identifier": "domain_name", "resource_type": "source", "quoting": {"database": null, "schema": null, "identifier": null, "column": null}, "loaded_at_field": "_fivetran_synced", "freshness": {"warn_after": {"count": 72, "period": "hour"}, "error_after": {"count": 168, "period": "hour"}, "filter": null}, "external": null, "description": "Domain names associated with an organization. An organization may have multiple domain names.", "columns": {"organization_id": {"name": "organization_id", "description": "Reference to the organization", "meta": {}, "data_type": null, "quote": null, "tags": []}, "domain_name": {"name": "domain_name", "description": "The name of the domain associated with the organization", "meta": {}, "data_type": null, "quote": null, "tags": []}, "index": {"name": "index", "description": "Index number of the domain name associated with the organization", "meta": {}, "data_type": null, "quote": null, "tags": []}}, "meta": {"is_enabled": false}, "source_meta": {}, "tags": [], "config": {"enabled": true}, "patch_path": null, "unrendered_config": {}, "relation_name": "`bq-project`.`zendesk`.`domain_name`", "created_at": 1647014738.0815942}, "source.zendesk_source.zendesk.group": {"fqn": ["zendesk_source", "zendesk", "group"], "database": "bq-project", "schema": "zendesk", "unique_id": "source.zendesk_source.zendesk.group", "package_name": "zendesk_source", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/zendesk_source", "path": "models/src_zendesk.yml", "original_file_path": "models/src_zendesk.yml", "name": "group", "source_name": "zendesk", "source_description": "", "loader": "fivetran", "identifier": "group", "resource_type": "source", "quoting": {"database": null, "schema": null, "identifier": true, "column": null}, "loaded_at_field": "_fivetran_synced", "freshness": null, "external": null, "description": "When support requests arrive in Zendesk Support, they can be assigned to a Group. Groups serve as the core element of ticket workflow; support agents are organized into Groups and tickets can be assigned to a Group only, or to an assigned agent within a Group. A ticket can never be assigned to an agent without also being  assigned to a Group.\n", "columns": {"id": {"name": "id", "description": "Automatically assigned when creating groups", "meta": {}, "data_type": null, "quote": null, "tags": []}, "name": {"name": "name", "description": "The name of the group", "meta": {}, "data_type": null, "quote": null, "tags": []}}, "meta": {}, "source_meta": {}, "tags": [], "config": {"enabled": true}, "patch_path": null, "unrendered_config": {}, "relation_name": "`bq-project`.`zendesk`.`group`", "created_at": 1647014738.0817401}, "source.zendesk_source.zendesk.organization_tag": {"fqn": ["zendesk_source", "zendesk", "organization_tag"], "database": "bq-project", "schema": "zendesk", "unique_id": "source.zendesk_source.zendesk.organization_tag", "package_name": "zendesk_source", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/zendesk_source", "path": "models/src_zendesk.yml", "original_file_path": "models/src_zendesk.yml", "name": "organization_tag", "source_name": "zendesk", "source_description": "", "loader": "fivetran", "identifier": "organization_tag", "resource_type": "source", "quoting": {"database": null, "schema": null, "identifier": null, "column": null}, "loaded_at_field": "_fivetran_synced", "freshness": {"warn_after": {"count": 72, "period": "hour"}, "error_after": {"count": 168, "period": "hour"}, "filter": null}, "external": null, "description": "The tags associated with an organization. An organization may have multiple tags.", "columns": {"organization_id": {"name": "organization_id", "description": "Reference to the organization", "meta": {}, "data_type": null, "quote": null, "tags": []}, "tag": {"name": "tag", "description": "Tag associated with the organization", "meta": {}, "data_type": null, "quote": null, "tags": []}}, "meta": {"is_enabled": false}, "source_meta": {}, "tags": [], "config": {"enabled": true}, "patch_path": null, "unrendered_config": {}, "relation_name": "`bq-project`.`zendesk`.`organization_tag`", "created_at": 1647014738.08189}, "source.zendesk_source.zendesk.organization": {"fqn": ["zendesk_source", "zendesk", "organization"], "database": "bq-project", "schema": "zendesk", "unique_id": "source.zendesk_source.zendesk.organization", "package_name": "zendesk_source", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/zendesk_source", "path": "models/src_zendesk.yml", "original_file_path": "models/src_zendesk.yml", "name": "organization", "source_name": "zendesk", "source_description": "", "loader": "fivetran", "identifier": "organization", "resource_type": "source", "quoting": {"database": null, "schema": null, "identifier": null, "column": null}, "loaded_at_field": "_fivetran_synced", "freshness": null, "external": null, "description": "Just as agents can be segmented into groups in Zendesk Support, your customers (end-users) can be segmented into  organizations. You can manually assign customers to an organization or automatically assign them to an organization  by their email address domain. Organizations can be used in business rules to route tickets to groups of agents or  to send email notifications.\n", "columns": {"id": {"name": "id", "description": "Automatically assigned when the organization is created", "meta": {}, "data_type": null, "quote": null, "tags": []}, "name": {"name": "name", "description": "A unique name for the organization", "meta": {}, "data_type": null, "quote": null, "tags": []}, "details": {"name": "details", "description": "Any details obout the organization, such as the address", "meta": {}, "data_type": null, "quote": null, "tags": []}, "url": {"name": "url", "description": "The API url of this organization", "meta": {}, "data_type": null, "quote": null, "tags": []}, "external_id": {"name": "external_id", "description": "A unique external id to associate organizations to an external record", "meta": {}, "data_type": null, "quote": null, "tags": []}, "created_at": {"name": "created_at", "description": "The time the organization was created", "meta": {}, "data_type": null, "quote": null, "tags": []}, "updated_at": {"name": "updated_at", "description": "The time of the last update of the organization", "meta": {}, "data_type": null, "quote": null, "tags": []}, "domain_names": {"name": "domain_names", "description": "An array of domain names associated with this organization", "meta": {}, "data_type": null, "quote": null, "tags": []}, "notes": {"name": "notes", "description": "Any notes you have about the organization", "meta": {}, "data_type": null, "quote": null, "tags": []}, "group_id": {"name": "group_id", "description": "New tickets from users in this organization are automatically put in this group", "meta": {}, "data_type": null, "quote": null, "tags": []}, "shared_tickets": {"name": "shared_tickets", "description": "End users in this organization are able to see each other's tickets", "meta": {}, "data_type": null, "quote": null, "tags": []}, "shared_comments": {"name": "shared_comments", "description": "End users in this organization are able to see each other's comments on tickets", "meta": {}, "data_type": null, "quote": null, "tags": []}, "tags": {"name": "tags", "description": "The tags of the organization", "meta": {}, "data_type": null, "quote": null, "tags": []}, "organization_fields": {"name": "organization_fields", "description": "Custom fields for this organization", "meta": {}, "data_type": null, "quote": null, "tags": []}}, "meta": {}, "source_meta": {}, "tags": [], "config": {"enabled": true}, "patch_path": null, "unrendered_config": {}, "relation_name": "`bq-project`.`zendesk`.`organization`", "created_at": 1647014738.082052}, "source.zendesk_source.zendesk.ticket_comment": {"fqn": ["zendesk_source", "zendesk", "ticket_comment"], "database": "bq-project", "schema": "zendesk", "unique_id": "source.zendesk_source.zendesk.ticket_comment", "package_name": "zendesk_source", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/zendesk_source", "path": "models/src_zendesk.yml", "original_file_path": "models/src_zendesk.yml", "name": "ticket_comment", "source_name": "zendesk", "source_description": "", "loader": "fivetran", "identifier": "ticket_comment", "resource_type": "source", "quoting": {"database": null, "schema": null, "identifier": null, "column": null}, "loaded_at_field": "_fivetran_synced", "freshness": {"warn_after": {"count": 72, "period": "hour"}, "error_after": {"count": 168, "period": "hour"}, "filter": null}, "external": null, "description": "Ticket comments represent the conversation between requesters, collaborators, and agents. Comments can be public or private.", "columns": {"id": {"name": "id", "description": "Automatically assigned when the comment is created", "meta": {}, "data_type": null, "quote": null, "tags": []}, "body": {"name": "body", "description": "The comment string", "meta": {}, "data_type": null, "quote": null, "tags": []}, "created": {"name": "created", "description": "The time the comment was created", "meta": {}, "data_type": null, "quote": null, "tags": []}, "public": {"name": "public", "description": "Boolean field indicating if the comment is public (true), or if it is an internal note (false)", "meta": {}, "data_type": null, "quote": null, "tags": []}, "ticket_id": {"name": "ticket_id", "description": "The ticket id associated with this comment", "meta": {}, "data_type": null, "quote": null, "tags": []}, "user_id": {"name": "user_id", "description": "The id of the comment author", "meta": {}, "data_type": null, "quote": null, "tags": []}, "facebook_comment": {"name": "facebook_comment", "description": "Boolean field indicating if the comment is a facebook comment", "meta": {}, "data_type": null, "quote": null, "tags": []}, "tweet": {"name": "tweet", "description": "Boolean field indicating if the comment is a twitter tweet", "meta": {}, "data_type": null, "quote": null, "tags": []}, "voice_comment": {"name": "voice_comment", "description": "Boolean field indicating if the comment is a voice comment", "meta": {}, "data_type": null, "quote": null, "tags": []}}, "meta": {}, "source_meta": {}, "tags": [], "config": {"enabled": true}, "patch_path": null, "unrendered_config": {}, "relation_name": "`bq-project`.`zendesk`.`ticket_comment`", "created_at": 1647014738.0822139}, "source.zendesk_source.zendesk.user_tag": {"fqn": ["zendesk_source", "zendesk", "user_tag"], "database": "bq-project", "schema": "zendesk", "unique_id": "source.zendesk_source.zendesk.user_tag", "package_name": "zendesk_source", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/zendesk_source", "path": "models/src_zendesk.yml", "original_file_path": "models/src_zendesk.yml", "name": "user_tag", "source_name": "zendesk", "source_description": "", "loader": "fivetran", "identifier": "user_tag", "resource_type": "source", "quoting": {"database": null, "schema": null, "identifier": null, "column": null}, "loaded_at_field": "_fivetran_synced", "freshness": {"warn_after": {"count": 72, "period": "hour"}, "error_after": {"count": 168, "period": "hour"}, "filter": null}, "external": null, "description": "Table containing all tags associated with a user. Only present if your account has user tagging enabled.", "columns": {"user_id": {"name": "user_id", "description": "Reference to the user", "meta": {}, "data_type": null, "quote": null, "tags": []}, "tag": {"name": "tag", "description": "Tag associated with the user", "meta": {}, "data_type": null, "quote": null, "tags": []}}, "meta": {"is_enabled": false}, "source_meta": {}, "tags": [], "config": {"enabled": true}, "patch_path": null, "unrendered_config": {}, "relation_name": "`bq-project`.`zendesk`.`user_tag`", "created_at": 1647014738.082363}, "source.zendesk_source.zendesk.user": {"fqn": ["zendesk_source", "zendesk", "user"], "database": "bq-project", "schema": "zendesk", "unique_id": "source.zendesk_source.zendesk.user", "package_name": "zendesk_source", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/zendesk_source", "path": "models/src_zendesk.yml", "original_file_path": "models/src_zendesk.yml", "name": "user", "source_name": "zendesk", "source_description": "", "loader": "fivetran", "identifier": "user", "resource_type": "source", "quoting": {"database": null, "schema": null, "identifier": null, "column": null}, "loaded_at_field": "_fivetran_synced", "freshness": null, "external": null, "description": "Zendesk has three types of users, end-users (your customers), agents, and administrators.", "columns": {"id": {"name": "id", "description": "Automatically assigned when the user is created", "meta": {}, "data_type": null, "quote": null, "tags": []}, "email": {"name": "email", "description": "The user's primary email address. *Writeable on create only. On update, a secondary email is added. See Email Address", "meta": {}, "data_type": null, "quote": null, "tags": []}, "name": {"name": "name", "description": "The user's name", "meta": {}, "data_type": null, "quote": null, "tags": []}, "active": {"name": "active", "description": "false if the user has been deleted", "meta": {}, "data_type": null, "quote": null, "tags": []}, "created_at": {"name": "created_at", "description": "The time the user was created", "meta": {}, "data_type": null, "quote": null, "tags": []}, "organization_id": {"name": "organization_id", "description": "The id of the user's organization. If the user has more than one organization memberships, the id of the user's default organization", "meta": {}, "data_type": null, "quote": null, "tags": []}, "role": {"name": "role", "description": "The user's role. Possible values are \"end-user\", \"agent\", or \"admin\"", "meta": {}, "data_type": null, "quote": null, "tags": []}, "time_zone": {"name": "time_zone", "description": "The user's time zone. See Time Zone", "meta": {}, "data_type": null, "quote": null, "tags": []}, "ticket_restriction": {"name": "ticket_restriction", "description": "Specifies which tickets the user has access to. Possible values are organization, groups, assigned, requested and null", "meta": {}, "data_type": null, "quote": null, "tags": []}}, "meta": {}, "source_meta": {}, "tags": [], "config": {"enabled": true}, "patch_path": null, "unrendered_config": {}, "relation_name": "`bq-project`.`zendesk`.`user`", "created_at": 1647014738.082515}, "source.zendesk_source.zendesk.schedule": {"fqn": ["zendesk_source", "zendesk", "schedule"], "database": "bq-project", "schema": "zendesk", "unique_id": "source.zendesk_source.zendesk.schedule", "package_name": "zendesk_source", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/zendesk_source", "path": "models/src_zendesk.yml", "original_file_path": "models/src_zendesk.yml", "name": "schedule", "source_name": "zendesk", "source_description": "", "loader": "fivetran", "identifier": "schedule", "resource_type": "source", "quoting": {"database": null, "schema": null, "identifier": null, "column": null}, "loaded_at_field": "_fivetran_synced", "freshness": null, "external": null, "description": "The support schedules created with different business hours and holidays.", "columns": {"id": {"name": "id", "description": "ID automatically assigned to the schedule upon creation", "meta": {}, "data_type": null, "quote": null, "tags": []}, "name": {"name": "name", "description": "Name of the schedule", "meta": {}, "data_type": null, "quote": null, "tags": []}, "created_at": {"name": "created_at", "description": "Time the schedule was created", "meta": {}, "data_type": null, "quote": null, "tags": []}, "start_time": {"name": "start_time", "description": "Start time of the schedule, in the schedule's time zone.", "meta": {}, "data_type": null, "quote": null, "tags": []}, "end_time": {"name": "end_time", "description": "End time of the schedule, in the schedule's time zone.", "meta": {}, "data_type": null, "quote": null, "tags": []}, "time_zone": {"name": "time_zone", "description": "Timezone in which the schedule operates.", "meta": {}, "data_type": null, "quote": null, "tags": []}}, "meta": {"is_enabled": true}, "source_meta": {}, "tags": [], "config": {"enabled": true}, "patch_path": null, "unrendered_config": {}, "relation_name": "`bq-project`.`zendesk`.`schedule`", "created_at": 1647014738.0826602}, "source.zendesk_source.zendesk.ticket_schedule": {"fqn": ["zendesk_source", "zendesk", "ticket_schedule"], "database": "bq-project", "schema": "zendesk", "unique_id": "source.zendesk_source.zendesk.ticket_schedule", "package_name": "zendesk_source", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/zendesk_source", "path": "models/src_zendesk.yml", "original_file_path": "models/src_zendesk.yml", "name": "ticket_schedule", "source_name": "zendesk", "source_description": "", "loader": "fivetran", "identifier": "ticket_schedule", "resource_type": "source", "quoting": {"database": null, "schema": null, "identifier": null, "column": null}, "loaded_at_field": "_fivetran_synced", "freshness": null, "external": null, "description": "The schedules applied to tickets through a trigger.", "columns": {"ticket_id": {"name": "ticket_id", "description": "The ID of the ticket assigned to the schedule", "meta": {}, "data_type": null, "quote": null, "tags": []}, "created_at": {"name": "created_at", "description": "The time the schedule was assigned to the ticket", "meta": {}, "data_type": null, "quote": null, "tags": []}, "schedule_id": {"name": "schedule_id", "description": "The ID of the schedule applied to the ticket", "meta": {}, "data_type": null, "quote": null, "tags": []}}, "meta": {}, "source_meta": {}, "tags": [], "config": {"enabled": true}, "patch_path": null, "unrendered_config": {}, "relation_name": "`bq-project`.`zendesk`.`ticket_schedule`", "created_at": 1647014738.0828009}, "source.zendesk_source.zendesk.ticket_form_history": {"fqn": ["zendesk_source", "zendesk", "ticket_form_history"], "database": "bq-project", "schema": "zendesk", "unique_id": "source.zendesk_source.zendesk.ticket_form_history", "package_name": "zendesk_source", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/zendesk_source", "path": "models/src_zendesk.yml", "original_file_path": "models/src_zendesk.yml", "name": "ticket_form_history", "source_name": "zendesk", "source_description": "", "loader": "fivetran", "identifier": "ticket_form_history", "resource_type": "source", "quoting": {"database": null, "schema": null, "identifier": null, "column": null}, "loaded_at_field": "_fivetran_synced", "freshness": {"warn_after": {"count": 72, "period": "hour"}, "error_after": {"count": 168, "period": "hour"}, "filter": null}, "external": null, "description": "Ticket forms allow an admin to define a subset of ticket fields for display to both agents and end users.", "columns": {"id": {"name": "id", "description": "Automatically assigned when creating ticket form", "meta": {}, "data_type": null, "quote": null, "tags": []}, "created_at": {"name": "created_at", "description": "The time the ticket form was created", "meta": {}, "data_type": null, "quote": null, "tags": []}, "updated_at": {"name": "updated_at", "description": "The time of the last update of the ticket form", "meta": {}, "data_type": null, "quote": null, "tags": []}, "display_name": {"name": "display_name", "description": "The name of the form that is displayed to an end user", "meta": {}, "data_type": null, "quote": null, "tags": []}, "active": {"name": "active", "description": "If the form is set as active", "meta": {}, "data_type": null, "quote": null, "tags": []}, "name": {"name": "name", "description": "The name of the form", "meta": {}, "data_type": null, "quote": null, "tags": []}}, "meta": {"is_enabled": true}, "source_meta": {}, "tags": [], "config": {"enabled": true}, "patch_path": null, "unrendered_config": {}, "relation_name": "`bq-project`.`zendesk`.`ticket_form_history`", "created_at": 1647014738.082954}, "source.zendesk_source.zendesk.ticket_tag": {"fqn": ["zendesk_source", "zendesk", "ticket_tag"], "database": "bq-project", "schema": "zendesk", "unique_id": "source.zendesk_source.zendesk.ticket_tag", "package_name": "zendesk_source", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/zendesk_source", "path": "models/src_zendesk.yml", "original_file_path": "models/src_zendesk.yml", "name": "ticket_tag", "source_name": "zendesk", "source_description": "", "loader": "fivetran", "identifier": "ticket_tag", "resource_type": "source", "quoting": {"database": null, "schema": null, "identifier": null, "column": null}, "loaded_at_field": "_fivetran_synced", "freshness": null, "external": null, "description": "Tags are words, or combinations of words, you can use to add more context to tickets. The table lists all tags currently associated with a ticket.\n", "columns": {"ticket_id": {"name": "ticket_id", "description": "The ID of the ticket associated with the tag", "meta": {}, "data_type": null, "quote": null, "tags": []}, "tags": {"name": "tags", "description": "The tag, or word(s), associated with the ticket", "meta": {}, "data_type": null, "quote": null, "tags": []}}, "meta": {}, "source_meta": {}, "tags": [], "config": {"enabled": true}, "patch_path": null, "unrendered_config": {}, "relation_name": "`bq-project`.`zendesk`.`ticket_tag`", "created_at": 1647014738.083091}, "source.zendesk_source.zendesk.ticket_field_history": {"fqn": ["zendesk_source", "zendesk", "ticket_field_history"], "database": "bq-project", "schema": "zendesk", "unique_id": "source.zendesk_source.zendesk.ticket_field_history", "package_name": "zendesk_source", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/zendesk_source", "path": "models/src_zendesk.yml", "original_file_path": "models/src_zendesk.yml", "name": "ticket_field_history", "source_name": "zendesk", "source_description": "", "loader": "fivetran", "identifier": "ticket_field_history", "resource_type": "source", "quoting": {"database": null, "schema": null, "identifier": null, "column": null}, "loaded_at_field": "_fivetran_synced", "freshness": null, "external": null, "description": "All fields and field values associated with tickets.", "columns": {"ticket_id": {"name": "ticket_id", "description": "The ID of the ticket associated with the field", "meta": {}, "data_type": null, "quote": null, "tags": []}, "field_name": {"name": "field_name", "description": "The name of the ticket field", "meta": {}, "data_type": null, "quote": null, "tags": []}, "updated": {"name": "updated", "description": "The time the ticket field value was created", "meta": {}, "data_type": null, "quote": null, "tags": []}, "value": {"name": "value", "description": "The value of the field", "meta": {}, "data_type": null, "quote": null, "tags": []}, "user_id": {"name": "user_id", "description": "The id of the user who made the update", "meta": {}, "data_type": null, "quote": null, "tags": []}}, "meta": {}, "source_meta": {}, "tags": [], "config": {"enabled": true}, "patch_path": null, "unrendered_config": {}, "relation_name": "`bq-project`.`zendesk`.`ticket_field_history`", "created_at": 1647014738.083234}, "source.zendesk_source.zendesk.daylight_time": {"fqn": ["zendesk_source", "zendesk", "daylight_time"], "database": "bq-project", "schema": "zendesk", "unique_id": "source.zendesk_source.zendesk.daylight_time", "package_name": "zendesk_source", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/zendesk_source", "path": "models/src_zendesk.yml", "original_file_path": "models/src_zendesk.yml", "name": "daylight_time", "source_name": "zendesk", "source_description": "", "loader": "fivetran", "identifier": "daylight_time", "resource_type": "source", "quoting": {"database": null, "schema": null, "identifier": null, "column": null}, "loaded_at_field": "_fivetran_synced", "freshness": null, "external": null, "description": "Appropriate offsets (from UTC) for timezones that engage or have engaged with Daylight Savings at some point since 1970.\n", "columns": {"daylight_end_utc": {"name": "daylight_end_utc", "description": "UTC timestamp of when Daylight Time ended in this year.", "meta": {}, "data_type": null, "quote": null, "tags": []}, "daylight_offset": {"name": "daylight_offset", "description": "Number of **hours** added during Daylight Savings Time.", "meta": {}, "data_type": null, "quote": null, "tags": []}, "daylight_start_utc": {"name": "daylight_start_utc", "description": "UTC timestamp of when Daylight Time began in this year.", "meta": {}, "data_type": null, "quote": null, "tags": []}, "time_zone": {"name": "time_zone", "description": "Name of the timezone.", "meta": {}, "data_type": null, "quote": null, "tags": []}, "year": {"name": "year", "description": "Year in which daylight savings occurred.", "meta": {}, "data_type": null, "quote": null, "tags": []}}, "meta": {}, "source_meta": {}, "tags": [], "config": {"enabled": true}, "patch_path": null, "unrendered_config": {}, "relation_name": "`bq-project`.`zendesk`.`daylight_time`", "created_at": 1647014738.0833752}, "source.zendesk_source.zendesk.time_zone": {"fqn": ["zendesk_source", "zendesk", "time_zone"], "database": "bq-project", "schema": "zendesk", "unique_id": "source.zendesk_source.zendesk.time_zone", "package_name": "zendesk_source", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/zendesk_source", "path": "models/src_zendesk.yml", "original_file_path": "models/src_zendesk.yml", "name": "time_zone", "source_name": "zendesk", "source_description": "", "loader": "fivetran", "identifier": "time_zone", "resource_type": "source", "quoting": {"database": null, "schema": null, "identifier": null, "column": null}, "loaded_at_field": "_fivetran_synced", "freshness": null, "external": null, "description": "Offsets (from UTC) for each timezone.", "columns": {"time_zone": {"name": "time_zone", "description": "Name of the time zone.", "meta": {}, "data_type": null, "quote": null, "tags": []}, "standard_offset": {"name": "standard_offset", "description": "Standard offset of the timezone (non-daylight savings hours). In `+/-hh:mm` format.", "meta": {}, "data_type": null, "quote": null, "tags": []}}, "meta": {}, "source_meta": {}, "tags": [], "config": {"enabled": true}, "patch_path": null, "unrendered_config": {}, "relation_name": "`bq-project`.`zendesk`.`time_zone`", "created_at": 1647014738.08351}}, "macros": {"macro.development.cents": {"unique_id": "macro.development.cents", "package_name": "development", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development", "path": "macros/cents.sql", "original_file_path": "macros/cents.sql", "name": "cents", "macro_sql": "{% macro cents(column_name, precision=2) %}\n    ({{ column_name }} / 100)::numeric(16, {{ precision }})\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "A macro to convert cents to dollars", "meta": {}, "docs": {"show": true}, "patch_path": "development://macros/macros.yml", "arguments": [{"name": "column_name", "type": "string", "description": "The name of the column you want to convert"}, {"name": "precision", "type": "integer", "description": "Number of decimal places. Defaults to 2."}], "created_at": 1647014737.7920508}, "macro.dbt_bigquery.date_sharded_table": {"unique_id": "macro.dbt_bigquery.date_sharded_table", "package_name": "dbt_bigquery", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/bigquery", "path": "macros/etc.sql", "original_file_path": "macros/etc.sql", "name": "date_sharded_table", "macro_sql": "{% macro date_sharded_table(base_name) %}\n    {{ return(base_name ~ \"[DBT__PARTITION_DATE]\") }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.578191}, "macro.dbt_bigquery.grant_access_to": {"unique_id": "macro.dbt_bigquery.grant_access_to", "package_name": "dbt_bigquery", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/bigquery", "path": "macros/etc.sql", "original_file_path": "macros/etc.sql", "name": "grant_access_to", "macro_sql": "{% macro grant_access_to(entity, entity_type, role, grant_target_dict) -%}\n  {% do adapter.grant_access_to(entity, entity_type, role, grant_target_dict) %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.5787158}, "macro.dbt_bigquery.get_partitions_metadata": {"unique_id": "macro.dbt_bigquery.get_partitions_metadata", "package_name": "dbt_bigquery", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/bigquery", "path": "macros/etc.sql", "original_file_path": "macros/etc.sql", "name": "get_partitions_metadata", "macro_sql": "\n\n{%- macro get_partitions_metadata(table) -%}\n  {%- if execute -%}\n    {%- set res = adapter.get_partitions_metadata(table) -%}\n    {{- return(res) -}}\n  {%- endif -%}\n  {{- return(None) -}}\n{%- endmacro -%}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.579423}, "macro.dbt_bigquery.bigquery__get_catalog": {"unique_id": "macro.dbt_bigquery.bigquery__get_catalog", "package_name": "dbt_bigquery", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/bigquery", "path": "macros/catalog.sql", "original_file_path": "macros/catalog.sql", "name": "bigquery__get_catalog", "macro_sql": "{% macro bigquery__get_catalog(information_schema, schemas) -%}\n\n  {%- if (schemas | length) == 0 -%}\n    {# Hopefully nothing cares about the columns we return when there are no rows #}\n    {%- set query  = \"select 1 as id limit 0\" -%}\n  {%- else -%}\n\n  {%- set query -%}\n    with tables as (\n        select\n            project_id as table_database,\n            dataset_id as table_schema,\n            table_id as original_table_name,\n\n            concat(project_id, '.', dataset_id, '.', table_id) as relation_id,\n\n            row_count,\n            size_bytes as size_bytes,\n            case\n                when type = 1 then 'table'\n                when type = 2 then 'view'\n                else 'external'\n            end as table_type,\n\n            REGEXP_CONTAINS(table_id, '^.+[0-9]{8}$') and coalesce(type, 0) = 1 as is_date_shard,\n            REGEXP_EXTRACT(table_id, '^(.+)[0-9]{8}$') as shard_base_name,\n            REGEXP_EXTRACT(table_id, '^.+([0-9]{8})$') as shard_name\n\n        from {{ information_schema.replace(information_schema_view='__TABLES__') }}\n        where (\n          {%- for schema in schemas -%}\n            upper(dataset_id) = upper('{{ schema }}'){%- if not loop.last %} or {% endif -%}\n          {%- endfor -%}\n        )\n    ),\n\n    extracted as (\n\n        select *,\n            case\n                when is_date_shard then shard_base_name\n                else original_table_name\n            end as table_name\n\n        from tables\n\n    ),\n\n    unsharded_tables as (\n\n        select\n            table_database,\n            table_schema,\n            table_name,\n            coalesce(table_type, 'external') as table_type,\n            is_date_shard,\n\n            struct(\n                min(shard_name) as shard_min,\n                max(shard_name) as shard_max,\n                count(*) as shard_count\n            ) as table_shards,\n\n            sum(size_bytes) as size_bytes,\n            sum(row_count) as row_count,\n\n            max(relation_id) as relation_id\n\n        from extracted\n        group by 1,2,3,4,5\n\n    ),\n\n    info_schema_columns as (\n\n        select\n            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,\n            table_catalog as table_database,\n            table_schema,\n            table_name,\n\n            -- use the \"real\" column name from the paths query below\n            column_name as base_column_name,\n            ordinal_position as column_index,\n\n            is_partitioning_column,\n            clustering_ordinal_position\n\n        from {{ information_schema.replace(information_schema_view='COLUMNS') }}\n        where ordinal_position is not null\n\n    ),\n\n    info_schema_column_paths as (\n\n        select\n            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,\n            field_path as column_name,\n            data_type as column_type,\n            column_name as base_column_name,\n            description as column_comment\n\n        from {{ information_schema.replace(information_schema_view='COLUMN_FIELD_PATHS') }}\n\n    ),\n\n    columns as (\n\n        select * except (base_column_name)\n        from info_schema_columns\n        join info_schema_column_paths using (relation_id, base_column_name)\n\n    ),\n\n    column_stats as (\n\n        select\n            table_database,\n            table_schema,\n            table_name,\n            max(relation_id) as relation_id,\n            max(case when is_partitioning_column = 'YES' then 1 else 0 end) = 1 as is_partitioned,\n            max(case when is_partitioning_column = 'YES' then column_name else null end) as partition_column,\n            max(case when clustering_ordinal_position is not null then 1 else 0 end) = 1 as is_clustered,\n            array_to_string(\n                array_agg(\n                    case\n                        when clustering_ordinal_position is not null then column_name\n                        else null\n                    end ignore nulls\n                    order by clustering_ordinal_position\n                ), ', '\n            ) as clustering_columns\n\n        from columns\n        group by 1,2,3\n\n    )\n\n    select\n        unsharded_tables.table_database,\n        unsharded_tables.table_schema,\n        case\n            when is_date_shard then concat(unsharded_tables.table_name, '*')\n            else unsharded_tables.table_name\n        end as table_name,\n        unsharded_tables.table_type,\n\n        -- coalesce name and type for External tables - these columns are not\n        -- present in the COLUMN_FIELD_PATHS resultset\n        coalesce(columns.column_name, '<unknown>') as column_name,\n        -- invent a row number to account for nested fields -- BQ does\n        -- not treat these nested properties as independent fields\n        row_number() over (\n            partition by relation_id\n            order by columns.column_index, columns.column_name\n        ) as column_index,\n        coalesce(columns.column_type, '<unknown>') as column_type,\n        columns.column_comment,\n\n        'Shard count' as `stats__date_shards__label`,\n        table_shards.shard_count as `stats__date_shards__value`,\n        'The number of date shards in this table' as `stats__date_shards__description`,\n        is_date_shard as `stats__date_shards__include`,\n\n        'Shard (min)' as `stats__date_shard_min__label`,\n        table_shards.shard_min as `stats__date_shard_min__value`,\n        'The first date shard in this table' as `stats__date_shard_min__description`,\n        is_date_shard as `stats__date_shard_min__include`,\n\n        'Shard (max)' as `stats__date_shard_max__label`,\n        table_shards.shard_max as `stats__date_shard_max__value`,\n        'The last date shard in this table' as `stats__date_shard_max__description`,\n        is_date_shard as `stats__date_shard_max__include`,\n\n        '# Rows' as `stats__num_rows__label`,\n        row_count as `stats__num_rows__value`,\n        'Approximate count of rows in this table' as `stats__num_rows__description`,\n        (unsharded_tables.table_type = 'table') as `stats__num_rows__include`,\n\n        'Approximate Size' as `stats__num_bytes__label`,\n        size_bytes as `stats__num_bytes__value`,\n        'Approximate size of table as reported by BigQuery' as `stats__num_bytes__description`,\n        (unsharded_tables.table_type = 'table') as `stats__num_bytes__include`,\n\n        'Partitioned By' as `stats__partitioning_type__label`,\n        partition_column as `stats__partitioning_type__value`,\n        'The partitioning column for this table' as `stats__partitioning_type__description`,\n        is_partitioned as `stats__partitioning_type__include`,\n\n        'Clustered By' as `stats__clustering_fields__label`,\n        clustering_columns as `stats__clustering_fields__value`,\n        'The clustering columns for this table' as `stats__clustering_fields__description`,\n        is_clustered as `stats__clustering_fields__include`\n\n    -- join using relation_id (an actual relation, not a shard prefix) to make\n    -- sure that column metadata is picked up through the join. This will only\n    -- return the column information for the \"max\" table in a date-sharded table set\n    from unsharded_tables\n    left join columns using (relation_id)\n    left join column_stats using (relation_id)\n  {%- endset -%}\n\n  {%- endif -%}\n\n  {{ return(run_query(query)) }}\n\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.replace", "macro.dbt.run_query"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.5851688}, "macro.dbt_bigquery.partition_by": {"unique_id": "macro.dbt_bigquery.partition_by", "package_name": "dbt_bigquery", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/bigquery", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "name": "partition_by", "macro_sql": "{% macro partition_by(partition_config) -%}\n    {%- if partition_config is none -%}\n      {% do return('') %}\n    {%- elif partition_config.data_type | lower in ('date','timestamp','datetime') -%}\n        partition by {{ partition_config.render() }}\n    {%- elif partition_config.data_type | lower in ('int64') -%}\n        {%- set range = partition_config.range -%}\n        partition by range_bucket(\n            {{ partition_config.field }},\n            generate_array({{ range.start}}, {{ range.end }}, {{ range.interval }})\n        )\n    {%- endif -%}\n{%- endmacro -%}\n\n", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.5940852}, "macro.dbt_bigquery.cluster_by": {"unique_id": "macro.dbt_bigquery.cluster_by", "package_name": "dbt_bigquery", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/bigquery", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "name": "cluster_by", "macro_sql": "{% macro cluster_by(raw_cluster_by) %}\n  {%- if raw_cluster_by is not none -%}\n  cluster by {% if raw_cluster_by is string -%}\n    {% set raw_cluster_by = [raw_cluster_by] %}\n  {%- endif -%}\n  {%- for cluster in raw_cluster_by -%}\n    {{ cluster }}\n    {%- if not loop.last -%}, {% endif -%}\n  {%- endfor -%}\n\n  {% endif %}\n\n{%- endmacro -%}\n\n", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.59501}, "macro.dbt_bigquery.bigquery_options": {"unique_id": "macro.dbt_bigquery.bigquery_options", "package_name": "dbt_bigquery", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/bigquery", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "name": "bigquery_options", "macro_sql": "{% macro bigquery_options(opts) %}\n  {% set options -%}\n    OPTIONS({% for opt_key, opt_val in opts.items() %}\n      {{ opt_key }}={{ opt_val }}{{ \",\" if not loop.last }}\n    {% endfor %})\n  {%- endset %}\n  {%- do return(options) -%}\n{%- endmacro -%}\n\n", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.595895}, "macro.dbt_bigquery.bigquery_table_options": {"unique_id": "macro.dbt_bigquery.bigquery_table_options", "package_name": "dbt_bigquery", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/bigquery", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "name": "bigquery_table_options", "macro_sql": "{% macro bigquery_table_options(config, node, temporary) %}\n  {% set opts = adapter.get_table_options(config, node, temporary) %}\n  {%- do return(bigquery_options(opts)) -%}\n{%- endmacro -%}\n\n", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_bigquery.bigquery_options"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.596537}, "macro.dbt_bigquery.bigquery__create_table_as": {"unique_id": "macro.dbt_bigquery.bigquery__create_table_as", "package_name": "dbt_bigquery", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/bigquery", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "name": "bigquery__create_table_as", "macro_sql": "{% macro bigquery__create_table_as(temporary, relation, sql) -%}\n  {%- set raw_partition_by = config.get('partition_by', none) -%}\n  {%- set raw_cluster_by = config.get('cluster_by', none) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {%- set partition_config = adapter.parse_partition_by(raw_partition_by) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create or replace table {{ relation }}\n  {{ partition_by(partition_config) }}\n  {{ cluster_by(raw_cluster_by) }}\n  {{ bigquery_table_options(config, model, temporary) }}\n  as (\n    {{ sql }}\n  );\n\n{%- endmacro -%}\n\n", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_bigquery.partition_by", "macro.dbt_bigquery.cluster_by", "macro.dbt_bigquery.bigquery_table_options"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.598128}, "macro.dbt_bigquery.bigquery_view_options": {"unique_id": "macro.dbt_bigquery.bigquery_view_options", "package_name": "dbt_bigquery", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/bigquery", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "name": "bigquery_view_options", "macro_sql": "{% macro bigquery_view_options(config, node) %}\n  {% set opts = adapter.get_view_options(config, node) %}\n  {%- do return(bigquery_options(opts)) -%}\n{%- endmacro -%}\n\n", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_bigquery.bigquery_options"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.598718}, "macro.dbt_bigquery.bigquery__create_view_as": {"unique_id": "macro.dbt_bigquery.bigquery__create_view_as", "package_name": "dbt_bigquery", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/bigquery", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "name": "bigquery__create_view_as", "macro_sql": "{% macro bigquery__create_view_as(relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create or replace view {{ relation }}\n  {{ bigquery_view_options(config, model) }}\n  as {{ sql }};\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_bigquery.bigquery_view_options"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.5995069}, "macro.dbt_bigquery.bigquery__create_schema": {"unique_id": "macro.dbt_bigquery.bigquery__create_schema", "package_name": "dbt_bigquery", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/bigquery", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "name": "bigquery__create_schema", "macro_sql": "{% macro bigquery__create_schema(relation) -%}\n  {{ adapter.create_schema(relation) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.599841}, "macro.dbt_bigquery.bigquery__drop_schema": {"unique_id": "macro.dbt_bigquery.bigquery__drop_schema", "package_name": "dbt_bigquery", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/bigquery", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "name": "bigquery__drop_schema", "macro_sql": "{% macro bigquery__drop_schema(relation) -%}\n  {{ adapter.drop_schema(relation) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.600211}, "macro.dbt_bigquery.bigquery__drop_relation": {"unique_id": "macro.dbt_bigquery.bigquery__drop_relation", "package_name": "dbt_bigquery", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/bigquery", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "name": "bigquery__drop_relation", "macro_sql": "{% macro bigquery__drop_relation(relation) -%}\n  {% call statement('drop_relation') -%}\n    drop {{ relation.type }} if exists {{ relation }}\n  {%- endcall %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.600935}, "macro.dbt_bigquery.bigquery__get_columns_in_relation": {"unique_id": "macro.dbt_bigquery.bigquery__get_columns_in_relation", "package_name": "dbt_bigquery", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/bigquery", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "name": "bigquery__get_columns_in_relation", "macro_sql": "{% macro bigquery__get_columns_in_relation(relation) -%}\n  {{ return(adapter.get_columns_in_relation(relation)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.601305}, "macro.dbt_bigquery.bigquery__list_relations_without_caching": {"unique_id": "macro.dbt_bigquery.bigquery__list_relations_without_caching", "package_name": "dbt_bigquery", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/bigquery", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "name": "bigquery__list_relations_without_caching", "macro_sql": "{% macro bigquery__list_relations_without_caching(schema_relation) -%}\n  {{ return(adapter.list_relations_without_caching(schema_relation)) }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.601665}, "macro.dbt_bigquery.bigquery__current_timestamp": {"unique_id": "macro.dbt_bigquery.bigquery__current_timestamp", "package_name": "dbt_bigquery", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/bigquery", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "name": "bigquery__current_timestamp", "macro_sql": "{% macro bigquery__current_timestamp() -%}\n  CURRENT_TIMESTAMP()\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.6018538}, "macro.dbt_bigquery.bigquery__snapshot_string_as_time": {"unique_id": "macro.dbt_bigquery.bigquery__snapshot_string_as_time", "package_name": "dbt_bigquery", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/bigquery", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "name": "bigquery__snapshot_string_as_time", "macro_sql": "{% macro bigquery__snapshot_string_as_time(timestamp) -%}\n    {%- set result = 'TIMESTAMP(\"' ~ timestamp ~ '\")' -%}\n    {{ return(result) }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.602292}, "macro.dbt_bigquery.bigquery__list_schemas": {"unique_id": "macro.dbt_bigquery.bigquery__list_schemas", "package_name": "dbt_bigquery", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/bigquery", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "name": "bigquery__list_schemas", "macro_sql": "{% macro bigquery__list_schemas(database) -%}\n  {{ return(adapter.list_schemas(database)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.602787}, "macro.dbt_bigquery.bigquery__check_schema_exists": {"unique_id": "macro.dbt_bigquery.bigquery__check_schema_exists", "package_name": "dbt_bigquery", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/bigquery", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "name": "bigquery__check_schema_exists", "macro_sql": "{% macro bigquery__check_schema_exists(information_schema, schema) %}\n  {{ return(adapter.check_schema_exists(information_schema.database, schema)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.603244}, "macro.dbt_bigquery.bigquery__persist_docs": {"unique_id": "macro.dbt_bigquery.bigquery__persist_docs", "package_name": "dbt_bigquery", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/bigquery", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "name": "bigquery__persist_docs", "macro_sql": "{% macro bigquery__persist_docs(relation, model, for_relation, for_columns) -%}\n  {% if for_columns and config.persist_column_docs() and model.columns %}\n    {% do alter_column_comment(relation, model.columns) %}\n  {% endif %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.alter_column_comment"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.603939}, "macro.dbt_bigquery.bigquery__alter_column_comment": {"unique_id": "macro.dbt_bigquery.bigquery__alter_column_comment", "package_name": "dbt_bigquery", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/bigquery", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "name": "bigquery__alter_column_comment", "macro_sql": "{% macro bigquery__alter_column_comment(relation, column_dict) -%}\n  {% do adapter.update_columns(relation, column_dict) %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.604336}, "macro.dbt_bigquery.bigquery__rename_relation": {"unique_id": "macro.dbt_bigquery.bigquery__rename_relation", "package_name": "dbt_bigquery", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/bigquery", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "name": "bigquery__rename_relation", "macro_sql": "{% macro bigquery__rename_relation(from_relation, to_relation) -%}\n  {% do adapter.rename_relation(from_relation, to_relation) %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.604727}, "macro.dbt_bigquery.bigquery__alter_relation_add_columns": {"unique_id": "macro.dbt_bigquery.bigquery__alter_relation_add_columns", "package_name": "dbt_bigquery", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/bigquery", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "name": "bigquery__alter_relation_add_columns", "macro_sql": "{% macro bigquery__alter_relation_add_columns(relation, add_columns) %}\n  \n  {% set sql -%}\n     \n     alter {{ relation.type }} {{ relation }}\n        {% for column in add_columns %}\n          add column {{ column.name }} {{ column.data_type }}{{ ',' if not loop.last }}\n        {% endfor %}\n  \n  {%- endset -%}\n\n  {{ return(run_query(sql)) }}\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.run_query"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.605802}, "macro.dbt_bigquery.bigquery__alter_relation_drop_columns": {"unique_id": "macro.dbt_bigquery.bigquery__alter_relation_drop_columns", "package_name": "dbt_bigquery", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/bigquery", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "name": "bigquery__alter_relation_drop_columns", "macro_sql": "{% macro bigquery__alter_relation_drop_columns(relation, drop_columns) %}\n  \n  {% set sql -%}\n     \n     alter {{ relation.type }} {{ relation }}\n\n        {% for column in drop_columns %}\n          drop column {{ column.name }}{{ ',' if not loop.last }}\n        {% endfor %}\n  \n  {%- endset -%}\n  \n  {{ return(run_query(sql)) }}\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.run_query"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.60675}, "macro.dbt_bigquery.bigquery__alter_column_type": {"unique_id": "macro.dbt_bigquery.bigquery__alter_column_type", "package_name": "dbt_bigquery", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/bigquery", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "name": "bigquery__alter_column_type", "macro_sql": "{% macro bigquery__alter_column_type(relation, column_name, new_column_type) -%}\n  {#-- Changing a column's data type using a query requires you to scan the entire table.\n    The query charges can be significant if the table is very large.\n\n    https://cloud.google.com/bigquery/docs/manually-changing-schemas#changing_a_columns_data_type\n  #}\n  {% set relation_columns = get_columns_in_relation(relation) %}\n\n  {% set sql %}\n    select\n      {%- for col in relation_columns -%}\n        {% if col.column == column_name %}\n          CAST({{ col.quoted }} AS {{ new_column_type }}) AS {{ col.quoted }}\n        {%- else %}\n          {{ col.quoted }}\n        {%- endif %}\n        {%- if not loop.last %},{% endif -%}\n      {%- endfor %}\n    from {{ relation }}\n  {% endset %}\n\n  {% call statement('alter_column_type') %}\n    {{ create_table_as(False, relation, sql)}}\n  {%- endcall %}\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.get_columns_in_relation", "macro.dbt.statement", "macro.dbt.create_table_as"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.608462}, "macro.dbt_bigquery.bigquery__test_unique": {"unique_id": "macro.dbt_bigquery.bigquery__test_unique", "package_name": "dbt_bigquery", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/bigquery", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "name": "bigquery__test_unique", "macro_sql": "{% macro bigquery__test_unique(model, column_name) %}\n\nwith dbt_test__target as (\n  \n  select {{ column_name }} as unique_field\n  from {{ model }}\n  where {{ column_name }} is not null\n  \n)\n\nselect\n    unique_field,\n    count(*) as n_records\n\nfrom dbt_test__target\ngroup by unique_field\nhaving count(*) > 1\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.608874}, "macro.dbt_bigquery.bigquery__create_csv_table": {"unique_id": "macro.dbt_bigquery.bigquery__create_csv_table", "package_name": "dbt_bigquery", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/bigquery", "path": "macros/materializations/seed.sql", "original_file_path": "macros/materializations/seed.sql", "name": "bigquery__create_csv_table", "macro_sql": "{% macro bigquery__create_csv_table(model, agate_table) %}\n    -- no-op\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.609638}, "macro.dbt_bigquery.bigquery__reset_csv_table": {"unique_id": "macro.dbt_bigquery.bigquery__reset_csv_table", "package_name": "dbt_bigquery", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/bigquery", "path": "macros/materializations/seed.sql", "original_file_path": "macros/materializations/seed.sql", "name": "bigquery__reset_csv_table", "macro_sql": "{% macro bigquery__reset_csv_table(model, full_refresh, old_relation, agate_table) %}\n    {{ adapter.drop_relation(old_relation) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.610042}, "macro.dbt_bigquery.bigquery__load_csv_rows": {"unique_id": "macro.dbt_bigquery.bigquery__load_csv_rows", "package_name": "dbt_bigquery", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/bigquery", "path": "macros/materializations/seed.sql", "original_file_path": "macros/materializations/seed.sql", "name": "bigquery__load_csv_rows", "macro_sql": "{% macro bigquery__load_csv_rows(model, agate_table) %}\n\n  {%- set column_override = model['config'].get('column_types', {}) -%}\n  {{ adapter.load_dataframe(model['database'], model['schema'], model['alias'],\n  \t\t\t\t\t\t\tagate_table, column_override) }}\n  {% if config.persist_relation_docs() and 'description' in model %}\n\n  \t{{ adapter.update_table_description(model['database'], model['schema'], model['alias'], model['description']) }}\n  {% endif %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.611552}, "macro.dbt_bigquery.bigquery__handle_existing_table": {"unique_id": "macro.dbt_bigquery.bigquery__handle_existing_table", "package_name": "dbt_bigquery", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/bigquery", "path": "macros/materializations/view.sql", "original_file_path": "macros/materializations/view.sql", "name": "bigquery__handle_existing_table", "macro_sql": "{% macro bigquery__handle_existing_table(full_refresh, old_relation) %}\n    {%- if full_refresh -%}\n      {{ adapter.drop_relation(old_relation) }}\n    {%- else -%}\n      {{ exceptions.relation_wrong_type(old_relation, 'view') }}\n    {%- endif -%}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.61279}, "macro.dbt_bigquery.materialization_view_bigquery": {"unique_id": "macro.dbt_bigquery.materialization_view_bigquery", "package_name": "dbt_bigquery", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/bigquery", "path": "macros/materializations/view.sql", "original_file_path": "macros/materializations/view.sql", "name": "materialization_view_bigquery", "macro_sql": "{% materialization view, adapter='bigquery' -%}\n    {% set to_return = create_or_replace_view() %}\n\n    {% set target_relation = this.incorporate(type='view') %}\n    {% do persist_docs(target_relation, model) %}\n\n    {% if config.get('grant_access_to') %}\n      {% for grant_target_dict in config.get('grant_access_to') %}\n        {% do adapter.grant_access_to(this, 'view', None, grant_target_dict) %}\n      {% endfor %}\n    {% endif %}\n\n    {% do return(to_return) %}\n\n{%- endmaterialization %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.create_or_replace_view", "macro.dbt.persist_docs"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.614261}, "macro.dbt_bigquery.materialization_table_bigquery": {"unique_id": "macro.dbt_bigquery.materialization_table_bigquery", "package_name": "dbt_bigquery", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/bigquery", "path": "macros/materializations/table.sql", "original_file_path": "macros/materializations/table.sql", "name": "materialization_table_bigquery", "macro_sql": "{% materialization table, adapter='bigquery' -%}\n\n  {%- set identifier = model['alias'] -%}\n  {%- set old_relation = adapter.get_relation(database=database, schema=schema, identifier=identifier) -%}\n  {%- set exists_not_as_table = (old_relation is not none and not old_relation.is_table) -%}\n  {%- set target_relation = api.Relation.create(database=database, schema=schema, identifier=identifier, type='table') -%}\n\n  {{ run_hooks(pre_hooks) }}\n\n  {#\n      We only need to drop this thing if it is not a table.\n      If it _is_ already a table, then we can overwrite it without downtime\n      Unlike table -> view, no need for `--full-refresh`: dropping a view is no big deal\n  #}\n  {%- if exists_not_as_table -%}\n      {{ adapter.drop_relation(old_relation) }}\n  {%- endif -%}\n\n  -- build model\n  {%- set raw_partition_by = config.get('partition_by', none) -%}\n  {%- set partition_by = adapter.parse_partition_by(raw_partition_by) -%}\n  {%- set cluster_by = config.get('cluster_by', none) -%}\n  {% if not adapter.is_replaceable(old_relation, partition_by, cluster_by) %}\n    {% do log(\"Hard refreshing \" ~ old_relation ~ \" because it is not replaceable\") %}\n    {% do adapter.drop_relation(old_relation) %}\n  {% endif %}\n  {% call statement('main') -%}\n    {{ create_table_as(False, target_relation, sql) }}\n  {% endcall -%}\n\n  {{ run_hooks(post_hooks) }}\n\n  {% do persist_docs(target_relation, model) %}\n\n  {{ return({'relations': [target_relation]}) }}\n\n{% endmaterialization %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.run_hooks", "macro.dbt.statement", "macro.dbt.create_table_as", "macro.dbt.persist_docs"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.618426}, "macro.dbt_bigquery.materialization_copy_bigquery": {"unique_id": "macro.dbt_bigquery.materialization_copy_bigquery", "package_name": "dbt_bigquery", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/bigquery", "path": "macros/materializations/copy.sql", "original_file_path": "macros/materializations/copy.sql", "name": "materialization_copy_bigquery", "macro_sql": "{% materialization copy, adapter='bigquery' -%}\n\n  {# Setup #}\n  {{ run_hooks(pre_hooks) }}\n\n  {% set destination = this.incorporate(type='table') %}\n\n  {# there can be several ref() or source() according to BQ copy API docs #}\n  {# cycle over ref() and source() to create source tables array #}\n  {% set source_array = [] %}\n  {% for ref_table in model.refs %}\n    {{ source_array.append(ref(*ref_table)) }}\n  {% endfor %}\n\n  {% for src_table in model.sources %}\n    {{ source_array.append(source(*src_table)) }}\n  {% endfor %}\n\n  {# Call adapter's copy_table function #}\n  {%- set result_str = adapter.copy_table(\n      source_array,\n      destination,\n      config.get('copy_materialization', default = 'table')) -%}\n\n  {{ store_result('main', response=result_str) }}\n\n  {# Clean up #}\n  {{ run_hooks(post_hooks) }}\n  {{ adapter.commit() }}\n\n  {{ return({'relations': [destination]}) }}\n{%- endmaterialization %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.run_hooks"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.621374}, "macro.dbt_bigquery.declare_dbt_max_partition": {"unique_id": "macro.dbt_bigquery.declare_dbt_max_partition", "package_name": "dbt_bigquery", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/bigquery", "path": "macros/materializations/incremental.sql", "original_file_path": "macros/materializations/incremental.sql", "name": "declare_dbt_max_partition", "macro_sql": "{% macro declare_dbt_max_partition(relation, partition_by, sql) %}\n\n  {% if '_dbt_max_partition' in sql %}\n\n    declare _dbt_max_partition {{ partition_by.data_type }} default (\n      select max({{ partition_by.field }}) from {{ this }}\n      where {{ partition_by.field }} is not null\n    );\n  \n  {% endif %}\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.625172}, "macro.dbt_bigquery.dbt_bigquery_validate_get_incremental_strategy": {"unique_id": "macro.dbt_bigquery.dbt_bigquery_validate_get_incremental_strategy", "package_name": "dbt_bigquery", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/bigquery", "path": "macros/materializations/incremental.sql", "original_file_path": "macros/materializations/incremental.sql", "name": "dbt_bigquery_validate_get_incremental_strategy", "macro_sql": "{% macro dbt_bigquery_validate_get_incremental_strategy(config) %}\n  {#-- Find and validate the incremental strategy #}\n  {%- set strategy = config.get(\"incremental_strategy\", default=\"merge\") -%}\n\n  {% set invalid_strategy_msg -%}\n    Invalid incremental strategy provided: {{ strategy }}\n    Expected one of: 'merge', 'insert_overwrite'\n  {%- endset %}\n  {% if strategy not in ['merge', 'insert_overwrite'] %}\n    {% do exceptions.raise_compiler_error(invalid_strategy_msg) %}\n  {% endif %}\n\n  {% do return(strategy) %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.626302}, "macro.dbt_bigquery.bq_insert_overwrite": {"unique_id": "macro.dbt_bigquery.bq_insert_overwrite", "package_name": "dbt_bigquery", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/bigquery", "path": "macros/materializations/incremental.sql", "original_file_path": "macros/materializations/incremental.sql", "name": "bq_insert_overwrite", "macro_sql": "{% macro bq_insert_overwrite(\n    tmp_relation, target_relation, sql, unique_key, partition_by, partitions, dest_columns, tmp_relation_exists\n) %}\n\n  {% if partitions is not none and partitions != [] %} {# static #}\n\n      {% set predicate -%}\n          {{ partition_by.render(alias='DBT_INTERNAL_DEST') }} in (\n              {{ partitions | join (', ') }}\n          )\n      {%- endset %}\n\n      {%- set source_sql -%}\n        (\n          {{sql}}\n        )\n      {%- endset -%}\n\n      {{ get_insert_overwrite_merge_sql(target_relation, source_sql, dest_columns, [predicate], include_sql_header=true) }}\n\n  {% else %} {# dynamic #}\n\n      {% set predicate -%}\n          {{ partition_by.render(alias='DBT_INTERNAL_DEST') }} in unnest(dbt_partitions_for_replacement)\n      {%- endset %}\n\n      {%- set source_sql -%}\n      (\n        select * from {{ tmp_relation }}\n      )\n      {%- endset -%}\n\n      -- generated script to merge partitions into {{ target_relation }}\n      declare dbt_partitions_for_replacement array<{{ partition_by.data_type }}>;\n\n      {# have we already created the temp table to check for schema changes? #}\n      {% if not tmp_relation_exists %}\n        {{ declare_dbt_max_partition(this, partition_by, sql) }}\n        \n        -- 1. create a temp table\n        {{ create_table_as(True, tmp_relation, sql) }}\n      {% else %}\n        -- 1. temp table already exists, we used it to check for schema changes\n      {% endif %}\n\n      -- 2. define partitions to update\n      set (dbt_partitions_for_replacement) = (\n          select as struct\n              array_agg(distinct {{ partition_by.render() }})\n          from {{ tmp_relation }}\n      );\n\n      {#\n        TODO: include_sql_header is a hack; consider a better approach that includes\n              the sql_header at the materialization-level instead\n      #}\n      -- 3. run the merge statement\n      {{ get_insert_overwrite_merge_sql(target_relation, source_sql, dest_columns, [predicate], include_sql_header=false) }};\n\n      -- 4. clean up the temp table\n      drop table if exists {{ tmp_relation }}\n\n  {% endif %}\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.get_insert_overwrite_merge_sql", "macro.dbt_bigquery.declare_dbt_max_partition", "macro.dbt.create_table_as"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.629602}, "macro.dbt_bigquery.bq_generate_incremental_build_sql": {"unique_id": "macro.dbt_bigquery.bq_generate_incremental_build_sql", "package_name": "dbt_bigquery", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/bigquery", "path": "macros/materializations/incremental.sql", "original_file_path": "macros/materializations/incremental.sql", "name": "bq_generate_incremental_build_sql", "macro_sql": "{% macro bq_generate_incremental_build_sql(\n    strategy, tmp_relation, target_relation, sql, unique_key, partition_by, partitions, dest_columns, tmp_relation_exists\n) %}\n  {#-- if partitioned, use BQ scripting to get the range of partition values to be updated --#}\n  {% if strategy == 'insert_overwrite' %}\n\n    {% set missing_partition_msg -%}\n      The 'insert_overwrite' strategy requires the `partition_by` config.\n    {%- endset %}\n    {% if partition_by is none %}\n      {% do exceptions.raise_compiler_error(missing_partition_msg) %}\n    {% endif %}\n\n    {% set build_sql = bq_insert_overwrite(\n        tmp_relation, target_relation, sql, unique_key, partition_by, partitions, dest_columns, on_schema_change\n    ) %}\n\n  {% else %} {# strategy == 'merge' #}\n    {%- set source_sql -%}\n      {%- if tmp_relation_exists -%}\n        (\n          select * from {{ tmp_relation }}\n        )\n      {%- else -%} {#-- wrap sql in parens to make it a subquery --#}\n        (\n          {{sql}}\n        )\n      {%- endif -%}\n    {%- endset -%}\n\n    {% set build_sql = get_merge_sql(target_relation, source_sql, unique_key, dest_columns) %}\n\n  {% endif %}\n\n  {{ return(build_sql) }}\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_bigquery.bq_insert_overwrite", "macro.dbt.get_merge_sql"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.631783}, "macro.dbt_bigquery.materialization_incremental_bigquery": {"unique_id": "macro.dbt_bigquery.materialization_incremental_bigquery", "package_name": "dbt_bigquery", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/bigquery", "path": "macros/materializations/incremental.sql", "original_file_path": "macros/materializations/incremental.sql", "name": "materialization_incremental_bigquery", "macro_sql": "{% materialization incremental, adapter='bigquery' -%}\n\n  {%- set unique_key = config.get('unique_key') -%}\n  {%- set full_refresh_mode = (should_full_refresh()) -%}\n\n  {%- set target_relation = this %}\n  {%- set existing_relation = load_relation(this) %}\n  {%- set tmp_relation = make_temp_relation(this) %}\n\n  {#-- Validate early so we don't run SQL if the strategy is invalid --#}\n  {% set strategy = dbt_bigquery_validate_get_incremental_strategy(config) -%}\n\n  {%- set raw_partition_by = config.get('partition_by', none) -%}\n  {%- set partition_by = adapter.parse_partition_by(raw_partition_by) -%}\n  {%- set partitions = config.get('partitions', none) -%}\n  {%- set cluster_by = config.get('cluster_by', none) -%}\n\n  {% set on_schema_change = incremental_validate_on_schema_change(config.get('on_schema_change'), default='ignore') %}\n\n  {{ run_hooks(pre_hooks) }}\n\n  {% if existing_relation is none %}\n      {% set build_sql = create_table_as(False, target_relation, sql) %}\n  \n  {% elif existing_relation.is_view %}\n      {#-- There's no way to atomically replace a view with a table on BQ --#}\n      {{ adapter.drop_relation(existing_relation) }}\n      {% set build_sql = create_table_as(False, target_relation, sql) %}\n  \n  {% elif full_refresh_mode %}\n      {#-- If the partition/cluster config has changed, then we must drop and recreate --#}\n      {% if not adapter.is_replaceable(existing_relation, partition_by, cluster_by) %}\n          {% do log(\"Hard refreshing \" ~ existing_relation ~ \" because it is not replaceable\") %}\n          {{ adapter.drop_relation(existing_relation) }}\n      {% endif %}\n      {% set build_sql = create_table_as(False, target_relation, sql) %}\n  \n  {% else %}\n    {% set tmp_relation_exists = false %}\n    {% if on_schema_change != 'ignore' %} {# Check first, since otherwise we may not build a temp table #}\n      {% do run_query(\n        declare_dbt_max_partition(this, partition_by, sql) + create_table_as(True, tmp_relation, sql)\n      ) %}\n      {% set tmp_relation_exists = true %}\n      {#-- Process schema changes. Returns dict of changes if successful. Use source columns for upserting/merging --#}\n      {% set dest_columns = process_schema_changes(on_schema_change, tmp_relation, existing_relation) %}\n    {% endif %}\n    {% if not dest_columns %}\n      {% set dest_columns = adapter.get_columns_in_relation(existing_relation) %}\n    {% endif %}\n    {% set build_sql = bq_generate_incremental_build_sql(\n        strategy, tmp_relation, target_relation, sql, unique_key, partition_by, partitions, dest_columns, tmp_relation_exists\n    ) %}\n\n  {% endif %}\n\n  {%- call statement('main') -%}\n    {{ build_sql }}\n  {% endcall %}\n\n  {{ run_hooks(post_hooks) }}\n\n  {% set target_relation = this.incorporate(type='table') %}\n\n  {% do persist_docs(target_relation, model) %}\n\n  {{ return({'relations': [target_relation]}) }}\n\n{%- endmaterialization %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.should_full_refresh", "macro.dbt.load_relation", "macro.dbt.make_temp_relation", "macro.dbt_bigquery.dbt_bigquery_validate_get_incremental_strategy", "macro.dbt.incremental_validate_on_schema_change", "macro.dbt.run_hooks", "macro.dbt.create_table_as", "macro.dbt.run_query", "macro.dbt_bigquery.declare_dbt_max_partition", "macro.dbt.process_schema_changes", "macro.dbt_bigquery.bq_generate_incremental_build_sql", "macro.dbt.statement", "macro.dbt.persist_docs"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.638249}, "macro.dbt_bigquery.bigquery__snapshot_hash_arguments": {"unique_id": "macro.dbt_bigquery.bigquery__snapshot_hash_arguments", "package_name": "dbt_bigquery", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/bigquery", "path": "macros/materializations/snapshot.sql", "original_file_path": "macros/materializations/snapshot.sql", "name": "bigquery__snapshot_hash_arguments", "macro_sql": "{% macro bigquery__snapshot_hash_arguments(args) -%}\n  to_hex(md5(concat({%- for arg in args -%}\n    coalesce(cast({{ arg }} as string), ''){% if not loop.last %}, '|',{% endif -%}\n  {%- endfor -%}\n  )))\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.639406}, "macro.dbt_bigquery.bigquery__create_columns": {"unique_id": "macro.dbt_bigquery.bigquery__create_columns", "package_name": "dbt_bigquery", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/bigquery", "path": "macros/materializations/snapshot.sql", "original_file_path": "macros/materializations/snapshot.sql", "name": "bigquery__create_columns", "macro_sql": "{% macro bigquery__create_columns(relation, columns) %}\n  {{ adapter.alter_table_add_columns(relation, columns) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.639801}, "macro.dbt_bigquery.bigquery__post_snapshot": {"unique_id": "macro.dbt_bigquery.bigquery__post_snapshot", "package_name": "dbt_bigquery", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/bigquery", "path": "macros/materializations/snapshot.sql", "original_file_path": "macros/materializations/snapshot.sql", "name": "bigquery__post_snapshot", "macro_sql": "{% macro bigquery__post_snapshot(staging_relation) %}\n  -- Clean up the snapshot temp table\n  {% do drop_relation(staging_relation) %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.drop_relation"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.640137}, "macro.dbt.run_hooks": {"unique_id": "macro.dbt.run_hooks", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/hooks.sql", "original_file_path": "macros/materializations/hooks.sql", "name": "run_hooks", "macro_sql": "{% macro run_hooks(hooks, inside_transaction=True) %}\n  {% for hook in hooks | selectattr('transaction', 'equalto', inside_transaction)  %}\n    {% if not inside_transaction and loop.first %}\n      {% call statement(auto_begin=inside_transaction) %}\n        commit;\n      {% endcall %}\n    {% endif %}\n    {% set rendered = render(hook.get('sql')) | trim %}\n    {% if (rendered | length) > 0 %}\n      {% call statement(auto_begin=inside_transaction) %}\n        {{ rendered }}\n      {% endcall %}\n    {% endif %}\n  {% endfor %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.642617}, "macro.dbt.make_hook_config": {"unique_id": "macro.dbt.make_hook_config", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/hooks.sql", "original_file_path": "macros/materializations/hooks.sql", "name": "make_hook_config", "macro_sql": "{% macro make_hook_config(sql, inside_transaction) %}\n    {{ tojson({\"sql\": sql, \"transaction\": inside_transaction}) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.643109}, "macro.dbt.before_begin": {"unique_id": "macro.dbt.before_begin", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/hooks.sql", "original_file_path": "macros/materializations/hooks.sql", "name": "before_begin", "macro_sql": "{% macro before_begin(sql) %}\n    {{ make_hook_config(sql, inside_transaction=False) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.make_hook_config"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.643475}, "macro.dbt.in_transaction": {"unique_id": "macro.dbt.in_transaction", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/hooks.sql", "original_file_path": "macros/materializations/hooks.sql", "name": "in_transaction", "macro_sql": "{% macro in_transaction(sql) %}\n    {{ make_hook_config(sql, inside_transaction=True) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.make_hook_config"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.643839}, "macro.dbt.after_commit": {"unique_id": "macro.dbt.after_commit", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/hooks.sql", "original_file_path": "macros/materializations/hooks.sql", "name": "after_commit", "macro_sql": "{% macro after_commit(sql) %}\n    {{ make_hook_config(sql, inside_transaction=False) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.make_hook_config"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.6442041}, "macro.dbt.set_sql_header": {"unique_id": "macro.dbt.set_sql_header", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/configs.sql", "original_file_path": "macros/materializations/configs.sql", "name": "set_sql_header", "macro_sql": "{% macro set_sql_header(config) -%}\n  {{ config.set('sql_header', caller()) }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.645112}, "macro.dbt.should_full_refresh": {"unique_id": "macro.dbt.should_full_refresh", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/configs.sql", "original_file_path": "macros/materializations/configs.sql", "name": "should_full_refresh", "macro_sql": "{% macro should_full_refresh() %}\n  {% set config_full_refresh = config.get('full_refresh') %}\n  {% if config_full_refresh is none %}\n    {% set config_full_refresh = flags.FULL_REFRESH %}\n  {% endif %}\n  {% do return(config_full_refresh) %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.645888}, "macro.dbt.should_store_failures": {"unique_id": "macro.dbt.should_store_failures", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/configs.sql", "original_file_path": "macros/materializations/configs.sql", "name": "should_store_failures", "macro_sql": "{% macro should_store_failures() %}\n  {% set config_store_failures = config.get('store_failures') %}\n  {% if config_store_failures is none %}\n    {% set config_store_failures = flags.STORE_FAILURES %}\n  {% endif %}\n  {% do return(config_store_failures) %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.64666}, "macro.dbt.snapshot_merge_sql": {"unique_id": "macro.dbt.snapshot_merge_sql", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/snapshots/snapshot_merge.sql", "original_file_path": "macros/materializations/snapshots/snapshot_merge.sql", "name": "snapshot_merge_sql", "macro_sql": "{% macro snapshot_merge_sql(target, source, insert_cols) -%}\n  {{ adapter.dispatch('snapshot_merge_sql', 'dbt')(target, source, insert_cols) }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.default__snapshot_merge_sql"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.647747}, "macro.dbt.default__snapshot_merge_sql": {"unique_id": "macro.dbt.default__snapshot_merge_sql", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/snapshots/snapshot_merge.sql", "original_file_path": "macros/materializations/snapshots/snapshot_merge.sql", "name": "default__snapshot_merge_sql", "macro_sql": "{% macro default__snapshot_merge_sql(target, source, insert_cols) -%}\n    {%- set insert_cols_csv = insert_cols | join(', ') -%}\n\n    merge into {{ target }} as DBT_INTERNAL_DEST\n    using {{ source }} as DBT_INTERNAL_SOURCE\n    on DBT_INTERNAL_SOURCE.dbt_scd_id = DBT_INTERNAL_DEST.dbt_scd_id\n\n    when matched\n     and DBT_INTERNAL_DEST.dbt_valid_to is null\n     and DBT_INTERNAL_SOURCE.dbt_change_type in ('update', 'delete')\n        then update\n        set dbt_valid_to = DBT_INTERNAL_SOURCE.dbt_valid_to\n\n    when not matched\n     and DBT_INTERNAL_SOURCE.dbt_change_type = 'insert'\n        then insert ({{ insert_cols_csv }})\n        values ({{ insert_cols_csv }})\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.648664}, "macro.dbt.strategy_dispatch": {"unique_id": "macro.dbt.strategy_dispatch", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/snapshots/strategies.sql", "original_file_path": "macros/materializations/snapshots/strategies.sql", "name": "strategy_dispatch", "macro_sql": "{% macro strategy_dispatch(name) -%}\n{% set original_name = name %}\n  {% if '.' in name %}\n    {% set package_name, name = name.split(\".\", 1) %}\n  {% else %}\n    {% set package_name = none %}\n  {% endif %}\n\n  {% if package_name is none %}\n    {% set package_context = context %}\n  {% elif package_name in context %}\n    {% set package_context = context[package_name] %}\n  {% else %}\n    {% set error_msg %}\n        Could not find package '{{package_name}}', called with '{{original_name}}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n\n  {%- set search_name = 'snapshot_' ~ name ~ '_strategy' -%}\n\n  {% if search_name not in package_context %}\n    {% set error_msg %}\n        The specified strategy macro '{{name}}' was not found in package '{{ package_name }}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n  {{ return(package_context[search_name]) }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.655057}, "macro.dbt.snapshot_hash_arguments": {"unique_id": "macro.dbt.snapshot_hash_arguments", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/snapshots/strategies.sql", "original_file_path": "macros/materializations/snapshots/strategies.sql", "name": "snapshot_hash_arguments", "macro_sql": "{% macro snapshot_hash_arguments(args) -%}\n  {{ adapter.dispatch('snapshot_hash_arguments', 'dbt')(args) }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_bigquery.bigquery__snapshot_hash_arguments"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.655564}, "macro.dbt.default__snapshot_hash_arguments": {"unique_id": "macro.dbt.default__snapshot_hash_arguments", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/snapshots/strategies.sql", "original_file_path": "macros/materializations/snapshots/strategies.sql", "name": "default__snapshot_hash_arguments", "macro_sql": "{% macro default__snapshot_hash_arguments(args) -%}\n    md5({%- for arg in args -%}\n        coalesce(cast({{ arg }} as varchar ), '')\n        {% if not loop.last %} || '|' || {% endif %}\n    {%- endfor -%})\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.6561291}, "macro.dbt.snapshot_get_time": {"unique_id": "macro.dbt.snapshot_get_time", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/snapshots/strategies.sql", "original_file_path": "macros/materializations/snapshots/strategies.sql", "name": "snapshot_get_time", "macro_sql": "{% macro snapshot_get_time() -%}\n  {{ adapter.dispatch('snapshot_get_time', 'dbt')() }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.default__snapshot_get_time"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.65649}, "macro.dbt.default__snapshot_get_time": {"unique_id": "macro.dbt.default__snapshot_get_time", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/snapshots/strategies.sql", "original_file_path": "macros/materializations/snapshots/strategies.sql", "name": "default__snapshot_get_time", "macro_sql": "{% macro default__snapshot_get_time() -%}\n  {{ current_timestamp() }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.current_timestamp"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.6567411}, "macro.dbt.snapshot_timestamp_strategy": {"unique_id": "macro.dbt.snapshot_timestamp_strategy", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/snapshots/strategies.sql", "original_file_path": "macros/materializations/snapshots/strategies.sql", "name": "snapshot_timestamp_strategy", "macro_sql": "{% macro snapshot_timestamp_strategy(node, snapshotted_rel, current_rel, config, target_exists) %}\n    {% set primary_key = config['unique_key'] %}\n    {% set updated_at = config['updated_at'] %}\n    {% set invalidate_hard_deletes = config.get('invalidate_hard_deletes', false) %}\n\n    {#/*\n        The snapshot relation might not have an {{ updated_at }} value if the\n        snapshot strategy is changed from `check` to `timestamp`. We\n        should use a dbt-created column for the comparison in the snapshot\n        table instead of assuming that the user-supplied {{ updated_at }}\n        will be present in the historical data.\n\n        See https://github.com/dbt-labs/dbt-core/issues/2350\n    */ #}\n    {% set row_changed_expr -%}\n        ({{ snapshotted_rel }}.dbt_valid_from < {{ current_rel }}.{{ updated_at }})\n    {%- endset %}\n\n    {% set scd_id_expr = snapshot_hash_arguments([primary_key, updated_at]) %}\n\n    {% do return({\n        \"unique_key\": primary_key,\n        \"updated_at\": updated_at,\n        \"row_changed\": row_changed_expr,\n        \"scd_id\": scd_id_expr,\n        \"invalidate_hard_deletes\": invalidate_hard_deletes\n    }) %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.snapshot_hash_arguments"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.658779}, "macro.dbt.snapshot_string_as_time": {"unique_id": "macro.dbt.snapshot_string_as_time", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/snapshots/strategies.sql", "original_file_path": "macros/materializations/snapshots/strategies.sql", "name": "snapshot_string_as_time", "macro_sql": "{% macro snapshot_string_as_time(timestamp) -%}\n    {{ adapter.dispatch('snapshot_string_as_time', 'dbt')(timestamp) }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_bigquery.bigquery__snapshot_string_as_time"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.65919}, "macro.dbt.default__snapshot_string_as_time": {"unique_id": "macro.dbt.default__snapshot_string_as_time", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/snapshots/strategies.sql", "original_file_path": "macros/materializations/snapshots/strategies.sql", "name": "default__snapshot_string_as_time", "macro_sql": "{% macro default__snapshot_string_as_time(timestamp) %}\n    {% do exceptions.raise_not_implemented(\n        'snapshot_string_as_time macro not implemented for adapter '+adapter.type()\n    ) %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.6596181}, "macro.dbt.snapshot_check_all_get_existing_columns": {"unique_id": "macro.dbt.snapshot_check_all_get_existing_columns", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/snapshots/strategies.sql", "original_file_path": "macros/materializations/snapshots/strategies.sql", "name": "snapshot_check_all_get_existing_columns", "macro_sql": "{% macro snapshot_check_all_get_existing_columns(node, target_exists) -%}\n    {%- set query_columns = get_columns_in_query(node['compiled_sql']) -%}\n    {%- if not target_exists -%}\n        {# no table yet -> return whatever the query does #}\n        {{ return([false, query_columns]) }}\n    {%- endif -%}\n    {# handle any schema changes #}\n    {%- set target_table = node.get('alias', node.get('name')) -%}\n    {%- set target_relation = adapter.get_relation(database=node.database, schema=node.schema, identifier=target_table) -%}\n    {%- set existing_cols = get_columns_in_query('select * from ' ~ target_relation) -%}\n    {%- set ns = namespace() -%} {# handle for-loop scoping with a namespace #}\n    {%- set ns.column_added = false -%}\n\n    {%- set intersection = [] -%}\n    {%- for col in query_columns -%}\n        {%- if col in existing_cols -%}\n            {%- do intersection.append(col) -%}\n        {%- else -%}\n            {% set ns.column_added = true %}\n        {%- endif -%}\n    {%- endfor -%}\n    {{ return([ns.column_added, intersection]) }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.get_columns_in_query"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.662051}, "macro.dbt.snapshot_check_strategy": {"unique_id": "macro.dbt.snapshot_check_strategy", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/snapshots/strategies.sql", "original_file_path": "macros/materializations/snapshots/strategies.sql", "name": "snapshot_check_strategy", "macro_sql": "{% macro snapshot_check_strategy(node, snapshotted_rel, current_rel, config, target_exists) %}\n    {% set check_cols_config = config['check_cols'] %}\n    {% set primary_key = config['unique_key'] %}\n    {% set invalidate_hard_deletes = config.get('invalidate_hard_deletes', false) %}\n    \n    {% set select_current_time -%}\n        select {{ snapshot_get_time() }} as snapshot_start\n    {%- endset %}\n\n    {#-- don't access the column by name, to avoid dealing with casing issues on snowflake #}\n    {%- set now = run_query(select_current_time)[0][0] -%}\n    {% if now is none or now is undefined -%}\n        {%- do exceptions.raise_compiler_error('Could not get a snapshot start time from the database') -%}\n    {%- endif %}\n    {% set updated_at = config.get('updated_at', snapshot_string_as_time(now)) %}\n\n    {% set column_added = false %}\n\n    {% if check_cols_config == 'all' %}\n        {% set column_added, check_cols = snapshot_check_all_get_existing_columns(node, target_exists) %}\n    {% elif check_cols_config is iterable and (check_cols_config | length) > 0 %}\n        {% set check_cols = check_cols_config %}\n    {% else %}\n        {% do exceptions.raise_compiler_error(\"Invalid value for 'check_cols': \" ~ check_cols_config) %}\n    {% endif %}\n\n    {%- set row_changed_expr -%}\n    (\n    {%- if column_added -%}\n        TRUE\n    {%- else -%}\n    {%- for col in check_cols -%}\n        {{ snapshotted_rel }}.{{ col }} != {{ current_rel }}.{{ col }}\n        or\n        (\n            (({{ snapshotted_rel }}.{{ col }} is null) and not ({{ current_rel }}.{{ col }} is null))\n            or\n            ((not {{ snapshotted_rel }}.{{ col }} is null) and ({{ current_rel }}.{{ col }} is null))\n        )\n        {%- if not loop.last %} or {% endif -%}\n    {%- endfor -%}\n    {%- endif -%}\n    )\n    {%- endset %}\n\n    {% set scd_id_expr = snapshot_hash_arguments([primary_key, updated_at]) %}\n\n    {% do return({\n        \"unique_key\": primary_key,\n        \"updated_at\": updated_at,\n        \"row_changed\": row_changed_expr,\n        \"scd_id\": scd_id_expr,\n        \"invalidate_hard_deletes\": invalidate_hard_deletes\n    }) %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.snapshot_get_time", "macro.dbt.run_query", "macro.dbt.snapshot_string_as_time", "macro.dbt.snapshot_check_all_get_existing_columns", "macro.dbt.snapshot_hash_arguments"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.6668942}, "macro.dbt.create_columns": {"unique_id": "macro.dbt.create_columns", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/snapshots/helpers.sql", "original_file_path": "macros/materializations/snapshots/helpers.sql", "name": "create_columns", "macro_sql": "{% macro create_columns(relation, columns) %}\n  {{ adapter.dispatch('create_columns', 'dbt')(relation, columns) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_bigquery.bigquery__create_columns"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.671865}, "macro.dbt.default__create_columns": {"unique_id": "macro.dbt.default__create_columns", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/snapshots/helpers.sql", "original_file_path": "macros/materializations/snapshots/helpers.sql", "name": "default__create_columns", "macro_sql": "{% macro default__create_columns(relation, columns) %}\n  {% for column in columns %}\n    {% call statement() %}\n      alter table {{ relation }} add column \"{{ column.name }}\" {{ column.data_type }};\n    {% endcall %}\n  {% endfor %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.6727948}, "macro.dbt.post_snapshot": {"unique_id": "macro.dbt.post_snapshot", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/snapshots/helpers.sql", "original_file_path": "macros/materializations/snapshots/helpers.sql", "name": "post_snapshot", "macro_sql": "{% macro post_snapshot(staging_relation) %}\n  {{ adapter.dispatch('post_snapshot', 'dbt')(staging_relation) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_bigquery.bigquery__post_snapshot"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.673325}, "macro.dbt.default__post_snapshot": {"unique_id": "macro.dbt.default__post_snapshot", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/snapshots/helpers.sql", "original_file_path": "macros/materializations/snapshots/helpers.sql", "name": "default__post_snapshot", "macro_sql": "{% macro default__post_snapshot(staging_relation) %}\n    {# no-op #}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.673553}, "macro.dbt.snapshot_staging_table": {"unique_id": "macro.dbt.snapshot_staging_table", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/snapshots/helpers.sql", "original_file_path": "macros/materializations/snapshots/helpers.sql", "name": "snapshot_staging_table", "macro_sql": "{% macro snapshot_staging_table(strategy, source_sql, target_relation) -%}\n  {{ adapter.dispatch('snapshot_staging_table', 'dbt')(strategy, source_sql, target_relation) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.default__snapshot_staging_table"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.674149}, "macro.dbt.default__snapshot_staging_table": {"unique_id": "macro.dbt.default__snapshot_staging_table", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/snapshots/helpers.sql", "original_file_path": "macros/materializations/snapshots/helpers.sql", "name": "default__snapshot_staging_table", "macro_sql": "{% macro default__snapshot_staging_table(strategy, source_sql, target_relation) -%}\n\n    with snapshot_query as (\n\n        {{ source_sql }}\n\n    ),\n\n    snapshotted_data as (\n\n        select *,\n            {{ strategy.unique_key }} as dbt_unique_key\n\n        from {{ target_relation }}\n        where dbt_valid_to is null\n\n    ),\n\n    insertions_source_data as (\n\n        select\n            *,\n            {{ strategy.unique_key }} as dbt_unique_key,\n            {{ strategy.updated_at }} as dbt_updated_at,\n            {{ strategy.updated_at }} as dbt_valid_from,\n            nullif({{ strategy.updated_at }}, {{ strategy.updated_at }}) as dbt_valid_to,\n            {{ strategy.scd_id }} as dbt_scd_id\n\n        from snapshot_query\n    ),\n\n    updates_source_data as (\n\n        select\n            *,\n            {{ strategy.unique_key }} as dbt_unique_key,\n            {{ strategy.updated_at }} as dbt_updated_at,\n            {{ strategy.updated_at }} as dbt_valid_from,\n            {{ strategy.updated_at }} as dbt_valid_to\n\n        from snapshot_query\n    ),\n\n    {%- if strategy.invalidate_hard_deletes %}\n\n    deletes_source_data as (\n\n        select \n            *,\n            {{ strategy.unique_key }} as dbt_unique_key\n        from snapshot_query\n    ),\n    {% endif %}\n\n    insertions as (\n\n        select\n            'insert' as dbt_change_type,\n            source_data.*\n\n        from insertions_source_data as source_data\n        left outer join snapshotted_data on snapshotted_data.dbt_unique_key = source_data.dbt_unique_key\n        where snapshotted_data.dbt_unique_key is null\n           or (\n                snapshotted_data.dbt_unique_key is not null\n            and (\n                {{ strategy.row_changed }}\n            )\n        )\n\n    ),\n\n    updates as (\n\n        select\n            'update' as dbt_change_type,\n            source_data.*,\n            snapshotted_data.dbt_scd_id\n\n        from updates_source_data as source_data\n        join snapshotted_data on snapshotted_data.dbt_unique_key = source_data.dbt_unique_key\n        where (\n            {{ strategy.row_changed }}\n        )\n    )\n\n    {%- if strategy.invalidate_hard_deletes -%}\n    ,\n\n    deletes as (\n    \n        select\n            'delete' as dbt_change_type,\n            source_data.*,\n            {{ snapshot_get_time() }} as dbt_valid_from,\n            {{ snapshot_get_time() }} as dbt_updated_at,\n            {{ snapshot_get_time() }} as dbt_valid_to,\n            snapshotted_data.dbt_scd_id\n    \n        from snapshotted_data\n        left join deletes_source_data as source_data on snapshotted_data.dbt_unique_key = source_data.dbt_unique_key\n        where source_data.dbt_unique_key is null\n    )\n    {%- endif %}\n\n    select * from insertions\n    union all\n    select * from updates\n    {%- if strategy.invalidate_hard_deletes %}\n    union all\n    select * from deletes\n    {%- endif %}\n\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.snapshot_get_time"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.676297}, "macro.dbt.build_snapshot_table": {"unique_id": "macro.dbt.build_snapshot_table", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/snapshots/helpers.sql", "original_file_path": "macros/materializations/snapshots/helpers.sql", "name": "build_snapshot_table", "macro_sql": "{% macro build_snapshot_table(strategy, sql) -%}\n  {{ adapter.dispatch('build_snapshot_table', 'dbt')(strategy, sql) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.default__build_snapshot_table"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.6768079}, "macro.dbt.default__build_snapshot_table": {"unique_id": "macro.dbt.default__build_snapshot_table", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/snapshots/helpers.sql", "original_file_path": "macros/materializations/snapshots/helpers.sql", "name": "default__build_snapshot_table", "macro_sql": "{% macro default__build_snapshot_table(strategy, sql) %}\n\n    select *,\n        {{ strategy.scd_id }} as dbt_scd_id,\n        {{ strategy.updated_at }} as dbt_updated_at,\n        {{ strategy.updated_at }} as dbt_valid_from,\n        nullif({{ strategy.updated_at }}, {{ strategy.updated_at }}) as dbt_valid_to\n    from (\n        {{ sql }}\n    ) sbq\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.67744}, "macro.dbt.build_snapshot_staging_table": {"unique_id": "macro.dbt.build_snapshot_staging_table", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/snapshots/helpers.sql", "original_file_path": "macros/materializations/snapshots/helpers.sql", "name": "build_snapshot_staging_table", "macro_sql": "{% macro build_snapshot_staging_table(strategy, sql, target_relation) %}\n    {% set tmp_relation = make_temp_relation(target_relation) %}\n\n    {% set select = snapshot_staging_table(strategy, sql, target_relation) %}\n\n    {% call statement('build_snapshot_staging_relation') %}\n        {{ create_table_as(True, tmp_relation, select) }}\n    {% endcall %}\n\n    {% do return(tmp_relation) %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.make_temp_relation", "macro.dbt.snapshot_staging_table", "macro.dbt.statement", "macro.dbt.create_table_as"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.678514}, "macro.dbt.materialization_snapshot_default": {"unique_id": "macro.dbt.materialization_snapshot_default", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/snapshots/snapshot.sql", "original_file_path": "macros/materializations/snapshots/snapshot.sql", "name": "materialization_snapshot_default", "macro_sql": "{% materialization snapshot, default %}\n  {%- set config = model['config'] -%}\n\n  {%- set target_table = model.get('alias', model.get('name')) -%}\n\n  {%- set strategy_name = config.get('strategy') -%}\n  {%- set unique_key = config.get('unique_key') %}\n\n  {% if not adapter.check_schema_exists(model.database, model.schema) %}\n    {% do create_schema(model.database, model.schema) %}\n  {% endif %}\n\n  {% set target_relation_exists, target_relation = get_or_create_relation(\n          database=model.database,\n          schema=model.schema,\n          identifier=target_table,\n          type='table') -%}\n\n  {%- if not target_relation.is_table -%}\n    {% do exceptions.relation_wrong_type(target_relation, 'table') %}\n  {%- endif -%}\n\n\n  {{ run_hooks(pre_hooks, inside_transaction=False) }}\n\n  {{ run_hooks(pre_hooks, inside_transaction=True) }}\n\n  {% set strategy_macro = strategy_dispatch(strategy_name) %}\n  {% set strategy = strategy_macro(model, \"snapshotted_data\", \"source_data\", config, target_relation_exists) %}\n\n  {% if not target_relation_exists %}\n\n      {% set build_sql = build_snapshot_table(strategy, model['compiled_sql']) %}\n      {% set final_sql = create_table_as(False, target_relation, build_sql) %}\n\n  {% else %}\n\n      {{ adapter.valid_snapshot_target(target_relation) }}\n\n      {% set staging_table = build_snapshot_staging_table(strategy, sql, target_relation) %}\n\n      -- this may no-op if the database does not require column expansion\n      {% do adapter.expand_target_column_types(from_relation=staging_table,\n                                               to_relation=target_relation) %}\n\n      {% set missing_columns = adapter.get_missing_columns(staging_table, target_relation)\n                                   | rejectattr('name', 'equalto', 'dbt_change_type')\n                                   | rejectattr('name', 'equalto', 'DBT_CHANGE_TYPE')\n                                   | rejectattr('name', 'equalto', 'dbt_unique_key')\n                                   | rejectattr('name', 'equalto', 'DBT_UNIQUE_KEY')\n                                   | list %}\n\n      {% do create_columns(target_relation, missing_columns) %}\n\n      {% set source_columns = adapter.get_columns_in_relation(staging_table)\n                                   | rejectattr('name', 'equalto', 'dbt_change_type')\n                                   | rejectattr('name', 'equalto', 'DBT_CHANGE_TYPE')\n                                   | rejectattr('name', 'equalto', 'dbt_unique_key')\n                                   | rejectattr('name', 'equalto', 'DBT_UNIQUE_KEY')\n                                   | list %}\n\n      {% set quoted_source_columns = [] %}\n      {% for column in source_columns %}\n        {% do quoted_source_columns.append(adapter.quote(column.name)) %}\n      {% endfor %}\n\n      {% set final_sql = snapshot_merge_sql(\n            target = target_relation,\n            source = staging_table,\n            insert_cols = quoted_source_columns\n         )\n      %}\n\n  {% endif %}\n\n  {% call statement('main') %}\n      {{ final_sql }}\n  {% endcall %}\n\n  {% do persist_docs(target_relation, model) %}\n\n  {% if not target_relation_exists %}\n    {% do create_indexes(target_relation) %}\n  {% endif %}\n\n  {{ run_hooks(post_hooks, inside_transaction=True) }}\n\n  {{ adapter.commit() }}\n\n  {% if staging_table is defined %}\n      {% do post_snapshot(staging_table) %}\n  {% endif %}\n\n  {{ run_hooks(post_hooks, inside_transaction=False) }}\n\n  {{ return({'relations': [target_relation]}) }}\n\n{% endmaterialization %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.create_schema", "macro.dbt.get_or_create_relation", "macro.dbt.run_hooks", "macro.dbt.strategy_dispatch", "macro.dbt.build_snapshot_table", "macro.dbt.create_table_as", "macro.dbt.build_snapshot_staging_table", "macro.dbt.create_columns", "macro.dbt.snapshot_merge_sql", "macro.dbt.statement", "macro.dbt.persist_docs", "macro.dbt.create_indexes", "macro.dbt.post_snapshot"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.6908438}, "macro.dbt.materialization_test_default": {"unique_id": "macro.dbt.materialization_test_default", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/tests/test.sql", "original_file_path": "macros/materializations/tests/test.sql", "name": "materialization_test_default", "macro_sql": "{%- materialization test, default -%}\n\n  {% set relations = [] %}\n\n  {% if should_store_failures() %}\n\n    {% set identifier = model['alias'] %}\n    {% set old_relation = adapter.get_relation(database=database, schema=schema, identifier=identifier) %}\n    {% set target_relation = api.Relation.create(\n        identifier=identifier, schema=schema, database=database, type='table') -%} %}\n    \n    {% if old_relation %}\n        {% do adapter.drop_relation(old_relation) %}\n    {% endif %}\n    \n    {% call statement(auto_begin=True) %}\n        {{ create_table_as(False, target_relation, sql) }}\n    {% endcall %}\n    \n    {% do relations.append(target_relation) %}\n  \n    {% set main_sql %}\n        select *\n        from {{ target_relation }}\n    {% endset %}\n    \n    {{ adapter.commit() }}\n  \n  {% else %}\n\n      {% set main_sql = sql %}\n  \n  {% endif %}\n\n  {% set limit = config.get('limit') %}\n  {% set fail_calc = config.get('fail_calc') %}\n  {% set warn_if = config.get('warn_if') %}\n  {% set error_if = config.get('error_if') %}\n\n  {% call statement('main', fetch_result=True) -%}\n\n    {{ get_test_sql(main_sql, fail_calc, warn_if, error_if, limit)}}\n\n  {%- endcall %}\n  \n  {{ return({'relations': relations}) }}\n\n{%- endmaterialization -%}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.should_store_failures", "macro.dbt.statement", "macro.dbt.create_table_as", "macro.dbt.get_test_sql"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.69564}, "macro.dbt.get_test_sql": {"unique_id": "macro.dbt.get_test_sql", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/tests/helpers.sql", "original_file_path": "macros/materializations/tests/helpers.sql", "name": "get_test_sql", "macro_sql": "{% macro get_test_sql(main_sql, fail_calc, warn_if, error_if, limit) -%}\n  {{ adapter.dispatch('get_test_sql', 'dbt')(main_sql, fail_calc, warn_if, error_if, limit) }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.default__get_test_sql"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.696774}, "macro.dbt.default__get_test_sql": {"unique_id": "macro.dbt.default__get_test_sql", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/tests/helpers.sql", "original_file_path": "macros/materializations/tests/helpers.sql", "name": "default__get_test_sql", "macro_sql": "{% macro default__get_test_sql(main_sql, fail_calc, warn_if, error_if, limit) -%}\n    select\n      {{ fail_calc }} as failures,\n      {{ fail_calc }} {{ warn_if }} as should_warn,\n      {{ fail_calc }} {{ error_if }} as should_error\n    from (\n      {{ main_sql }}\n      {{ \"limit \" ~ limit if limit != none }}\n    ) dbt_internal_test\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.6975439}, "macro.dbt.get_where_subquery": {"unique_id": "macro.dbt.get_where_subquery", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/tests/where_subquery.sql", "original_file_path": "macros/materializations/tests/where_subquery.sql", "name": "get_where_subquery", "macro_sql": "{% macro get_where_subquery(relation) -%}\n    {% do return(adapter.dispatch('get_where_subquery', 'dbt')(relation)) %}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.default__get_where_subquery"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.698464}, "macro.dbt.default__get_where_subquery": {"unique_id": "macro.dbt.default__get_where_subquery", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/tests/where_subquery.sql", "original_file_path": "macros/materializations/tests/where_subquery.sql", "name": "default__get_where_subquery", "macro_sql": "{% macro default__get_where_subquery(relation) -%}\n    {% set where = config.get('where', '') %}\n    {% if where %}\n        {%- set filtered -%}\n            (select * from {{ relation }} where {{ where }}) dbt_subquery\n        {%- endset -%}\n        {% do return(filtered) %}\n    {%- else -%}\n        {% do return(relation) %}\n    {%- endif -%}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.6993952}, "macro.dbt.get_quoted_csv": {"unique_id": "macro.dbt.get_quoted_csv", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/models/incremental/column_helpers.sql", "original_file_path": "macros/materializations/models/incremental/column_helpers.sql", "name": "get_quoted_csv", "macro_sql": "{% macro get_quoted_csv(column_names) %}\n    \n    {% set quoted = [] %}\n    {% for col in column_names -%}\n        {%- do quoted.append(adapter.quote(col)) -%}\n    {%- endfor %}\n\n    {%- set dest_cols_csv = quoted | join(', ') -%}\n    {{ return(dest_cols_csv) }}\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.701351}, "macro.dbt.diff_columns": {"unique_id": "macro.dbt.diff_columns", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/models/incremental/column_helpers.sql", "original_file_path": "macros/materializations/models/incremental/column_helpers.sql", "name": "diff_columns", "macro_sql": "{% macro diff_columns(source_columns, target_columns) %}\n\n  {% set result = [] %}\n  {% set source_names = source_columns | map(attribute = 'column') | list %}\n  {% set target_names = target_columns | map(attribute = 'column') | list %}\n   \n   {# --check whether the name attribute exists in the target - this does not perform a data type check #}\n   {% for sc in source_columns %}\n     {% if sc.name not in target_names %}\n        {{ result.append(sc) }}\n     {% endif %}\n   {% endfor %}\n  \n  {{ return(result) }}\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.702723}, "macro.dbt.diff_column_data_types": {"unique_id": "macro.dbt.diff_column_data_types", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/models/incremental/column_helpers.sql", "original_file_path": "macros/materializations/models/incremental/column_helpers.sql", "name": "diff_column_data_types", "macro_sql": "{% macro diff_column_data_types(source_columns, target_columns) %}\n  \n  {% set result = [] %}\n  {% for sc in source_columns %}\n    {% set tc = target_columns | selectattr(\"name\", \"equalto\", sc.name) | list | first %}\n    {% if tc %}\n      {% if sc.data_type != tc.data_type %}\n        {{ result.append( { 'column_name': tc.name, 'new_type': sc.data_type } ) }} \n      {% endif %}\n    {% endif %}\n  {% endfor %}\n\n  {{ return(result) }}\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.7044811}, "macro.dbt.get_merge_sql": {"unique_id": "macro.dbt.get_merge_sql", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/models/incremental/merge.sql", "original_file_path": "macros/materializations/models/incremental/merge.sql", "name": "get_merge_sql", "macro_sql": "{% macro get_merge_sql(target, source, unique_key, dest_columns, predicates=none) -%}\n  {{ adapter.dispatch('get_merge_sql', 'dbt')(target, source, unique_key, dest_columns, predicates) }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.default__get_merge_sql"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.708983}, "macro.dbt.default__get_merge_sql": {"unique_id": "macro.dbt.default__get_merge_sql", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/models/incremental/merge.sql", "original_file_path": "macros/materializations/models/incremental/merge.sql", "name": "default__get_merge_sql", "macro_sql": "{% macro default__get_merge_sql(target, source, unique_key, dest_columns, predicates) -%}\n    {%- set predicates = [] if predicates is none else [] + predicates -%}\n    {%- set dest_cols_csv = get_quoted_csv(dest_columns | map(attribute=\"name\")) -%}\n    {%- set update_columns = config.get('merge_update_columns', default = dest_columns | map(attribute=\"quoted\") | list) -%}\n    {%- set sql_header = config.get('sql_header', none) -%}\n\n    {% if unique_key %}\n        {% set unique_key_match %}\n            DBT_INTERNAL_SOURCE.{{ unique_key }} = DBT_INTERNAL_DEST.{{ unique_key }}\n        {% endset %}\n        {% do predicates.append(unique_key_match) %}\n    {% else %}\n        {% do predicates.append('FALSE') %}\n    {% endif %}\n\n    {{ sql_header if sql_header is not none }}\n\n    merge into {{ target }} as DBT_INTERNAL_DEST\n        using {{ source }} as DBT_INTERNAL_SOURCE\n        on {{ predicates | join(' and ') }}\n\n    {% if unique_key %}\n    when matched then update set\n        {% for column_name in update_columns -%}\n            {{ column_name }} = DBT_INTERNAL_SOURCE.{{ column_name }}\n            {%- if not loop.last %}, {%- endif %}\n        {%- endfor %}\n    {% endif %}\n\n    when not matched then insert\n        ({{ dest_cols_csv }})\n    values\n        ({{ dest_cols_csv }})\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.get_quoted_csv"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.711843}, "macro.dbt.get_delete_insert_merge_sql": {"unique_id": "macro.dbt.get_delete_insert_merge_sql", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/models/incremental/merge.sql", "original_file_path": "macros/materializations/models/incremental/merge.sql", "name": "get_delete_insert_merge_sql", "macro_sql": "{% macro get_delete_insert_merge_sql(target, source, unique_key, dest_columns) -%}\n  {{ adapter.dispatch('get_delete_insert_merge_sql', 'dbt')(target, source, unique_key, dest_columns) }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.default__get_delete_insert_merge_sql"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.712416}, "macro.dbt.default__get_delete_insert_merge_sql": {"unique_id": "macro.dbt.default__get_delete_insert_merge_sql", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/models/incremental/merge.sql", "original_file_path": "macros/materializations/models/incremental/merge.sql", "name": "default__get_delete_insert_merge_sql", "macro_sql": "{% macro default__get_delete_insert_merge_sql(target, source, unique_key, dest_columns) -%}\n\n    {%- set dest_cols_csv = get_quoted_csv(dest_columns | map(attribute=\"name\")) -%}\n\n    {% if unique_key is not none %}\n    delete from {{ target }}\n    where ({{ unique_key }}) in (\n        select ({{ unique_key }})\n        from {{ source }}\n    );\n    {% endif %}\n\n    insert into {{ target }} ({{ dest_cols_csv }})\n    (\n        select {{ dest_cols_csv }}\n        from {{ source }}\n    )\n\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.get_quoted_csv"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.7134662}, "macro.dbt.get_insert_overwrite_merge_sql": {"unique_id": "macro.dbt.get_insert_overwrite_merge_sql", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/models/incremental/merge.sql", "original_file_path": "macros/materializations/models/incremental/merge.sql", "name": "get_insert_overwrite_merge_sql", "macro_sql": "{% macro get_insert_overwrite_merge_sql(target, source, dest_columns, predicates, include_sql_header=false) -%}\n  {{ adapter.dispatch('get_insert_overwrite_merge_sql', 'dbt')(target, source, dest_columns, predicates, include_sql_header) }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.default__get_insert_overwrite_merge_sql"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.714106}, "macro.dbt.default__get_insert_overwrite_merge_sql": {"unique_id": "macro.dbt.default__get_insert_overwrite_merge_sql", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/models/incremental/merge.sql", "original_file_path": "macros/materializations/models/incremental/merge.sql", "name": "default__get_insert_overwrite_merge_sql", "macro_sql": "{% macro default__get_insert_overwrite_merge_sql(target, source, dest_columns, predicates, include_sql_header) -%}\n    {%- set predicates = [] if predicates is none else [] + predicates -%}\n    {%- set dest_cols_csv = get_quoted_csv(dest_columns | map(attribute=\"name\")) -%}\n    {%- set sql_header = config.get('sql_header', none) -%}\n\n    {{ sql_header if sql_header is not none and include_sql_header }}\n\n    merge into {{ target }} as DBT_INTERNAL_DEST\n        using {{ source }} as DBT_INTERNAL_SOURCE\n        on FALSE\n\n    when not matched by source\n        {% if predicates %} and {{ predicates | join(' and ') }} {% endif %}\n        then delete\n\n    when not matched then insert\n        ({{ dest_cols_csv }})\n    values\n        ({{ dest_cols_csv }})\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.get_quoted_csv"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.715786}, "macro.dbt.is_incremental": {"unique_id": "macro.dbt.is_incremental", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/models/incremental/is_incremental.sql", "original_file_path": "macros/materializations/models/incremental/is_incremental.sql", "name": "is_incremental", "macro_sql": "{% macro is_incremental() %}\n    {#-- do not run introspective queries in parsing #}\n    {% if not execute %}\n        {{ return(False) }}\n    {% else %}\n        {% set relation = adapter.get_relation(this.database, this.schema, this.table) %}\n        {{ return(relation is not none\n                  and relation.type == 'table'\n                  and model.config.materialized == 'incremental'\n                  and not should_full_refresh()) }}\n    {% endif %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.should_full_refresh"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.717367}, "macro.dbt.materialization_incremental_default": {"unique_id": "macro.dbt.materialization_incremental_default", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/models/incremental/incremental.sql", "original_file_path": "macros/materializations/models/incremental/incremental.sql", "name": "materialization_incremental_default", "macro_sql": "{% materialization incremental, default -%}\n\n  {% set unique_key = config.get('unique_key') %}\n\n  {% set target_relation = this.incorporate(type='table') %}\n  {% set existing_relation = load_relation(this) %}\n  {% set tmp_relation = make_temp_relation(target_relation) %}\n  {%- set full_refresh_mode = (should_full_refresh()) -%}\n\n  {% set on_schema_change = incremental_validate_on_schema_change(config.get('on_schema_change'), default='ignore') %}\n\n  {% set tmp_identifier = model['name'] + '__dbt_tmp' %}\n  {% set backup_identifier = model['name'] + \"__dbt_backup\" %}\n\n  -- the intermediate_ and backup_ relations should not already exist in the database; get_relation\n  -- will return None in that case. Otherwise, we get a relation that we can drop\n  -- later, before we try to use this name for the current operation. This has to happen before\n  -- BEGIN, in a separate transaction\n  {% set preexisting_intermediate_relation = adapter.get_relation(identifier=tmp_identifier, \n                                                                  schema=schema,\n                                                                  database=database) %}                                               \n  {% set preexisting_backup_relation = adapter.get_relation(identifier=backup_identifier,\n                                                            schema=schema,\n                                                            database=database) %}\n  {{ drop_relation_if_exists(preexisting_intermediate_relation) }}\n  {{ drop_relation_if_exists(preexisting_backup_relation) }}\n\n  {{ run_hooks(pre_hooks, inside_transaction=False) }}\n\n  -- `BEGIN` happens here:\n  {{ run_hooks(pre_hooks, inside_transaction=True) }}\n\n  {% set to_drop = [] %}\n\n  {# -- first check whether we want to full refresh for source view or config reasons #}\n  {% set trigger_full_refresh = (full_refresh_mode or existing_relation.is_view) %}\n\n  {% if existing_relation is none %}\n      {% set build_sql = create_table_as(False, target_relation, sql) %}\n{% elif trigger_full_refresh %}\n      {#-- Make sure the backup doesn't exist so we don't encounter issues with the rename below #}\n      {% set tmp_identifier = model['name'] + '__dbt_tmp' %}\n      {% set backup_identifier = model['name'] + '__dbt_backup' %}\n      {% set intermediate_relation = existing_relation.incorporate(path={\"identifier\": tmp_identifier}) %}\n      {% set backup_relation = existing_relation.incorporate(path={\"identifier\": backup_identifier}) %}\n\n      {% set build_sql = create_table_as(False, intermediate_relation, sql) %}\n      {% set need_swap = true %}\n      {% do to_drop.append(backup_relation) %}\n  {% else %}\n    {% do run_query(create_table_as(True, tmp_relation, sql)) %}\n    {% do adapter.expand_target_column_types(\n             from_relation=tmp_relation,\n             to_relation=target_relation) %}\n    {#-- Process schema changes. Returns dict of changes if successful. Use source columns for upserting/merging --#}\n    {% set dest_columns = process_schema_changes(on_schema_change, tmp_relation, existing_relation) %}\n    {% if not dest_columns %}\n      {% set dest_columns = adapter.get_columns_in_relation(existing_relation) %}\n    {% endif %}\n    {% set build_sql = get_delete_insert_merge_sql(target_relation, tmp_relation, unique_key, dest_columns) %}\n  \n  {% endif %}\n\n  {% call statement(\"main\") %}\n      {{ build_sql }}\n  {% endcall %}\n\n  {% if need_swap %} \n      {% do adapter.rename_relation(target_relation, backup_relation) %} \n      {% do adapter.rename_relation(intermediate_relation, target_relation) %} \n  {% endif %}\n\n  {% do persist_docs(target_relation, model) %}\n\n  {% if existing_relation is none or existing_relation.is_view or should_full_refresh() %}\n    {% do create_indexes(target_relation) %}\n  {% endif %}\n\n  {{ run_hooks(post_hooks, inside_transaction=True) }}\n\n  -- `COMMIT` happens here\n  {% do adapter.commit() %}\n\n  {% for rel in to_drop %}\n      {% do adapter.drop_relation(rel) %}\n  {% endfor %}\n\n  {{ run_hooks(post_hooks, inside_transaction=False) }}\n\n  {{ return({'relations': [target_relation]}) }}\n\n{%- endmaterialization %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.load_relation", "macro.dbt.make_temp_relation", "macro.dbt.should_full_refresh", "macro.dbt.incremental_validate_on_schema_change", "macro.dbt.drop_relation_if_exists", "macro.dbt.run_hooks", "macro.dbt.create_table_as", "macro.dbt.run_query", "macro.dbt.process_schema_changes", "macro.dbt.get_delete_insert_merge_sql", "macro.dbt.statement", "macro.dbt.persist_docs", "macro.dbt.create_indexes"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.728875}, "macro.dbt.incremental_validate_on_schema_change": {"unique_id": "macro.dbt.incremental_validate_on_schema_change", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/models/incremental/on_schema_change.sql", "original_file_path": "macros/materializations/models/incremental/on_schema_change.sql", "name": "incremental_validate_on_schema_change", "macro_sql": "{% macro incremental_validate_on_schema_change(on_schema_change, default='ignore') %}\n   \n   {% if on_schema_change not in ['sync_all_columns', 'append_new_columns', 'fail', 'ignore'] %}\n     \n     {% set log_message = 'Invalid value for on_schema_change (%s) specified. Setting default value of %s.' % (on_schema_change, default) %}\n     {% do log(log_message) %}\n     \n     {{ return(default) }}\n\n   {% else %}\n\n     {{ return(on_schema_change) }}\n   \n   {% endif %}\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.736673}, "macro.dbt.check_for_schema_changes": {"unique_id": "macro.dbt.check_for_schema_changes", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/models/incremental/on_schema_change.sql", "original_file_path": "macros/materializations/models/incremental/on_schema_change.sql", "name": "check_for_schema_changes", "macro_sql": "{% macro check_for_schema_changes(source_relation, target_relation) %}\n  \n  {% set schema_changed = False %}\n  \n  {%- set source_columns = adapter.get_columns_in_relation(source_relation) -%}\n  {%- set target_columns = adapter.get_columns_in_relation(target_relation) -%}\n  {%- set source_not_in_target = diff_columns(source_columns, target_columns) -%}\n  {%- set target_not_in_source = diff_columns(target_columns, source_columns) -%}\n\n  {% set new_target_types = diff_column_data_types(source_columns, target_columns) %}\n\n  {% if source_not_in_target != [] %}\n    {% set schema_changed = True %}\n  {% elif target_not_in_source != [] or new_target_types != [] %}\n    {% set schema_changed = True %}\n  {% elif new_target_types != [] %}\n    {% set schema_changed = True %}\n  {% endif %}\n  \n  {% set changes_dict = {\n    'schema_changed': schema_changed,\n    'source_not_in_target': source_not_in_target,\n    'target_not_in_source': target_not_in_source,\n    'source_columns': source_columns,\n    'target_columns': target_columns,\n    'new_target_types': new_target_types\n  } %}\n\n  {% set msg %}\n    In {{ target_relation }}:\n        Schema changed: {{ schema_changed }}\n        Source columns not in target: {{ source_not_in_target }}\n        Target columns not in source: {{ target_not_in_source }}\n        New column types: {{ new_target_types }}\n  {% endset %}\n  \n  {% do log(msg) %}\n\n  {{ return(changes_dict) }}\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.diff_columns", "macro.dbt.diff_column_data_types"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.7399528}, "macro.dbt.sync_column_schemas": {"unique_id": "macro.dbt.sync_column_schemas", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/models/incremental/on_schema_change.sql", "original_file_path": "macros/materializations/models/incremental/on_schema_change.sql", "name": "sync_column_schemas", "macro_sql": "{% macro sync_column_schemas(on_schema_change, target_relation, schema_changes_dict) %}\n  \n  {%- set add_to_target_arr = schema_changes_dict['source_not_in_target'] -%}\n\n  {%- if on_schema_change == 'append_new_columns'-%}\n     {%- if add_to_target_arr | length > 0 -%}\n       {%- do alter_relation_add_remove_columns(target_relation, add_to_target_arr, none) -%}\n     {%- endif -%}\n  \n  {% elif on_schema_change == 'sync_all_columns' %}\n     {%- set remove_from_target_arr = schema_changes_dict['target_not_in_source'] -%}\n     {%- set new_target_types = schema_changes_dict['new_target_types'] -%}\n  \n     {% if add_to_target_arr | length > 0 or remove_from_target_arr | length > 0 %} \n       {%- do alter_relation_add_remove_columns(target_relation, add_to_target_arr, remove_from_target_arr) -%}\n     {% endif %}\n\n     {% if new_target_types != [] %}\n       {% for ntt in new_target_types %}\n         {% set column_name = ntt['column_name'] %}\n         {% set new_type = ntt['new_type'] %}\n         {% do alter_column_type(target_relation, column_name, new_type) %}\n       {% endfor %}\n     {% endif %}\n  \n  {% endif %}\n\n  {% set schema_change_message %}\n    In {{ target_relation }}:\n        Schema change approach: {{ on_schema_change }}\n        Columns added: {{ add_to_target_arr }}\n        Columns removed: {{ remove_from_target_arr }}\n        Data types changed: {{ new_target_types }}\n  {% endset %}\n  \n  {% do log(schema_change_message) %}\n  \n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.alter_relation_add_remove_columns", "macro.dbt.alter_column_type"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.742996}, "macro.dbt.process_schema_changes": {"unique_id": "macro.dbt.process_schema_changes", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/models/incremental/on_schema_change.sql", "original_file_path": "macros/materializations/models/incremental/on_schema_change.sql", "name": "process_schema_changes", "macro_sql": "{% macro process_schema_changes(on_schema_change, source_relation, target_relation) %}\n    \n    {% if on_schema_change == 'ignore' %}\n\n     {{ return({}) }}\n\n    {% else %}\n    \n      {% set schema_changes_dict = check_for_schema_changes(source_relation, target_relation) %}\n      \n      {% if schema_changes_dict['schema_changed'] %}\n    \n        {% if on_schema_change == 'fail' %}\n        \n          {% set fail_msg %}\n              The source and target schemas on this incremental model are out of sync!\n              They can be reconciled in several ways: \n                - set the `on_schema_change` config to either append_new_columns or sync_all_columns, depending on your situation.\n                - Re-run the incremental model with `full_refresh: True` to update the target schema.\n                - update the schema manually and re-run the process.\n          {% endset %}\n          \n          {% do exceptions.raise_compiler_error(fail_msg) %}\n        \n        {# -- unless we ignore, run the sync operation per the config #}\n        {% else %}\n          \n          {% do sync_column_schemas(on_schema_change, target_relation, schema_changes_dict) %}\n        \n        {% endif %}\n      \n      {% endif %}\n\n      {{ return(schema_changes_dict['source_columns']) }}\n    \n    {% endif %}\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.check_for_schema_changes", "macro.dbt.sync_column_schemas"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.7447848}, "macro.dbt.materialization_table_default": {"unique_id": "macro.dbt.materialization_table_default", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/models/table/table.sql", "original_file_path": "macros/materializations/models/table/table.sql", "name": "materialization_table_default", "macro_sql": "{% materialization table, default %}\n  {%- set identifier = model['alias'] -%}\n  {%- set tmp_identifier = model['name'] + '__dbt_tmp' -%}\n  {%- set backup_identifier = model['name'] + '__dbt_backup' -%}\n\n  {%- set old_relation = adapter.get_relation(database=database, schema=schema, identifier=identifier) -%}\n  {%- set target_relation = api.Relation.create(identifier=identifier,\n                                                schema=schema,\n                                                database=database,\n                                                type='table') -%}\n  {%- set intermediate_relation = api.Relation.create(identifier=tmp_identifier,\n                                                      schema=schema,\n                                                      database=database,\n                                                      type='table') -%}\n  -- the intermediate_relation should not already exist in the database; get_relation\n  -- will return None in that case. Otherwise, we get a relation that we can drop\n  -- later, before we try to use this name for the current operation\n  {%- set preexisting_intermediate_relation = adapter.get_relation(identifier=tmp_identifier, \n                                                                   schema=schema,\n                                                                   database=database) -%}\n  /*\n      See ../view/view.sql for more information about this relation.\n  */\n  {%- set backup_relation_type = 'table' if old_relation is none else old_relation.type -%}\n  {%- set backup_relation = api.Relation.create(identifier=backup_identifier,\n                                                schema=schema,\n                                                database=database,\n                                                type=backup_relation_type) -%}\n  -- as above, the backup_relation should not already exist\n  {%- set preexisting_backup_relation = adapter.get_relation(identifier=backup_identifier,\n                                                             schema=schema,\n                                                             database=database) -%}\n\n\n  -- drop the temp relations if they exist already in the database\n  {{ drop_relation_if_exists(preexisting_intermediate_relation) }}\n  {{ drop_relation_if_exists(preexisting_backup_relation) }}\n\n  {{ run_hooks(pre_hooks, inside_transaction=False) }}\n\n  -- `BEGIN` happens here:\n  {{ run_hooks(pre_hooks, inside_transaction=True) }}\n\n  -- build model\n  {% call statement('main') -%}\n    {{ get_create_table_as_sql(False, intermediate_relation, sql) }}\n  {%- endcall %}\n\n  -- cleanup\n  {% if old_relation is not none %}\n      {{ adapter.rename_relation(old_relation, backup_relation) }}\n  {% endif %}\n\n  {{ adapter.rename_relation(intermediate_relation, target_relation) }}\n\n  {% do create_indexes(target_relation) %}\n\n  {{ run_hooks(post_hooks, inside_transaction=True) }}\n\n  {% do persist_docs(target_relation, model) %}\n\n  -- `COMMIT` happens here\n  {{ adapter.commit() }}\n\n  -- finally, drop the existing/backup relation after the commit\n  {{ drop_relation_if_exists(backup_relation) }}\n\n  {{ run_hooks(post_hooks, inside_transaction=False) }}\n\n  {{ return({'relations': [target_relation]}) }}\n{% endmaterialization %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.drop_relation_if_exists", "macro.dbt.run_hooks", "macro.dbt.statement", "macro.dbt.get_create_table_as_sql", "macro.dbt.create_indexes", "macro.dbt.persist_docs"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.752403}, "macro.dbt.get_create_table_as_sql": {"unique_id": "macro.dbt.get_create_table_as_sql", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/models/table/create_table_as.sql", "original_file_path": "macros/materializations/models/table/create_table_as.sql", "name": "get_create_table_as_sql", "macro_sql": "{% macro get_create_table_as_sql(temporary, relation, sql) -%}\n  {{ adapter.dispatch('get_create_table_as_sql', 'dbt')(temporary, relation, sql) }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.default__get_create_table_as_sql"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.75346}, "macro.dbt.default__get_create_table_as_sql": {"unique_id": "macro.dbt.default__get_create_table_as_sql", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/models/table/create_table_as.sql", "original_file_path": "macros/materializations/models/table/create_table_as.sql", "name": "default__get_create_table_as_sql", "macro_sql": "{% macro default__get_create_table_as_sql(temporary, relation, sql) -%}\n  {{ return(create_table_as(temporary, relation, sql)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.create_table_as"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.7539341}, "macro.dbt.create_table_as": {"unique_id": "macro.dbt.create_table_as", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/models/table/create_table_as.sql", "original_file_path": "macros/materializations/models/table/create_table_as.sql", "name": "create_table_as", "macro_sql": "{% macro create_table_as(temporary, relation, sql) -%}\n  {{ adapter.dispatch('create_table_as', 'dbt')(temporary, relation, sql) }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_bigquery.bigquery__create_table_as"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.754441}, "macro.dbt.default__create_table_as": {"unique_id": "macro.dbt.default__create_table_as", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/models/table/create_table_as.sql", "original_file_path": "macros/materializations/models/table/create_table_as.sql", "name": "default__create_table_as", "macro_sql": "{% macro default__create_table_as(temporary, relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n  \n  {{ sql_header if sql_header is not none }}\n  \n  create {% if temporary: -%}temporary{%- endif %} table\n    {{ relation.include(database=(not temporary), schema=(not temporary)) }}\n  as (\n    {{ sql }}\n  );\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.755519}, "macro.dbt.materialization_view_default": {"unique_id": "macro.dbt.materialization_view_default", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/models/view/view.sql", "original_file_path": "macros/materializations/models/view/view.sql", "name": "materialization_view_default", "macro_sql": "{%- materialization view, default -%}\n\n  {%- set identifier = model['alias'] -%}\n  {%- set tmp_identifier = model['name'] + '__dbt_tmp' -%}\n  {%- set backup_identifier = model['name'] + '__dbt_backup' -%}\n\n  {%- set old_relation = adapter.get_relation(database=database, schema=schema, identifier=identifier) -%}\n  {%- set target_relation = api.Relation.create(identifier=identifier, schema=schema, database=database,\n                                                type='view') -%}\n  {%- set intermediate_relation = api.Relation.create(identifier=tmp_identifier,\n                                                      schema=schema, database=database, type='view') -%}\n  -- the intermediate_relation should not already exist in the database; get_relation\n  -- will return None in that case. Otherwise, we get a relation that we can drop\n  -- later, before we try to use this name for the current operation\n  {%- set preexisting_intermediate_relation = adapter.get_relation(identifier=tmp_identifier, \n                                                                   schema=schema,\n                                                                   database=database) -%}\n  /*\n     This relation (probably) doesn't exist yet. If it does exist, it's a leftover from\n     a previous run, and we're going to try to drop it immediately. At the end of this\n     materialization, we're going to rename the \"old_relation\" to this identifier,\n     and then we're going to drop it. In order to make sure we run the correct one of:\n       - drop view ...\n       - drop table ...\n\n     We need to set the type of this relation to be the type of the old_relation, if it exists,\n     or else \"view\" as a sane default if it does not. Note that if the old_relation does not\n     exist, then there is nothing to move out of the way and subsequentally drop. In that case,\n     this relation will be effectively unused.\n  */\n  {%- set backup_relation_type = 'view' if old_relation is none else old_relation.type -%}\n  {%- set backup_relation = api.Relation.create(identifier=backup_identifier,\n                                                schema=schema, database=database,\n                                                type=backup_relation_type) -%}\n  -- as above, the backup_relation should not already exist\n  {%- set preexisting_backup_relation = adapter.get_relation(identifier=backup_identifier,\n                                                             schema=schema,\n                                                             database=database) -%}\n\n  {{ run_hooks(pre_hooks, inside_transaction=False) }}\n\n  -- drop the temp relations if they exist already in the database\n  {{ drop_relation_if_exists(preexisting_intermediate_relation) }}\n  {{ drop_relation_if_exists(preexisting_backup_relation) }}\n\n  -- `BEGIN` happens here:\n  {{ run_hooks(pre_hooks, inside_transaction=True) }}\n\n  -- build model\n  {% call statement('main') -%}\n    {{ create_view_as(intermediate_relation, sql) }}\n  {%- endcall %}\n\n  -- cleanup\n  -- move the existing view out of the way\n  {% if old_relation is not none %}\n    {{ adapter.rename_relation(old_relation, backup_relation) }}\n  {% endif %}\n  {{ adapter.rename_relation(intermediate_relation, target_relation) }}\n\n  {% do persist_docs(target_relation, model) %}\n\n  {{ run_hooks(post_hooks, inside_transaction=True) }}\n\n  {{ adapter.commit() }}\n\n  {{ drop_relation_if_exists(backup_relation) }}\n\n  {{ run_hooks(post_hooks, inside_transaction=False) }}\n\n  {{ return({'relations': [target_relation]}) }}\n\n{%- endmaterialization -%}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.run_hooks", "macro.dbt.drop_relation_if_exists", "macro.dbt.statement", "macro.dbt.create_view_as", "macro.dbt.persist_docs"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.762954}, "macro.dbt.handle_existing_table": {"unique_id": "macro.dbt.handle_existing_table", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/models/view/helpers.sql", "original_file_path": "macros/materializations/models/view/helpers.sql", "name": "handle_existing_table", "macro_sql": "{% macro handle_existing_table(full_refresh, old_relation) %}\n    {{ adapter.dispatch('handle_existing_table', 'dbt')(full_refresh, old_relation) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_bigquery.bigquery__handle_existing_table"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.763778}, "macro.dbt.default__handle_existing_table": {"unique_id": "macro.dbt.default__handle_existing_table", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/models/view/helpers.sql", "original_file_path": "macros/materializations/models/view/helpers.sql", "name": "default__handle_existing_table", "macro_sql": "{% macro default__handle_existing_table(full_refresh, old_relation) %}\n    {{ log(\"Dropping relation \" ~ old_relation ~ \" because it is of type \" ~ old_relation.type) }}\n    {{ adapter.drop_relation(old_relation) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.764419}, "macro.dbt.create_or_replace_view": {"unique_id": "macro.dbt.create_or_replace_view", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/models/view/create_or_replace_view.sql", "original_file_path": "macros/materializations/models/view/create_or_replace_view.sql", "name": "create_or_replace_view", "macro_sql": "{% macro create_or_replace_view() %}\n  {%- set identifier = model['alias'] -%}\n\n  {%- set old_relation = adapter.get_relation(database=database, schema=schema, identifier=identifier) -%}\n\n  {%- set exists_as_view = (old_relation is not none and old_relation.is_view) -%}\n\n  {%- set target_relation = api.Relation.create(\n      identifier=identifier, schema=schema, database=database,\n      type='view') -%}\n\n  {{ run_hooks(pre_hooks) }}\n\n  -- If there's a table with the same name and we weren't told to full refresh,\n  -- that's an error. If we were told to full refresh, drop it. This behavior differs\n  -- for Snowflake and BigQuery, so multiple dispatch is used.\n  {%- if old_relation is not none and old_relation.is_table -%}\n    {{ handle_existing_table(should_full_refresh(), old_relation) }}\n  {%- endif -%}\n\n  -- build model\n  {% call statement('main') -%}\n    {{ get_create_view_as_sql(target_relation, sql) }}\n  {%- endcall %}\n\n  {{ run_hooks(post_hooks) }}\n\n  {{ return({'relations': [target_relation]}) }}\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.run_hooks", "macro.dbt.handle_existing_table", "macro.dbt.should_full_refresh", "macro.dbt.statement", "macro.dbt.get_create_view_as_sql"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.767329}, "macro.dbt.get_create_view_as_sql": {"unique_id": "macro.dbt.get_create_view_as_sql", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/models/view/create_view_as.sql", "original_file_path": "macros/materializations/models/view/create_view_as.sql", "name": "get_create_view_as_sql", "macro_sql": "{% macro get_create_view_as_sql(relation, sql) -%}\n  {{ adapter.dispatch('get_create_view_as_sql', 'dbt')(relation, sql) }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.default__get_create_view_as_sql"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.768341}, "macro.dbt.default__get_create_view_as_sql": {"unique_id": "macro.dbt.default__get_create_view_as_sql", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/models/view/create_view_as.sql", "original_file_path": "macros/materializations/models/view/create_view_as.sql", "name": "default__get_create_view_as_sql", "macro_sql": "{% macro default__get_create_view_as_sql(relation, sql) -%}\n  {{ return(create_view_as(relation, sql)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.create_view_as"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.768759}, "macro.dbt.create_view_as": {"unique_id": "macro.dbt.create_view_as", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/models/view/create_view_as.sql", "original_file_path": "macros/materializations/models/view/create_view_as.sql", "name": "create_view_as", "macro_sql": "{% macro create_view_as(relation, sql) -%}\n  {{ adapter.dispatch('create_view_as', 'dbt')(relation, sql) }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_bigquery.bigquery__create_view_as"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.7692218}, "macro.dbt.default__create_view_as": {"unique_id": "macro.dbt.default__create_view_as", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/models/view/create_view_as.sql", "original_file_path": "macros/materializations/models/view/create_view_as.sql", "name": "default__create_view_as", "macro_sql": "{% macro default__create_view_as(relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n  create view {{ relation }} as (\n    {{ sql }}\n  );\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.769876}, "macro.dbt.materialization_seed_default": {"unique_id": "macro.dbt.materialization_seed_default", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/seeds/seed.sql", "original_file_path": "macros/materializations/seeds/seed.sql", "name": "materialization_seed_default", "macro_sql": "{% materialization seed, default %}\n\n  {%- set identifier = model['alias'] -%}\n  {%- set full_refresh_mode = (should_full_refresh()) -%}\n\n  {%- set old_relation = adapter.get_relation(database=database, schema=schema, identifier=identifier) -%}\n\n  {%- set exists_as_table = (old_relation is not none and old_relation.is_table) -%}\n  {%- set exists_as_view = (old_relation is not none and old_relation.is_view) -%}\n\n  {%- set agate_table = load_agate_table() -%}\n  {%- do store_result('agate_table', response='OK', agate_table=agate_table) -%}\n\n  {{ run_hooks(pre_hooks, inside_transaction=False) }}\n\n  -- `BEGIN` happens here:\n  {{ run_hooks(pre_hooks, inside_transaction=True) }}\n\n  -- build model\n  {% set create_table_sql = \"\" %}\n  {% if exists_as_view %}\n    {{ exceptions.raise_compiler_error(\"Cannot seed to '{}', it is a view\".format(old_relation)) }}\n  {% elif exists_as_table %}\n    {% set create_table_sql = reset_csv_table(model, full_refresh_mode, old_relation, agate_table) %}\n  {% else %}\n    {% set create_table_sql = create_csv_table(model, agate_table) %}\n  {% endif %}\n\n  {% set code = 'CREATE' if full_refresh_mode else 'INSERT' %}\n  {% set rows_affected = (agate_table.rows | length) %}\n  {% set sql = load_csv_rows(model, agate_table) %}\n\n  {% call noop_statement('main', code ~ ' ' ~ rows_affected, code, rows_affected) %}\n    {{ create_table_sql }};\n    -- dbt seed --\n    {{ sql }}\n  {% endcall %}\n\n  {% set target_relation = this.incorporate(type='table') %}\n  {% do persist_docs(target_relation, model) %}\n\n  {% if full_refresh_mode or not exists_as_table %}\n    {% do create_indexes(target_relation) %}\n  {% endif %}\n\n  {{ run_hooks(post_hooks, inside_transaction=True) }}\n\n  -- `COMMIT` happens here\n  {{ adapter.commit() }}\n\n  {{ run_hooks(post_hooks, inside_transaction=False) }}\n\n  {{ return({'relations': [target_relation]}) }}\n\n{% endmaterialization %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.should_full_refresh", "macro.dbt.run_hooks", "macro.dbt.reset_csv_table", "macro.dbt.create_csv_table", "macro.dbt.load_csv_rows", "macro.dbt.noop_statement", "macro.dbt.persist_docs", "macro.dbt.create_indexes"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.776864}, "macro.dbt.create_csv_table": {"unique_id": "macro.dbt.create_csv_table", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/seeds/helpers.sql", "original_file_path": "macros/materializations/seeds/helpers.sql", "name": "create_csv_table", "macro_sql": "{% macro create_csv_table(model, agate_table) -%}\n  {{ adapter.dispatch('create_csv_table', 'dbt')(model, agate_table) }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_bigquery.bigquery__create_csv_table"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.783363}, "macro.dbt.default__create_csv_table": {"unique_id": "macro.dbt.default__create_csv_table", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/seeds/helpers.sql", "original_file_path": "macros/materializations/seeds/helpers.sql", "name": "default__create_csv_table", "macro_sql": "{% macro default__create_csv_table(model, agate_table) %}\n  {%- set column_override = model['config'].get('column_types', {}) -%}\n  {%- set quote_seed_column = model['config'].get('quote_columns', None) -%}\n\n  {% set sql %}\n    create table {{ this.render() }} (\n        {%- for col_name in agate_table.column_names -%}\n            {%- set inferred_type = adapter.convert_type(agate_table, loop.index0) -%}\n            {%- set type = column_override.get(col_name, inferred_type) -%}\n            {%- set column_name = (col_name | string) -%}\n            {{ adapter.quote_seed_column(column_name, quote_seed_column) }} {{ type }} {%- if not loop.last -%}, {%- endif -%}\n        {%- endfor -%}\n    )\n  {% endset %}\n\n  {% call statement('_') -%}\n    {{ sql }}\n  {%- endcall %}\n\n  {{ return(sql) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.7856152}, "macro.dbt.reset_csv_table": {"unique_id": "macro.dbt.reset_csv_table", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/seeds/helpers.sql", "original_file_path": "macros/materializations/seeds/helpers.sql", "name": "reset_csv_table", "macro_sql": "{% macro reset_csv_table(model, full_refresh, old_relation, agate_table) -%}\n  {{ adapter.dispatch('reset_csv_table', 'dbt')(model, full_refresh, old_relation, agate_table) }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_bigquery.bigquery__reset_csv_table"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.786192}, "macro.dbt.default__reset_csv_table": {"unique_id": "macro.dbt.default__reset_csv_table", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/seeds/helpers.sql", "original_file_path": "macros/materializations/seeds/helpers.sql", "name": "default__reset_csv_table", "macro_sql": "{% macro default__reset_csv_table(model, full_refresh, old_relation, agate_table) %}\n    {% set sql = \"\" %}\n    {% if full_refresh %}\n        {{ adapter.drop_relation(old_relation) }}\n        {% set sql = create_csv_table(model, agate_table) %}\n    {% else %}\n        {{ adapter.truncate_relation(old_relation) }}\n        {% set sql = \"truncate table \" ~ old_relation %}\n    {% endif %}\n\n    {{ return(sql) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.create_csv_table"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.78745}, "macro.dbt.get_binding_char": {"unique_id": "macro.dbt.get_binding_char", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/seeds/helpers.sql", "original_file_path": "macros/materializations/seeds/helpers.sql", "name": "get_binding_char", "macro_sql": "{% macro get_binding_char() -%}\n  {{ adapter.dispatch('get_binding_char', 'dbt')() }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.default__get_binding_char"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.787812}, "macro.dbt.default__get_binding_char": {"unique_id": "macro.dbt.default__get_binding_char", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/seeds/helpers.sql", "original_file_path": "macros/materializations/seeds/helpers.sql", "name": "default__get_binding_char", "macro_sql": "{% macro default__get_binding_char() %}\n  {{ return('%s') }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.788107}, "macro.dbt.get_batch_size": {"unique_id": "macro.dbt.get_batch_size", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/seeds/helpers.sql", "original_file_path": "macros/materializations/seeds/helpers.sql", "name": "get_batch_size", "macro_sql": "{% macro get_batch_size() -%}\n  {{ return(adapter.dispatch('get_batch_size', 'dbt')()) }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.default__get_batch_size"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.788505}, "macro.dbt.default__get_batch_size": {"unique_id": "macro.dbt.default__get_batch_size", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/seeds/helpers.sql", "original_file_path": "macros/materializations/seeds/helpers.sql", "name": "default__get_batch_size", "macro_sql": "{% macro default__get_batch_size() %}\n  {{ return(10000) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.7888598}, "macro.dbt.get_seed_column_quoted_csv": {"unique_id": "macro.dbt.get_seed_column_quoted_csv", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/seeds/helpers.sql", "original_file_path": "macros/materializations/seeds/helpers.sql", "name": "get_seed_column_quoted_csv", "macro_sql": "{% macro get_seed_column_quoted_csv(model, column_names) %}\n  {%- set quote_seed_column = model['config'].get('quote_columns', None) -%}\n    {% set quoted = [] %}\n    {% for col in column_names -%}\n        {%- do quoted.append(adapter.quote_seed_column(col, quote_seed_column)) -%}\n    {%- endfor %}\n\n    {%- set dest_cols_csv = quoted | join(', ') -%}\n    {{ return(dest_cols_csv) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.790047}, "macro.dbt.load_csv_rows": {"unique_id": "macro.dbt.load_csv_rows", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/seeds/helpers.sql", "original_file_path": "macros/materializations/seeds/helpers.sql", "name": "load_csv_rows", "macro_sql": "{% macro load_csv_rows(model, agate_table) -%}\n  {{ adapter.dispatch('load_csv_rows', 'dbt')(model, agate_table) }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_bigquery.bigquery__load_csv_rows"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.7905128}, "macro.dbt.default__load_csv_rows": {"unique_id": "macro.dbt.default__load_csv_rows", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/seeds/helpers.sql", "original_file_path": "macros/materializations/seeds/helpers.sql", "name": "default__load_csv_rows", "macro_sql": "{% macro default__load_csv_rows(model, agate_table) %}\n\n  {% set batch_size = get_batch_size() %}\n\n  {% set cols_sql = get_seed_column_quoted_csv(model, agate_table.column_names) %}\n  {% set bindings = [] %}\n\n  {% set statements = [] %}\n\n  {% for chunk in agate_table.rows | batch(batch_size) %}\n      {% set bindings = [] %}\n\n      {% for row in chunk %}\n          {% do bindings.extend(row) %}\n      {% endfor %}\n\n      {% set sql %}\n          insert into {{ this.render() }} ({{ cols_sql }}) values\n          {% for row in chunk -%}\n              ({%- for column in agate_table.column_names -%}\n                  {{ get_binding_char() }}\n                  {%- if not loop.last%},{%- endif %}\n              {%- endfor -%})\n              {%- if not loop.last%},{%- endif %}\n          {%- endfor %}\n      {% endset %}\n\n      {% do adapter.add_query(sql, bindings=bindings, abridge_sql_log=True) %}\n\n      {% if loop.index0 == 0 %}\n          {% do statements.append(sql) %}\n      {% endif %}\n  {% endfor %}\n\n  {# Return SQL so we can render it out into the compiled files #}\n  {{ return(statements[0]) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.get_batch_size", "macro.dbt.get_seed_column_quoted_csv", "macro.dbt.get_binding_char"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.7936199}, "macro.dbt.generate_alias_name": {"unique_id": "macro.dbt.generate_alias_name", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/get_custom_name/get_custom_alias.sql", "original_file_path": "macros/get_custom_name/get_custom_alias.sql", "name": "generate_alias_name", "macro_sql": "{% macro generate_alias_name(custom_alias_name=none, node=none) -%}\n    {% do return(adapter.dispatch('generate_alias_name', 'dbt')(custom_alias_name, node)) %}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.default__generate_alias_name"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.794642}, "macro.dbt.default__generate_alias_name": {"unique_id": "macro.dbt.default__generate_alias_name", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/get_custom_name/get_custom_alias.sql", "original_file_path": "macros/get_custom_name/get_custom_alias.sql", "name": "default__generate_alias_name", "macro_sql": "{% macro default__generate_alias_name(custom_alias_name=none, node=none) -%}\n\n    {%- if custom_alias_name is none -%}\n\n        {{ node.name }}\n\n    {%- else -%}\n\n        {{ custom_alias_name | trim }}\n\n    {%- endif -%}\n\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.795211}, "macro.dbt.generate_schema_name": {"unique_id": "macro.dbt.generate_schema_name", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/get_custom_name/get_custom_schema.sql", "original_file_path": "macros/get_custom_name/get_custom_schema.sql", "name": "generate_schema_name", "macro_sql": "{% macro generate_schema_name(custom_schema_name=none, node=none) -%}\n    {{ return(adapter.dispatch('generate_schema_name', 'dbt')(custom_schema_name, node)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.default__generate_schema_name"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.796447}, "macro.dbt.default__generate_schema_name": {"unique_id": "macro.dbt.default__generate_schema_name", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/get_custom_name/get_custom_schema.sql", "original_file_path": "macros/get_custom_name/get_custom_schema.sql", "name": "default__generate_schema_name", "macro_sql": "{% macro default__generate_schema_name(custom_schema_name, node) -%}\n\n    {%- set default_schema = target.schema -%}\n    {%- if custom_schema_name is none -%}\n\n        {{ default_schema }}\n\n    {%- else -%}\n\n        {{ default_schema }}_{{ custom_schema_name | trim }}\n\n    {%- endif -%}\n\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.797107}, "macro.dbt.generate_schema_name_for_env": {"unique_id": "macro.dbt.generate_schema_name_for_env", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/get_custom_name/get_custom_schema.sql", "original_file_path": "macros/get_custom_name/get_custom_schema.sql", "name": "generate_schema_name_for_env", "macro_sql": "{% macro generate_schema_name_for_env(custom_schema_name, node) -%}\n\n    {%- set default_schema = target.schema -%}\n    {%- if target.name == 'prod' and custom_schema_name is not none -%}\n\n        {{ custom_schema_name | trim }}\n\n    {%- else -%}\n\n        {{ default_schema }}\n\n    {%- endif -%}\n\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.797824}, "macro.dbt.generate_database_name": {"unique_id": "macro.dbt.generate_database_name", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/get_custom_name/get_custom_database.sql", "original_file_path": "macros/get_custom_name/get_custom_database.sql", "name": "generate_database_name", "macro_sql": "{% macro generate_database_name(custom_database_name=none, node=none) -%}\n    {% do return(adapter.dispatch('generate_database_name', 'dbt')(custom_database_name, node)) %}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.default__generate_database_name"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.798837}, "macro.dbt.default__generate_database_name": {"unique_id": "macro.dbt.default__generate_database_name", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/get_custom_name/get_custom_database.sql", "original_file_path": "macros/get_custom_name/get_custom_database.sql", "name": "default__generate_database_name", "macro_sql": "{% macro default__generate_database_name(custom_database_name=none, node=none) -%}\n    {%- set default_database = target.database -%}\n    {%- if custom_database_name is none -%}\n\n        {{ default_database }}\n\n    {%- else -%}\n\n        {{ custom_database_name }}\n\n    {%- endif -%}\n\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.799472}, "macro.dbt.default__test_relationships": {"unique_id": "macro.dbt.default__test_relationships", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/generic_test_sql/relationships.sql", "original_file_path": "macros/generic_test_sql/relationships.sql", "name": "default__test_relationships", "macro_sql": "{% macro default__test_relationships(model, column_name, to, field) %}\n\nwith child as (\n    select {{ column_name }} as from_field\n    from {{ model }}\n    where {{ column_name }} is not null\n),\n\nparent as (\n    select {{ field }} as to_field\n    from {{ to }}\n)\n\nselect\n    from_field\n\nfrom child\nleft join parent\n    on child.from_field = parent.to_field\n\nwhere parent.to_field is null\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.800378}, "macro.dbt.default__test_not_null": {"unique_id": "macro.dbt.default__test_not_null", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/generic_test_sql/not_null.sql", "original_file_path": "macros/generic_test_sql/not_null.sql", "name": "default__test_not_null", "macro_sql": "{% macro default__test_not_null(model, column_name) %}\n\nselect *\nfrom {{ model }}\nwhere {{ column_name }} is null\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.8009658}, "macro.dbt.default__test_unique": {"unique_id": "macro.dbt.default__test_unique", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/generic_test_sql/unique.sql", "original_file_path": "macros/generic_test_sql/unique.sql", "name": "default__test_unique", "macro_sql": "{% macro default__test_unique(model, column_name) %}\n\nselect\n    {{ column_name }} as unique_field,\n    count(*) as n_records\n\nfrom {{ model }}\nwhere {{ column_name }} is not null\ngroup by {{ column_name }}\nhaving count(*) > 1\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.8016908}, "macro.dbt.default__test_accepted_values": {"unique_id": "macro.dbt.default__test_accepted_values", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/generic_test_sql/accepted_values.sql", "original_file_path": "macros/generic_test_sql/accepted_values.sql", "name": "default__test_accepted_values", "macro_sql": "{% macro default__test_accepted_values(model, column_name, values, quote=True) %}\n\nwith all_values as (\n\n    select\n        {{ column_name }} as value_field,\n        count(*) as n_records\n\n    from {{ model }}\n    group by {{ column_name }}\n\n)\n\nselect *\nfrom all_values\nwhere value_field not in (\n    {% for value in values -%}\n        {% if quote -%}\n        '{{ value }}'\n        {%- else -%}\n        {{ value }}\n        {%- endif -%}\n        {%- if not loop.last -%},{%- endif %}\n    {%- endfor %}\n)\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.8032398}, "macro.dbt.statement": {"unique_id": "macro.dbt.statement", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/etc/statement.sql", "original_file_path": "macros/etc/statement.sql", "name": "statement", "macro_sql": "{% macro statement(name=None, fetch_result=False, auto_begin=True) -%}\n  {%- if execute: -%}\n    {%- set sql = caller() -%}\n\n    {%- if name == 'main' -%}\n      {{ log('Writing runtime SQL for node \"{}\"'.format(model['unique_id'])) }}\n      {{ write(sql) }}\n    {%- endif -%}\n\n    {%- set res, table = adapter.execute(sql, auto_begin=auto_begin, fetch=fetch_result) -%}\n    {%- if name is not none -%}\n      {{ store_result(name, response=res, agate_table=table) }}\n    {%- endif -%}\n\n  {%- endif -%}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.805803}, "macro.dbt.noop_statement": {"unique_id": "macro.dbt.noop_statement", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/etc/statement.sql", "original_file_path": "macros/etc/statement.sql", "name": "noop_statement", "macro_sql": "{% macro noop_statement(name=None, message=None, code=None, rows_affected=None, res=None) -%}\n  {%- set sql = caller() -%}\n\n  {%- if name == 'main' -%}\n    {{ log('Writing runtime SQL for node \"{}\"'.format(model['unique_id'])) }}\n    {{ write(sql) }}\n  {%- endif -%}\n\n  {%- if name is not none -%}\n    {{ store_raw_result(name, message=message, code=code, rows_affected=rows_affected, agate_table=res) }}\n  {%- endif -%}\n\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.807229}, "macro.dbt.run_query": {"unique_id": "macro.dbt.run_query", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/etc/statement.sql", "original_file_path": "macros/etc/statement.sql", "name": "run_query", "macro_sql": "{% macro run_query(sql) %}\n  {% call statement(\"run_query_statement\", fetch_result=true, auto_begin=false) %}\n    {{ sql }}\n  {% endcall %}\n\n  {% do return(load_result(\"run_query_statement\").table) %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.807963}, "macro.dbt.convert_datetime": {"unique_id": "macro.dbt.convert_datetime", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/etc/datetime.sql", "original_file_path": "macros/etc/datetime.sql", "name": "convert_datetime", "macro_sql": "{% macro convert_datetime(date_str, date_fmt) %}\n\n  {% set error_msg -%}\n      The provided partition date '{{ date_str }}' does not match the expected format '{{ date_fmt }}'\n  {%- endset %}\n\n  {% set res = try_or_compiler_error(error_msg, modules.datetime.datetime.strptime, date_str.strip(), date_fmt) %}\n  {{ return(res) }}\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.811059}, "macro.dbt.dates_in_range": {"unique_id": "macro.dbt.dates_in_range", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/etc/datetime.sql", "original_file_path": "macros/etc/datetime.sql", "name": "dates_in_range", "macro_sql": "{% macro dates_in_range(start_date_str, end_date_str=none, in_fmt=\"%Y%m%d\", out_fmt=\"%Y%m%d\") %}\n    {% set end_date_str = start_date_str if end_date_str is none else end_date_str %}\n\n    {% set start_date = convert_datetime(start_date_str, in_fmt) %}\n    {% set end_date = convert_datetime(end_date_str, in_fmt) %}\n\n    {% set day_count = (end_date - start_date).days %}\n    {% if day_count < 0 %}\n        {% set msg -%}\n            Partiton start date is after the end date ({{ start_date }}, {{ end_date }})\n        {%- endset %}\n\n        {{ exceptions.raise_compiler_error(msg, model) }}\n    {% endif %}\n\n    {% set date_list = [] %}\n    {% for i in range(0, day_count + 1) %}\n        {% set the_date = (modules.datetime.timedelta(days=i) + start_date) %}\n        {% if not out_fmt %}\n            {% set _ = date_list.append(the_date) %}\n        {% else %}\n            {% set _ = date_list.append(the_date.strftime(out_fmt)) %}\n        {% endif %}\n    {% endfor %}\n\n    {{ return(date_list) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.convert_datetime"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.8140311}, "macro.dbt.partition_range": {"unique_id": "macro.dbt.partition_range", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/etc/datetime.sql", "original_file_path": "macros/etc/datetime.sql", "name": "partition_range", "macro_sql": "{% macro partition_range(raw_partition_date, date_fmt='%Y%m%d') %}\n    {% set partition_range = (raw_partition_date | string).split(\",\") %}\n\n    {% if (partition_range | length) == 1 %}\n      {% set start_date = partition_range[0] %}\n      {% set end_date = none %}\n    {% elif (partition_range | length) == 2 %}\n      {% set start_date = partition_range[0] %}\n      {% set end_date = partition_range[1] %}\n    {% else %}\n      {{ exceptions.raise_compiler_error(\"Invalid partition time. Expected format: {Start Date}[,{End Date}]. Got: \" ~ raw_partition_date) }}\n    {% endif %}\n\n    {{ return(dates_in_range(start_date, end_date, in_fmt=date_fmt)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.dates_in_range"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.816019}, "macro.dbt.py_current_timestring": {"unique_id": "macro.dbt.py_current_timestring", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/etc/datetime.sql", "original_file_path": "macros/etc/datetime.sql", "name": "py_current_timestring", "macro_sql": "{% macro py_current_timestring() %}\n    {% set dt = modules.datetime.datetime.now() %}\n    {% do return(dt.strftime(\"%Y%m%d%H%M%S%f\")) %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.8166}, "macro.dbt.create_schema": {"unique_id": "macro.dbt.create_schema", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/adapters/schema.sql", "original_file_path": "macros/adapters/schema.sql", "name": "create_schema", "macro_sql": "{% macro create_schema(relation) -%}\n  {{ adapter.dispatch('create_schema', 'dbt')(relation) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_bigquery.bigquery__create_schema"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.8175309}, "macro.dbt.default__create_schema": {"unique_id": "macro.dbt.default__create_schema", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/adapters/schema.sql", "original_file_path": "macros/adapters/schema.sql", "name": "default__create_schema", "macro_sql": "{% macro default__create_schema(relation) -%}\n  {%- call statement('create_schema') -%}\n    create schema if not exists {{ relation.without_identifier() }}\n  {% endcall %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.817995}, "macro.dbt.drop_schema": {"unique_id": "macro.dbt.drop_schema", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/adapters/schema.sql", "original_file_path": "macros/adapters/schema.sql", "name": "drop_schema", "macro_sql": "{% macro drop_schema(relation) -%}\n  {{ adapter.dispatch('drop_schema', 'dbt')(relation) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_bigquery.bigquery__drop_schema"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.818403}, "macro.dbt.default__drop_schema": {"unique_id": "macro.dbt.default__drop_schema", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/adapters/schema.sql", "original_file_path": "macros/adapters/schema.sql", "name": "default__drop_schema", "macro_sql": "{% macro default__drop_schema(relation) -%}\n  {%- call statement('drop_schema') -%}\n    drop schema if exists {{ relation.without_identifier() }} cascade\n  {% endcall %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.818864}, "macro.dbt.get_create_index_sql": {"unique_id": "macro.dbt.get_create_index_sql", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/adapters/indexes.sql", "original_file_path": "macros/adapters/indexes.sql", "name": "get_create_index_sql", "macro_sql": "{% macro get_create_index_sql(relation, index_dict) -%}\n  {{ return(adapter.dispatch('get_create_index_sql', 'dbt')(relation, index_dict)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.default__get_create_index_sql"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.819948}, "macro.dbt.default__get_create_index_sql": {"unique_id": "macro.dbt.default__get_create_index_sql", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/adapters/indexes.sql", "original_file_path": "macros/adapters/indexes.sql", "name": "default__get_create_index_sql", "macro_sql": "{% macro default__get_create_index_sql(relation, index_dict) -%}\n  {% do return(None) %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.820296}, "macro.dbt.create_indexes": {"unique_id": "macro.dbt.create_indexes", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/adapters/indexes.sql", "original_file_path": "macros/adapters/indexes.sql", "name": "create_indexes", "macro_sql": "{% macro create_indexes(relation) -%}\n  {{ adapter.dispatch('create_indexes', 'dbt')(relation) }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.default__create_indexes"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.820695}, "macro.dbt.default__create_indexes": {"unique_id": "macro.dbt.default__create_indexes", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/adapters/indexes.sql", "original_file_path": "macros/adapters/indexes.sql", "name": "default__create_indexes", "macro_sql": "{% macro default__create_indexes(relation) -%}\n  {%- set _indexes = config.get('indexes', default=[]) -%}\n\n  {% for _index_dict in _indexes %}\n    {% set create_index_sql = get_create_index_sql(relation, _index_dict) %}\n    {% if create_index_sql %}\n      {% do run_query(create_index_sql) %}\n    {% endif %}\n  {% endfor %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.get_create_index_sql", "macro.dbt.run_query"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.821846}, "macro.dbt.make_temp_relation": {"unique_id": "macro.dbt.make_temp_relation", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/adapters/relation.sql", "original_file_path": "macros/adapters/relation.sql", "name": "make_temp_relation", "macro_sql": "{% macro make_temp_relation(base_relation, suffix='__dbt_tmp') %}\n  {{ return(adapter.dispatch('make_temp_relation', 'dbt')(base_relation, suffix))}}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.default__make_temp_relation"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.824675}, "macro.dbt.default__make_temp_relation": {"unique_id": "macro.dbt.default__make_temp_relation", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/adapters/relation.sql", "original_file_path": "macros/adapters/relation.sql", "name": "default__make_temp_relation", "macro_sql": "{% macro default__make_temp_relation(base_relation, suffix) %}\n    {% set tmp_identifier = base_relation.identifier ~ suffix %}\n    {% set tmp_relation = base_relation.incorporate(\n                                path={\"identifier\": tmp_identifier}) -%}\n\n    {% do return(tmp_relation) %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.8254411}, "macro.dbt.drop_relation": {"unique_id": "macro.dbt.drop_relation", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/adapters/relation.sql", "original_file_path": "macros/adapters/relation.sql", "name": "drop_relation", "macro_sql": "{% macro drop_relation(relation) -%}\n  {{ return(adapter.dispatch('drop_relation', 'dbt')(relation)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_bigquery.bigquery__drop_relation"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.825902}, "macro.dbt.default__drop_relation": {"unique_id": "macro.dbt.default__drop_relation", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/adapters/relation.sql", "original_file_path": "macros/adapters/relation.sql", "name": "default__drop_relation", "macro_sql": "{% macro default__drop_relation(relation) -%}\n  {% call statement('drop_relation', auto_begin=False) -%}\n    drop {{ relation.type }} if exists {{ relation }} cascade\n  {%- endcall %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.826446}, "macro.dbt.truncate_relation": {"unique_id": "macro.dbt.truncate_relation", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/adapters/relation.sql", "original_file_path": "macros/adapters/relation.sql", "name": "truncate_relation", "macro_sql": "{% macro truncate_relation(relation) -%}\n  {{ return(adapter.dispatch('truncate_relation', 'dbt')(relation)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.default__truncate_relation"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.826901}, "macro.dbt.default__truncate_relation": {"unique_id": "macro.dbt.default__truncate_relation", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/adapters/relation.sql", "original_file_path": "macros/adapters/relation.sql", "name": "default__truncate_relation", "macro_sql": "{% macro default__truncate_relation(relation) -%}\n  {% call statement('truncate_relation') -%}\n    truncate table {{ relation }}\n  {%- endcall %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.82731}, "macro.dbt.rename_relation": {"unique_id": "macro.dbt.rename_relation", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/adapters/relation.sql", "original_file_path": "macros/adapters/relation.sql", "name": "rename_relation", "macro_sql": "{% macro rename_relation(from_relation, to_relation) -%}\n  {{ return(adapter.dispatch('rename_relation', 'dbt')(from_relation, to_relation)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_bigquery.bigquery__rename_relation"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.8279822}, "macro.dbt.default__rename_relation": {"unique_id": "macro.dbt.default__rename_relation", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/adapters/relation.sql", "original_file_path": "macros/adapters/relation.sql", "name": "default__rename_relation", "macro_sql": "{% macro default__rename_relation(from_relation, to_relation) -%}\n  {% set target_name = adapter.quote_as_configured(to_relation.identifier, 'identifier') %}\n  {% call statement('rename_relation') -%}\n    alter table {{ from_relation }} rename to {{ target_name }}\n  {%- endcall %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.828694}, "macro.dbt.get_or_create_relation": {"unique_id": "macro.dbt.get_or_create_relation", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/adapters/relation.sql", "original_file_path": "macros/adapters/relation.sql", "name": "get_or_create_relation", "macro_sql": "{% macro get_or_create_relation(database, schema, identifier, type) -%}\n  {{ return(adapter.dispatch('get_or_create_relation', 'dbt')(database, schema, identifier, type)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.default__get_or_create_relation"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.8293161}, "macro.dbt.default__get_or_create_relation": {"unique_id": "macro.dbt.default__get_or_create_relation", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/adapters/relation.sql", "original_file_path": "macros/adapters/relation.sql", "name": "default__get_or_create_relation", "macro_sql": "{% macro default__get_or_create_relation(database, schema, identifier, type) %}\n  {%- set target_relation = adapter.get_relation(database=database, schema=schema, identifier=identifier) %}\n\n  {% if target_relation %}\n    {% do return([true, target_relation]) %}\n  {% endif %}\n\n  {%- set new_relation = api.Relation.create(\n      database=database,\n      schema=schema,\n      identifier=identifier,\n      type=type\n  ) -%}\n  {% do return([false, new_relation]) %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.830701}, "macro.dbt.load_relation": {"unique_id": "macro.dbt.load_relation", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/adapters/relation.sql", "original_file_path": "macros/adapters/relation.sql", "name": "load_relation", "macro_sql": "{% macro load_relation(relation) %}\n  {% do return(adapter.get_relation(\n    database=relation.database,\n    schema=relation.schema,\n    identifier=relation.identifier\n  )) -%}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.83127}, "macro.dbt.drop_relation_if_exists": {"unique_id": "macro.dbt.drop_relation_if_exists", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/adapters/relation.sql", "original_file_path": "macros/adapters/relation.sql", "name": "drop_relation_if_exists", "macro_sql": "{% macro drop_relation_if_exists(relation) %}\n  {% if relation is not none %}\n    {{ adapter.drop_relation(relation) }}\n  {% endif %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.831767}, "macro.dbt.current_timestamp": {"unique_id": "macro.dbt.current_timestamp", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/adapters/freshness.sql", "original_file_path": "macros/adapters/freshness.sql", "name": "current_timestamp", "macro_sql": "{% macro current_timestamp() -%}\n  {{ adapter.dispatch('current_timestamp', 'dbt')() }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.bigquery__current_timestamp"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.8328571}, "macro.dbt.default__current_timestamp": {"unique_id": "macro.dbt.default__current_timestamp", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/adapters/freshness.sql", "original_file_path": "macros/adapters/freshness.sql", "name": "default__current_timestamp", "macro_sql": "{% macro default__current_timestamp() -%}\n  {{ exceptions.raise_not_implemented(\n    'current_timestamp macro not implemented for adapter '+adapter.type()) }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.833227}, "macro.dbt.collect_freshness": {"unique_id": "macro.dbt.collect_freshness", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/adapters/freshness.sql", "original_file_path": "macros/adapters/freshness.sql", "name": "collect_freshness", "macro_sql": "{% macro collect_freshness(source, loaded_at_field, filter) %}\n  {{ return(adapter.dispatch('collect_freshness', 'dbt')(source, loaded_at_field, filter))}}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.fivetran_utils.default__collect_freshness"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.833799}, "macro.dbt.default__collect_freshness": {"unique_id": "macro.dbt.default__collect_freshness", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/adapters/freshness.sql", "original_file_path": "macros/adapters/freshness.sql", "name": "default__collect_freshness", "macro_sql": "{% macro default__collect_freshness(source, loaded_at_field, filter) %}\n  {% call statement('collect_freshness', fetch_result=True, auto_begin=False) -%}\n    select\n      max({{ loaded_at_field }}) as max_loaded_at,\n      {{ current_timestamp() }} as snapshotted_at\n    from {{ source }}\n    {% if filter %}\n    where {{ filter }}\n    {% endif %}\n  {% endcall %}\n  {{ return(load_result('collect_freshness').table) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.statement", "macro.dbt_utils.current_timestamp"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.835259}, "macro.dbt.alter_column_comment": {"unique_id": "macro.dbt.alter_column_comment", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/adapters/persist_docs.sql", "original_file_path": "macros/adapters/persist_docs.sql", "name": "alter_column_comment", "macro_sql": "{% macro alter_column_comment(relation, column_dict) -%}\n  {{ return(adapter.dispatch('alter_column_comment', 'dbt')(relation, column_dict)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_bigquery.bigquery__alter_column_comment"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.836826}, "macro.dbt.default__alter_column_comment": {"unique_id": "macro.dbt.default__alter_column_comment", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/adapters/persist_docs.sql", "original_file_path": "macros/adapters/persist_docs.sql", "name": "default__alter_column_comment", "macro_sql": "{% macro default__alter_column_comment(relation, column_dict) -%}\n  {{ exceptions.raise_not_implemented(\n    'alter_column_comment macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.837253}, "macro.dbt.alter_relation_comment": {"unique_id": "macro.dbt.alter_relation_comment", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/adapters/persist_docs.sql", "original_file_path": "macros/adapters/persist_docs.sql", "name": "alter_relation_comment", "macro_sql": "{% macro alter_relation_comment(relation, relation_comment) -%}\n  {{ return(adapter.dispatch('alter_relation_comment', 'dbt')(relation, relation_comment)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.default__alter_relation_comment"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.837766}, "macro.dbt.default__alter_relation_comment": {"unique_id": "macro.dbt.default__alter_relation_comment", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/adapters/persist_docs.sql", "original_file_path": "macros/adapters/persist_docs.sql", "name": "default__alter_relation_comment", "macro_sql": "{% macro default__alter_relation_comment(relation, relation_comment) -%}\n  {{ exceptions.raise_not_implemented(\n    'alter_relation_comment macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.838194}, "macro.dbt.persist_docs": {"unique_id": "macro.dbt.persist_docs", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/adapters/persist_docs.sql", "original_file_path": "macros/adapters/persist_docs.sql", "name": "persist_docs", "macro_sql": "{% macro persist_docs(relation, model, for_relation=true, for_columns=true) -%}\n  {{ return(adapter.dispatch('persist_docs', 'dbt')(relation, model, for_relation, for_columns)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_bigquery.bigquery__persist_docs"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.838933}, "macro.dbt.default__persist_docs": {"unique_id": "macro.dbt.default__persist_docs", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/adapters/persist_docs.sql", "original_file_path": "macros/adapters/persist_docs.sql", "name": "default__persist_docs", "macro_sql": "{% macro default__persist_docs(relation, model, for_relation, for_columns) -%}\n  {% if for_relation and config.persist_relation_docs() and model.description %}\n    {% do run_query(alter_relation_comment(relation, model.description)) %}\n  {% endif %}\n\n  {% if for_columns and config.persist_column_docs() and model.columns %}\n    {% do run_query(alter_column_comment(relation, model.columns)) %}\n  {% endif %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.run_query", "macro.dbt.alter_relation_comment", "macro.dbt.alter_column_comment"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.840157}, "macro.dbt.get_catalog": {"unique_id": "macro.dbt.get_catalog", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/adapters/metadata.sql", "original_file_path": "macros/adapters/metadata.sql", "name": "get_catalog", "macro_sql": "{% macro get_catalog(information_schema, schemas) -%}\n  {{ return(adapter.dispatch('get_catalog', 'dbt')(information_schema, schemas)) }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_bigquery.bigquery__get_catalog"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.8428328}, "macro.dbt.default__get_catalog": {"unique_id": "macro.dbt.default__get_catalog", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/adapters/metadata.sql", "original_file_path": "macros/adapters/metadata.sql", "name": "default__get_catalog", "macro_sql": "{% macro default__get_catalog(information_schema, schemas) -%}\n\n  {% set typename = adapter.type() %}\n  {% set msg -%}\n    get_catalog not implemented for {{ typename }}\n  {%- endset %}\n\n  {{ exceptions.raise_compiler_error(msg) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.843486}, "macro.dbt.information_schema_name": {"unique_id": "macro.dbt.information_schema_name", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/adapters/metadata.sql", "original_file_path": "macros/adapters/metadata.sql", "name": "information_schema_name", "macro_sql": "{% macro information_schema_name(database) %}\n  {{ return(adapter.dispatch('information_schema_name', 'dbt')(database)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.default__information_schema_name"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.843951}, "macro.dbt.default__information_schema_name": {"unique_id": "macro.dbt.default__information_schema_name", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/adapters/metadata.sql", "original_file_path": "macros/adapters/metadata.sql", "name": "default__information_schema_name", "macro_sql": "{% macro default__information_schema_name(database) -%}\n  {%- if database -%}\n    {{ database }}.INFORMATION_SCHEMA\n  {%- else -%}\n    INFORMATION_SCHEMA\n  {%- endif -%}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.844345}, "macro.dbt.list_schemas": {"unique_id": "macro.dbt.list_schemas", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/adapters/metadata.sql", "original_file_path": "macros/adapters/metadata.sql", "name": "list_schemas", "macro_sql": "{% macro list_schemas(database) -%}\n  {{ return(adapter.dispatch('list_schemas', 'dbt')(database)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_bigquery.bigquery__list_schemas"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.844794}, "macro.dbt.default__list_schemas": {"unique_id": "macro.dbt.default__list_schemas", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/adapters/metadata.sql", "original_file_path": "macros/adapters/metadata.sql", "name": "default__list_schemas", "macro_sql": "{% macro default__list_schemas(database) -%}\n  {% set sql %}\n    select distinct schema_name\n    from {{ information_schema_name(database) }}.SCHEMATA\n    where catalog_name ilike '{{ database }}'\n  {% endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.information_schema_name", "macro.dbt.run_query"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.845542}, "macro.dbt.check_schema_exists": {"unique_id": "macro.dbt.check_schema_exists", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/adapters/metadata.sql", "original_file_path": "macros/adapters/metadata.sql", "name": "check_schema_exists", "macro_sql": "{% macro check_schema_exists(information_schema, schema) -%}\n  {{ return(adapter.dispatch('check_schema_exists', 'dbt')(information_schema, schema)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_bigquery.bigquery__check_schema_exists"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.846175}, "macro.dbt.default__check_schema_exists": {"unique_id": "macro.dbt.default__check_schema_exists", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/adapters/metadata.sql", "original_file_path": "macros/adapters/metadata.sql", "name": "default__check_schema_exists", "macro_sql": "{% macro default__check_schema_exists(information_schema, schema) -%}\n  {% set sql -%}\n        select count(*)\n        from {{ information_schema.replace(information_schema_view='SCHEMATA') }}\n        where catalog_name='{{ information_schema.database }}'\n          and schema_name='{{ schema }}'\n  {%- endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.replace", "macro.dbt.run_query"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.847244}, "macro.dbt.list_relations_without_caching": {"unique_id": "macro.dbt.list_relations_without_caching", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/adapters/metadata.sql", "original_file_path": "macros/adapters/metadata.sql", "name": "list_relations_without_caching", "macro_sql": "{% macro list_relations_without_caching(schema_relation) %}\n  {{ return(adapter.dispatch('list_relations_without_caching', 'dbt')(schema_relation)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_bigquery.bigquery__list_relations_without_caching"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.847866}, "macro.dbt.default__list_relations_without_caching": {"unique_id": "macro.dbt.default__list_relations_without_caching", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/adapters/metadata.sql", "original_file_path": "macros/adapters/metadata.sql", "name": "default__list_relations_without_caching", "macro_sql": "{% macro default__list_relations_without_caching(schema_relation) %}\n  {{ exceptions.raise_not_implemented(\n    'list_relations_without_caching macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.848289}, "macro.dbt.get_columns_in_relation": {"unique_id": "macro.dbt.get_columns_in_relation", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/adapters/columns.sql", "original_file_path": "macros/adapters/columns.sql", "name": "get_columns_in_relation", "macro_sql": "{% macro get_columns_in_relation(relation) -%}\n  {{ return(adapter.dispatch('get_columns_in_relation', 'dbt')(relation)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_bigquery.bigquery__get_columns_in_relation"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.851341}, "macro.dbt.default__get_columns_in_relation": {"unique_id": "macro.dbt.default__get_columns_in_relation", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/adapters/columns.sql", "original_file_path": "macros/adapters/columns.sql", "name": "default__get_columns_in_relation", "macro_sql": "{% macro default__get_columns_in_relation(relation) -%}\n  {{ exceptions.raise_not_implemented(\n    'get_columns_in_relation macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.8517492}, "macro.dbt.sql_convert_columns_in_relation": {"unique_id": "macro.dbt.sql_convert_columns_in_relation", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/adapters/columns.sql", "original_file_path": "macros/adapters/columns.sql", "name": "sql_convert_columns_in_relation", "macro_sql": "{% macro sql_convert_columns_in_relation(table) -%}\n  {% set columns = [] %}\n  {% for row in table %}\n    {% do columns.append(api.Column(*row)) %}\n  {% endfor %}\n  {{ return(columns) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.8529038}, "macro.dbt.get_columns_in_query": {"unique_id": "macro.dbt.get_columns_in_query", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/adapters/columns.sql", "original_file_path": "macros/adapters/columns.sql", "name": "get_columns_in_query", "macro_sql": "{% macro get_columns_in_query(select_sql) -%}\n  {{ return(adapter.dispatch('get_columns_in_query', 'dbt')(select_sql)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.default__get_columns_in_query"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.853583}, "macro.dbt.default__get_columns_in_query": {"unique_id": "macro.dbt.default__get_columns_in_query", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/adapters/columns.sql", "original_file_path": "macros/adapters/columns.sql", "name": "default__get_columns_in_query", "macro_sql": "{% macro default__get_columns_in_query(select_sql) %}\n    {% call statement('get_columns_in_query', fetch_result=True, auto_begin=False) -%}\n        select * from (\n            {{ select_sql }}\n        ) as __dbt_sbq\n        where false\n        limit 0\n    {% endcall %}\n\n    {{ return(load_result('get_columns_in_query').table.columns | map(attribute='name') | list) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.8544462}, "macro.dbt.alter_column_type": {"unique_id": "macro.dbt.alter_column_type", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/adapters/columns.sql", "original_file_path": "macros/adapters/columns.sql", "name": "alter_column_type", "macro_sql": "{% macro alter_column_type(relation, column_name, new_column_type) -%}\n  {{ return(adapter.dispatch('alter_column_type', 'dbt')(relation, column_name, new_column_type)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_bigquery.bigquery__alter_column_type"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.855347}, "macro.dbt.default__alter_column_type": {"unique_id": "macro.dbt.default__alter_column_type", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/adapters/columns.sql", "original_file_path": "macros/adapters/columns.sql", "name": "default__alter_column_type", "macro_sql": "{% macro default__alter_column_type(relation, column_name, new_column_type) -%}\n  {#\n    1. Create a new column (w/ temp name and correct type)\n    2. Copy data over to it\n    3. Drop the existing column (cascade!)\n    4. Rename the new column to existing column\n  #}\n  {%- set tmp_column = column_name + \"__dbt_alter\" -%}\n\n  {% call statement('alter_column_type') %}\n    alter table {{ relation }} add column {{ adapter.quote(tmp_column) }} {{ new_column_type }};\n    update {{ relation }} set {{ adapter.quote(tmp_column) }} = {{ adapter.quote(column_name) }};\n    alter table {{ relation }} drop column {{ adapter.quote(column_name) }} cascade;\n    alter table {{ relation }} rename column {{ adapter.quote(tmp_column) }} to {{ adapter.quote(column_name) }}\n  {% endcall %}\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.856916}, "macro.dbt.alter_relation_add_remove_columns": {"unique_id": "macro.dbt.alter_relation_add_remove_columns", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/adapters/columns.sql", "original_file_path": "macros/adapters/columns.sql", "name": "alter_relation_add_remove_columns", "macro_sql": "{% macro alter_relation_add_remove_columns(relation, add_columns = none, remove_columns = none) -%}\n  {{ return(adapter.dispatch('alter_relation_add_remove_columns', 'dbt')(relation, add_columns, remove_columns)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.default__alter_relation_add_remove_columns"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.857616}, "macro.dbt.default__alter_relation_add_remove_columns": {"unique_id": "macro.dbt.default__alter_relation_add_remove_columns", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/adapters/columns.sql", "original_file_path": "macros/adapters/columns.sql", "name": "default__alter_relation_add_remove_columns", "macro_sql": "{% macro default__alter_relation_add_remove_columns(relation, add_columns, remove_columns) %}\n  \n  {% if add_columns is none %}\n    {% set add_columns = [] %}\n  {% endif %}\n  {% if remove_columns is none %}\n    {% set remove_columns = [] %}\n  {% endif %}\n  \n  {% set sql -%}\n     \n     alter {{ relation.type }} {{ relation }}\n       \n            {% for column in add_columns %}\n               add column {{ column.name }} {{ column.data_type }}{{ ',' if not loop.last }}\n            {% endfor %}{{ ',' if add_columns and remove_columns }}\n            \n            {% for column in remove_columns %}\n                drop column {{ column.name }}{{ ',' if not loop.last }}\n            {% endfor %}\n  \n  {%- endset -%}\n\n  {% do run_query(sql) %}\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.run_query"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.859822}, "macro.dbt.test_unique": {"unique_id": "macro.dbt.test_unique", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "tests/generic/builtin.sql", "original_file_path": "tests/generic/builtin.sql", "name": "test_unique", "macro_sql": "{% test unique(model, column_name) %}\n    {% set macro = adapter.dispatch('test_unique', 'dbt') %}\n    {{ macro(model, column_name) }}\n{% endtest %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_bigquery.bigquery__test_unique"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.8611069}, "macro.dbt.test_not_null": {"unique_id": "macro.dbt.test_not_null", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "tests/generic/builtin.sql", "original_file_path": "tests/generic/builtin.sql", "name": "test_not_null", "macro_sql": "{% test not_null(model, column_name) %}\n    {% set macro = adapter.dispatch('test_not_null', 'dbt') %}\n    {{ macro(model, column_name) }}\n{% endtest %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.default__test_not_null"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.861712}, "macro.dbt.test_accepted_values": {"unique_id": "macro.dbt.test_accepted_values", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "tests/generic/builtin.sql", "original_file_path": "tests/generic/builtin.sql", "name": "test_accepted_values", "macro_sql": "{% test accepted_values(model, column_name, values, quote=True) %}\n    {% set macro = adapter.dispatch('test_accepted_values', 'dbt') %}\n    {{ macro(model, column_name, values, quote) }}\n{% endtest %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.default__test_accepted_values"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.862442}, "macro.dbt.test_relationships": {"unique_id": "macro.dbt.test_relationships", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "tests/generic/builtin.sql", "original_file_path": "tests/generic/builtin.sql", "name": "test_relationships", "macro_sql": "{% test relationships(model, column_name, to, field) %}\n    {% set macro = adapter.dispatch('test_relationships', 'dbt') %}\n    {{ macro(model, column_name, to, field) }}\n{% endtest %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.default__test_relationships"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.863513}, "macro.dbt_utils.except": {"unique_id": "macro.dbt_utils.except", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/except.sql", "original_file_path": "macros/cross_db_utils/except.sql", "name": "except", "macro_sql": "{% macro except() %}\n  {{ return(adapter.dispatch('except', 'dbt_utils')()) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.bigquery__except"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.864295}, "macro.dbt_utils.default__except": {"unique_id": "macro.dbt_utils.default__except", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/except.sql", "original_file_path": "macros/cross_db_utils/except.sql", "name": "default__except", "macro_sql": "{% macro default__except() %}\n\n    except\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.86449}, "macro.dbt_utils.bigquery__except": {"unique_id": "macro.dbt_utils.bigquery__except", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/except.sql", "original_file_path": "macros/cross_db_utils/except.sql", "name": "bigquery__except", "macro_sql": "{% macro bigquery__except() %}\n\n    except distinct\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.864676}, "macro.dbt_utils.replace": {"unique_id": "macro.dbt_utils.replace", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/replace.sql", "original_file_path": "macros/cross_db_utils/replace.sql", "name": "replace", "macro_sql": "{% macro replace(field, old_chars, new_chars) -%}\n    {{ return(adapter.dispatch('replace', 'dbt_utils') (field, old_chars, new_chars)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__replace"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.866024}, "macro.dbt_utils.default__replace": {"unique_id": "macro.dbt_utils.default__replace", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/replace.sql", "original_file_path": "macros/cross_db_utils/replace.sql", "name": "default__replace", "macro_sql": "{% macro default__replace(field, old_chars, new_chars) %}\n\n    replace(\n        {{ field }},\n        {{ old_chars }},\n        {{ new_chars }}\n    )\n    \n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.866442}, "macro.dbt_utils.concat": {"unique_id": "macro.dbt_utils.concat", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/concat.sql", "original_file_path": "macros/cross_db_utils/concat.sql", "name": "concat", "macro_sql": "{% macro concat(fields) -%}\n  {{ return(adapter.dispatch('concat', 'dbt_utils')(fields)) }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__concat"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.86718}, "macro.dbt_utils.default__concat": {"unique_id": "macro.dbt_utils.default__concat", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/concat.sql", "original_file_path": "macros/cross_db_utils/concat.sql", "name": "default__concat", "macro_sql": "{% macro default__concat(fields) -%}\n    {{ fields|join(' || ') }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.8674922}, "macro.dbt_utils.type_string": {"unique_id": "macro.dbt_utils.type_string", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/datatypes.sql", "original_file_path": "macros/cross_db_utils/datatypes.sql", "name": "type_string", "macro_sql": "\n\n{%- macro type_string() -%}\n  {{ return(adapter.dispatch('type_string', 'dbt_utils')()) }}\n{%- endmacro -%}\n\n", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__type_string"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.8689542}, "macro.dbt_utils.default__type_string": {"unique_id": "macro.dbt_utils.default__type_string", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/datatypes.sql", "original_file_path": "macros/cross_db_utils/datatypes.sql", "name": "default__type_string", "macro_sql": "{% macro default__type_string() %}\n    string\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.8692732}, "macro.dbt_utils.redshift__type_string": {"unique_id": "macro.dbt_utils.redshift__type_string", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/datatypes.sql", "original_file_path": "macros/cross_db_utils/datatypes.sql", "name": "redshift__type_string", "macro_sql": "\n\n{%- macro redshift__type_string() -%}\n    varchar\n{%- endmacro -%}\n\n", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.869461}, "macro.dbt_utils.postgres__type_string": {"unique_id": "macro.dbt_utils.postgres__type_string", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/datatypes.sql", "original_file_path": "macros/cross_db_utils/datatypes.sql", "name": "postgres__type_string", "macro_sql": "{% macro postgres__type_string() %}\n    varchar\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.869643}, "macro.dbt_utils.snowflake__type_string": {"unique_id": "macro.dbt_utils.snowflake__type_string", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/datatypes.sql", "original_file_path": "macros/cross_db_utils/datatypes.sql", "name": "snowflake__type_string", "macro_sql": "{% macro snowflake__type_string() %}\n    varchar\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.869824}, "macro.dbt_utils.type_timestamp": {"unique_id": "macro.dbt_utils.type_timestamp", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/datatypes.sql", "original_file_path": "macros/cross_db_utils/datatypes.sql", "name": "type_timestamp", "macro_sql": "\n\n{%- macro type_timestamp() -%}\n  {{ return(adapter.dispatch('type_timestamp', 'dbt_utils')()) }}\n{%- endmacro -%}\n\n", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__type_timestamp"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.870222}, "macro.dbt_utils.default__type_timestamp": {"unique_id": "macro.dbt_utils.default__type_timestamp", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/datatypes.sql", "original_file_path": "macros/cross_db_utils/datatypes.sql", "name": "default__type_timestamp", "macro_sql": "{% macro default__type_timestamp() %}\n    timestamp\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.870454}, "macro.dbt_utils.postgres__type_timestamp": {"unique_id": "macro.dbt_utils.postgres__type_timestamp", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/datatypes.sql", "original_file_path": "macros/cross_db_utils/datatypes.sql", "name": "postgres__type_timestamp", "macro_sql": "{% macro postgres__type_timestamp() %}\n    timestamp without time zone\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.870636}, "macro.dbt_utils.snowflake__type_timestamp": {"unique_id": "macro.dbt_utils.snowflake__type_timestamp", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/datatypes.sql", "original_file_path": "macros/cross_db_utils/datatypes.sql", "name": "snowflake__type_timestamp", "macro_sql": "{% macro snowflake__type_timestamp() %}\n    timestamp_ntz\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.870815}, "macro.dbt_utils.type_float": {"unique_id": "macro.dbt_utils.type_float", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/datatypes.sql", "original_file_path": "macros/cross_db_utils/datatypes.sql", "name": "type_float", "macro_sql": "\n\n{%- macro type_float() -%}\n  {{ return(adapter.dispatch('type_float', 'dbt_utils')()) }}\n{%- endmacro -%}\n\n", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.bigquery__type_float"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.8712142}, "macro.dbt_utils.default__type_float": {"unique_id": "macro.dbt_utils.default__type_float", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/datatypes.sql", "original_file_path": "macros/cross_db_utils/datatypes.sql", "name": "default__type_float", "macro_sql": "{% macro default__type_float() %}\n    float\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.871402}, "macro.dbt_utils.bigquery__type_float": {"unique_id": "macro.dbt_utils.bigquery__type_float", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/datatypes.sql", "original_file_path": "macros/cross_db_utils/datatypes.sql", "name": "bigquery__type_float", "macro_sql": "{% macro bigquery__type_float() %}\n    float64\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.871584}, "macro.dbt_utils.type_numeric": {"unique_id": "macro.dbt_utils.type_numeric", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/datatypes.sql", "original_file_path": "macros/cross_db_utils/datatypes.sql", "name": "type_numeric", "macro_sql": "\n\n{%- macro type_numeric() -%}\n  {{ return(adapter.dispatch('type_numeric', 'dbt_utils')()) }}\n{%- endmacro -%}\n\n", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.bigquery__type_numeric"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.8719842}, "macro.dbt_utils.default__type_numeric": {"unique_id": "macro.dbt_utils.default__type_numeric", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/datatypes.sql", "original_file_path": "macros/cross_db_utils/datatypes.sql", "name": "default__type_numeric", "macro_sql": "{% macro default__type_numeric() %}\n    numeric(28, 6)\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.87217}, "macro.dbt_utils.bigquery__type_numeric": {"unique_id": "macro.dbt_utils.bigquery__type_numeric", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/datatypes.sql", "original_file_path": "macros/cross_db_utils/datatypes.sql", "name": "bigquery__type_numeric", "macro_sql": "{% macro bigquery__type_numeric() %}\n    numeric\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.8724852}, "macro.dbt_utils.type_bigint": {"unique_id": "macro.dbt_utils.type_bigint", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/datatypes.sql", "original_file_path": "macros/cross_db_utils/datatypes.sql", "name": "type_bigint", "macro_sql": "\n\n{%- macro type_bigint() -%}\n  {{ return(adapter.dispatch('type_bigint', 'dbt_utils')()) }}\n{%- endmacro -%}\n\n", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.bigquery__type_bigint"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.873048}, "macro.dbt_utils.default__type_bigint": {"unique_id": "macro.dbt_utils.default__type_bigint", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/datatypes.sql", "original_file_path": "macros/cross_db_utils/datatypes.sql", "name": "default__type_bigint", "macro_sql": "{% macro default__type_bigint() %}\n    bigint\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.873238}, "macro.dbt_utils.bigquery__type_bigint": {"unique_id": "macro.dbt_utils.bigquery__type_bigint", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/datatypes.sql", "original_file_path": "macros/cross_db_utils/datatypes.sql", "name": "bigquery__type_bigint", "macro_sql": "{% macro bigquery__type_bigint() %}\n    int64\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.8734221}, "macro.dbt_utils.type_int": {"unique_id": "macro.dbt_utils.type_int", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/datatypes.sql", "original_file_path": "macros/cross_db_utils/datatypes.sql", "name": "type_int", "macro_sql": "\n\n{%- macro type_int() -%}\n  {{ return(adapter.dispatch('type_int', 'dbt_utils')()) }}\n{%- endmacro -%}\n\n", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.bigquery__type_int"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.8738182}, "macro.dbt_utils.default__type_int": {"unique_id": "macro.dbt_utils.default__type_int", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/datatypes.sql", "original_file_path": "macros/cross_db_utils/datatypes.sql", "name": "default__type_int", "macro_sql": "{% macro default__type_int() %}\n    int\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.874007}, "macro.dbt_utils.bigquery__type_int": {"unique_id": "macro.dbt_utils.bigquery__type_int", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/datatypes.sql", "original_file_path": "macros/cross_db_utils/datatypes.sql", "name": "bigquery__type_int", "macro_sql": "{% macro bigquery__type_int() %}\n    int64\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.874194}, "macro.dbt_utils._is_relation": {"unique_id": "macro.dbt_utils._is_relation", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/_is_relation.sql", "original_file_path": "macros/cross_db_utils/_is_relation.sql", "name": "_is_relation", "macro_sql": "{% macro _is_relation(obj, macro) %}\n    {%- if not (obj is mapping and obj.get('metadata', {}).get('type', '').endswith('Relation')) -%}\n        {%- do exceptions.raise_compiler_error(\"Macro \" ~ macro ~ \" expected a Relation but received the value: \" ~ obj) -%}\n    {%- endif -%}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.875733}, "macro.dbt_utils.length": {"unique_id": "macro.dbt_utils.length", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/length.sql", "original_file_path": "macros/cross_db_utils/length.sql", "name": "length", "macro_sql": "{% macro length(expression) -%}\n    {{ return(adapter.dispatch('length', 'dbt_utils') (expression)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__length"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.876551}, "macro.dbt_utils.default__length": {"unique_id": "macro.dbt_utils.default__length", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/length.sql", "original_file_path": "macros/cross_db_utils/length.sql", "name": "default__length", "macro_sql": "{% macro default__length(expression) %}\n    \n    length(\n        {{ expression }}\n    )\n    \n{%- endmacro -%}\n\n\n", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.8768268}, "macro.dbt_utils.redshift__length": {"unique_id": "macro.dbt_utils.redshift__length", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/length.sql", "original_file_path": "macros/cross_db_utils/length.sql", "name": "redshift__length", "macro_sql": "{% macro redshift__length(expression) %}\n\n    len(\n        {{ expression }}\n    )\n    \n{%- endmacro -%}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.8770912}, "macro.dbt_utils.dateadd": {"unique_id": "macro.dbt_utils.dateadd", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/dateadd.sql", "original_file_path": "macros/cross_db_utils/dateadd.sql", "name": "dateadd", "macro_sql": "{% macro dateadd(datepart, interval, from_date_or_timestamp) %}\n  {{ return(adapter.dispatch('dateadd', 'dbt_utils')(datepart, interval, from_date_or_timestamp)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.bigquery__dateadd"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.878562}, "macro.dbt_utils.default__dateadd": {"unique_id": "macro.dbt_utils.default__dateadd", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/dateadd.sql", "original_file_path": "macros/cross_db_utils/dateadd.sql", "name": "default__dateadd", "macro_sql": "{% macro default__dateadd(datepart, interval, from_date_or_timestamp) %}\n\n    dateadd(\n        {{ datepart }},\n        {{ interval }},\n        {{ from_date_or_timestamp }}\n        )\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.878979}, "macro.dbt_utils.bigquery__dateadd": {"unique_id": "macro.dbt_utils.bigquery__dateadd", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/dateadd.sql", "original_file_path": "macros/cross_db_utils/dateadd.sql", "name": "bigquery__dateadd", "macro_sql": "{% macro bigquery__dateadd(datepart, interval, from_date_or_timestamp) %}\n\n        datetime_add(\n            cast( {{ from_date_or_timestamp }} as datetime),\n        interval {{ interval }} {{ datepart }}\n        )\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.879392}, "macro.dbt_utils.postgres__dateadd": {"unique_id": "macro.dbt_utils.postgres__dateadd", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/dateadd.sql", "original_file_path": "macros/cross_db_utils/dateadd.sql", "name": "postgres__dateadd", "macro_sql": "{% macro postgres__dateadd(datepart, interval, from_date_or_timestamp) %}\n\n    {{ from_date_or_timestamp }} + ((interval '1 {{ datepart }}') * ({{ interval }}))\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.879804}, "macro.dbt_utils.redshift__dateadd": {"unique_id": "macro.dbt_utils.redshift__dateadd", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/dateadd.sql", "original_file_path": "macros/cross_db_utils/dateadd.sql", "name": "redshift__dateadd", "macro_sql": "{% macro redshift__dateadd(datepart, interval, from_date_or_timestamp) %}\n\n    {{ return(dbt_utils.default__dateadd(datepart, interval, from_date_or_timestamp)) }}\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__dateadd"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.8802931}, "macro.dbt_utils.intersect": {"unique_id": "macro.dbt_utils.intersect", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/intersect.sql", "original_file_path": "macros/cross_db_utils/intersect.sql", "name": "intersect", "macro_sql": "{% macro intersect() %}\n  {{ return(adapter.dispatch('intersect', 'dbt_utils')()) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.bigquery__intersect"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.8810298}, "macro.dbt_utils.default__intersect": {"unique_id": "macro.dbt_utils.default__intersect", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/intersect.sql", "original_file_path": "macros/cross_db_utils/intersect.sql", "name": "default__intersect", "macro_sql": "{% macro default__intersect() %}\n\n    intersect\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.88122}, "macro.dbt_utils.bigquery__intersect": {"unique_id": "macro.dbt_utils.bigquery__intersect", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/intersect.sql", "original_file_path": "macros/cross_db_utils/intersect.sql", "name": "bigquery__intersect", "macro_sql": "{% macro bigquery__intersect() %}\n\n    intersect distinct\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.881403}, "macro.dbt_utils.escape_single_quotes": {"unique_id": "macro.dbt_utils.escape_single_quotes", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/escape_single_quotes.sql", "original_file_path": "macros/cross_db_utils/escape_single_quotes.sql", "name": "escape_single_quotes", "macro_sql": "{% macro escape_single_quotes(expression) %}\n      {{ return(adapter.dispatch('escape_single_quotes', 'dbt_utils') (expression)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.bigquery__escape_single_quotes"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.88229}, "macro.dbt_utils.default__escape_single_quotes": {"unique_id": "macro.dbt_utils.default__escape_single_quotes", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/escape_single_quotes.sql", "original_file_path": "macros/cross_db_utils/escape_single_quotes.sql", "name": "default__escape_single_quotes", "macro_sql": "{% macro default__escape_single_quotes(expression) -%}\n{{ expression | replace(\"'\",\"''\") }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.882637}, "macro.dbt_utils.snowflake__escape_single_quotes": {"unique_id": "macro.dbt_utils.snowflake__escape_single_quotes", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/escape_single_quotes.sql", "original_file_path": "macros/cross_db_utils/escape_single_quotes.sql", "name": "snowflake__escape_single_quotes", "macro_sql": "{% macro snowflake__escape_single_quotes(expression) -%}\n{{ expression | replace(\"'\", \"\\\\'\") }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.88298}, "macro.dbt_utils.bigquery__escape_single_quotes": {"unique_id": "macro.dbt_utils.bigquery__escape_single_quotes", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/escape_single_quotes.sql", "original_file_path": "macros/cross_db_utils/escape_single_quotes.sql", "name": "bigquery__escape_single_quotes", "macro_sql": "{% macro bigquery__escape_single_quotes(expression) -%}\n{{ expression | replace(\"'\", \"\\\\'\") }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.8833249}, "macro.dbt_utils.right": {"unique_id": "macro.dbt_utils.right", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/right.sql", "original_file_path": "macros/cross_db_utils/right.sql", "name": "right", "macro_sql": "{% macro right(string_text, length_expression) -%}\n    {{ return(adapter.dispatch('right', 'dbt_utils') (string_text, length_expression)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.bigquery__right"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.8844988}, "macro.dbt_utils.default__right": {"unique_id": "macro.dbt_utils.default__right", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/right.sql", "original_file_path": "macros/cross_db_utils/right.sql", "name": "default__right", "macro_sql": "{% macro default__right(string_text, length_expression) %}\n\n    right(\n        {{ string_text }},\n        {{ length_expression }}\n    )\n    \n{%- endmacro -%}\n\n", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.884842}, "macro.dbt_utils.bigquery__right": {"unique_id": "macro.dbt_utils.bigquery__right", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/right.sql", "original_file_path": "macros/cross_db_utils/right.sql", "name": "bigquery__right", "macro_sql": "{% macro bigquery__right(string_text, length_expression) %}\n\n    case when {{ length_expression }} = 0 \n        then ''\n    else \n        substr(\n            {{ string_text }},\n            -1 * ({{ length_expression }})\n        )\n    end\n\n{%- endmacro -%}\n\n", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.8853068}, "macro.dbt_utils.snowflake__right": {"unique_id": "macro.dbt_utils.snowflake__right", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/right.sql", "original_file_path": "macros/cross_db_utils/right.sql", "name": "snowflake__right", "macro_sql": "{% macro snowflake__right(string_text, length_expression) %}\n\n    case when {{ length_expression }} = 0 \n        then ''\n    else \n        right(\n            {{ string_text }},\n            {{ length_expression }}\n        )\n    end\n\n{%- endmacro -%}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.885702}, "macro.dbt_utils.datediff": {"unique_id": "macro.dbt_utils.datediff", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/datediff.sql", "original_file_path": "macros/cross_db_utils/datediff.sql", "name": "datediff", "macro_sql": "{% macro datediff(first_date, second_date, datepart) %}\n  {{ return(adapter.dispatch('datediff', 'dbt_utils')(first_date, second_date, datepart)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.bigquery__datediff"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.890294}, "macro.dbt_utils.default__datediff": {"unique_id": "macro.dbt_utils.default__datediff", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/datediff.sql", "original_file_path": "macros/cross_db_utils/datediff.sql", "name": "default__datediff", "macro_sql": "{% macro default__datediff(first_date, second_date, datepart) %}\n\n    datediff(\n        {{ datepart }},\n        {{ first_date }},\n        {{ second_date }}\n        )\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.890708}, "macro.dbt_utils.bigquery__datediff": {"unique_id": "macro.dbt_utils.bigquery__datediff", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/datediff.sql", "original_file_path": "macros/cross_db_utils/datediff.sql", "name": "bigquery__datediff", "macro_sql": "{% macro bigquery__datediff(first_date, second_date, datepart) %}\n\n    datetime_diff(\n        cast({{second_date}} as datetime),\n        cast({{first_date}} as datetime),\n        {{datepart}}\n    )\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.8911092}, "macro.dbt_utils.postgres__datediff": {"unique_id": "macro.dbt_utils.postgres__datediff", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/datediff.sql", "original_file_path": "macros/cross_db_utils/datediff.sql", "name": "postgres__datediff", "macro_sql": "{% macro postgres__datediff(first_date, second_date, datepart) %}\n\n    {% if datepart == 'year' %}\n        (date_part('year', ({{second_date}})::date) - date_part('year', ({{first_date}})::date))\n    {% elif datepart == 'quarter' %}\n        ({{ dbt_utils.datediff(first_date, second_date, 'year') }} * 4 + date_part('quarter', ({{second_date}})::date) - date_part('quarter', ({{first_date}})::date))\n    {% elif datepart == 'month' %}\n        ({{ dbt_utils.datediff(first_date, second_date, 'year') }} * 12 + date_part('month', ({{second_date}})::date) - date_part('month', ({{first_date}})::date))\n    {% elif datepart == 'day' %}\n        (({{second_date}})::date - ({{first_date}})::date)\n    {% elif datepart == 'week' %}\n        ({{ dbt_utils.datediff(first_date, second_date, 'day') }} / 7 + case\n            when date_part('dow', ({{first_date}})::timestamp) <= date_part('dow', ({{second_date}})::timestamp) then\n                case when {{first_date}} <= {{second_date}} then 0 else -1 end\n            else\n                case when {{first_date}} <= {{second_date}} then 1 else 0 end\n        end)\n    {% elif datepart == 'hour' %}\n        ({{ dbt_utils.datediff(first_date, second_date, 'day') }} * 24 + date_part('hour', ({{second_date}})::timestamp) - date_part('hour', ({{first_date}})::timestamp))\n    {% elif datepart == 'minute' %}\n        ({{ dbt_utils.datediff(first_date, second_date, 'hour') }} * 60 + date_part('minute', ({{second_date}})::timestamp) - date_part('minute', ({{first_date}})::timestamp))\n    {% elif datepart == 'second' %}\n        ({{ dbt_utils.datediff(first_date, second_date, 'minute') }} * 60 + floor(date_part('second', ({{second_date}})::timestamp)) - floor(date_part('second', ({{first_date}})::timestamp)))\n    {% elif datepart == 'millisecond' %}\n        ({{ dbt_utils.datediff(first_date, second_date, 'minute') }} * 60000 + floor(date_part('millisecond', ({{second_date}})::timestamp)) - floor(date_part('millisecond', ({{first_date}})::timestamp)))\n    {% elif datepart == 'microsecond' %}\n        ({{ dbt_utils.datediff(first_date, second_date, 'minute') }} * 60000000 + floor(date_part('microsecond', ({{second_date}})::timestamp)) - floor(date_part('microsecond', ({{first_date}})::timestamp)))\n    {% else %}\n        {{ exceptions.raise_compiler_error(\"Unsupported datepart for macro datediff in postgres: {!r}\".format(datepart)) }}\n    {% endif %}\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.datediff"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.895513}, "macro.dbt_utils.redshift__datediff": {"unique_id": "macro.dbt_utils.redshift__datediff", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/datediff.sql", "original_file_path": "macros/cross_db_utils/datediff.sql", "name": "redshift__datediff", "macro_sql": "{% macro redshift__datediff(first_date, second_date, datepart) %}\n\n    {{ return(dbt_utils.default__datediff(first_date, second_date, datepart)) }}\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__datediff"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.896019}, "macro.dbt_utils.safe_cast": {"unique_id": "macro.dbt_utils.safe_cast", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/safe_cast.sql", "original_file_path": "macros/cross_db_utils/safe_cast.sql", "name": "safe_cast", "macro_sql": "{% macro safe_cast(field, type) %}\n  {{ return(adapter.dispatch('safe_cast', 'dbt_utils') (field, type)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.bigquery__safe_cast"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.8969579}, "macro.dbt_utils.default__safe_cast": {"unique_id": "macro.dbt_utils.default__safe_cast", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/safe_cast.sql", "original_file_path": "macros/cross_db_utils/safe_cast.sql", "name": "default__safe_cast", "macro_sql": "{% macro default__safe_cast(field, type) %}\n    {# most databases don't support this function yet\n    so we just need to use cast #}\n    cast({{field}} as {{type}})\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.8973088}, "macro.dbt_utils.snowflake__safe_cast": {"unique_id": "macro.dbt_utils.snowflake__safe_cast", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/safe_cast.sql", "original_file_path": "macros/cross_db_utils/safe_cast.sql", "name": "snowflake__safe_cast", "macro_sql": "{% macro snowflake__safe_cast(field, type) %}\n    try_cast({{field}} as {{type}})\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.897633}, "macro.dbt_utils.bigquery__safe_cast": {"unique_id": "macro.dbt_utils.bigquery__safe_cast", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/safe_cast.sql", "original_file_path": "macros/cross_db_utils/safe_cast.sql", "name": "bigquery__safe_cast", "macro_sql": "{% macro bigquery__safe_cast(field, type) %}\n    safe_cast({{field}} as {{type}})\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.897957}, "macro.dbt_utils.hash": {"unique_id": "macro.dbt_utils.hash", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/hash.sql", "original_file_path": "macros/cross_db_utils/hash.sql", "name": "hash", "macro_sql": "{% macro hash(field) -%}\n  {{ return(adapter.dispatch('hash', 'dbt_utils') (field)) }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.bigquery__hash"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.89875}, "macro.dbt_utils.default__hash": {"unique_id": "macro.dbt_utils.default__hash", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/hash.sql", "original_file_path": "macros/cross_db_utils/hash.sql", "name": "default__hash", "macro_sql": "{% macro default__hash(field) -%}\n    md5(cast({{field}} as {{dbt_utils.type_string()}}))\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.type_string"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.899178}, "macro.dbt_utils.bigquery__hash": {"unique_id": "macro.dbt_utils.bigquery__hash", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/hash.sql", "original_file_path": "macros/cross_db_utils/hash.sql", "name": "bigquery__hash", "macro_sql": "{% macro bigquery__hash(field) -%}\n    to_hex({{dbt_utils.default__hash(field)}})\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__hash"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.899503}, "macro.dbt_utils.cast_bool_to_text": {"unique_id": "macro.dbt_utils.cast_bool_to_text", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/cast_bool_to_text.sql", "original_file_path": "macros/cross_db_utils/cast_bool_to_text.sql", "name": "cast_bool_to_text", "macro_sql": "{% macro cast_bool_to_text(field) %}\n  {{ adapter.dispatch('cast_bool_to_text', 'dbt_utils') (field) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__cast_bool_to_text"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.900312}, "macro.dbt_utils.default__cast_bool_to_text": {"unique_id": "macro.dbt_utils.default__cast_bool_to_text", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/cast_bool_to_text.sql", "original_file_path": "macros/cross_db_utils/cast_bool_to_text.sql", "name": "default__cast_bool_to_text", "macro_sql": "{% macro default__cast_bool_to_text(field) %}\n    cast({{ field }} as {{ dbt_utils.type_string() }})\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.type_string"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.90067}, "macro.dbt_utils.redshift__cast_bool_to_text": {"unique_id": "macro.dbt_utils.redshift__cast_bool_to_text", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/cast_bool_to_text.sql", "original_file_path": "macros/cross_db_utils/cast_bool_to_text.sql", "name": "redshift__cast_bool_to_text", "macro_sql": "{% macro redshift__cast_bool_to_text(field) %}\n    case\n        when {{ field }} is true then 'true'\n        when {{ field }} is false then 'false'\n    end::text\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.900983}, "macro.dbt_utils.identifier": {"unique_id": "macro.dbt_utils.identifier", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/identifier.sql", "original_file_path": "macros/cross_db_utils/identifier.sql", "name": "identifier", "macro_sql": "{% macro identifier(value) %}\t\n  {%- set error_message = '\n    Warning: the `identifier` macro is no longer supported and will be deprecated in a future release of dbt-utils. \\\n    Use `adapter.quote` instead. The {}.{} model triggered this warning. \\\n    '.format(model.package_name, model.name) -%}\n  {%- do exceptions.warn(error_message) -%}\n  {{ return(adapter.dispatch('identifier', 'dbt_utils') (value)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.bigquery__identifier"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.902227}, "macro.dbt_utils.default__identifier": {"unique_id": "macro.dbt_utils.default__identifier", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/identifier.sql", "original_file_path": "macros/cross_db_utils/identifier.sql", "name": "default__identifier", "macro_sql": "{% macro default__identifier(value) -%}\t\n    \"{{ value }}\"\t\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.9024918}, "macro.dbt_utils.bigquery__identifier": {"unique_id": "macro.dbt_utils.bigquery__identifier", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/identifier.sql", "original_file_path": "macros/cross_db_utils/identifier.sql", "name": "bigquery__identifier", "macro_sql": "{% macro bigquery__identifier(value) -%}\t\n    `{{ value }}`\t\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.9027488}, "macro.dbt_utils.any_value": {"unique_id": "macro.dbt_utils.any_value", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/any_value.sql", "original_file_path": "macros/cross_db_utils/any_value.sql", "name": "any_value", "macro_sql": "{% macro any_value(expression) -%}\n    {{ return(adapter.dispatch('any_value', 'dbt_utils') (expression)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__any_value"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.903549}, "macro.dbt_utils.default__any_value": {"unique_id": "macro.dbt_utils.default__any_value", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/any_value.sql", "original_file_path": "macros/cross_db_utils/any_value.sql", "name": "default__any_value", "macro_sql": "{% macro default__any_value(expression) -%}\n    \n    any_value({{ expression }})\n    \n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.9038122}, "macro.dbt_utils.postgres__any_value": {"unique_id": "macro.dbt_utils.postgres__any_value", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/any_value.sql", "original_file_path": "macros/cross_db_utils/any_value.sql", "name": "postgres__any_value", "macro_sql": "{% macro postgres__any_value(expression) -%}\n    {#- /*Postgres doesn't support any_value, so we're using min() to get the same result*/ -#}\n    min({{ expression }})\n    \n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.90408}, "macro.dbt_utils.position": {"unique_id": "macro.dbt_utils.position", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/position.sql", "original_file_path": "macros/cross_db_utils/position.sql", "name": "position", "macro_sql": "{% macro position(substring_text, string_text) -%}\n    {{ return(adapter.dispatch('position', 'dbt_utils') (substring_text, string_text)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.bigquery__position"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.905}, "macro.dbt_utils.default__position": {"unique_id": "macro.dbt_utils.default__position", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/position.sql", "original_file_path": "macros/cross_db_utils/position.sql", "name": "default__position", "macro_sql": "{% macro default__position(substring_text, string_text) %}\n\n    position(\n        {{ substring_text }} in {{ string_text }}\n    )\n    \n{%- endmacro -%}\n\n", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.905379}, "macro.dbt_utils.bigquery__position": {"unique_id": "macro.dbt_utils.bigquery__position", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/position.sql", "original_file_path": "macros/cross_db_utils/position.sql", "name": "bigquery__position", "macro_sql": "{% macro bigquery__position(substring_text, string_text) %}\n\n    strpos(\n        {{ string_text }},\n        {{ substring_text }}\n        \n    )\n    \n{%- endmacro -%}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.905749}, "macro.dbt_utils.string_literal": {"unique_id": "macro.dbt_utils.string_literal", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/literal.sql", "original_file_path": "macros/cross_db_utils/literal.sql", "name": "string_literal", "macro_sql": "{%- macro string_literal(value) -%}\n  {{ return(adapter.dispatch('string_literal', 'dbt_utils') (value)) }}\n{%- endmacro -%}\n\n", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__string_literal"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.9064782}, "macro.dbt_utils.default__string_literal": {"unique_id": "macro.dbt_utils.default__string_literal", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/literal.sql", "original_file_path": "macros/cross_db_utils/literal.sql", "name": "default__string_literal", "macro_sql": "{% macro default__string_literal(value) -%}\n    '{{ value }}'\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.906741}, "macro.dbt_utils.current_timestamp": {"unique_id": "macro.dbt_utils.current_timestamp", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/current_timestamp.sql", "original_file_path": "macros/cross_db_utils/current_timestamp.sql", "name": "current_timestamp", "macro_sql": "{% macro current_timestamp() -%}\n  {{ return(adapter.dispatch('current_timestamp', 'dbt_utils')()) }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.bigquery__current_timestamp"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.90808}, "macro.dbt_utils.default__current_timestamp": {"unique_id": "macro.dbt_utils.default__current_timestamp", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/current_timestamp.sql", "original_file_path": "macros/cross_db_utils/current_timestamp.sql", "name": "default__current_timestamp", "macro_sql": "{% macro default__current_timestamp() %}\n    current_timestamp::{{dbt_utils.type_timestamp()}}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.type_timestamp"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.908482}, "macro.dbt_utils.redshift__current_timestamp": {"unique_id": "macro.dbt_utils.redshift__current_timestamp", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/current_timestamp.sql", "original_file_path": "macros/cross_db_utils/current_timestamp.sql", "name": "redshift__current_timestamp", "macro_sql": "{% macro redshift__current_timestamp() %}\n    getdate()\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.90867}, "macro.dbt_utils.bigquery__current_timestamp": {"unique_id": "macro.dbt_utils.bigquery__current_timestamp", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/current_timestamp.sql", "original_file_path": "macros/cross_db_utils/current_timestamp.sql", "name": "bigquery__current_timestamp", "macro_sql": "{% macro bigquery__current_timestamp() %}\n    current_timestamp\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.908851}, "macro.dbt_utils.current_timestamp_in_utc": {"unique_id": "macro.dbt_utils.current_timestamp_in_utc", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/current_timestamp.sql", "original_file_path": "macros/cross_db_utils/current_timestamp.sql", "name": "current_timestamp_in_utc", "macro_sql": "{% macro current_timestamp_in_utc() -%}\n  {{ return(adapter.dispatch('current_timestamp_in_utc', 'dbt_utils')()) }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__current_timestamp_in_utc"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.9092438}, "macro.dbt_utils.default__current_timestamp_in_utc": {"unique_id": "macro.dbt_utils.default__current_timestamp_in_utc", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/current_timestamp.sql", "original_file_path": "macros/cross_db_utils/current_timestamp.sql", "name": "default__current_timestamp_in_utc", "macro_sql": "{% macro default__current_timestamp_in_utc() %}\n    {{dbt_utils.current_timestamp()}}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.current_timestamp"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.909524}, "macro.dbt_utils.snowflake__current_timestamp_in_utc": {"unique_id": "macro.dbt_utils.snowflake__current_timestamp_in_utc", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/current_timestamp.sql", "original_file_path": "macros/cross_db_utils/current_timestamp.sql", "name": "snowflake__current_timestamp_in_utc", "macro_sql": "{% macro snowflake__current_timestamp_in_utc() %}\n    convert_timezone('UTC', {{dbt_utils.current_timestamp()}})::{{dbt_utils.type_timestamp()}}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.current_timestamp", "macro.dbt_utils.type_timestamp"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.909896}, "macro.dbt_utils.postgres__current_timestamp_in_utc": {"unique_id": "macro.dbt_utils.postgres__current_timestamp_in_utc", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/current_timestamp.sql", "original_file_path": "macros/cross_db_utils/current_timestamp.sql", "name": "postgres__current_timestamp_in_utc", "macro_sql": "{% macro postgres__current_timestamp_in_utc() %}\n    (current_timestamp at time zone 'utc')::{{dbt_utils.type_timestamp()}}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.type_timestamp"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.9102201}, "macro.dbt_utils.redshift__current_timestamp_in_utc": {"unique_id": "macro.dbt_utils.redshift__current_timestamp_in_utc", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/current_timestamp.sql", "original_file_path": "macros/cross_db_utils/current_timestamp.sql", "name": "redshift__current_timestamp_in_utc", "macro_sql": "{% macro redshift__current_timestamp_in_utc() %}\n    {{ return(dbt_utils.default__current_timestamp_in_utc()) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__current_timestamp_in_utc"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.910549}, "macro.dbt_utils.width_bucket": {"unique_id": "macro.dbt_utils.width_bucket", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/width_bucket.sql", "original_file_path": "macros/cross_db_utils/width_bucket.sql", "name": "width_bucket", "macro_sql": "{% macro width_bucket(expr, min_value, max_value, num_buckets) %}\n  {{ return(adapter.dispatch('width_bucket', 'dbt_utils') (expr, min_value, max_value, num_buckets)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__width_bucket"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.9130292}, "macro.dbt_utils.default__width_bucket": {"unique_id": "macro.dbt_utils.default__width_bucket", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/width_bucket.sql", "original_file_path": "macros/cross_db_utils/width_bucket.sql", "name": "default__width_bucket", "macro_sql": "{% macro default__width_bucket(expr, min_value, max_value, num_buckets) -%}\n\n    {% set bin_size -%}\n    (( {{ max_value }} - {{ min_value }} ) / {{ num_buckets }} )\n    {%- endset %}\n    (\n        -- to break ties when the amount is eaxtly at the bucket egde\n        case\n            when\n                mod(\n                    {{ dbt_utils.safe_cast(expr, dbt_utils.type_numeric() ) }},\n                    {{ dbt_utils.safe_cast(bin_size, dbt_utils.type_numeric() ) }}\n                ) = 0\n            then 1\n            else 0\n        end\n    ) +\n      -- Anything over max_value goes the N+1 bucket\n    least(\n        ceil(\n            ({{ expr }} - {{ min_value }})/{{ bin_size }}\n        ),\n        {{ num_buckets }} + 1\n    )\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.safe_cast", "macro.dbt_utils.type_numeric"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.9141839}, "macro.dbt_utils.redshift__width_bucket": {"unique_id": "macro.dbt_utils.redshift__width_bucket", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/width_bucket.sql", "original_file_path": "macros/cross_db_utils/width_bucket.sql", "name": "redshift__width_bucket", "macro_sql": "{% macro redshift__width_bucket(expr, min_value, max_value, num_buckets) -%}\n\n    {% set bin_size -%}\n    (( {{ max_value }} - {{ min_value }} ) / {{ num_buckets }} )\n    {%- endset %}\n    (\n        -- to break ties when the amount is exactly at the bucket edge\n        case\n            when\n                {{ dbt_utils.safe_cast(expr, dbt_utils.type_numeric() ) }} %\n                {{ dbt_utils.safe_cast(bin_size, dbt_utils.type_numeric() ) }}\n                 = 0\n            then 1\n            else 0\n        end\n    ) +\n      -- Anything over max_value goes the N+1 bucket\n    least(\n        ceil(\n            ({{ expr }} - {{ min_value }})/{{ bin_size }}\n        ),\n        {{ num_buckets }} + 1\n    )\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.safe_cast", "macro.dbt_utils.type_numeric"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.91533}, "macro.dbt_utils.snowflake__width_bucket": {"unique_id": "macro.dbt_utils.snowflake__width_bucket", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/width_bucket.sql", "original_file_path": "macros/cross_db_utils/width_bucket.sql", "name": "snowflake__width_bucket", "macro_sql": "{% macro snowflake__width_bucket(expr, min_value, max_value, num_buckets) %}\n    width_bucket({{ expr }}, {{ min_value }}, {{ max_value }}, {{ num_buckets }} )\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.915811}, "macro.dbt_utils.bool_or": {"unique_id": "macro.dbt_utils.bool_or", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/bool_or.sql", "original_file_path": "macros/cross_db_utils/bool_or.sql", "name": "bool_or", "macro_sql": "{% macro bool_or(expression) -%}\n    {{ return(adapter.dispatch('bool_or', 'dbt_utils') (expression)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.bigquery__bool_or"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.9166772}, "macro.dbt_utils.default__bool_or": {"unique_id": "macro.dbt_utils.default__bool_or", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/bool_or.sql", "original_file_path": "macros/cross_db_utils/bool_or.sql", "name": "default__bool_or", "macro_sql": "{% macro default__bool_or(expression) -%}\n    \n    bool_or({{ expression }})\n    \n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.916939}, "macro.dbt_utils.snowflake__bool_or": {"unique_id": "macro.dbt_utils.snowflake__bool_or", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/bool_or.sql", "original_file_path": "macros/cross_db_utils/bool_or.sql", "name": "snowflake__bool_or", "macro_sql": "{% macro snowflake__bool_or(expression) -%}\n    \n    boolor_agg({{ expression }})\n    \n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.917195}, "macro.dbt_utils.bigquery__bool_or": {"unique_id": "macro.dbt_utils.bigquery__bool_or", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/bool_or.sql", "original_file_path": "macros/cross_db_utils/bool_or.sql", "name": "bigquery__bool_or", "macro_sql": "{% macro bigquery__bool_or(expression) -%}\n    \n    logical_or({{ expression }})\n    \n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.917446}, "macro.dbt_utils.last_day": {"unique_id": "macro.dbt_utils.last_day", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/last_day.sql", "original_file_path": "macros/cross_db_utils/last_day.sql", "name": "last_day", "macro_sql": "{% macro last_day(date, datepart) %}\n  {{ return(adapter.dispatch('last_day', 'dbt_utils') (date, datepart)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__last_day"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.918677}, "macro.dbt_utils.default_last_day": {"unique_id": "macro.dbt_utils.default_last_day", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/last_day.sql", "original_file_path": "macros/cross_db_utils/last_day.sql", "name": "default_last_day", "macro_sql": "\n\n\n{%- macro default_last_day(date, datepart) -%}\n    cast(\n        {{dbt_utils.dateadd('day', '-1',\n        dbt_utils.dateadd(datepart, '1', dbt_utils.date_trunc(datepart, date))\n        )}}\n        as date)\n{%- endmacro -%}\n\n\n", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.dateadd", "macro.dbt_utils.date_trunc"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.9193358}, "macro.dbt_utils.default__last_day": {"unique_id": "macro.dbt_utils.default__last_day", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/last_day.sql", "original_file_path": "macros/cross_db_utils/last_day.sql", "name": "default__last_day", "macro_sql": "{% macro default__last_day(date, datepart) -%}\n    {{dbt_utils.default_last_day(date, datepart)}}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default_last_day"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.919704}, "macro.dbt_utils.postgres__last_day": {"unique_id": "macro.dbt_utils.postgres__last_day", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/last_day.sql", "original_file_path": "macros/cross_db_utils/last_day.sql", "name": "postgres__last_day", "macro_sql": "{% macro postgres__last_day(date, datepart) -%}\n\n    {%- if datepart == 'quarter' -%}\n    -- postgres dateadd does not support quarter interval.\n    cast(\n        {{dbt_utils.dateadd('day', '-1',\n        dbt_utils.dateadd('month', '3', dbt_utils.date_trunc(datepart, date))\n        )}}\n        as date)\n    {%- else -%}\n    {{dbt_utils.default_last_day(date, datepart)}}\n    {%- endif -%}\n\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.dateadd", "macro.dbt_utils.date_trunc", "macro.dbt_utils.default_last_day"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.9207501}, "macro.dbt_utils.redshift__last_day": {"unique_id": "macro.dbt_utils.redshift__last_day", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/last_day.sql", "original_file_path": "macros/cross_db_utils/last_day.sql", "name": "redshift__last_day", "macro_sql": "{% macro redshift__last_day(date, datepart) %}\n\n    {{ return(dbt_utils.default__last_day(date, datepart)) }}\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__last_day"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.921186}, "macro.dbt_utils.split_part": {"unique_id": "macro.dbt_utils.split_part", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/split_part.sql", "original_file_path": "macros/cross_db_utils/split_part.sql", "name": "split_part", "macro_sql": "{% macro split_part(string_text, delimiter_text, part_number) %}\n  {{ return(adapter.dispatch('split_part', 'dbt_utils') (string_text, delimiter_text, part_number)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.bigquery__split_part"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.922229}, "macro.dbt_utils.default__split_part": {"unique_id": "macro.dbt_utils.default__split_part", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/split_part.sql", "original_file_path": "macros/cross_db_utils/split_part.sql", "name": "default__split_part", "macro_sql": "{% macro default__split_part(string_text, delimiter_text, part_number) %}\n\n    split_part(\n        {{ string_text }},\n        {{ delimiter_text }},\n        {{ part_number }}\n        )\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.922774}, "macro.dbt_utils.bigquery__split_part": {"unique_id": "macro.dbt_utils.bigquery__split_part", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/split_part.sql", "original_file_path": "macros/cross_db_utils/split_part.sql", "name": "bigquery__split_part", "macro_sql": "{% macro bigquery__split_part(string_text, delimiter_text, part_number) %}\n\n    split(\n        {{ string_text }},\n        {{ delimiter_text }}\n        )[safe_offset({{ part_number - 1 }})]\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.923222}, "macro.dbt_utils.date_trunc": {"unique_id": "macro.dbt_utils.date_trunc", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/date_trunc.sql", "original_file_path": "macros/cross_db_utils/date_trunc.sql", "name": "date_trunc", "macro_sql": "{% macro date_trunc(datepart, date) -%}\n  {{ return(adapter.dispatch('date_trunc', 'dbt_utils') (datepart, date)) }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.bigquery__date_trunc"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.924238}, "macro.dbt_utils.default__date_trunc": {"unique_id": "macro.dbt_utils.default__date_trunc", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/date_trunc.sql", "original_file_path": "macros/cross_db_utils/date_trunc.sql", "name": "default__date_trunc", "macro_sql": "{% macro default__date_trunc(datepart, date) %}\n    date_trunc('{{datepart}}', {{date}})\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.9245708}, "macro.dbt_utils.bigquery__date_trunc": {"unique_id": "macro.dbt_utils.bigquery__date_trunc", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/date_trunc.sql", "original_file_path": "macros/cross_db_utils/date_trunc.sql", "name": "bigquery__date_trunc", "macro_sql": "{% macro bigquery__date_trunc(datepart, date) %}\n    timestamp_trunc(\n        cast({{date}} as timestamp),\n        {{datepart}}\n    )\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.9249}, "macro.dbt_utils._is_ephemeral": {"unique_id": "macro.dbt_utils._is_ephemeral", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/_is_ephemeral.sql", "original_file_path": "macros/cross_db_utils/_is_ephemeral.sql", "name": "_is_ephemeral", "macro_sql": "{% macro _is_ephemeral(obj, macro) %}\n    {%- if obj.is_cte -%}\n        {% set ephemeral_prefix = api.Relation.add_ephemeral_prefix('') %}\n        {% if obj.name.startswith(ephemeral_prefix) %}\n            {% set model_name = obj.name[(ephemeral_prefix|length):] %}\n        {% else %}\n            {% set model_name = obj.name %}\n        {%- endif -%}\n        {% set error_message %}\nThe `{{ macro }}` macro cannot be used with ephemeral models, as it relies on the information schema.\n\n`{{ model_name }}` is an ephemeral model. Consider making it a view or table instead.\n        {% endset %}\n        {%- do exceptions.raise_compiler_error(error_message) -%}\n    {%- endif -%}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.926881}, "macro.dbt_utils.get_period_boundaries": {"unique_id": "macro.dbt_utils.get_period_boundaries", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/materializations/insert_by_period_materialization.sql", "original_file_path": "macros/materializations/insert_by_period_materialization.sql", "name": "get_period_boundaries", "macro_sql": "{% macro get_period_boundaries(target_schema, target_table, timestamp_field, start_date, stop_date, period) -%}\n    {{ return(adapter.dispatch('get_period_boundaries', 'dbt_utils')(target_schema, target_table, timestamp_field, start_date, stop_date, period)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__get_period_boundaries"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.936023}, "macro.dbt_utils.default__get_period_boundaries": {"unique_id": "macro.dbt_utils.default__get_period_boundaries", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/materializations/insert_by_period_materialization.sql", "original_file_path": "macros/materializations/insert_by_period_materialization.sql", "name": "default__get_period_boundaries", "macro_sql": "{% macro default__get_period_boundaries(target_schema, target_table, timestamp_field, start_date, stop_date, period) -%}\n\n  {% call statement('period_boundaries', fetch_result=True) -%}\n    with data as (\n      select\n          coalesce(max(\"{{timestamp_field}}\"), '{{start_date}}')::timestamp as start_timestamp,\n          coalesce(\n            {{dbt_utils.dateadd('millisecond',\n                                -1,\n                                \"nullif('\" ~ stop_date ~ \"','')::timestamp\")}},\n            {{dbt_utils.current_timestamp()}}\n          ) as stop_timestamp\n      from \"{{target_schema}}\".\"{{target_table}}\"\n    )\n\n    select\n      start_timestamp,\n      stop_timestamp,\n      {{dbt_utils.datediff('start_timestamp',\n                           'stop_timestamp',\n                           period)}}  + 1 as num_periods\n    from data\n  {%- endcall %}\n\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.statement", "macro.dbt_utils.dateadd", "macro.dbt_utils.current_timestamp", "macro.dbt_utils.datediff"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.9372952}, "macro.dbt_utils.get_period_sql": {"unique_id": "macro.dbt_utils.get_period_sql", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/materializations/insert_by_period_materialization.sql", "original_file_path": "macros/materializations/insert_by_period_materialization.sql", "name": "get_period_sql", "macro_sql": "{% macro get_period_sql(target_cols_csv, sql, timestamp_field, period, start_timestamp, stop_timestamp, offset) -%}\n    {{ return(adapter.dispatch('get_period_sql', 'dbt_utils')(target_cols_csv, sql, timestamp_field, period, start_timestamp, stop_timestamp, offset)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__get_period_sql"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.938234}, "macro.dbt_utils.default__get_period_sql": {"unique_id": "macro.dbt_utils.default__get_period_sql", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/materializations/insert_by_period_materialization.sql", "original_file_path": "macros/materializations/insert_by_period_materialization.sql", "name": "default__get_period_sql", "macro_sql": "{% macro default__get_period_sql(target_cols_csv, sql, timestamp_field, period, start_timestamp, stop_timestamp, offset) -%}\n\n  {%- set period_filter -%}\n    (\"{{timestamp_field}}\" >  '{{start_timestamp}}'::timestamp + interval '{{offset}} {{period}}' and\n     \"{{timestamp_field}}\" <= '{{start_timestamp}}'::timestamp + interval '{{offset}} {{period}}' + interval '1 {{period}}' and\n     \"{{timestamp_field}}\" <  '{{stop_timestamp}}'::timestamp)\n  {%- endset -%}\n\n  {%- set filtered_sql = sql | replace(\"__PERIOD_FILTER__\", period_filter) -%}\n\n  select\n    {{target_cols_csv}}\n  from (\n    {{filtered_sql}}\n  )\n\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.939646}, "macro.dbt_utils.materialization_insert_by_period_default": {"unique_id": "macro.dbt_utils.materialization_insert_by_period_default", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/materializations/insert_by_period_materialization.sql", "original_file_path": "macros/materializations/insert_by_period_materialization.sql", "name": "materialization_insert_by_period_default", "macro_sql": "{% materialization insert_by_period, default -%}\n  {%- set timestamp_field = config.require('timestamp_field') -%}\n  {%- set start_date = config.require('start_date') -%}\n  {%- set stop_date = config.get('stop_date') or '' -%}\n  {%- set period = config.get('period') or 'week' -%}\n\n  {%- if sql.find('__PERIOD_FILTER__') == -1 -%}\n    {%- set error_message -%}\n      Model '{{ model.unique_id }}' does not include the required string '__PERIOD_FILTER__' in its sql\n    {%- endset -%}\n    {{ exceptions.raise_compiler_error(error_message) }}\n  {%- endif -%}\n\n  {%- set identifier = model['name'] -%}\n\n  {%- set old_relation = adapter.get_relation(database=database, schema=schema, identifier=identifier) -%}\n  {%- set target_relation = api.Relation.create(identifier=identifier, schema=schema, type='table') -%}\n\n  {%- set non_destructive_mode = (flags.NON_DESTRUCTIVE == True) -%}\n  {%- set full_refresh_mode = (flags.FULL_REFRESH == True) -%}\n\n  {%- set exists_as_table = (old_relation is not none and old_relation.is_table) -%}\n  {%- set exists_not_as_table = (old_relation is not none and not old_relation.is_table) -%}\n\n  {%- set should_truncate = (non_destructive_mode and full_refresh_mode and exists_as_table) -%}\n  {%- set should_drop = (not should_truncate and (full_refresh_mode or exists_not_as_table)) -%}\n  {%- set force_create = (flags.FULL_REFRESH and not flags.NON_DESTRUCTIVE) -%}\n\n  -- setup\n  {% if old_relation is none -%}\n    -- noop\n  {%- elif should_truncate -%}\n    {{adapter.truncate_relation(old_relation)}}\n  {%- elif should_drop -%}\n    {{adapter.drop_relation(old_relation)}}\n    {%- set old_relation = none -%}\n  {%- endif %}\n\n  {{run_hooks(pre_hooks, inside_transaction=False)}}\n\n  -- `begin` happens here, so `commit` after it to finish the transaction\n  {{run_hooks(pre_hooks, inside_transaction=True)}}\n  {% call statement() -%}\n    begin; -- make extra sure we've closed out the transaction\n    commit;\n  {%- endcall %}\n\n  -- build model\n  {% if force_create or old_relation is none -%}\n    {# Create an empty target table -#}\n    {% call statement('main') -%}\n      {%- set empty_sql = sql | replace(\"__PERIOD_FILTER__\", 'false') -%}\n      {{create_table_as(False, target_relation, empty_sql)}}\n    {%- endcall %}\n  {%- endif %}\n\n  {% set _ = dbt_utils.get_period_boundaries(schema,\n                                              identifier,\n                                              timestamp_field,\n                                              start_date,\n                                              stop_date,\n                                              period) %}\n  {%- set start_timestamp = load_result('period_boundaries')['data'][0][0] | string -%}\n  {%- set stop_timestamp = load_result('period_boundaries')['data'][0][1] | string -%}\n  {%- set num_periods = load_result('period_boundaries')['data'][0][2] | int -%}\n\n  {% set target_columns = adapter.get_columns_in_relation(target_relation) %}\n  {%- set target_cols_csv = target_columns | map(attribute='quoted') | join(', ') -%}\n  {%- set loop_vars = {'sum_rows_inserted': 0} -%}\n\n  -- commit each period as a separate transaction\n  {% for i in range(num_periods) -%}\n    {%- set msg = \"Running for \" ~ period ~ \" \" ~ (i + 1) ~ \" of \" ~ (num_periods) -%}\n    {{ dbt_utils.log_info(msg) }}\n\n    {%- set tmp_identifier = model['name'] ~ '__dbt_incremental_period' ~ i ~ '_tmp' -%}\n    {%- set tmp_relation = api.Relation.create(identifier=tmp_identifier,\n                                               schema=schema, type='table') -%}\n    {% call statement() -%}\n      {% set tmp_table_sql = dbt_utils.get_period_sql(target_cols_csv,\n                                                       sql,\n                                                       timestamp_field,\n                                                       period,\n                                                       start_timestamp,\n                                                       stop_timestamp,\n                                                       i) %}\n      {{dbt.create_table_as(True, tmp_relation, tmp_table_sql)}}\n    {%- endcall %}\n\n    {{adapter.expand_target_column_types(from_relation=tmp_relation,\n                                         to_relation=target_relation)}}\n    {%- set name = 'main-' ~ i -%}\n    {% call statement(name, fetch_result=True) -%}\n      insert into {{target_relation}} ({{target_cols_csv}})\n      (\n          select\n              {{target_cols_csv}}\n          from {{tmp_relation.include(schema=False)}}\n      );\n    {%- endcall %}\n    {% set result = load_result('main-' ~ i) %}\n    {% if 'response' in result.keys() %} {# added in v0.19.0 #}\n        {% set rows_inserted = result['response']['rows_affected'] %}\n    {% else %} {# older versions #}\n        {% set rows_inserted = result['status'].split(\" \")[2] | int %}\n    {% endif %}\n    \n    {%- set sum_rows_inserted = loop_vars['sum_rows_inserted'] + rows_inserted -%}\n    {%- if loop_vars.update({'sum_rows_inserted': sum_rows_inserted}) %} {% endif -%}\n\n    {%- set msg = \"Ran for \" ~ period ~ \" \" ~ (i + 1) ~ \" of \" ~ (num_periods) ~ \"; \" ~ rows_inserted ~ \" records inserted\" -%}\n    {{ dbt_utils.log_info(msg) }}\n\n  {%- endfor %}\n\n  {% call statement() -%}\n    begin;\n  {%- endcall %}\n\n  {{run_hooks(post_hooks, inside_transaction=True)}}\n\n  {% call statement() -%}\n    commit;\n  {%- endcall %}\n\n  {{run_hooks(post_hooks, inside_transaction=False)}}\n\n  {%- set status_string = \"INSERT \" ~ loop_vars['sum_rows_inserted'] -%}\n\n  {% call noop_statement('main', status_string) -%}\n    -- no-op\n  {%- endcall %}\n\n  -- Return the relations created in this materialization\n  {{ return({'relations': [target_relation]}) }}  \n\n{%- endmaterialization %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.run_hooks", "macro.dbt.statement", "macro.dbt.create_table_as", "macro.dbt_utils.get_period_boundaries", "macro.dbt_utils.log_info", "macro.dbt_utils.get_period_sql", "macro.dbt.noop_statement"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.9522061}, "macro.dbt_utils.get_url_host": {"unique_id": "macro.dbt_utils.get_url_host", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/web/get_url_host.sql", "original_file_path": "macros/web/get_url_host.sql", "name": "get_url_host", "macro_sql": "{% macro get_url_host(field) -%}\n    {{ return(adapter.dispatch('get_url_host', 'dbt_utils')(field)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__get_url_host"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.953238}, "macro.dbt_utils.default__get_url_host": {"unique_id": "macro.dbt_utils.default__get_url_host", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/web/get_url_host.sql", "original_file_path": "macros/web/get_url_host.sql", "name": "default__get_url_host", "macro_sql": "{% macro default__get_url_host(field) -%}\n\n{%- set parsed =\n    dbt_utils.split_part(\n        dbt_utils.split_part(\n            dbt_utils.replace(\n                dbt_utils.replace(\n                    dbt_utils.replace(field, \"'android-app://'\", \"''\"\n                    ), \"'http://'\", \"''\"\n                ), \"'https://'\", \"''\"\n            ), \"'/'\", 1\n        ), \"'?'\", 1\n    )\n\n-%}\n\n\n    {{ dbt_utils.safe_cast(\n        parsed,\n        dbt_utils.type_string()\n        )}}\n\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.split_part", "macro.dbt_utils.replace", "macro.dbt_utils.safe_cast", "macro.dbt_utils.type_string"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.9545221}, "macro.dbt_utils.get_url_path": {"unique_id": "macro.dbt_utils.get_url_path", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/web/get_url_path.sql", "original_file_path": "macros/web/get_url_path.sql", "name": "get_url_path", "macro_sql": "{% macro get_url_path(field) -%}\n    {{ return(adapter.dispatch('get_url_path', 'dbt_utils')(field)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__get_url_path"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.955762}, "macro.dbt_utils.default__get_url_path": {"unique_id": "macro.dbt_utils.default__get_url_path", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/web/get_url_path.sql", "original_file_path": "macros/web/get_url_path.sql", "name": "default__get_url_path", "macro_sql": "{% macro default__get_url_path(field) -%}\n\n    {%- set stripped_url = \n        dbt_utils.replace(\n            dbt_utils.replace(field, \"'http://'\", \"''\"), \"'https://'\", \"''\")\n    -%}\n\n    {%- set first_slash_pos -%}\n        coalesce(\n            nullif({{dbt_utils.position(\"'/'\", stripped_url)}}, 0),\n            {{dbt_utils.position(\"'?'\", stripped_url)}} - 1\n            )\n    {%- endset -%}\n\n    {%- set parsed_path =\n        dbt_utils.split_part(\n            dbt_utils.right(\n                stripped_url, \n                dbt_utils.length(stripped_url) ~ \"-\" ~ first_slash_pos\n                ), \n            \"'?'\", 1\n            )\n    -%}\n\n    {{ dbt_utils.safe_cast(\n        parsed_path,\n        dbt_utils.type_string()\n    )}}\n    \n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.replace", "macro.dbt_utils.position", "macro.dbt_utils.split_part", "macro.dbt_utils.right", "macro.dbt_utils.length", "macro.dbt_utils.safe_cast", "macro.dbt_utils.type_string"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.957369}, "macro.dbt_utils.get_url_parameter": {"unique_id": "macro.dbt_utils.get_url_parameter", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/web/get_url_parameter.sql", "original_file_path": "macros/web/get_url_parameter.sql", "name": "get_url_parameter", "macro_sql": "{% macro get_url_parameter(field, url_parameter) -%}\n    {{ return(adapter.dispatch('get_url_parameter', 'dbt_utils')(field, url_parameter)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__get_url_parameter"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.958233}, "macro.dbt_utils.default__get_url_parameter": {"unique_id": "macro.dbt_utils.default__get_url_parameter", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/web/get_url_parameter.sql", "original_file_path": "macros/web/get_url_parameter.sql", "name": "default__get_url_parameter", "macro_sql": "{% macro default__get_url_parameter(field, url_parameter) -%}\n\n{%- set formatted_url_parameter = \"'\" + url_parameter + \"='\" -%}\n\n{%- set split = dbt_utils.split_part(dbt_utils.split_part(field, formatted_url_parameter, 2), \"'&'\", 1) -%}\n\nnullif({{ split }},'')\n\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.split_part"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.959031}, "macro.dbt_utils.pretty_log_format": {"unique_id": "macro.dbt_utils.pretty_log_format", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/jinja_helpers/pretty_log_format.sql", "original_file_path": "macros/jinja_helpers/pretty_log_format.sql", "name": "pretty_log_format", "macro_sql": "{% macro pretty_log_format(message) %}\n    {{ return(adapter.dispatch('pretty_log_format', 'dbt_utils')(message)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__pretty_log_format"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.959789}, "macro.dbt_utils.default__pretty_log_format": {"unique_id": "macro.dbt_utils.default__pretty_log_format", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/jinja_helpers/pretty_log_format.sql", "original_file_path": "macros/jinja_helpers/pretty_log_format.sql", "name": "default__pretty_log_format", "macro_sql": "{% macro default__pretty_log_format(message) %}\n    {{ return( dbt_utils.pretty_time() ~ ' + ' ~ message) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.pretty_time"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.960362}, "macro.dbt_utils.pretty_time": {"unique_id": "macro.dbt_utils.pretty_time", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/jinja_helpers/pretty_time.sql", "original_file_path": "macros/jinja_helpers/pretty_time.sql", "name": "pretty_time", "macro_sql": "{% macro pretty_time(format='%H:%M:%S') %}\n    {{ return(adapter.dispatch('pretty_time', 'dbt_utils')(format)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__pretty_time"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.9611561}, "macro.dbt_utils.default__pretty_time": {"unique_id": "macro.dbt_utils.default__pretty_time", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/jinja_helpers/pretty_time.sql", "original_file_path": "macros/jinja_helpers/pretty_time.sql", "name": "default__pretty_time", "macro_sql": "{% macro default__pretty_time(format='%H:%M:%S') %}\n    {{ return(modules.datetime.datetime.now().strftime(format)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.961644}, "macro.dbt_utils.log_info": {"unique_id": "macro.dbt_utils.log_info", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/jinja_helpers/log_info.sql", "original_file_path": "macros/jinja_helpers/log_info.sql", "name": "log_info", "macro_sql": "{% macro log_info(message) %}\n    {{ return(adapter.dispatch('log_info', 'dbt_utils')(message)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__log_info"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.96239}, "macro.dbt_utils.default__log_info": {"unique_id": "macro.dbt_utils.default__log_info", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/jinja_helpers/log_info.sql", "original_file_path": "macros/jinja_helpers/log_info.sql", "name": "default__log_info", "macro_sql": "{% macro default__log_info(message) %}\n    {{ log(dbt_utils.pretty_log_format(message), info=True) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.pretty_log_format"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.962821}, "macro.dbt_utils.slugify": {"unique_id": "macro.dbt_utils.slugify", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/jinja_helpers/slugify.sql", "original_file_path": "macros/jinja_helpers/slugify.sql", "name": "slugify", "macro_sql": "{% macro slugify(string) %}\n\n{#- Lower case the string -#}\n{% set string = string | lower %}\n{#- Replace spaces and dashes with underscores -#}\n{% set string = modules.re.sub('[ -]+', '_', string) %}\n{#- Only take letters, numbers, and underscores -#}\n{% set string = modules.re.sub('[^a-z0-9_]+', '', string) %}\n\n{{ return(string) }}\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.964075}, "macro.dbt_utils.test_fewer_rows_than": {"unique_id": "macro.dbt_utils.test_fewer_rows_than", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/schema_tests/fewer_rows_than.sql", "original_file_path": "macros/schema_tests/fewer_rows_than.sql", "name": "test_fewer_rows_than", "macro_sql": "{% test fewer_rows_than(model, compare_model) %}\n  {{ return(adapter.dispatch('test_fewer_rows_than', 'dbt_utils')(model, compare_model)) }}\n{% endtest %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__test_fewer_rows_than"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.9652102}, "macro.dbt_utils.default__test_fewer_rows_than": {"unique_id": "macro.dbt_utils.default__test_fewer_rows_than", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/schema_tests/fewer_rows_than.sql", "original_file_path": "macros/schema_tests/fewer_rows_than.sql", "name": "default__test_fewer_rows_than", "macro_sql": "{% macro default__test_fewer_rows_than(model, compare_model) %}\n\n{{ config(fail_calc = 'coalesce(row_count_delta, 0)') }}\n\nwith a as (\n\n    select count(*) as count_our_model from {{ model }}\n\n),\nb as (\n\n    select count(*) as count_comparison_model from {{ compare_model }}\n\n),\ncounts as (\n\n    select\n        count_our_model,\n        count_comparison_model\n    from a\n    cross join b\n\n),\nfinal as (\n\n    select *,\n        case\n            -- fail the test if we have more rows than the reference model and return the row count delta\n            when count_our_model > count_comparison_model then (count_our_model - count_comparison_model)\n            -- fail the test if they are the same number\n            when count_our_model = count_comparison_model then 1\n            -- pass the test if the delta is positive (i.e. return the number 0)\n            else 0\n    end as row_count_delta\n    from counts\n\n)\n\nselect * from final\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.965748}, "macro.dbt_utils.test_equal_rowcount": {"unique_id": "macro.dbt_utils.test_equal_rowcount", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/schema_tests/equal_rowcount.sql", "original_file_path": "macros/schema_tests/equal_rowcount.sql", "name": "test_equal_rowcount", "macro_sql": "{% test equal_rowcount(model, compare_model) %}\n  {{ return(adapter.dispatch('test_equal_rowcount', 'dbt_utils')(model, compare_model)) }}\n{% endtest %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__test_equal_rowcount"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.9667149}, "macro.dbt_utils.default__test_equal_rowcount": {"unique_id": "macro.dbt_utils.default__test_equal_rowcount", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/schema_tests/equal_rowcount.sql", "original_file_path": "macros/schema_tests/equal_rowcount.sql", "name": "default__test_equal_rowcount", "macro_sql": "{% macro default__test_equal_rowcount(model, compare_model) %}\n\n{#-- Needs to be set at parse time, before we return '' below --#}\n{{ config(fail_calc = 'coalesce(diff_count, 0)') }}\n\n{#-- Prevent querying of db in parsing mode. This works because this macro does not create any new refs. #}\n{%- if not execute -%}\n    {{ return('') }}\n{% endif %}\n\nwith a as (\n\n    select count(*) as count_a from {{ model }}\n\n),\nb as (\n\n    select count(*) as count_b from {{ compare_model }}\n\n),\nfinal as (\n\n    select\n        count_a,\n        count_b,\n        abs(count_a - count_b) as diff_count\n    from a\n    cross join b\n\n)\n\nselect * from final\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.9674392}, "macro.dbt_utils.test_relationships_where": {"unique_id": "macro.dbt_utils.test_relationships_where", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/schema_tests/relationships_where.sql", "original_file_path": "macros/schema_tests/relationships_where.sql", "name": "test_relationships_where", "macro_sql": "{% test relationships_where(model, column_name, to, field, from_condition=\"1=1\", to_condition=\"1=1\") %}\n  {{ return(adapter.dispatch('test_relationships_where', 'dbt_utils')(model, column_name, to, field, from_condition, to_condition)) }}\n{% endtest %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__test_relationships_where"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.969225}, "macro.dbt_utils.default__test_relationships_where": {"unique_id": "macro.dbt_utils.default__test_relationships_where", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/schema_tests/relationships_where.sql", "original_file_path": "macros/schema_tests/relationships_where.sql", "name": "default__test_relationships_where", "macro_sql": "{% macro default__test_relationships_where(model, column_name, to, field, from_condition=\"1=1\", to_condition=\"1=1\") %}\n\n{# T-SQL has no boolean data type so we use 1=1 which returns TRUE #}\n{# ref https://stackoverflow.com/a/7170753/3842610 #}\n\nwith left_table as (\n\n  select\n    {{column_name}} as id\n\n  from {{model}}\n\n  where {{column_name}} is not null\n    and {{from_condition}}\n\n),\n\nright_table as (\n\n  select\n    {{field}} as id\n\n  from {{to}}\n\n  where {{field}} is not null\n    and {{to_condition}}\n\n),\n\nexceptions as (\n\n  select\n    left_table.id,\n    right_table.id as right_id\n\n  from left_table\n\n  left join right_table\n         on left_table.id = right_table.id\n\n  where right_table.id is null\n\n)\n\nselect * from exceptions\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.9700701}, "macro.dbt_utils.test_recency": {"unique_id": "macro.dbt_utils.test_recency", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/schema_tests/recency.sql", "original_file_path": "macros/schema_tests/recency.sql", "name": "test_recency", "macro_sql": "{% test recency(model, field, datepart, interval) %}\n  {{ return(adapter.dispatch('test_recency', 'dbt_utils')(model, field, datepart, interval)) }}\n{% endtest %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__test_recency"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.971095}, "macro.dbt_utils.default__test_recency": {"unique_id": "macro.dbt_utils.default__test_recency", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/schema_tests/recency.sql", "original_file_path": "macros/schema_tests/recency.sql", "name": "default__test_recency", "macro_sql": "{% macro default__test_recency(model, field, datepart, interval) %}\n\n{% set threshold = dbt_utils.dateadd(datepart, interval * -1, dbt_utils.current_timestamp()) %}\n\nwith recency as (\n\n    select max({{field}}) as most_recent\n    from {{ model }}\n\n)\n\nselect\n\n    most_recent,\n    {{ threshold }} as threshold\n\nfrom recency\nwhere most_recent < {{ threshold }}\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.dateadd", "macro.dbt_utils.current_timestamp"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.972113}, "macro.dbt_utils.test_not_constant": {"unique_id": "macro.dbt_utils.test_not_constant", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/schema_tests/not_constant.sql", "original_file_path": "macros/schema_tests/not_constant.sql", "name": "test_not_constant", "macro_sql": "{% test not_constant(model, column_name) %}\n  {{ return(adapter.dispatch('test_not_constant', 'dbt_utils')(model, column_name)) }}\n{% endtest %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__test_not_constant"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.97298}, "macro.dbt_utils.default__test_not_constant": {"unique_id": "macro.dbt_utils.default__test_not_constant", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/schema_tests/not_constant.sql", "original_file_path": "macros/schema_tests/not_constant.sql", "name": "default__test_not_constant", "macro_sql": "{% macro default__test_not_constant(model, column_name) %}\n\n\nselect\n    {# In TSQL, subquery aggregate columns need aliases #}\n    {# thus: a filler col name, 'filler_column' #}\n    count(distinct {{ column_name }}) as filler_column\n\nfrom {{ model }}\n\nhaving count(distinct {{ column_name }}) = 1\n\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.9734159}, "macro.dbt_utils.test_accepted_range": {"unique_id": "macro.dbt_utils.test_accepted_range", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/schema_tests/accepted_range.sql", "original_file_path": "macros/schema_tests/accepted_range.sql", "name": "test_accepted_range", "macro_sql": "{% test accepted_range(model, column_name, min_value=none, max_value=none, inclusive=true) %}\n  {{ return(adapter.dispatch('test_accepted_range', 'dbt_utils')(model, column_name, min_value, max_value, inclusive)) }}\n{% endtest %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__test_accepted_range"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.975094}, "macro.dbt_utils.default__test_accepted_range": {"unique_id": "macro.dbt_utils.default__test_accepted_range", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/schema_tests/accepted_range.sql", "original_file_path": "macros/schema_tests/accepted_range.sql", "name": "default__test_accepted_range", "macro_sql": "{% macro default__test_accepted_range(model, column_name, min_value=none, max_value=none, inclusive=true) %}\n\nwith meet_condition as(\n  select *\n  from {{ model }}\n),\n\nvalidation_errors as (\n  select *\n  from meet_condition\n  where\n    -- never true, defaults to an empty result set. Exists to ensure any combo of the `or` clauses below succeeds\n    1 = 2\n\n  {%- if min_value is not none %}\n    -- records with a value >= min_value are permitted. The `not` flips this to find records that don't meet the rule.\n    or not {{ column_name }} > {{- \"=\" if inclusive }} {{ min_value }}\n  {%- endif %}\n\n  {%- if max_value is not none %}\n    -- records with a value <= max_value are permitted. The `not` flips this to find records that don't meet the rule.\n    or not {{ column_name }} < {{- \"=\" if inclusive }} {{ max_value }}\n  {%- endif %}\n)\n\nselect *\nfrom validation_errors\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.976256}, "macro.dbt_utils.test_not_accepted_values": {"unique_id": "macro.dbt_utils.test_not_accepted_values", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/schema_tests/not_accepted_values.sql", "original_file_path": "macros/schema_tests/not_accepted_values.sql", "name": "test_not_accepted_values", "macro_sql": "{% test not_accepted_values(model, column_name, values, quote=True) %}\n  {{ return(adapter.dispatch('test_not_accepted_values', 'dbt_utils')(model, column_name, values, quote)) }}\n{% endtest %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__test_not_accepted_values"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.977497}, "macro.dbt_utils.default__test_not_accepted_values": {"unique_id": "macro.dbt_utils.default__test_not_accepted_values", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/schema_tests/not_accepted_values.sql", "original_file_path": "macros/schema_tests/not_accepted_values.sql", "name": "default__test_not_accepted_values", "macro_sql": "{% macro default__test_not_accepted_values(model, column_name, values, quote=True) %}\nwith all_values as (\n\n    select distinct\n        {{ column_name }} as value_field\n\n    from {{ model }}\n\n),\n\nvalidation_errors as (\n\n    select\n        value_field\n\n    from all_values\n    where value_field in (\n        {% for value in values -%}\n            {% if quote -%}\n            '{{ value }}'\n            {%- else -%}\n            {{ value }}\n            {%- endif -%}\n            {%- if not loop.last -%},{%- endif %}\n        {%- endfor %}\n        )\n\n)\n\nselect *\nfrom validation_errors\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.978442}, "macro.dbt_utils.test_unique_where": {"unique_id": "macro.dbt_utils.test_unique_where", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/schema_tests/test_unique_where.sql", "original_file_path": "macros/schema_tests/test_unique_where.sql", "name": "test_unique_where", "macro_sql": "{% test unique_where(model, column_name) %}\r\n  {%- set deprecation_warning = '\r\n    Warning: `dbt_utils.unique_where` is no longer supported.\r\n    Starting in dbt v0.20.0, the built-in `unique` test supports a `where` config.\r\n    ' -%}\r\n  {%- do exceptions.warn(deprecation_warning) -%}\r\n  {{ return(adapter.dispatch('test_unique_where', 'dbt_utils')(model, column_name)) }}\r\n{% endtest %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__test_unique_where"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.9795651}, "macro.dbt_utils.default__test_unique_where": {"unique_id": "macro.dbt_utils.default__test_unique_where", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/schema_tests/test_unique_where.sql", "original_file_path": "macros/schema_tests/test_unique_where.sql", "name": "default__test_unique_where", "macro_sql": "{% macro default__test_unique_where(model, column_name) %}\r\n  {{ return(test_unique(model, column_name)) }}\r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.test_unique"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.979985}, "macro.dbt_utils.test_at_least_one": {"unique_id": "macro.dbt_utils.test_at_least_one", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/schema_tests/at_least_one.sql", "original_file_path": "macros/schema_tests/at_least_one.sql", "name": "test_at_least_one", "macro_sql": "{% test at_least_one(model, column_name) %}\n  {{ return(adapter.dispatch('test_at_least_one', 'dbt_utils')(model, column_name)) }}\n{% endtest %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__test_at_least_one"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.980858}, "macro.dbt_utils.default__test_at_least_one": {"unique_id": "macro.dbt_utils.default__test_at_least_one", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/schema_tests/at_least_one.sql", "original_file_path": "macros/schema_tests/at_least_one.sql", "name": "default__test_at_least_one", "macro_sql": "{% macro default__test_at_least_one(model, column_name) %}\n\nselect *\nfrom (\n    select\n        {# In TSQL, subquery aggregate columns need aliases #}\n        {# thus: a filler col name, 'filler_column' #}\n      count({{ column_name }}) as filler_column\n\n    from {{ model }}\n\n    having count({{ column_name }}) = 0\n\n) validation_errors\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.981368}, "macro.dbt_utils.test_unique_combination_of_columns": {"unique_id": "macro.dbt_utils.test_unique_combination_of_columns", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/schema_tests/unique_combination_of_columns.sql", "original_file_path": "macros/schema_tests/unique_combination_of_columns.sql", "name": "test_unique_combination_of_columns", "macro_sql": "{% test unique_combination_of_columns(model, combination_of_columns, quote_columns=false) %}\n  {{ return(adapter.dispatch('test_unique_combination_of_columns', 'dbt_utils')(model, combination_of_columns, quote_columns)) }}\n{% endtest %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__test_unique_combination_of_columns"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.9827719}, "macro.dbt_utils.default__test_unique_combination_of_columns": {"unique_id": "macro.dbt_utils.default__test_unique_combination_of_columns", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/schema_tests/unique_combination_of_columns.sql", "original_file_path": "macros/schema_tests/unique_combination_of_columns.sql", "name": "default__test_unique_combination_of_columns", "macro_sql": "{% macro default__test_unique_combination_of_columns(model, combination_of_columns, quote_columns=false) %}\n\n{% if not quote_columns %}\n    {%- set column_list=combination_of_columns %}\n{% elif quote_columns %}\n    {%- set column_list=[] %}\n        {% for column in combination_of_columns -%}\n            {% set column_list = column_list.append( adapter.quote(column) ) %}\n        {%- endfor %}\n{% else %}\n    {{ exceptions.raise_compiler_error(\n        \"`quote_columns` argument for unique_combination_of_columns test must be one of [True, False] Got: '\" ~ quote ~\"'.'\"\n    ) }}\n{% endif %}\n\n{%- set columns_csv=column_list | join(', ') %}\n\n\nwith validation_errors as (\n\n    select\n        {{ columns_csv }}\n    from {{ model }}\n    group by {{ columns_csv }}\n    having count(*) > 1\n\n)\n\nselect *\nfrom validation_errors\n\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.984462}, "macro.dbt_utils.test_cardinality_equality": {"unique_id": "macro.dbt_utils.test_cardinality_equality", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/schema_tests/cardinality_equality.sql", "original_file_path": "macros/schema_tests/cardinality_equality.sql", "name": "test_cardinality_equality", "macro_sql": "{% test cardinality_equality(model, column_name, to, field) %}\n    {{ return(adapter.dispatch('test_cardinality_equality', 'dbt_utils')(model, column_name, to, field)) }}\n{% endtest %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__test_cardinality_equality"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.9856791}, "macro.dbt_utils.default__test_cardinality_equality": {"unique_id": "macro.dbt_utils.default__test_cardinality_equality", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/schema_tests/cardinality_equality.sql", "original_file_path": "macros/schema_tests/cardinality_equality.sql", "name": "default__test_cardinality_equality", "macro_sql": "{% macro default__test_cardinality_equality(model, column_name, to, field) %}\n\n{# T-SQL does not let you use numbers as aliases for columns #}\n{# Thus, no \"GROUP BY 1\" #}\n\nwith table_a as (\nselect\n  {{ column_name }},\n  count(*) as num_rows\nfrom {{ model }}\ngroup by {{ column_name }}\n),\n\ntable_b as (\nselect\n  {{ field }},\n  count(*) as num_rows\nfrom {{ to }}\ngroup by {{ field }}\n),\n\nexcept_a as (\n  select *\n  from table_a\n  {{ dbt_utils.except() }}\n  select *\n  from table_b\n),\n\nexcept_b as (\n  select *\n  from table_b\n  {{ dbt_utils.except() }}\n  select *\n  from table_a\n),\n\nunioned as (\n  select *\n  from except_a\n  union all\n  select *\n  from except_b\n)\n\nselect *\nfrom unioned\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.except"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.98652}, "macro.dbt_utils.test_expression_is_true": {"unique_id": "macro.dbt_utils.test_expression_is_true", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/schema_tests/expression_is_true.sql", "original_file_path": "macros/schema_tests/expression_is_true.sql", "name": "test_expression_is_true", "macro_sql": "{% test expression_is_true(model, expression, column_name=None, condition='1=1') %}\n{# T-SQL has no boolean data type so we use 1=1 which returns TRUE #}\n{# ref https://stackoverflow.com/a/7170753/3842610 #}\n  {{ return(adapter.dispatch('test_expression_is_true', 'dbt_utils')(model, expression, column_name, condition)) }}\n{% endtest %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__test_expression_is_true"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.987682}, "macro.dbt_utils.default__test_expression_is_true": {"unique_id": "macro.dbt_utils.default__test_expression_is_true", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/schema_tests/expression_is_true.sql", "original_file_path": "macros/schema_tests/expression_is_true.sql", "name": "default__test_expression_is_true", "macro_sql": "{% macro default__test_expression_is_true(model, expression, column_name, condition) %}\n\nwith meet_condition as (\n    select * from {{ model }} where {{ condition }}\n)\n\nselect\n    *\nfrom meet_condition\n{% if column_name is none %}\nwhere not({{ expression }})\n{%- else %}\nwhere not({{ column_name }} {{ expression }})\n{%- endif %}\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.988416}, "macro.dbt_utils.test_not_null_proportion": {"unique_id": "macro.dbt_utils.test_not_null_proportion", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/schema_tests/not_null_proportion.sql", "original_file_path": "macros/schema_tests/not_null_proportion.sql", "name": "test_not_null_proportion", "macro_sql": "{% macro test_not_null_proportion(model) %}\n  {{ return(adapter.dispatch('test_not_null_proportion', 'dbt_utils')(model, **kwargs)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__test_not_null_proportion"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.989543}, "macro.dbt_utils.default__test_not_null_proportion": {"unique_id": "macro.dbt_utils.default__test_not_null_proportion", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/schema_tests/not_null_proportion.sql", "original_file_path": "macros/schema_tests/not_null_proportion.sql", "name": "default__test_not_null_proportion", "macro_sql": "{% macro default__test_not_null_proportion(model) %}\n\n{% set column_name = kwargs.get('column_name', kwargs.get('arg')) %}\n{% set at_least = kwargs.get('at_least', kwargs.get('arg')) %}\n{% set at_most = kwargs.get('at_most', kwargs.get('arg', 1)) %}\n\nwith validation as (\n  select\n    sum(case when {{ column_name }} is null then 0 else 1 end) / cast(count(*) as numeric) as not_null_proportion\n  from {{ model }}\n),\nvalidation_errors as (\n  select\n    not_null_proportion\n  from validation\n  where not_null_proportion < {{ at_least }} or not_null_proportion > {{ at_most }}\n)\nselect\n  *\nfrom validation_errors\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.990826}, "macro.dbt_utils.test_sequential_values": {"unique_id": "macro.dbt_utils.test_sequential_values", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/schema_tests/sequential_values.sql", "original_file_path": "macros/schema_tests/sequential_values.sql", "name": "test_sequential_values", "macro_sql": "{% test sequential_values(model, column_name, interval=1, datepart=None) %}\n\n  {{ return(adapter.dispatch('test_sequential_values', 'dbt_utils')(model, column_name, interval, datepart)) }}\n\n{% endtest %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__test_sequential_values"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.992235}, "macro.dbt_utils.default__test_sequential_values": {"unique_id": "macro.dbt_utils.default__test_sequential_values", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/schema_tests/sequential_values.sql", "original_file_path": "macros/schema_tests/sequential_values.sql", "name": "default__test_sequential_values", "macro_sql": "{% macro default__test_sequential_values(model, column_name, interval=1, datepart=None) %}\n\n{% set previous_column_name = \"previous_\" ~ dbt_utils.slugify(column_name) %}\n\nwith windowed as (\n\n    select\n        {{ column_name }},\n        lag({{ column_name }}) over (\n            order by {{ column_name }}\n        ) as {{ previous_column_name }}\n    from {{ model }}\n),\n\nvalidation_errors as (\n    select\n        *\n    from windowed\n    {% if datepart %}\n    where not(cast({{ column_name }} as {{ dbt_utils.type_timestamp() }})= cast({{ dbt_utils.dateadd(datepart, interval, previous_column_name) }} as {{ dbt_utils.type_timestamp() }}))\n    {% else %}\n    where not({{ column_name }} = {{ previous_column_name }} + {{ interval }})\n    {% endif %}\n)\n\nselect *\nfrom validation_errors\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.slugify", "macro.dbt_utils.type_timestamp", "macro.dbt_utils.dateadd"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.993898}, "macro.dbt_utils.test_not_null_where": {"unique_id": "macro.dbt_utils.test_not_null_where", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/schema_tests/test_not_null_where.sql", "original_file_path": "macros/schema_tests/test_not_null_where.sql", "name": "test_not_null_where", "macro_sql": "{% test not_null_where(model, column_name) %}\r\n  {%- set deprecation_warning = '\r\n    Warning: `dbt_utils.not_null_where` is no longer supported.\r\n    Starting in dbt v0.20.0, the built-in `not_null` test supports a `where` config.\r\n    ' -%}\r\n  {%- do exceptions.warn(deprecation_warning) -%}\r\n  {{ return(adapter.dispatch('test_not_null_where', 'dbt_utils')(model, column_name)) }}\r\n{% endtest %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__test_not_null_where"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.994984}, "macro.dbt_utils.default__test_not_null_where": {"unique_id": "macro.dbt_utils.default__test_not_null_where", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/schema_tests/test_not_null_where.sql", "original_file_path": "macros/schema_tests/test_not_null_where.sql", "name": "default__test_not_null_where", "macro_sql": "{% macro default__test_not_null_where(model, column_name) %}\r\n  {{ return(test_not_null(model, column_name)) }}\r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.test_not_null"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.9954062}, "macro.dbt_utils.test_equality": {"unique_id": "macro.dbt_utils.test_equality", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/schema_tests/equality.sql", "original_file_path": "macros/schema_tests/equality.sql", "name": "test_equality", "macro_sql": "{% test equality(model, compare_model, compare_columns=None) %}\n  {{ return(adapter.dispatch('test_equality', 'dbt_utils')(model, compare_model, compare_columns)) }}\n{% endtest %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__test_equality"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.9968991}, "macro.dbt_utils.default__test_equality": {"unique_id": "macro.dbt_utils.default__test_equality", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/schema_tests/equality.sql", "original_file_path": "macros/schema_tests/equality.sql", "name": "default__test_equality", "macro_sql": "{% macro default__test_equality(model, compare_model, compare_columns=None) %}\n\n{% set set_diff %}\n    count(*) + coalesce(abs(\n        sum(case when which_diff = 'a_minus_b' then 1 else 0 end) -\n        sum(case when which_diff = 'b_minus_a' then 1 else 0 end)\n    ), 0)\n{% endset %}\n\n{#-- Needs to be set at parse time, before we return '' below --#}\n{{ config(fail_calc = set_diff) }}\n\n{#-- Prevent querying of db in parsing mode. This works because this macro does not create any new refs. #}\n{%- if not execute -%}\n    {{ return('') }}\n{% endif %}\n\n-- setup\n{%- do dbt_utils._is_relation(model, 'test_equality') -%}\n\n{#-\nIf the compare_cols arg is provided, we can run this test without querying the\ninformation schema\u00a0\u2014 this allows the model to be an ephemeral model\n-#}\n\n{%- if not compare_columns -%}\n    {%- do dbt_utils._is_ephemeral(model, 'test_equality') -%}\n    {%- set compare_columns = adapter.get_columns_in_relation(model) | map(attribute='quoted') -%}\n{%- endif -%}\n\n{% set compare_cols_csv = compare_columns | join(', ') %}\n\nwith a as (\n\n    select * from {{ model }}\n\n),\n\nb as (\n\n    select * from {{ compare_model }}\n\n),\n\na_minus_b as (\n\n    select {{compare_cols_csv}} from a\n    {{ dbt_utils.except() }}\n    select {{compare_cols_csv}} from b\n\n),\n\nb_minus_a as (\n\n    select {{compare_cols_csv}} from b\n    {{ dbt_utils.except() }}\n    select {{compare_cols_csv}} from a\n\n),\n\nunioned as (\n\n    select 'a_minus_b' as which_diff, a_minus_b.* from a_minus_b\n    union all\n    select 'b_minus_a' as which_diff, b_minus_a.* from b_minus_a\n\n)\n\nselect * from unioned\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils._is_relation", "macro.dbt_utils._is_ephemeral", "macro.dbt_utils.except"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014735.99905}, "macro.dbt_utils.test_mutually_exclusive_ranges": {"unique_id": "macro.dbt_utils.test_mutually_exclusive_ranges", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/schema_tests/mutually_exclusive_ranges.sql", "original_file_path": "macros/schema_tests/mutually_exclusive_ranges.sql", "name": "test_mutually_exclusive_ranges", "macro_sql": "{% test mutually_exclusive_ranges(model, lower_bound_column, upper_bound_column, partition_by=None, gaps='allowed', zero_length_range_allowed=False) %}\n  {{ return(adapter.dispatch('test_mutually_exclusive_ranges', 'dbt_utils')(model, lower_bound_column, upper_bound_column, partition_by, gaps, zero_length_range_allowed)) }}\n{% endtest %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__test_mutually_exclusive_ranges"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.0039418}, "macro.dbt_utils.default__test_mutually_exclusive_ranges": {"unique_id": "macro.dbt_utils.default__test_mutually_exclusive_ranges", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/schema_tests/mutually_exclusive_ranges.sql", "original_file_path": "macros/schema_tests/mutually_exclusive_ranges.sql", "name": "default__test_mutually_exclusive_ranges", "macro_sql": "{% macro default__test_mutually_exclusive_ranges(model, lower_bound_column, upper_bound_column, partition_by=None, gaps='allowed', zero_length_range_allowed=False) %}\n{% if gaps == 'not_allowed' %}\n    {% set allow_gaps_operator='=' %}\n    {% set allow_gaps_operator_in_words='equal_to' %}\n{% elif gaps == 'allowed' %}\n    {% set allow_gaps_operator='<=' %}\n    {% set allow_gaps_operator_in_words='less_than_or_equal_to' %}\n{% elif gaps == 'required' %}\n    {% set allow_gaps_operator='<' %}\n    {% set allow_gaps_operator_in_words='less_than' %}\n{% else %}\n    {{ exceptions.raise_compiler_error(\n        \"`gaps` argument for mutually_exclusive_ranges test must be one of ['not_allowed', 'allowed', 'required'] Got: '\" ~ gaps ~\"'.'\"\n    ) }}\n{% endif %}\n{% if not zero_length_range_allowed %}\n    {% set allow_zero_length_operator='<' %}\n    {% set allow_zero_length_operator_in_words='less_than' %}\n{% elif zero_length_range_allowed %}\n    {% set allow_zero_length_operator='<=' %}\n    {% set allow_zero_length_operator_in_words='less_than_or_equal_to' %}\n{% else %}\n    {{ exceptions.raise_compiler_error(\n        \"`zero_length_range_allowed` argument for mutually_exclusive_ranges test must be one of [true, false] Got: '\" ~ zero_length_range_allowed ~\"'.'\"\n    ) }}\n{% endif %}\n\n{% set partition_clause=\"partition by \" ~ partition_by if partition_by else '' %}\n\nwith window_functions as (\n\n    select\n        {% if partition_by %}\n        {{ partition_by }} as partition_by_col,\n        {% endif %}\n        {{ lower_bound_column }} as lower_bound,\n        {{ upper_bound_column }} as upper_bound,\n\n        lead({{ lower_bound_column }}) over (\n            {{ partition_clause }}\n            order by {{ lower_bound_column }}\n        ) as next_lower_bound,\n\n        row_number() over (\n            {{ partition_clause }}\n            order by {{ lower_bound_column }} desc\n        ) = 1 as is_last_record\n\n    from {{ model }}\n\n),\n\ncalc as (\n    -- We want to return records where one of our assumptions fails, so we'll use\n    -- the `not` function with `and` statements so we can write our assumptions nore cleanly\n    select\n        *,\n\n        -- For each record: lower_bound should be < upper_bound.\n        -- Coalesce it to return an error on the null case (implicit assumption\n        -- these columns are not_null)\n        coalesce(\n            lower_bound {{ allow_zero_length_operator }} upper_bound,\n            false\n        ) as lower_bound_{{ allow_zero_length_operator_in_words }}_upper_bound,\n\n        -- For each record: upper_bound {{ allow_gaps_operator }} the next lower_bound.\n        -- Coalesce it to handle null cases for the last record.\n        coalesce(\n            upper_bound {{ allow_gaps_operator }} next_lower_bound,\n            is_last_record,\n            false\n        ) as upper_bound_{{ allow_gaps_operator_in_words }}_next_lower_bound\n\n    from window_functions\n\n),\n\nvalidation_errors as (\n\n    select\n        *\n    from calc\n\n    where not(\n        -- THE FOLLOWING SHOULD BE TRUE --\n        lower_bound_{{ allow_zero_length_operator_in_words }}_upper_bound\n        and upper_bound_{{ allow_gaps_operator_in_words }}_next_lower_bound\n    )\n)\n\nselect * from validation_errors\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.0078652}, "macro.dbt_utils.get_intervals_between": {"unique_id": "macro.dbt_utils.get_intervals_between", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/sql/date_spine.sql", "original_file_path": "macros/sql/date_spine.sql", "name": "get_intervals_between", "macro_sql": "{% macro get_intervals_between(start_date, end_date, datepart) -%}\n    {{ return(adapter.dispatch('get_intervals_between', 'dbt_utils')(start_date, end_date, datepart)) }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__get_intervals_between"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.009395}, "macro.dbt_utils.default__get_intervals_between": {"unique_id": "macro.dbt_utils.default__get_intervals_between", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/sql/date_spine.sql", "original_file_path": "macros/sql/date_spine.sql", "name": "default__get_intervals_between", "macro_sql": "{% macro default__get_intervals_between(start_date, end_date, datepart) -%}\n    {%- call statement('get_intervals_between', fetch_result=True) %}\n\n        select {{dbt_utils.datediff(start_date, end_date, datepart)}}\n\n    {%- endcall -%}\n\n    {%- set value_list = load_result('get_intervals_between') -%}\n\n    {%- if value_list and value_list['data'] -%}\n        {%- set values = value_list['data'] | map(attribute=0) | list %}\n        {{ return(values[0]) }}\n    {%- else -%}\n        {{ return(1) }}\n    {%- endif -%}\n\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.statement", "macro.dbt_utils.datediff"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.010858}, "macro.dbt_utils.date_spine": {"unique_id": "macro.dbt_utils.date_spine", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/sql/date_spine.sql", "original_file_path": "macros/sql/date_spine.sql", "name": "date_spine", "macro_sql": "{% macro date_spine(datepart, start_date, end_date) %}\n    {{ return(adapter.dispatch('date_spine', 'dbt_utils')(datepart, start_date, end_date)) }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__date_spine"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.0114272}, "macro.dbt_utils.default__date_spine": {"unique_id": "macro.dbt_utils.default__date_spine", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/sql/date_spine.sql", "original_file_path": "macros/sql/date_spine.sql", "name": "default__date_spine", "macro_sql": "{% macro default__date_spine(datepart, start_date, end_date) %}\n\n\n{# call as follows:\n\ndate_spine(\n    \"day\",\n    \"to_date('01/01/2016', 'mm/dd/yyyy')\",\n    \"dateadd(week, 1, current_date)\"\n) #}\n\n\nwith rawdata as (\n\n    {{dbt_utils.generate_series(\n        dbt_utils.get_intervals_between(start_date, end_date, datepart)\n    )}}\n\n),\n\nall_periods as (\n\n    select (\n        {{\n            dbt_utils.dateadd(\n                datepart,\n                \"row_number() over (order by 1) - 1\",\n                start_date\n            )\n        }}\n    ) as date_{{datepart}}\n    from rawdata\n\n),\n\nfiltered as (\n\n    select *\n    from all_periods\n    where date_{{datepart}} <= {{ end_date }}\n\n)\n\nselect * from filtered\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.generate_series", "macro.dbt_utils.get_intervals_between", "macro.dbt_utils.dateadd"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.01231}, "macro.dbt_utils.nullcheck_table": {"unique_id": "macro.dbt_utils.nullcheck_table", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/sql/nullcheck_table.sql", "original_file_path": "macros/sql/nullcheck_table.sql", "name": "nullcheck_table", "macro_sql": "{% macro nullcheck_table(relation) %}\n    {{ return(adapter.dispatch('nullcheck_table', 'dbt_utils')(relation)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__nullcheck_table"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.013197}, "macro.dbt_utils.default__nullcheck_table": {"unique_id": "macro.dbt_utils.default__nullcheck_table", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/sql/nullcheck_table.sql", "original_file_path": "macros/sql/nullcheck_table.sql", "name": "default__nullcheck_table", "macro_sql": "{% macro default__nullcheck_table(relation) %}\n\n  {%- do dbt_utils._is_relation(relation, 'nullcheck_table') -%}\n  {%- do dbt_utils._is_ephemeral(relation, 'nullcheck_table') -%}\n  {% set cols = adapter.get_columns_in_relation(relation) %}\n\n  select {{ dbt_utils.nullcheck(cols) }}\n  from {{relation}}\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils._is_relation", "macro.dbt_utils._is_ephemeral", "macro.dbt_utils.nullcheck"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.014053}, "macro.dbt_utils.get_relations_by_pattern": {"unique_id": "macro.dbt_utils.get_relations_by_pattern", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/sql/get_relations_by_pattern.sql", "original_file_path": "macros/sql/get_relations_by_pattern.sql", "name": "get_relations_by_pattern", "macro_sql": "{% macro get_relations_by_pattern(schema_pattern, table_pattern, exclude='', database=target.database) %}\n    {{ return(adapter.dispatch('get_relations_by_pattern', 'dbt_utils')(schema_pattern, table_pattern, exclude, database)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__get_relations_by_pattern"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.015527}, "macro.dbt_utils.default__get_relations_by_pattern": {"unique_id": "macro.dbt_utils.default__get_relations_by_pattern", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/sql/get_relations_by_pattern.sql", "original_file_path": "macros/sql/get_relations_by_pattern.sql", "name": "default__get_relations_by_pattern", "macro_sql": "{% macro default__get_relations_by_pattern(schema_pattern, table_pattern, exclude='', database=target.database) %}\n\n    {%- call statement('get_tables', fetch_result=True) %}\n\n      {{ dbt_utils.get_tables_by_pattern_sql(schema_pattern, table_pattern, exclude, database) }}\n\n    {%- endcall -%}\n\n    {%- set table_list = load_result('get_tables') -%}\n\n    {%- if table_list and table_list['table'] -%}\n        {%- set tbl_relations = [] -%}\n        {%- for row in table_list['table'] -%}\n            {%- set tbl_relation = api.Relation.create(\n                database=database,\n                schema=row.table_schema,\n                identifier=row.table_name,\n                type=row.table_type\n            ) -%}\n            {%- do tbl_relations.append(tbl_relation) -%}\n        {%- endfor -%}\n\n        {{ return(tbl_relations) }}\n    {%- else -%}\n        {{ return([]) }}\n    {%- endif -%}\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.statement", "macro.dbt_utils.get_tables_by_pattern_sql"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.017666}, "macro.dbt_utils.get_powers_of_two": {"unique_id": "macro.dbt_utils.get_powers_of_two", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/sql/generate_series.sql", "original_file_path": "macros/sql/generate_series.sql", "name": "get_powers_of_two", "macro_sql": "{% macro get_powers_of_two(upper_bound) %}\n    {{ return(adapter.dispatch('get_powers_of_two', 'dbt_utils')(upper_bound)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__get_powers_of_two"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.019238}, "macro.dbt_utils.default__get_powers_of_two": {"unique_id": "macro.dbt_utils.default__get_powers_of_two", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/sql/generate_series.sql", "original_file_path": "macros/sql/generate_series.sql", "name": "default__get_powers_of_two", "macro_sql": "{% macro default__get_powers_of_two(upper_bound) %}\n\n    {% if upper_bound <= 0 %}\n    {{ exceptions.raise_compiler_error(\"upper bound must be positive\") }}\n    {% endif %}\n\n    {% for _ in range(1, 100) %}\n       {% if upper_bound <= 2 ** loop.index %}{{ return(loop.index) }}{% endif %}\n    {% endfor %}\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.020277}, "macro.dbt_utils.generate_series": {"unique_id": "macro.dbt_utils.generate_series", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/sql/generate_series.sql", "original_file_path": "macros/sql/generate_series.sql", "name": "generate_series", "macro_sql": "{% macro generate_series(upper_bound) %}\n    {{ return(adapter.dispatch('generate_series', 'dbt_utils')(upper_bound)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__generate_series"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.020745}, "macro.dbt_utils.default__generate_series": {"unique_id": "macro.dbt_utils.default__generate_series", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/sql/generate_series.sql", "original_file_path": "macros/sql/generate_series.sql", "name": "default__generate_series", "macro_sql": "{% macro default__generate_series(upper_bound) %}\n\n    {% set n = dbt_utils.get_powers_of_two(upper_bound) %}\n\n    with p as (\n        select 0 as generated_number union all select 1\n    ), unioned as (\n\n    select\n\n    {% for i in range(n) %}\n    p{{i}}.generated_number * power(2, {{i}})\n    {% if not loop.last %} + {% endif %}\n    {% endfor %}\n    + 1\n    as generated_number\n\n    from\n\n    {% for i in range(n) %}\n    p as p{{i}}\n    {% if not loop.last %} cross join {% endif %}\n    {% endfor %}\n\n    )\n\n    select *\n    from unioned\n    where generated_number <= {{upper_bound}}\n    order by generated_number\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.get_powers_of_two"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.0222569}, "macro.dbt_utils.get_relations_by_prefix": {"unique_id": "macro.dbt_utils.get_relations_by_prefix", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/sql/get_relations_by_prefix.sql", "original_file_path": "macros/sql/get_relations_by_prefix.sql", "name": "get_relations_by_prefix", "macro_sql": "{% macro get_relations_by_prefix(schema, prefix, exclude='', database=target.database) %}\n    {{ return(adapter.dispatch('get_relations_by_prefix', 'dbt_utils')(schema, prefix, exclude, database)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__get_relations_by_prefix"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.0237482}, "macro.dbt_utils.default__get_relations_by_prefix": {"unique_id": "macro.dbt_utils.default__get_relations_by_prefix", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/sql/get_relations_by_prefix.sql", "original_file_path": "macros/sql/get_relations_by_prefix.sql", "name": "default__get_relations_by_prefix", "macro_sql": "{% macro default__get_relations_by_prefix(schema, prefix, exclude='', database=target.database) %}\n\n    {%- call statement('get_tables', fetch_result=True) %}\n\n      {{ dbt_utils.get_tables_by_prefix_sql(schema, prefix, exclude, database) }}\n\n    {%- endcall -%}\n\n    {%- set table_list = load_result('get_tables') -%}\n\n    {%- if table_list and table_list['table'] -%}\n        {%- set tbl_relations = [] -%}\n        {%- for row in table_list['table'] -%}\n            {%- set tbl_relation = api.Relation.create(\n                database=database,\n                schema=row.table_schema,\n                identifier=row.table_name,\n                type=row.table_type\n            ) -%}\n            {%- do tbl_relations.append(tbl_relation) -%}\n        {%- endfor -%}\n\n        {{ return(tbl_relations) }}\n    {%- else -%}\n        {{ return([]) }}\n    {%- endif -%}\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.statement", "macro.dbt_utils.get_tables_by_prefix_sql"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.02597}, "macro.dbt_utils.get_tables_by_prefix_sql": {"unique_id": "macro.dbt_utils.get_tables_by_prefix_sql", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/sql/get_tables_by_prefix_sql.sql", "original_file_path": "macros/sql/get_tables_by_prefix_sql.sql", "name": "get_tables_by_prefix_sql", "macro_sql": "{% macro get_tables_by_prefix_sql(schema, prefix, exclude='', database=target.database) %}\n    {{ return(adapter.dispatch('get_tables_by_prefix_sql', 'dbt_utils')(schema, prefix, exclude, database)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__get_tables_by_prefix_sql"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.027114}, "macro.dbt_utils.default__get_tables_by_prefix_sql": {"unique_id": "macro.dbt_utils.default__get_tables_by_prefix_sql", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/sql/get_tables_by_prefix_sql.sql", "original_file_path": "macros/sql/get_tables_by_prefix_sql.sql", "name": "default__get_tables_by_prefix_sql", "macro_sql": "{% macro default__get_tables_by_prefix_sql(schema, prefix, exclude='', database=target.database) %}\n\n    {{ dbt_utils.get_tables_by_pattern_sql(\n        schema_pattern = schema,\n        table_pattern = prefix ~ '%',\n        exclude = exclude,\n        database = database\n    ) }}\n    \n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.get_tables_by_pattern_sql"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.027819}, "macro.dbt_utils.star": {"unique_id": "macro.dbt_utils.star", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/sql/star.sql", "original_file_path": "macros/sql/star.sql", "name": "star", "macro_sql": "{% macro star(from, relation_alias=False, except=[], prefix='', suffix='') -%}\n    {{ return(adapter.dispatch('star', 'dbt_utils')(from, relation_alias, except, prefix, suffix)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__star"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.029494}, "macro.dbt_utils.default__star": {"unique_id": "macro.dbt_utils.default__star", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/sql/star.sql", "original_file_path": "macros/sql/star.sql", "name": "default__star", "macro_sql": "{% macro default__star(from, relation_alias=False, except=[], prefix='', suffix='') -%}\n    {%- do dbt_utils._is_relation(from, 'star') -%}\n    {%- do dbt_utils._is_ephemeral(from, 'star') -%}\n\n    {#-- Prevent querying of db in parsing mode. This works because this macro does not create any new refs. #}\n    {%- if not execute -%}\n        {{ return('') }}\n    {% endif %}\n\n    {%- set include_cols = [] %}\n    {%- set cols = adapter.get_columns_in_relation(from) -%}\n    {%- set except = except | map(\"lower\") | list %}\n    {%- for col in cols -%}\n\n        {%- if col.column|lower not in except -%}\n            {% do include_cols.append(col.column) %}\n\n        {%- endif %}\n    {%- endfor %}\n\n    {%- for col in include_cols %}\n\n        {%- if relation_alias %}{{ relation_alias }}.{% else %}{%- endif -%}{{ adapter.quote(col)|trim }} {%- if prefix!='' or suffix!='' -%} as {{ adapter.quote(prefix ~ col ~ suffix)|trim }} {%- endif -%}\n        {%- if not loop.last %},{{ '\\n  ' }}{% endif %}\n\n    {%- endfor -%}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils._is_relation", "macro.dbt_utils._is_ephemeral"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.032524}, "macro.dbt_utils.unpivot": {"unique_id": "macro.dbt_utils.unpivot", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/sql/unpivot.sql", "original_file_path": "macros/sql/unpivot.sql", "name": "unpivot", "macro_sql": "{% macro unpivot(relation=none, cast_to='varchar', exclude=none, remove=none, field_name='field_name', value_name='value', table=none) -%}\n    {{ return(adapter.dispatch('unpivot', 'dbt_utils')(relation, cast_to, exclude, remove, field_name, value_name, table)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__unpivot"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.035719}, "macro.dbt_utils.default__unpivot": {"unique_id": "macro.dbt_utils.default__unpivot", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/sql/unpivot.sql", "original_file_path": "macros/sql/unpivot.sql", "name": "default__unpivot", "macro_sql": "{% macro default__unpivot(relation=none, cast_to='varchar', exclude=none, remove=none, field_name='field_name', value_name='value', table=none) -%}\n\n    {% if table %}\n        {%- set error_message = '\n            Warning: the `unpivot` macro no longer accepts a `table` parameter. \\\n            This parameter will be deprecated in a future release of dbt-utils. Use the `relation` parameter instead. \\\n            The {}.{} model triggered this warning. \\\n            '.format(model.package_name, model.name) -%}\n        {%- do exceptions.warn(error_message) -%}\n    {% endif %}\n\n    {% if relation and table %}\n        {{ exceptions.raise_compiler_error(\"Error: both the `relation` and `table` parameters were provided to `unpivot` macro. Choose one only (we recommend `relation`).\") }}\n    {% elif not relation and table %}\n        {% set relation=table %}\n    {% elif not relation and not table %}\n        {{ exceptions.raise_compiler_error(\"Error: argument `relation` is required for `unpivot` macro.\") }}\n    {% endif %}\n\n  {%- set exclude = exclude if exclude is not none else [] %}\n  {%- set remove = remove if remove is not none else [] %}\n\n  {%- set include_cols = [] %}\n\n  {%- set table_columns = {} %}\n\n  {%- do table_columns.update({relation: []}) %}\n\n  {%- do dbt_utils._is_relation(relation, 'unpivot') -%}\n  {%- do dbt_utils._is_ephemeral(relation, 'unpivot') -%}\n  {%- set cols = adapter.get_columns_in_relation(relation) %}\n\n  {%- for col in cols -%}\n    {%- if col.column.lower() not in remove|map('lower') and col.column.lower() not in exclude|map('lower') -%}\n      {% do include_cols.append(col) %}\n    {%- endif %}\n  {%- endfor %}\n\n\n  {%- for col in include_cols -%}\n    select\n      {%- for exclude_col in exclude %}\n        {{ exclude_col }},\n      {%- endfor %}\n\n      cast('{{ col.column }}' as {{ dbt_utils.type_string() }}) as {{ field_name }},\n      cast(  {% if col.data_type == 'boolean' %}\n           {{ dbt_utils.cast_bool_to_text(col.column) }}\n             {% else %}\n           {{ col.column }}\n             {% endif %}\n           as {{ cast_to }}) as {{ value_name }}\n\n    from {{ relation }}\n\n    {% if not loop.last -%}\n      union all\n    {% endif -%}\n  {%- endfor -%}\n\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils._is_relation", "macro.dbt_utils._is_ephemeral", "macro.dbt_utils.type_string", "macro.dbt_utils.cast_bool_to_text"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.040734}, "macro.dbt_utils.union_relations": {"unique_id": "macro.dbt_utils.union_relations", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/sql/union.sql", "original_file_path": "macros/sql/union.sql", "name": "union_relations", "macro_sql": "{%- macro union_relations(relations, column_override=none, include=[], exclude=[], source_column_name='_dbt_source_relation') -%}\n    {{ return(adapter.dispatch('union_relations', 'dbt_utils')(relations, column_override, include, exclude, source_column_name)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__union_relations"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.044518}, "macro.dbt_utils.default__union_relations": {"unique_id": "macro.dbt_utils.default__union_relations", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/sql/union.sql", "original_file_path": "macros/sql/union.sql", "name": "default__union_relations", "macro_sql": "\n\n{%- macro default__union_relations(relations, column_override=none, include=[], exclude=[], source_column_name='_dbt_source_relation') -%}\n\n    {%- if exclude and include -%}\n        {{ exceptions.raise_compiler_error(\"Both an exclude and include list were provided to the `union` macro. Only one is allowed\") }}\n    {%- endif -%}\n\n    {#-- Prevent querying of db in parsing mode. This works because this macro does not create any new refs. -#}\n    {%- if not execute %}\n        {{ return('') }}\n    {% endif -%}\n\n    {%- set column_override = column_override if column_override is not none else {} -%}\n\n    {%- set relation_columns = {} -%}\n    {%- set column_superset = {} -%}\n\n    {%- for relation in relations -%}\n\n        {%- do relation_columns.update({relation: []}) -%}\n\n        {%- do dbt_utils._is_relation(relation, 'union_relations') -%}\n        {%- do dbt_utils._is_ephemeral(relation, 'union_relations') -%}\n        {%- set cols = adapter.get_columns_in_relation(relation) -%}\n        {%- for col in cols -%}\n\n        {#- If an exclude list was provided and the column is in the list, do nothing -#}\n        {%- if exclude and col.column in exclude -%}\n\n        {#- If an include list was provided and the column is not in the list, do nothing -#}\n        {%- elif include and col.column not in include -%}\n\n        {#- Otherwise add the column to the column superset -#}\n        {%- else -%}\n\n            {#- update the list of columns in this relation -#}\n            {%- do relation_columns[relation].append(col.column) -%}\n\n            {%- if col.column in column_superset -%}\n\n                {%- set stored = column_superset[col.column] -%}\n                {%- if col.is_string() and stored.is_string() and col.string_size() > stored.string_size() -%}\n\n                    {%- do column_superset.update({col.column: col}) -%}\n\n                {%- endif %}\n\n            {%- else -%}\n\n                {%- do column_superset.update({col.column: col}) -%}\n\n            {%- endif -%}\n\n        {%- endif -%}\n\n        {%- endfor -%}\n    {%- endfor -%}\n\n    {%- set ordered_column_names = column_superset.keys() -%}\n\n    {% if (include | length > 0 or exclude | length > 0) and not column_superset.keys() %}\n        {%- set relations_string -%}\n            {%- for relation in relations -%}\n                {{ relation.name }}\n            {%- if not loop.last %}, {% endif -%}\n            {%- endfor -%}\n        {%- endset -%}\n\n        {%- set error_message -%}\n            There were no columns found to union for relations {{ relations_string }}\n        {%- endset -%}\n\n        {{ exceptions.raise_compiler_error(error_message) }}\n    {%- endif -%}\n\n    {%- for relation in relations %}\n\n        (\n            select\n\n                cast({{ dbt_utils.string_literal(relation) }} as {{ dbt_utils.type_string() }}) as {{ source_column_name }},\n                {% for col_name in ordered_column_names -%}\n\n                    {%- set col = column_superset[col_name] %}\n                    {%- set col_type = column_override.get(col.column, col.data_type) %}\n                    {%- set col_name = adapter.quote(col_name) if col_name in relation_columns[relation] else 'null' %}\n                    cast({{ col_name }} as {{ col_type }}) as {{ col.quoted }} {% if not loop.last %},{% endif -%}\n\n                {%- endfor %}\n\n            from {{ relation }}\n        )\n\n        {% if not loop.last -%}\n            union all\n        {% endif -%}\n\n    {%- endfor -%}\n\n{%- endmacro -%}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils._is_relation", "macro.dbt_utils._is_ephemeral", "macro.dbt_utils.string_literal", "macro.dbt_utils.type_string"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.0520692}, "macro.dbt_utils.group_by": {"unique_id": "macro.dbt_utils.group_by", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/sql/groupby.sql", "original_file_path": "macros/sql/groupby.sql", "name": "group_by", "macro_sql": "{%- macro group_by(n) -%}\n    {{ return(adapter.dispatch('group_by', 'dbt_utils')(n)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__group_by"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.0529559}, "macro.dbt_utils.default__group_by": {"unique_id": "macro.dbt_utils.default__group_by", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/sql/groupby.sql", "original_file_path": "macros/sql/groupby.sql", "name": "default__group_by", "macro_sql": "\n\n{%- macro default__group_by(n) -%}\n\n  group by {% for i in range(1, n + 1) -%}\n      {{ i }}{{ ',' if not loop.last }}   \n   {%- endfor -%}\n\n{%- endmacro -%}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.0536199}, "macro.dbt_utils.surrogate_key": {"unique_id": "macro.dbt_utils.surrogate_key", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/sql/surrogate_key.sql", "original_file_path": "macros/sql/surrogate_key.sql", "name": "surrogate_key", "macro_sql": "{%- macro surrogate_key(field_list) -%}\n    {# needed for safe_add to allow for non-keyword arguments see SO post #}\n    {# https://stackoverflow.com/questions/13944751/args-kwargs-in-jinja2-macros #}\n    {% set frustrating_jinja_feature = varargs %}\n    {{ return(adapter.dispatch('surrogate_key', 'dbt_utils')(field_list, *varargs)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__surrogate_key"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.054999}, "macro.dbt_utils.default__surrogate_key": {"unique_id": "macro.dbt_utils.default__surrogate_key", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/sql/surrogate_key.sql", "original_file_path": "macros/sql/surrogate_key.sql", "name": "default__surrogate_key", "macro_sql": "\n\n{%- macro default__surrogate_key(field_list) -%}\n\n{%- if varargs|length >= 1 or field_list is string %}\n\n{%- set error_message = '\nWarning: the `surrogate_key` macro now takes a single list argument instead of \\\nmultiple string arguments. Support for multiple string arguments will be \\\ndeprecated in a future release of dbt-utils. The {}.{} model triggered this warning. \\\n'.format(model.package_name, model.name) -%}\n\n{%- do exceptions.warn(error_message) -%}\n\n{# first argument is not included in varargs, so add first element to field_list_xf #}\n{%- set field_list_xf = [field_list] -%}\n\n{%- for field in varargs %}\n{%- set _ = field_list_xf.append(field) -%}\n{%- endfor -%}\n\n{%- else -%}\n\n{# if using list, just set field_list_xf as field_list #}\n{%- set field_list_xf = field_list -%}\n\n{%- endif -%}\n\n\n{%- set fields = [] -%}\n\n{%- for field in field_list_xf -%}\n\n    {%- set _ = fields.append(\n        \"coalesce(cast(\" ~ field ~ \" as \" ~ dbt_utils.type_string() ~ \"), '')\"\n    ) -%}\n\n    {%- if not loop.last %}\n        {%- set _ = fields.append(\"'-'\") -%}\n    {%- endif -%}\n\n{%- endfor -%}\n\n{{dbt_utils.hash(dbt_utils.concat(fields))}}\n\n{%- endmacro -%}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.type_string", "macro.dbt_utils.hash", "macro.dbt_utils.concat"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.057759}, "macro.dbt_utils.safe_add": {"unique_id": "macro.dbt_utils.safe_add", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/sql/safe_add.sql", "original_file_path": "macros/sql/safe_add.sql", "name": "safe_add", "macro_sql": "{%- macro safe_add() -%}\n    {# needed for safe_add to allow for non-keyword arguments see SO post #}\n    {# https://stackoverflow.com/questions/13944751/args-kwargs-in-jinja2-macros #}\n    {% set frustrating_jinja_feature = varargs %}\n    {{ return(adapter.dispatch('safe_add', 'dbt_utils')(*varargs)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__safe_add"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.058878}, "macro.dbt_utils.default__safe_add": {"unique_id": "macro.dbt_utils.default__safe_add", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/sql/safe_add.sql", "original_file_path": "macros/sql/safe_add.sql", "name": "default__safe_add", "macro_sql": "\n\n{%- macro default__safe_add() -%}\n\n{% set fields = [] %}\n\n{%- for field in varargs -%}\n\n    {% do fields.append(\"coalesce(\" ~ field ~ \", 0)\") %}\n\n{%- endfor -%}\n\n{{ fields|join(' +\\n  ') }}\n\n{%- endmacro -%}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.05967}, "macro.dbt_utils.nullcheck": {"unique_id": "macro.dbt_utils.nullcheck", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/sql/nullcheck.sql", "original_file_path": "macros/sql/nullcheck.sql", "name": "nullcheck", "macro_sql": "{% macro nullcheck(cols) %}\n    {{ return(adapter.dispatch('nullcheck', 'dbt_utils')(cols)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__nullcheck"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.060582}, "macro.dbt_utils.default__nullcheck": {"unique_id": "macro.dbt_utils.default__nullcheck", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/sql/nullcheck.sql", "original_file_path": "macros/sql/nullcheck.sql", "name": "default__nullcheck", "macro_sql": "{% macro default__nullcheck(cols) %}\n{%- for col in cols %}\n\n    {% if col.is_string() -%}\n\n    nullif({{col.name}},'') as {{col.name}}\n\n    {%- else -%}\n\n    {{col.name}}\n\n    {%- endif -%}\n\n{%- if not loop.last -%} , {%- endif -%}\n\n{%- endfor -%}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.06159}, "macro.dbt_utils.get_tables_by_pattern_sql": {"unique_id": "macro.dbt_utils.get_tables_by_pattern_sql", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/sql/get_tables_by_pattern_sql.sql", "original_file_path": "macros/sql/get_tables_by_pattern_sql.sql", "name": "get_tables_by_pattern_sql", "macro_sql": "{% macro get_tables_by_pattern_sql(schema_pattern, table_pattern, exclude='', database=target.database) %}\n    {{ return(adapter.dispatch('get_tables_by_pattern_sql', 'dbt_utils')\n        (schema_pattern, table_pattern, exclude, database)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.bigquery__get_tables_by_pattern_sql"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.0645561}, "macro.dbt_utils.default__get_tables_by_pattern_sql": {"unique_id": "macro.dbt_utils.default__get_tables_by_pattern_sql", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/sql/get_tables_by_pattern_sql.sql", "original_file_path": "macros/sql/get_tables_by_pattern_sql.sql", "name": "default__get_tables_by_pattern_sql", "macro_sql": "{% macro default__get_tables_by_pattern_sql(schema_pattern, table_pattern, exclude='', database=target.database) %}\n\n        select distinct\n            table_schema as \"table_schema\",\n            table_name as \"table_name\",\n            {{ dbt_utils.get_table_types_sql() }}\n        from {{ database }}.information_schema.tables\n        where table_schema ilike '{{ schema_pattern }}'\n        and table_name ilike '{{ table_pattern }}'\n        and table_name not ilike '{{ exclude }}'\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.get_table_types_sql"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.0653088}, "macro.dbt_utils.bigquery__get_tables_by_pattern_sql": {"unique_id": "macro.dbt_utils.bigquery__get_tables_by_pattern_sql", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/sql/get_tables_by_pattern_sql.sql", "original_file_path": "macros/sql/get_tables_by_pattern_sql.sql", "name": "bigquery__get_tables_by_pattern_sql", "macro_sql": "{% macro bigquery__get_tables_by_pattern_sql(schema_pattern, table_pattern, exclude='', database=target.database) %}\n\n    {% if '%' in schema_pattern %}\n        {% set schemata=dbt_utils._bigquery__get_matching_schemata(schema_pattern, database) %}\n    {% else %}\n        {% set schemata=[schema_pattern] %}\n    {% endif %}\n\n    {% set sql %}\n        {% for schema in schemata %}\n            select distinct\n                table_schema,\n                table_name,\n                case table_type\n                    when 'BASE TABLE' then 'table'\n                    else lower(table_type)\n                end as table_type\n\n            from {{ adapter.quote(database) }}.{{ schema }}.INFORMATION_SCHEMA.TABLES\n            where lower(table_name) like lower ('{{ table_pattern }}')\n                and lower(table_name) not like lower ('{{ exclude }}')\n\n            {% if not loop.last %} union all {% endif %}\n\n        {% endfor %}\n    {% endset %}\n\n    {{ return(sql) }}\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils._bigquery__get_matching_schemata"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.067146}, "macro.dbt_utils._bigquery__get_matching_schemata": {"unique_id": "macro.dbt_utils._bigquery__get_matching_schemata", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/sql/get_tables_by_pattern_sql.sql", "original_file_path": "macros/sql/get_tables_by_pattern_sql.sql", "name": "_bigquery__get_matching_schemata", "macro_sql": "{% macro _bigquery__get_matching_schemata(schema_pattern, database) %}\n    {% if execute %}\n\n        {% set sql %}\n        select schema_name from {{ adapter.quote(database) }}.INFORMATION_SCHEMA.SCHEMATA\n        where lower(schema_name) like lower('{{ schema_pattern }}')\n        {% endset %}\n\n        {% set results=run_query(sql) %}\n\n        {% set schemata=results.columns['schema_name'].values() %}\n\n        {{ return(schemata) }}\n\n    {% else %}\n\n        {{ return([]) }}\n\n    {% endif %}\n\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.run_query"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.068649}, "macro.dbt_utils.get_column_values": {"unique_id": "macro.dbt_utils.get_column_values", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/sql/get_column_values.sql", "original_file_path": "macros/sql/get_column_values.sql", "name": "get_column_values", "macro_sql": "{% macro get_column_values(table, column, order_by='count(*) desc', max_records=none, default=none) -%}\n    {{ return(adapter.dispatch('get_column_values', 'dbt_utils')(table, column, order_by, max_records, default)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__get_column_values"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.07116}, "macro.dbt_utils.default__get_column_values": {"unique_id": "macro.dbt_utils.default__get_column_values", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/sql/get_column_values.sql", "original_file_path": "macros/sql/get_column_values.sql", "name": "default__get_column_values", "macro_sql": "{% macro default__get_column_values(table, column, order_by='count(*) desc', max_records=none, default=none) -%}\n{% if default is none %}\n    {% set default = [] %}\n{% endif %}\n    {#-- Prevent querying of db in parsing mode. This works because this macro does not create any new refs. #}\n    {%- if not execute -%}\n        {{ return(default) }}\n    {% endif %}\n\n    {# Not all relations are tables. Renaming for internal clarity without breaking functionality for anyone using named arguments #}\n    {# TODO: Change the method signature in a future 0.x.0 release #}\n    {%- set target_relation = table -%}\n\n    {# adapter.load_relation is a convenience wrapper to avoid building a Relation when we already have one #}\n    {% set relation_exists = (load_relation(target_relation)) is not none %}\n\n    {%- call statement('get_column_values', fetch_result=true) %}\n\n        {%- if not relation_exists and default is none -%}\n\n          {{ exceptions.raise_compiler_error(\"In get_column_values(): relation \" ~ target_relation ~ \" does not exist and no default value was provided.\") }}\n\n        {%- elif not relation_exists and default is not none -%}\n\n          {{ log(\"Relation \" ~ target_relation ~ \" does not exist. Returning the default value: \" ~ default) }}\n\n          {{ return(default) }}\n\n        {%- else -%}\n\n\n            select\n                {{ column }} as value\n\n            from {{ target_relation }}\n            group by {{ column }}\n            order by {{ order_by }}\n\n            {% if max_records is not none %}\n            limit {{ max_records }}\n            {% endif %}\n\n        {% endif %}\n\n    {%- endcall -%}\n\n    {%- set value_list = load_result('get_column_values') -%}\n\n    {%- if value_list and value_list['data'] -%}\n        {%- set values = value_list['data'] | map(attribute=0) | list %}\n        {{ return(values) }}\n    {%- else -%}\n        {{ return(default) }}\n    {%- endif -%}\n\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.load_relation", "macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.0755358}, "macro.dbt_utils.pivot": {"unique_id": "macro.dbt_utils.pivot", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/sql/pivot.sql", "original_file_path": "macros/sql/pivot.sql", "name": "pivot", "macro_sql": "{% macro pivot(column,\n               values,\n               alias=True,\n               agg='sum',\n               cmp='=',\n               prefix='',\n               suffix='',\n               then_value=1,\n               else_value=0,\n               quote_identifiers=True,\n               distinct=False) %}\n    {{ return(adapter.dispatch('pivot', 'dbt_utils')(column, values, alias, agg, cmp, prefix, suffix, then_value, else_value, quote_identifiers, distinct)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__pivot"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.094341}, "macro.dbt_utils.default__pivot": {"unique_id": "macro.dbt_utils.default__pivot", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/sql/pivot.sql", "original_file_path": "macros/sql/pivot.sql", "name": "default__pivot", "macro_sql": "{% macro default__pivot(column,\n               values,\n               alias=True,\n               agg='sum',\n               cmp='=',\n               prefix='',\n               suffix='',\n               then_value=1,\n               else_value=0,\n               quote_identifiers=True,\n               distinct=False) %}\n  {% for value in values %}\n    {{ agg }}(\n      {% if distinct %} distinct {% endif %}\n      case\n      when {{ column }} {{ cmp }} '{{ dbt_utils.escape_single_quotes(value) }}'\n        then {{ then_value }}\n      else {{ else_value }}\n      end\n    )\n    {% if alias %}\n      {% if quote_identifiers %}\n            as {{ adapter.quote(prefix ~ value ~ suffix) }}\n      {% else %}\n        as {{ dbt_utils.slugify(prefix ~ value ~ suffix) }}\n      {% endif %}\n    {% endif %}\n    {% if not loop.last %},{% endif %}\n  {% endfor %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.escape_single_quotes", "macro.dbt_utils.slugify"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.0972211}, "macro.dbt_utils.get_query_results_as_dict": {"unique_id": "macro.dbt_utils.get_query_results_as_dict", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/sql/get_query_results_as_dict.sql", "original_file_path": "macros/sql/get_query_results_as_dict.sql", "name": "get_query_results_as_dict", "macro_sql": "{% macro get_query_results_as_dict(query) %}\n    {{ return(adapter.dispatch('get_query_results_as_dict', 'dbt_utils')(query)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__get_query_results_as_dict"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.098801}, "macro.dbt_utils.default__get_query_results_as_dict": {"unique_id": "macro.dbt_utils.default__get_query_results_as_dict", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/sql/get_query_results_as_dict.sql", "original_file_path": "macros/sql/get_query_results_as_dict.sql", "name": "default__get_query_results_as_dict", "macro_sql": "{% macro default__get_query_results_as_dict(query) %}\n\n{# This macro returns a dictionary of the form {column_name: (tuple_of_results)} #}\n\n    {%- call statement('get_query_results', fetch_result=True,auto_begin=false) -%}\n\n        {{ query }}\n\n    {%- endcall -%}\n\n    {% set sql_results={} %}\n\n    {%- if execute -%}\n        {% set sql_results_table = load_result('get_query_results').table.columns %}\n        {% for column_name, column in sql_results_table.items() %}\n            {% do sql_results.update({column_name: column.values()}) %}\n        {% endfor %}\n    {%- endif -%}\n\n    {{ return(sql_results) }}\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.1006641}, "macro.dbt_utils.get_table_types_sql": {"unique_id": "macro.dbt_utils.get_table_types_sql", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/sql/get_table_types_sql.sql", "original_file_path": "macros/sql/get_table_types_sql.sql", "name": "get_table_types_sql", "macro_sql": "{%- macro get_table_types_sql() -%}\n  {{ return(adapter.dispatch('get_table_types_sql', 'dbt_utils')()) }}\n{%- endmacro -%}\n\n", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__get_table_types_sql"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.102546}, "macro.dbt_utils.default__get_table_types_sql": {"unique_id": "macro.dbt_utils.default__get_table_types_sql", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/sql/get_table_types_sql.sql", "original_file_path": "macros/sql/get_table_types_sql.sql", "name": "default__get_table_types_sql", "macro_sql": "{% macro default__get_table_types_sql() %}\n            case table_type\n                when 'BASE TABLE' then 'table'\n                when 'EXTERNAL TABLE' then 'external'\n                when 'MATERIALIZED VIEW' then 'materializedview'\n                else lower(table_type)\n            end as \"table_type\"\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.104168}, "macro.dbt_utils.postgres__get_table_types_sql": {"unique_id": "macro.dbt_utils.postgres__get_table_types_sql", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/sql/get_table_types_sql.sql", "original_file_path": "macros/sql/get_table_types_sql.sql", "name": "postgres__get_table_types_sql", "macro_sql": "{% macro postgres__get_table_types_sql() %}\n            case table_type\n                when 'BASE TABLE' then 'table'\n                when 'FOREIGN' then 'external'\n                when 'MATERIALIZED VIEW' then 'materializedview'\n                else lower(table_type)\n            end as \"table_type\"\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.104448}, "macro.dbt_utils.degrees_to_radians": {"unique_id": "macro.dbt_utils.degrees_to_radians", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/sql/haversine_distance.sql", "original_file_path": "macros/sql/haversine_distance.sql", "name": "degrees_to_radians", "macro_sql": "{% macro degrees_to_radians(degrees) -%}\n    acos(-1) * {{degrees}} / 180\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.1069171}, "macro.dbt_utils.haversine_distance": {"unique_id": "macro.dbt_utils.haversine_distance", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/sql/haversine_distance.sql", "original_file_path": "macros/sql/haversine_distance.sql", "name": "haversine_distance", "macro_sql": "{% macro haversine_distance(lat1, lon1, lat2, lon2, unit='mi') -%}\n    {{ return(adapter.dispatch('haversine_distance', 'dbt_utils')(lat1,lon1,lat2,lon2,unit)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.bigquery__haversine_distance"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.107924}, "macro.dbt_utils.default__haversine_distance": {"unique_id": "macro.dbt_utils.default__haversine_distance", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/sql/haversine_distance.sql", "original_file_path": "macros/sql/haversine_distance.sql", "name": "default__haversine_distance", "macro_sql": "{% macro default__haversine_distance(lat1, lon1, lat2, lon2, unit='mi') -%}\n{%- if unit == 'mi' %}\n    {% set conversion_rate = 1 %}\n{% elif unit == 'km' %}\n    {% set conversion_rate = 1.60934 %}\n{% else %}\n    {{ exceptions.raise_compiler_error(\"unit input must be one of 'mi' or 'km'. Got \" ~ unit) }}\n{% endif %}\n\n    2 * 3961 * asin(sqrt(power((sin(radians(({{ lat2 }} - {{ lat1 }}) / 2))), 2) +\n    cos(radians({{lat1}})) * cos(radians({{lat2}})) *\n    power((sin(radians(({{ lon2 }} - {{ lon1 }}) / 2))), 2))) * {{ conversion_rate }}\n\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.109806}, "macro.dbt_utils.bigquery__haversine_distance": {"unique_id": "macro.dbt_utils.bigquery__haversine_distance", "package_name": "dbt_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/dbt_utils", "path": "macros/sql/haversine_distance.sql", "original_file_path": "macros/sql/haversine_distance.sql", "name": "bigquery__haversine_distance", "macro_sql": "{% macro bigquery__haversine_distance(lat1, lon1, lat2, lon2, unit='mi') -%}\n{% set radians_lat1 = dbt_utils.degrees_to_radians(lat1) %}\n{% set radians_lat2 = dbt_utils.degrees_to_radians(lat2) %}\n{% set radians_lon1 = dbt_utils.degrees_to_radians(lon1) %}\n{% set radians_lon2 = dbt_utils.degrees_to_radians(lon2) %}\n{%- if unit == 'mi' %}\n    {% set conversion_rate = 1 %}\n{% elif unit == 'km' %}\n    {% set conversion_rate = 1.60934 %}\n{% else %}\n    {{ exceptions.raise_compiler_error(\"unit input must be one of 'mi' or 'km'. Got \" ~ unit) }}\n{% endif %}\n    2 * 3961 * asin(sqrt(power(sin(({{ radians_lat2 }} - {{ radians_lat1 }}) / 2), 2) +\n    cos({{ radians_lat1 }}) * cos({{ radians_lat2 }}) *\n    power(sin(({{ radians_lon2 }} - {{ radians_lon1 }}) / 2), 2))) * {{ conversion_rate }}\n\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.degrees_to_radians"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.112816}, "macro.fivetran_utils.enabled_vars": {"unique_id": "macro.fivetran_utils.enabled_vars", "package_name": "fivetran_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/fivetran_utils", "path": "macros/enabled_vars.sql", "original_file_path": "macros/enabled_vars.sql", "name": "enabled_vars", "macro_sql": "{% macro enabled_vars(vars) %}\n\n{% for v in vars %}\n    \n    {% if var(v, True) == False %}\n    {{ return(False) }}\n    {% endif %}\n\n{% endfor %}\n\n{{ return(True) }}\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.114936}, "macro.fivetran_utils.percentile": {"unique_id": "macro.fivetran_utils.percentile", "package_name": "fivetran_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/fivetran_utils", "path": "macros/percentile.sql", "original_file_path": "macros/percentile.sql", "name": "percentile", "macro_sql": "{% macro percentile(percentile_field, partition_field, percent) -%}\n\n{{ adapter.dispatch('percentile', 'fivetran_utils') (percentile_field, partition_field, percent) }}\n\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.fivetran_utils.bigquery__percentile"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.117416}, "macro.fivetran_utils.default__percentile": {"unique_id": "macro.fivetran_utils.default__percentile", "package_name": "fivetran_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/fivetran_utils", "path": "macros/percentile.sql", "original_file_path": "macros/percentile.sql", "name": "default__percentile", "macro_sql": "{% macro default__percentile(percentile_field, partition_field, percent)  %}\n\n    percentile_cont( \n        {{ percent }} )\n        within group ( order by {{ percentile_field }} )\n        over ( partition by {{ partition_field }} )\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.117959}, "macro.fivetran_utils.redshift__percentile": {"unique_id": "macro.fivetran_utils.redshift__percentile", "package_name": "fivetran_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/fivetran_utils", "path": "macros/percentile.sql", "original_file_path": "macros/percentile.sql", "name": "redshift__percentile", "macro_sql": "{% macro redshift__percentile(percentile_field, partition_field, percent)  %}\n\n    percentile_cont( \n        {{ percent }} )\n        within group ( order by {{ percentile_field }} )\n        over ( partition by {{ partition_field }} )\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.1185238}, "macro.fivetran_utils.bigquery__percentile": {"unique_id": "macro.fivetran_utils.bigquery__percentile", "package_name": "fivetran_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/fivetran_utils", "path": "macros/percentile.sql", "original_file_path": "macros/percentile.sql", "name": "bigquery__percentile", "macro_sql": "{% macro bigquery__percentile(percentile_field, partition_field, percent)  %}\n\n    percentile_cont( \n        {{ percentile_field }}, \n        {{ percent }}) \n        over (partition by {{ partition_field }}    \n        )\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.11907}, "macro.fivetran_utils.postgres__percentile": {"unique_id": "macro.fivetran_utils.postgres__percentile", "package_name": "fivetran_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/fivetran_utils", "path": "macros/percentile.sql", "original_file_path": "macros/percentile.sql", "name": "postgres__percentile", "macro_sql": "{% macro postgres__percentile(percentile_field, partition_field, percent)  %}\n\n    percentile_cont( \n        {{ percent }} )\n        within group ( order by {{ percentile_field }} )\n    /* have to group by partition field */\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.119526}, "macro.fivetran_utils.spark__percentile": {"unique_id": "macro.fivetran_utils.spark__percentile", "package_name": "fivetran_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/fivetran_utils", "path": "macros/percentile.sql", "original_file_path": "macros/percentile.sql", "name": "spark__percentile", "macro_sql": "{% macro spark__percentile(percentile_field, partition_field, percent)  %}\n\n    percentile( \n        {{ percentile_field }}, \n        {{ percent }}) \n        over (partition by {{ partition_field }}    \n        )\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.120048}, "macro.fivetran_utils.pivot_json_extract": {"unique_id": "macro.fivetran_utils.pivot_json_extract", "package_name": "fivetran_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/fivetran_utils", "path": "macros/pivot_json_extract.sql", "original_file_path": "macros/pivot_json_extract.sql", "name": "pivot_json_extract", "macro_sql": "{% macro pivot_json_extract(string, list_of_properties) %}\n\n{%- for property in list_of_properties -%}\n\nreplace( {{ fivetran_utils.json_extract(string, property) }}, '\"', '') as {{ property | replace(' ', '_') | lower }}\n\n{%- if not loop.last -%},{%- endif %}\n{% endfor -%}\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.fivetran_utils.json_extract"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.1216938}, "macro.fivetran_utils.persist_pass_through_columns": {"unique_id": "macro.fivetran_utils.persist_pass_through_columns", "package_name": "fivetran_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/fivetran_utils", "path": "macros/persist_pass_through_columns.sql", "original_file_path": "macros/persist_pass_through_columns.sql", "name": "persist_pass_through_columns", "macro_sql": "{% macro persist_pass_through_columns(pass_through_variable) %}\n\n{% if var(pass_through_variable, none) %}\n    {% for field in var(pass_through_variable) %}\n        , {{ field.alias if field.alias else field.name }}\n    {% endfor %}\n{% endif %}\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.123088}, "macro.fivetran_utils.json_parse": {"unique_id": "macro.fivetran_utils.json_parse", "package_name": "fivetran_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/fivetran_utils", "path": "macros/json_parse.sql", "original_file_path": "macros/json_parse.sql", "name": "json_parse", "macro_sql": "{% macro json_parse(string, string_path) -%}\n\n{{ adapter.dispatch('json_parse', 'fivetran_utils') (string, string_path) }}\n\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.fivetran_utils.bigquery__json_parse"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.127092}, "macro.fivetran_utils.default__json_parse": {"unique_id": "macro.fivetran_utils.default__json_parse", "package_name": "fivetran_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/fivetran_utils", "path": "macros/json_parse.sql", "original_file_path": "macros/json_parse.sql", "name": "default__json_parse", "macro_sql": "{% macro default__json_parse(string, string_path) %}\n\n  json_extract_path_text({{string}}, {%- for s in string_path -%}'{{ s }}'{%- if not loop.last -%},{%- endif -%}{%- endfor -%} )\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.128136}, "macro.fivetran_utils.redshift__json_parse": {"unique_id": "macro.fivetran_utils.redshift__json_parse", "package_name": "fivetran_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/fivetran_utils", "path": "macros/json_parse.sql", "original_file_path": "macros/json_parse.sql", "name": "redshift__json_parse", "macro_sql": "{% macro redshift__json_parse(string, string_path) %}\n\n  json_extract_path_text({{string}}, {%- for s in string_path -%}'{{ s }}'{%- if not loop.last -%},{%- endif -%}{%- endfor -%} )\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.129088}, "macro.fivetran_utils.bigquery__json_parse": {"unique_id": "macro.fivetran_utils.bigquery__json_parse", "package_name": "fivetran_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/fivetran_utils", "path": "macros/json_parse.sql", "original_file_path": "macros/json_parse.sql", "name": "bigquery__json_parse", "macro_sql": "{% macro bigquery__json_parse(string, string_path) %}\n\n \n  json_extract_scalar({{string}}, '$.{%- for s in string_path -%}{{ s }}{%- if not loop.last -%}.{%- endif -%}{%- endfor -%} ')\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.129858}, "macro.fivetran_utils.postgres__json_parse": {"unique_id": "macro.fivetran_utils.postgres__json_parse", "package_name": "fivetran_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/fivetran_utils", "path": "macros/json_parse.sql", "original_file_path": "macros/json_parse.sql", "name": "postgres__json_parse", "macro_sql": "{% macro postgres__json_parse(string, string_path) %}\n\n  {{string}}::json #>> '{ {%- for s in string_path -%}{{ s }}{%- if not loop.last -%},{%- endif -%}{%- endfor -%} }'\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.130624}, "macro.fivetran_utils.snowflake__json_parse": {"unique_id": "macro.fivetran_utils.snowflake__json_parse", "package_name": "fivetran_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/fivetran_utils", "path": "macros/json_parse.sql", "original_file_path": "macros/json_parse.sql", "name": "snowflake__json_parse", "macro_sql": "{% macro snowflake__json_parse(string, string_path) %}\n\n  parse_json( {{string}} ) {%- for s in string_path -%}{% if s is number %}[{{ s }}]{% else %}['{{ s }}']{% endif %}{%- endfor -%}\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.131936}, "macro.fivetran_utils.spark__json_parse": {"unique_id": "macro.fivetran_utils.spark__json_parse", "package_name": "fivetran_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/fivetran_utils", "path": "macros/json_parse.sql", "original_file_path": "macros/json_parse.sql", "name": "spark__json_parse", "macro_sql": "{% macro spark__json_parse(string, string_path) %}\n\n  {{string}} : {%- for s in string_path -%}{% if s is number %}[{{ s }}]{% else %}['{{ s }}']{% endif %}{%- endfor -%}\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.1330712}, "macro.fivetran_utils.max_bool": {"unique_id": "macro.fivetran_utils.max_bool", "package_name": "fivetran_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/fivetran_utils", "path": "macros/max_bool.sql", "original_file_path": "macros/max_bool.sql", "name": "max_bool", "macro_sql": "{% macro max_bool(boolean_field) -%}\n\n{{ adapter.dispatch('max_bool', 'fivetran_utils') (boolean_field) }}\n\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.fivetran_utils.bigquery__max_bool"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.134253}, "macro.fivetran_utils.default__max_bool": {"unique_id": "macro.fivetran_utils.default__max_bool", "package_name": "fivetran_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/fivetran_utils", "path": "macros/max_bool.sql", "original_file_path": "macros/max_bool.sql", "name": "default__max_bool", "macro_sql": "{% macro default__max_bool(boolean_field)  %}\n\n    bool_or( {{ boolean_field }} )\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.1345952}, "macro.fivetran_utils.snowflake__max_bool": {"unique_id": "macro.fivetran_utils.snowflake__max_bool", "package_name": "fivetran_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/fivetran_utils", "path": "macros/max_bool.sql", "original_file_path": "macros/max_bool.sql", "name": "snowflake__max_bool", "macro_sql": "{% macro snowflake__max_bool(boolean_field)  %}\n\n    max( {{ boolean_field }} )\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.134921}, "macro.fivetran_utils.bigquery__max_bool": {"unique_id": "macro.fivetran_utils.bigquery__max_bool", "package_name": "fivetran_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/fivetran_utils", "path": "macros/max_bool.sql", "original_file_path": "macros/max_bool.sql", "name": "bigquery__max_bool", "macro_sql": "{% macro bigquery__max_bool(boolean_field)  %}\n\n    max( {{ boolean_field }} )\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.135247}, "macro.fivetran_utils.calculated_fields": {"unique_id": "macro.fivetran_utils.calculated_fields", "package_name": "fivetran_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/fivetran_utils", "path": "macros/calculated_fields.sql", "original_file_path": "macros/calculated_fields.sql", "name": "calculated_fields", "macro_sql": "{% macro calculated_fields(variable) -%}\n\n{% if var(variable, none) %}\n    {% for field in var(variable) %}\n        , {{ field.transform_sql }} as {{ field.name }} \n    {% endfor %}\n{% endif %}\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.1366029}, "macro.fivetran_utils.seed_data_helper": {"unique_id": "macro.fivetran_utils.seed_data_helper", "package_name": "fivetran_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/fivetran_utils", "path": "macros/seed_data_helper.sql", "original_file_path": "macros/seed_data_helper.sql", "name": "seed_data_helper", "macro_sql": "{% macro seed_data_helper(seed_name, warehouses) %}\n\n{% if target.type in warehouses %}\n    {% for w in warehouses %}\n        {% if target.type == w %}\n            {{ return(ref(seed_name ~ \"_\" ~ w ~ \"\")) }}\n        {% endif %}\n    {% endfor %}\n{% else %}\n{{ return(ref(seed_name)) }}\n{% endif %}\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.138964}, "macro.fivetran_utils.fill_pass_through_columns": {"unique_id": "macro.fivetran_utils.fill_pass_through_columns", "package_name": "fivetran_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/fivetran_utils", "path": "macros/fill_pass_through_columns.sql", "original_file_path": "macros/fill_pass_through_columns.sql", "name": "fill_pass_through_columns", "macro_sql": "{% macro fill_pass_through_columns(pass_through_variable) %}\n\n{% if var(pass_through_variable) %}\n    {% for field in var(pass_through_variable) %}\n        {% if field.transform_sql %}\n            , {{ field.transform_sql }} as {{ field.alias if field.alias else field.name }}\n        {% else %}\n            , {{ field.alias if field.alias else field.name }}\n        {% endif %}\n    {% endfor %}\n{% endif %}\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.1411898}, "macro.fivetran_utils.string_agg": {"unique_id": "macro.fivetran_utils.string_agg", "package_name": "fivetran_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/fivetran_utils", "path": "macros/string_agg.sql", "original_file_path": "macros/string_agg.sql", "name": "string_agg", "macro_sql": "{% macro string_agg(field_to_agg, delimiter) -%}\n\n{{ adapter.dispatch('string_agg', 'fivetran_utils') (field_to_agg, delimiter) }}\n\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.fivetran_utils.default__string_agg"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.142911}, "macro.fivetran_utils.default__string_agg": {"unique_id": "macro.fivetran_utils.default__string_agg", "package_name": "fivetran_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/fivetran_utils", "path": "macros/string_agg.sql", "original_file_path": "macros/string_agg.sql", "name": "default__string_agg", "macro_sql": "{% macro default__string_agg(field_to_agg, delimiter) %}\n    string_agg({{ field_to_agg }}, {{ delimiter }})\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.1433442}, "macro.fivetran_utils.snowflake__string_agg": {"unique_id": "macro.fivetran_utils.snowflake__string_agg", "package_name": "fivetran_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/fivetran_utils", "path": "macros/string_agg.sql", "original_file_path": "macros/string_agg.sql", "name": "snowflake__string_agg", "macro_sql": "{% macro snowflake__string_agg(field_to_agg, delimiter) %}\n    listagg({{ field_to_agg }}, {{ delimiter }})\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.1438808}, "macro.fivetran_utils.redshift__string_agg": {"unique_id": "macro.fivetran_utils.redshift__string_agg", "package_name": "fivetran_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/fivetran_utils", "path": "macros/string_agg.sql", "original_file_path": "macros/string_agg.sql", "name": "redshift__string_agg", "macro_sql": "{% macro redshift__string_agg(field_to_agg, delimiter) %}\n    listagg({{ field_to_agg }}, {{ delimiter }})\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.144309}, "macro.fivetran_utils.spark__string_agg": {"unique_id": "macro.fivetran_utils.spark__string_agg", "package_name": "fivetran_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/fivetran_utils", "path": "macros/string_agg.sql", "original_file_path": "macros/string_agg.sql", "name": "spark__string_agg", "macro_sql": "{% macro spark__string_agg(field_to_agg, delimiter) %}\n    -- collect set will remove duplicates\n    replace(replace(replace(cast( collect_set({{ field_to_agg }}) as string), '[', ''), ']', ''), ', ', {{ delimiter }} )\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.144734}, "macro.fivetran_utils.timestamp_diff": {"unique_id": "macro.fivetran_utils.timestamp_diff", "package_name": "fivetran_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/fivetran_utils", "path": "macros/timestamp_diff.sql", "original_file_path": "macros/timestamp_diff.sql", "name": "timestamp_diff", "macro_sql": "{% macro timestamp_diff(first_date, second_date, datepart) %}\n  {{ adapter.dispatch('timestamp_diff', 'fivetran_utils')(first_date, second_date, datepart) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.fivetran_utils.bigquery__timestamp_diff"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.150628}, "macro.fivetran_utils.default__timestamp_diff": {"unique_id": "macro.fivetran_utils.default__timestamp_diff", "package_name": "fivetran_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/fivetran_utils", "path": "macros/timestamp_diff.sql", "original_file_path": "macros/timestamp_diff.sql", "name": "default__timestamp_diff", "macro_sql": "{% macro default__timestamp_diff(first_date, second_date, datepart) %}\n\n    datediff(\n        {{ datepart }},\n        {{ first_date }},\n        {{ second_date }}\n        )\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.151167}, "macro.fivetran_utils.redshift__timestamp_diff": {"unique_id": "macro.fivetran_utils.redshift__timestamp_diff", "package_name": "fivetran_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/fivetran_utils", "path": "macros/timestamp_diff.sql", "original_file_path": "macros/timestamp_diff.sql", "name": "redshift__timestamp_diff", "macro_sql": "{% macro redshift__timestamp_diff(first_date, second_date, datepart) %}\n\n    datediff(\n        {{ datepart }},\n        {{ first_date }},\n        {{ second_date }}\n        )\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.152653}, "macro.fivetran_utils.bigquery__timestamp_diff": {"unique_id": "macro.fivetran_utils.bigquery__timestamp_diff", "package_name": "fivetran_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/fivetran_utils", "path": "macros/timestamp_diff.sql", "original_file_path": "macros/timestamp_diff.sql", "name": "bigquery__timestamp_diff", "macro_sql": "{% macro bigquery__timestamp_diff(first_date, second_date, datepart) %}\n\n    timestamp_diff(\n        {{second_date}},\n        {{first_date}},\n        {{datepart}}\n    )\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.153259}, "macro.fivetran_utils.postgres__timestamp_diff": {"unique_id": "macro.fivetran_utils.postgres__timestamp_diff", "package_name": "fivetran_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/fivetran_utils", "path": "macros/timestamp_diff.sql", "original_file_path": "macros/timestamp_diff.sql", "name": "postgres__timestamp_diff", "macro_sql": "{% macro postgres__timestamp_diff(first_date, second_date, datepart) %}\n\n    {% if datepart == 'year' %}\n        (date_part('year', ({{second_date}})::date) - date_part('year', ({{first_date}})::date))\n    {% elif datepart == 'quarter' %}\n        ({{ dbt_utils.datediff(first_date, second_date, 'year') }} * 4 + date_part('quarter', ({{second_date}})::date) - date_part('quarter', ({{first_date}})::date))\n    {% elif datepart == 'month' %}\n        ({{ dbt_utils.datediff(first_date, second_date, 'year') }} * 12 + date_part('month', ({{second_date}})::date) - date_part('month', ({{first_date}})::date))\n    {% elif datepart == 'day' %}\n        (({{second_date}})::date - ({{first_date}})::date)\n    {% elif datepart == 'week' %}\n        ({{ dbt_utils.datediff(first_date, second_date, 'day') }} / 7 + case\n            when date_part('dow', ({{first_date}})::timestamp) <= date_part('dow', ({{second_date}})::timestamp) then\n                case when {{first_date}} <= {{second_date}} then 0 else -1 end\n            else\n                case when {{first_date}} <= {{second_date}} then 1 else 0 end\n        end)\n    {% elif datepart == 'hour' %}\n        ({{ dbt_utils.datediff(first_date, second_date, 'day') }} * 24 + date_part('hour', ({{second_date}})::timestamp) - date_part('hour', ({{first_date}})::timestamp))\n    {% elif datepart == 'minute' %}\n        ({{ dbt_utils.datediff(first_date, second_date, 'hour') }} * 60 + date_part('minute', ({{second_date}})::timestamp) - date_part('minute', ({{first_date}})::timestamp))\n    {% elif datepart == 'second' %}\n        ({{ dbt_utils.datediff(first_date, second_date, 'minute') }} * 60 + floor(date_part('second', ({{second_date}})::timestamp)) - floor(date_part('second', ({{first_date}})::timestamp)))\n    {% elif datepart == 'millisecond' %}\n        ({{ dbt_utils.datediff(first_date, second_date, 'minute') }} * 60000 + floor(date_part('millisecond', ({{second_date}})::timestamp)) - floor(date_part('millisecond', ({{first_date}})::timestamp)))\n    {% elif datepart == 'microsecond' %}\n        ({{ dbt_utils.datediff(first_date, second_date, 'minute') }} * 60000000 + floor(date_part('microsecond', ({{second_date}})::timestamp)) - floor(date_part('microsecond', ({{first_date}})::timestamp)))\n    {% else %}\n        {{ exceptions.raise_compiler_error(\"Unsupported datepart for macro datediff in postgres: {!r}\".format(datepart)) }}\n    {% endif %}\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.datediff"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.1601238}, "macro.fivetran_utils.generate_docs": {"unique_id": "macro.fivetran_utils.generate_docs", "package_name": "fivetran_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/fivetran_utils", "path": "macros/generate_docs.sql", "original_file_path": "macros/generate_docs.sql", "name": "generate_docs", "macro_sql": "{% macro generate_docs(package) %}\n\n{% set package = \"\"~ package ~\"\" %}\n\n{% set zsh_command = \"source dbt_packages/fivetran_utils/generate_docs.sh '../dbt_\"\"\"~ package ~\"\"\"\"+\"'\" %}\n\n{{ log (zsh_command, info=True) }}\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.161612}, "macro.fivetran_utils.generate_columns_macro": {"unique_id": "macro.fivetran_utils.generate_columns_macro", "package_name": "fivetran_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/fivetran_utils", "path": "macros/generate_columns_macro.sql", "original_file_path": "macros/generate_columns_macro.sql", "name": "generate_columns_macro", "macro_sql": "{% macro generate_columns_macro(table_name, schema_name, database_name=target.database) %}\n\n{% set columns = get_columns_for_macro(table_name, schema_name, database_name) %}\n\n{% set jinja_macro=[] %}\n\n{% do jinja_macro.append('{% macro get_' ~ table_name ~ '_columns() %}') %}\n{% do jinja_macro.append('') %}\n{% do jinja_macro.append('{% set columns = [') %}\n\n{% for col in columns %}\n{% do jinja_macro.append('    ' ~ col ~ (',' if not loop.last)) %}\n{% endfor %}\n\n{% do jinja_macro.append('] %}') %}\n{% do jinja_macro.append('') %}\n{% do jinja_macro.append('{{ return(columns) }}') %}\n{% do jinja_macro.append('') %}\n{% do jinja_macro.append('{% endmacro %}') %}\n\n{% if execute %}\n\n    {% set joined = jinja_macro | join ('\\n') %}\n    {{ log(joined, info=True) }}\n    {% do return(joined) %}\n\n{% endif %}\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.fivetran_utils.get_columns_for_macro"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.1661508}, "macro.fivetran_utils.source_relation": {"unique_id": "macro.fivetran_utils.source_relation", "package_name": "fivetran_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/fivetran_utils", "path": "macros/source_relation.sql", "original_file_path": "macros/source_relation.sql", "name": "source_relation", "macro_sql": "{% macro source_relation(union_schema_variable='union_schemas', union_database_variable='union_databases') -%}\n\n{{ adapter.dispatch('source_relation', 'fivetran_utils') (union_schema_variable, union_database_variable) }}\n\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.fivetran_utils.default__source_relation"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.167638}, "macro.fivetran_utils.default__source_relation": {"unique_id": "macro.fivetran_utils.default__source_relation", "package_name": "fivetran_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/fivetran_utils", "path": "macros/source_relation.sql", "original_file_path": "macros/source_relation.sql", "name": "default__source_relation", "macro_sql": "{% macro default__source_relation(union_schema_variable, union_database_variable) %}\n\n{% if var(union_schema_variable, none)  %}\n, case\n    {% for schema in var(union_schema_variable) %}\n    when lower(replace(replace(_dbt_source_relation,'\"',''),'`','')) like '%.{{ schema|lower }}.%' then '{{ schema|lower }}'\n    {% endfor %}\n  end as source_relation\n{% elif var(union_database_variable, none) %}\n, case\n    {% for database in var(union_database_variable) %}\n    when lower(replace(replace(_dbt_source_relation,'\"',''),'`','')) like '%{{ database|lower }}.%' then '{{ database|lower }}'\n    {% endfor %}\n  end as source_relation\n{% else %}\n, cast('' as {{ dbt_utils.type_string() }}) as source_relation\n{% endif %}\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.type_string"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.169434}, "macro.fivetran_utils.first_value": {"unique_id": "macro.fivetran_utils.first_value", "package_name": "fivetran_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/fivetran_utils", "path": "macros/first_value.sql", "original_file_path": "macros/first_value.sql", "name": "first_value", "macro_sql": "{% macro first_value(first_value_field, partition_field, order_by_field, order=\"asc\") -%}\n\n{{ adapter.dispatch('first_value', 'fivetran_utils') (first_value_field, partition_field, order_by_field, order) }}\n\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.fivetran_utils.default__first_value"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.170916}, "macro.fivetran_utils.default__first_value": {"unique_id": "macro.fivetran_utils.default__first_value", "package_name": "fivetran_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/fivetran_utils", "path": "macros/first_value.sql", "original_file_path": "macros/first_value.sql", "name": "default__first_value", "macro_sql": "{% macro default__first_value(first_value_field, partition_field, order_by_field, order=\"asc\")  %}\n\n    first_value( {{ first_value_field }} ignore nulls ) over (partition by {{ partition_field }} order by {{ order_by_field }} {{ order }} )\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.171555}, "macro.fivetran_utils.redshift__first_value": {"unique_id": "macro.fivetran_utils.redshift__first_value", "package_name": "fivetran_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/fivetran_utils", "path": "macros/first_value.sql", "original_file_path": "macros/first_value.sql", "name": "redshift__first_value", "macro_sql": "{% macro redshift__first_value(first_value_field, partition_field, order_by_field, order=\"asc\") %}\n\n    first_value( {{ first_value_field }} ignore nulls ) over (partition by {{ partition_field }} order by {{ order_by_field }} {{ order }} , {{ partition_field }} rows unbounded preceding )\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.172251}, "macro.fivetran_utils.add_dbt_source_relation": {"unique_id": "macro.fivetran_utils.add_dbt_source_relation", "package_name": "fivetran_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/fivetran_utils", "path": "macros/add_dbt_source_relation.sql", "original_file_path": "macros/add_dbt_source_relation.sql", "name": "add_dbt_source_relation", "macro_sql": "{% macro add_dbt_source_relation() %}\n\n{% if var('union_schemas', none) or var('union_databases', none) %}\n, _dbt_source_relation\n{% endif %}\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.173242}, "macro.fivetran_utils.add_pass_through_columns": {"unique_id": "macro.fivetran_utils.add_pass_through_columns", "package_name": "fivetran_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/fivetran_utils", "path": "macros/add_pass_through_columns.sql", "original_file_path": "macros/add_pass_through_columns.sql", "name": "add_pass_through_columns", "macro_sql": "{% macro add_pass_through_columns(base_columns, pass_through_var) %}\n\n  {% if pass_through_var %}\n\n    {% for column in pass_through_var %}\n\n      {% if column.alias %}\n\n      {% do base_columns.append({ \"name\": column.name, \"alias\": column.alias, \"datatype\": column.datatype if column.datatype else dbt_utils.type_string()}) %}\n\n      {% else %}\n\n      {% do base_columns.append({ \"name\": column.name, \"datatype\": column.datatype if column.datatype else dbt_utils.type_string()}) %}\n        \n      {% endif %}\n\n    {% endfor %}\n\n  {% endif %}\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.type_string"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.176054}, "macro.fivetran_utils.staging_models_automation": {"unique_id": "macro.fivetran_utils.staging_models_automation", "package_name": "fivetran_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/fivetran_utils", "path": "macros/staging_models_automation.sql", "original_file_path": "macros/staging_models_automation.sql", "name": "staging_models_automation", "macro_sql": "{% macro staging_models_automation(package, source_schema, source_database, tables) %}\n\n{% set package = \"\"~ package ~\"\" %}\n{% set source_schema = \"\"~ source_schema ~\"\" %}\n{% set source_database = \"\"~ source_database ~\"\" %}\n\n{% set zsh_command_columns = \"source dbt_packages/fivetran_utils/generate_columns.sh '../dbt_\"\"\"~ package ~\"\"\"_source' stg_\"\"\"~ package ~\"\"\" \"\"\"~ source_database ~\"\"\" \"\"\"~ source_schema ~\"\"\" \" %}\n{% set zsh_command_models = \"source dbt_packages/fivetran_utils/generate_models.sh '../dbt_\"\"\"~ package ~\"\"\"_source' stg_\"\"\"~ package ~\"\"\" \"\"\"~ source_database ~\"\"\" \"\"\"~ source_schema ~\"\"\" \" %}\n\n{%- set columns_array = [] -%}\n{%- set models_array = [] -%}\n\n{% for t in tables %}\n    {% set help_command = zsh_command_columns + t %}\n    {{ columns_array.append(help_command) }}\n\n    {% set help_command = zsh_command_models + t %}\n    {{ models_array.append(help_command) }}\n\n{% endfor %}\n\n{{ log(columns_array|join(' && \\n') + ' && \\n' + models_array|join(' && \\n'), info=True) }}\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.180586}, "macro.fivetran_utils.union_relations": {"unique_id": "macro.fivetran_utils.union_relations", "package_name": "fivetran_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/fivetran_utils", "path": "macros/union_relations.sql", "original_file_path": "macros/union_relations.sql", "name": "union_relations", "macro_sql": "{%- macro union_relations(relations, aliases=none, column_override=none, include=[], exclude=[], source_column_name=none) -%}\n\n    {%- if exclude and include -%}\n        {{ exceptions.raise_compiler_error(\"Both an exclude and include list were provided to the `union` macro. Only one is allowed\") }}\n    {%- endif -%}\n\n    {#-- Prevent querying of db in parsing mode. This works because this macro does not create any new refs. -#}\n    {%- if not execute %}\n        {{ return('') }}\n    {% endif -%}\n\n    {%- set column_override = column_override if column_override is not none else {} -%}\n    {%- set source_column_name = source_column_name if source_column_name is not none else '_dbt_source_relation' -%}\n\n    {%- set relation_columns = {} -%}\n    {%- set column_superset = {} -%}\n\n    {%- for relation in relations -%}\n\n        {%- do relation_columns.update({relation: []}) -%}\n\n        {%- do dbt_utils._is_relation(relation, 'union_relations') -%}\n        {%- set cols = adapter.get_columns_in_relation(relation) -%}\n        {%- for col in cols -%}\n\n        {#- If an exclude list was provided and the column is in the list, do nothing -#}\n        {%- if exclude and col.column in exclude -%}\n\n        {#- If an include list was provided and the column is not in the list, do nothing -#}\n        {%- elif include and col.column not in include -%}\n\n        {#- Otherwise add the column to the column superset -#}\n        {%- else -%}\n\n            {#- update the list of columns in this relation -#}\n            {%- do relation_columns[relation].append(col.column) -%}\n\n            {%- if col.column in column_superset -%}\n\n                {%- set stored = column_superset[col.column] -%}\n                {%- if col.is_string() and stored.is_string() and col.string_size() > stored.string_size() -%}\n\n                    {%- do column_superset.update({col.column: col}) -%}\n\n                {%- endif %}\n\n            {%- else -%}\n\n                {%- do column_superset.update({col.column: col}) -%}\n\n            {%- endif -%}\n\n        {%- endif -%}\n\n        {%- endfor -%}\n    {%- endfor -%}\n\n    {%- set ordered_column_names = column_superset.keys() -%}\n\n    {%- for relation in relations %}\n\n        (\n            select\n\n                cast({{ dbt_utils.string_literal(relation) }} as {{ dbt_utils.type_string() }}) as {{ source_column_name }},\n                {% for col_name in ordered_column_names -%}\n\n                    {%- set col = column_superset[col_name] %}\n                    {%- set col_type = column_override.get(col.column, col.data_type) %}\n                    {%- set col_name = adapter.quote(col_name) if col_name in relation_columns[relation] else 'null' %}\n                    cast({{ col_name }} as {{ col_type }}) as {{ col.quoted }} {% if not loop.last %},{% endif -%}\n\n                {%- endfor %}\n\n            from {{ aliases[loop.index0] if aliases else relation }}\n        )\n\n        {% if not loop.last -%}\n            union all\n        {% endif -%}\n\n    {%- endfor -%}\n\n{%- endmacro -%}\n\n", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils._is_relation", "macro.dbt_utils.string_literal", "macro.dbt_utils.type_string"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.1921139}, "macro.fivetran_utils.union_tables": {"unique_id": "macro.fivetran_utils.union_tables", "package_name": "fivetran_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/fivetran_utils", "path": "macros/union_relations.sql", "original_file_path": "macros/union_relations.sql", "name": "union_tables", "macro_sql": "{%- macro union_tables(tables, column_override=none, include=[], exclude=[], source_column_name='_dbt_source_table') -%}\n\n    {%- do exceptions.warn(\"Warning: the `union_tables` macro is no longer supported and will be deprecated in a future release of dbt-utils. Use the `union_relations` macro instead\") -%}\n\n    {{ return(dbt_utils.union_relations(tables, column_override, include, exclude, source_column_name)) }}\n\n{%- endmacro -%}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.union_relations"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.193275}, "macro.fivetran_utils.snowflake_seed_data": {"unique_id": "macro.fivetran_utils.snowflake_seed_data", "package_name": "fivetran_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/fivetran_utils", "path": "macros/snowflake_seed_data.sql", "original_file_path": "macros/snowflake_seed_data.sql", "name": "snowflake_seed_data", "macro_sql": "{% macro snowflake_seed_data(seed_name) %}\n\n{% if target.type == 'snowflake' %}\n{{ return(ref(seed_name ~ '_snowflake')) }}\n{% else %}\n{{ return(ref(seed_name)) }}\n{% endif %}\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.1948328}, "macro.fivetran_utils.default__get_columns_for_macro": {"unique_id": "macro.fivetran_utils.default__get_columns_for_macro", "package_name": "fivetran_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/fivetran_utils", "path": "macros/get_columns_for_macro.sql", "original_file_path": "macros/get_columns_for_macro.sql", "name": "default__get_columns_for_macro", "macro_sql": "{% macro default__get_columns_for_macro(table_name, schema_name, database_name=target.database) %}\n\n{% set query %}\n\nselect\n    concat(\n      '{\"name\": \"', \n      lower(column_name), \n      '\", \"datatype\": ',\n      case\n        when lower(data_type) like '%timestamp%' then 'dbt_utils.type_timestamp()' \n        when lower(data_type) = 'text' then 'dbt_utils.type_string()' \n        when lower(data_type) = 'boolean' then '\"boolean\"'\n        when lower(data_type) like '%num%' then 'dbt_utils.type_numeric()' \n        when lower(data_type) = 'float' then 'dbt_utils.type_float()' \n        when lower(data_type) = 'date' then '\"date\"'\n      end,\n      '}')\nfrom {{ database_name }}.information_schema.columns\nwhere lower(table_name) = '{{ table_name }}'\nand lower(table_schema) = '{{ schema_name }}'\norder by 1\n\n{% endset %}\n\n{% set results = run_query(query) %}\n{% set results_list = results.columns[0].values() %}}\n\n{{ return(results_list) }}\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.run_query"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.197587}, "macro.fivetran_utils.bigquery__get_columns_for_macro": {"unique_id": "macro.fivetran_utils.bigquery__get_columns_for_macro", "package_name": "fivetran_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/fivetran_utils", "path": "macros/get_columns_for_macro.sql", "original_file_path": "macros/get_columns_for_macro.sql", "name": "bigquery__get_columns_for_macro", "macro_sql": "{% macro bigquery__get_columns_for_macro(table_name, schema_name, database_name=target.database) %}\n\n{% set query %}\n\nselect\n    concat(\n      '{\"name\": \"', \n      lower(column_name), \n      '\", \"datatype\": ',\n      case\n        when lower(data_type) like '%timestamp%' then 'dbt_utils.type_timestamp()' \n        when lower(data_type) = 'string' then 'dbt_utils.type_string()' \n        when lower(data_type) = 'bool' then '\"boolean\"'\n        when lower(data_type) like '%num%' then 'dbt_utils.type_numeric()' \n        when lower(data_type) = 'float64' then 'dbt_utils.type_float()' \n        when lower(data_type) = 'int64' then 'dbt_utils.type_int()' \n        when lower(data_type) = 'date' then '\"date\"' \n        when lower(data_type) = 'datetime' then '\"datetime\"' \n      end,\n      '}')\nfrom `{{ database_name }}`.{{ schema_name }}.INFORMATION_SCHEMA.COLUMNS\nwhere lower(table_name) = '{{ table_name }}'\nand lower(table_schema) = '{{ schema_name }}'\norder by 1\n\n{% endset %}\n\n{% set results = run_query(query) %}\n{% set results_list = results.columns[0].values() %}}\n\n{{ return(results_list) }}\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.run_query"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.1990001}, "macro.fivetran_utils.get_columns_for_macro": {"unique_id": "macro.fivetran_utils.get_columns_for_macro", "package_name": "fivetran_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/fivetran_utils", "path": "macros/get_columns_for_macro.sql", "original_file_path": "macros/get_columns_for_macro.sql", "name": "get_columns_for_macro", "macro_sql": "{% macro get_columns_for_macro(table_name, schema_name, database_name) -%}\n  {{ return(adapter.dispatch('get_columns_for_macro')(table_name, schema_name, database_name)) }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.fivetran_utils.bigquery__get_columns_for_macro"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.199657}, "macro.fivetran_utils.fill_staging_columns": {"unique_id": "macro.fivetran_utils.fill_staging_columns", "package_name": "fivetran_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/fivetran_utils", "path": "macros/fill_staging_columns.sql", "original_file_path": "macros/fill_staging_columns.sql", "name": "fill_staging_columns", "macro_sql": "{% macro fill_staging_columns(source_columns, staging_columns) -%}\n\n{%- set source_column_names = source_columns|map(attribute='name')|map('lower')|list -%}\n\n{%- for column in staging_columns %}\n    {% if column.name|lower in source_column_names -%}\n        {{ fivetran_utils.quote_column(column) }} as \n        {%- if 'alias' in column %} {{ column.alias }} {% else %} {{ fivetran_utils.quote_column(column) }} {%- endif -%}\n    {%- else -%}\n        cast(null as {{ column.datatype }})\n        {%- if 'alias' in column %} as {{ column.alias }} {% else %} as {{ fivetran_utils.quote_column(column) }} {% endif -%}\n    {%- endif -%}\n    {%- if not loop.last -%} , {% endif -%}\n{% endfor %}\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.fivetran_utils.quote_column"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.2037601}, "macro.fivetran_utils.quote_column": {"unique_id": "macro.fivetran_utils.quote_column", "package_name": "fivetran_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/fivetran_utils", "path": "macros/fill_staging_columns.sql", "original_file_path": "macros/fill_staging_columns.sql", "name": "quote_column", "macro_sql": "{% macro quote_column(column) %}\n    {% if 'quote' in column %}\n        {% if column.quote %}\n            {% if target.type in ('bigquery', 'spark') %}\n            `{{ column.name }}`\n            {% elif target.type == 'snowflake' %}\n            \"{{ column.name | upper }}\"\n            {% else %}\n            \"{{ column.name }}\"\n            {% endif %}\n        {% else %}\n        {{ column.name }}\n        {% endif %}\n    {% else %}\n    {{ column.name }}\n    {% endif %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.205489}, "macro.fivetran_utils.json_extract": {"unique_id": "macro.fivetran_utils.json_extract", "package_name": "fivetran_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/fivetran_utils", "path": "macros/json_extract.sql", "original_file_path": "macros/json_extract.sql", "name": "json_extract", "macro_sql": "{% macro json_extract(string, string_path) -%}\n\n{{ adapter.dispatch('json_extract', 'fivetran_utils') (string, string_path) }}\n\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.fivetran_utils.bigquery__json_extract"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.2070742}, "macro.fivetran_utils.default__json_extract": {"unique_id": "macro.fivetran_utils.default__json_extract", "package_name": "fivetran_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/fivetran_utils", "path": "macros/json_extract.sql", "original_file_path": "macros/json_extract.sql", "name": "default__json_extract", "macro_sql": "{% macro default__json_extract(string, string_path) %}\n\n  json_extract_path_text({{string}}, {{ \"'\" ~ string_path ~ \"'\" }} )\n \n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.207564}, "macro.fivetran_utils.snowflake__json_extract": {"unique_id": "macro.fivetran_utils.snowflake__json_extract", "package_name": "fivetran_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/fivetran_utils", "path": "macros/json_extract.sql", "original_file_path": "macros/json_extract.sql", "name": "snowflake__json_extract", "macro_sql": "{% macro snowflake__json_extract(string, string_path) %}\n\n  json_extract_path_text(try_parse_json( {{string}} ), {{ \"'\" ~ string_path ~ \"'\" }} )\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.2080488}, "macro.fivetran_utils.redshift__json_extract": {"unique_id": "macro.fivetran_utils.redshift__json_extract", "package_name": "fivetran_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/fivetran_utils", "path": "macros/json_extract.sql", "original_file_path": "macros/json_extract.sql", "name": "redshift__json_extract", "macro_sql": "{% macro redshift__json_extract(string, string_path) %}\n\n  case when is_valid_json( {{string}} ) then json_extract_path_text({{string}}, {{ \"'\" ~ string_path ~ \"'\" }} ) else null end\n \n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.20859}, "macro.fivetran_utils.bigquery__json_extract": {"unique_id": "macro.fivetran_utils.bigquery__json_extract", "package_name": "fivetran_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/fivetran_utils", "path": "macros/json_extract.sql", "original_file_path": "macros/json_extract.sql", "name": "bigquery__json_extract", "macro_sql": "{% macro bigquery__json_extract(string, string_path) %}\n\n  json_extract_scalar({{string}}, {{ \"'$.\" ~ string_path ~ \"'\" }} )\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.2090821}, "macro.fivetran_utils.postgres__json_extract": {"unique_id": "macro.fivetran_utils.postgres__json_extract", "package_name": "fivetran_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/fivetran_utils", "path": "macros/json_extract.sql", "original_file_path": "macros/json_extract.sql", "name": "postgres__json_extract", "macro_sql": "{% macro postgres__json_extract(string, string_path) %}\n\n  {{string}}::json->>{{\"'\" ~ string_path ~ \"'\" }}\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.209565}, "macro.fivetran_utils.collect_freshness": {"unique_id": "macro.fivetran_utils.collect_freshness", "package_name": "fivetran_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/fivetran_utils", "path": "macros/collect_freshness.sql", "original_file_path": "macros/collect_freshness.sql", "name": "collect_freshness", "macro_sql": "{% macro collect_freshness(source, loaded_at_field, filter) %}\n  {{ return(adapter.dispatch('collect_freshness')(source, loaded_at_field, filter))}}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.fivetran_utils.default__collect_freshness"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.211371}, "macro.fivetran_utils.default__collect_freshness": {"unique_id": "macro.fivetran_utils.default__collect_freshness", "package_name": "fivetran_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/fivetran_utils", "path": "macros/collect_freshness.sql", "original_file_path": "macros/collect_freshness.sql", "name": "default__collect_freshness", "macro_sql": "{% macro default__collect_freshness(source, loaded_at_field, filter) %}\n  {% call statement('collect_freshness', fetch_result=True, auto_begin=False) -%}\n\n  {%- set enabled_array = [] -%}\n  {% for node in graph.sources.values() %}\n    {% if node.identifier == source.identifier %}\n      {% if (node.meta['is_enabled'] | default(true)) %}\n        {%- do enabled_array.append(1) -%}\n      {% endif %}\n    {% endif %}\n  {% endfor %}\n  {% set is_enabled = (enabled_array != []) %}\n\n    select\n      {% if is_enabled %}\n      max({{ loaded_at_field }})\n      {% else %} \n      {{ current_timestamp() }} {% endif %} as max_loaded_at,\n      {{ current_timestamp() }} as snapshotted_at\n\n    {% if is_enabled %}\n    from {{ source }}\n      {% if filter %}\n      where {{ filter }}\n      {% endif %}\n    {% endif %}\n\n  {% endcall %}\n  {{ return(load_result('collect_freshness').table) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.statement", "macro.dbt_utils.current_timestamp"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.2143989}, "macro.fivetran_utils.timestamp_add": {"unique_id": "macro.fivetran_utils.timestamp_add", "package_name": "fivetran_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/fivetran_utils", "path": "macros/timestamp_add.sql", "original_file_path": "macros/timestamp_add.sql", "name": "timestamp_add", "macro_sql": "{% macro timestamp_add(datepart, interval, from_timestamp) -%}\n\n{{ adapter.dispatch('timestamp_add', 'fivetran_utils') (datepart, interval, from_timestamp) }}\n\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.fivetran_utils.bigquery__timestamp_add"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.216141}, "macro.fivetran_utils.default__timestamp_add": {"unique_id": "macro.fivetran_utils.default__timestamp_add", "package_name": "fivetran_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/fivetran_utils", "path": "macros/timestamp_add.sql", "original_file_path": "macros/timestamp_add.sql", "name": "default__timestamp_add", "macro_sql": "{% macro default__timestamp_add(datepart, interval, from_timestamp) %}\n\n    timestampadd(\n        {{ datepart }},\n        {{ interval }},\n        {{ from_timestamp }}\n        )\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.216651}, "macro.fivetran_utils.bigquery__timestamp_add": {"unique_id": "macro.fivetran_utils.bigquery__timestamp_add", "package_name": "fivetran_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/fivetran_utils", "path": "macros/timestamp_add.sql", "original_file_path": "macros/timestamp_add.sql", "name": "bigquery__timestamp_add", "macro_sql": "{% macro bigquery__timestamp_add(datepart, interval, from_timestamp) %}\n\n        timestamp_add({{ from_timestamp }}, interval  {{ interval }} {{ datepart }})\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.2171571}, "macro.fivetran_utils.redshift__timestamp_add": {"unique_id": "macro.fivetran_utils.redshift__timestamp_add", "package_name": "fivetran_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/fivetran_utils", "path": "macros/timestamp_add.sql", "original_file_path": "macros/timestamp_add.sql", "name": "redshift__timestamp_add", "macro_sql": "{% macro redshift__timestamp_add(datepart, interval, from_timestamp) %}\n\n        dateadd(\n        {{ datepart }},\n        {{ interval }},\n        {{ from_timestamp }}\n        )\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.217664}, "macro.fivetran_utils.postgres__timestamp_add": {"unique_id": "macro.fivetran_utils.postgres__timestamp_add", "package_name": "fivetran_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/fivetran_utils", "path": "macros/timestamp_add.sql", "original_file_path": "macros/timestamp_add.sql", "name": "postgres__timestamp_add", "macro_sql": "{% macro postgres__timestamp_add(datepart, interval, from_timestamp) %}\n\n    {{ from_timestamp }} + ((interval '1 {{ datepart }}') * ({{ interval }}))\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.218167}, "macro.fivetran_utils.spark__timestamp_add": {"unique_id": "macro.fivetran_utils.spark__timestamp_add", "package_name": "fivetran_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/fivetran_utils", "path": "macros/timestamp_add.sql", "original_file_path": "macros/timestamp_add.sql", "name": "spark__timestamp_add", "macro_sql": "{% macro spark__timestamp_add(datepart, interval, from_timestamp) %}\n\n    {{ dbt_utils.dateadd(datepart, interval, from_timestamp) }}\n        \n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.dateadd"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.218713}, "macro.fivetran_utils.ceiling": {"unique_id": "macro.fivetran_utils.ceiling", "package_name": "fivetran_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/fivetran_utils", "path": "macros/ceiling.sql", "original_file_path": "macros/ceiling.sql", "name": "ceiling", "macro_sql": "{% macro ceiling(num) -%}\n\n{{ adapter.dispatch('ceiling', 'fivetran_utils') (num) }}\n\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.fivetran_utils.default__ceiling"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.219624}, "macro.fivetran_utils.default__ceiling": {"unique_id": "macro.fivetran_utils.default__ceiling", "package_name": "fivetran_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/fivetran_utils", "path": "macros/ceiling.sql", "original_file_path": "macros/ceiling.sql", "name": "default__ceiling", "macro_sql": "{% macro default__ceiling(num) %}\n    ceiling({{ num }})\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.2199419}, "macro.fivetran_utils.snowflake__ceiling": {"unique_id": "macro.fivetran_utils.snowflake__ceiling", "package_name": "fivetran_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/fivetran_utils", "path": "macros/ceiling.sql", "original_file_path": "macros/ceiling.sql", "name": "snowflake__ceiling", "macro_sql": "{% macro snowflake__ceiling(num) %}\n    ceil({{ num }})\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.2204149}, "macro.fivetran_utils.remove_prefix_from_columns": {"unique_id": "macro.fivetran_utils.remove_prefix_from_columns", "package_name": "fivetran_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/fivetran_utils", "path": "macros/remove_prefix_from_columns.sql", "original_file_path": "macros/remove_prefix_from_columns.sql", "name": "remove_prefix_from_columns", "macro_sql": "{% macro remove_prefix_from_columns(columns, prefix='', exclude=[]) %}\n\n        {%- for col in columns if col.name not in exclude -%}\n        {%- if col.name[:prefix|length]|lower == prefix -%}\n        {{ col.name }} as {{ col.name[prefix|length:] }}\n        {%- else -%}\n        {{ col.name }}\n        {%- endif -%}\n        {%- if not loop.last -%},{%- endif %}\n        {% endfor -%}\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.222482}, "macro.fivetran_utils.union_data": {"unique_id": "macro.fivetran_utils.union_data", "package_name": "fivetran_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/fivetran_utils", "path": "macros/union_data.sql", "original_file_path": "macros/union_data.sql", "name": "union_data", "macro_sql": "{% macro union_data(table_identifier, database_variable, schema_variable, default_database, default_schema, default_variable, union_schema_variable='union_schemas', union_database_variable='union_databases') -%}\n\n{{ adapter.dispatch('union_data', 'fivetran_utils') (\n    table_identifier, \n    database_variable, \n    schema_variable, \n    default_database, \n    default_schema, \n    default_variable,\n    union_schema_variable,\n    union_database_variable\n    ) }}\n\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.fivetran_utils.default__union_data"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.2253802}, "macro.fivetran_utils.default__union_data": {"unique_id": "macro.fivetran_utils.default__union_data", "package_name": "fivetran_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/fivetran_utils", "path": "macros/union_data.sql", "original_file_path": "macros/union_data.sql", "name": "default__union_data", "macro_sql": "{% macro default__union_data(\n    table_identifier, \n    database_variable, \n    schema_variable, \n    default_database, \n    default_schema, \n    default_variable,\n    union_schema_variable,\n    union_database_variable\n    ) %}\n\n{% if var(union_schema_variable, none) %}\n\n    {% set relations = [] %}\n    \n    {% if var(union_schema_variable) is string %}\n    {% set trimmed = var(union_schema_variable)|trim('[')|trim(']') %}\n    {% set schemas = trimmed.split(',')|map('trim',\" \")|map('trim','\"')|map('trim',\"'\") %}\n    {% else %}\n    {% set schemas = var(union_schema_variable) %}\n    {% endif %}\n\n    {% for schema in var(union_schema_variable) %}\n\n    {% set relation=adapter.get_relation(\n        database=var(database_variable, default_database),\n        schema=schema,\n        identifier=table_identifier\n    ) -%}\n    \n    {% set relation_exists=relation is not none %}\n\n    {% if relation_exists %}\n\n    {% do relations.append(relation) %}\n    \n    {% endif %}\n\n    {% endfor %}\n\n    {{ dbt_utils.union_relations(relations) }}\n\n{% elif var(union_database_variable, none) %}\n\n    {% set relations = [] %}\n\n    {% for database in var(union_database_variable) %}\n\n    {% set relation=adapter.get_relation(\n        database=database,\n        schema=var(schema_variable, default_schema),\n        identifier=table_identifier\n    ) -%}\n\n    {% set relation_exists=relation is not none %}\n\n    {% if relation_exists %}\n\n    {% do relations.append(relation) %}\n    \n    {% endif %}\n\n    {% endfor %}\n\n    {{ dbt_utils.union_relations(relations) }}\n\n{% else %}\n\n    select * \n    from {{ var(default_variable) }}\n\n{% endif %}\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.union_relations"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.230687}, "macro.fivetran_utils.dummy_coalesce_value": {"unique_id": "macro.fivetran_utils.dummy_coalesce_value", "package_name": "fivetran_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/fivetran_utils", "path": "macros/dummy_coalesce_value.sql", "original_file_path": "macros/dummy_coalesce_value.sql", "name": "dummy_coalesce_value", "macro_sql": "{% macro dummy_coalesce_value(column) %}\n\n{% set coalesce_value = {\n 'STRING': \"'DUMMY_STRING'\",\n 'BOOLEAN': 'null',\n 'INT': 999999999,\n 'FLOAT': 999999999.99,\n 'TIMESTAMP': 'cast(\"2099-12-31\" as timestamp)',\n 'DATE': 'cast(\"2099-12-31\" as date)',\n} %}\n\n{% if column.is_float() %}\n{{ return(coalesce_value['FLOAT']) }}\n\n{% elif column.is_numeric() %}\n{{ return(coalesce_value['INT']) }}\n\n{% elif column.is_string() %}\n{{ return(coalesce_value['STRING']) }}\n\n{% elif column.data_type|lower == 'boolean' %}\n{{ return(coalesce_value['BOOLEAN']) }}\n\n{% elif 'timestamp' in column.data_type|lower %}\n{{ return(coalesce_value['TIMESTAMP']) }}\n\n{% elif 'date' in column.data_type|lower %}\n{{ return(coalesce_value['DATE']) }}\n\n{% elif 'int' in column.data_type|lower %}\n{{ return(coalesce_value['INT']) }}\n\n{% endif %}\n\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.234882}, "macro.fivetran_utils.array_agg": {"unique_id": "macro.fivetran_utils.array_agg", "package_name": "fivetran_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/fivetran_utils", "path": "macros/array_agg.sql", "original_file_path": "macros/array_agg.sql", "name": "array_agg", "macro_sql": "{% macro array_agg(field_to_agg) -%}\n\n{{ adapter.dispatch('array_agg', 'fivetran_utils') (field_to_agg) }}\n\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.fivetran_utils.default__array_agg"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.235786}, "macro.fivetran_utils.default__array_agg": {"unique_id": "macro.fivetran_utils.default__array_agg", "package_name": "fivetran_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/fivetran_utils", "path": "macros/array_agg.sql", "original_file_path": "macros/array_agg.sql", "name": "default__array_agg", "macro_sql": "{% macro default__array_agg(field_to_agg) %}\n    array_agg({{ field_to_agg }})\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.2361019}, "macro.fivetran_utils.redshift__array_agg": {"unique_id": "macro.fivetran_utils.redshift__array_agg", "package_name": "fivetran_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/fivetran_utils", "path": "macros/array_agg.sql", "original_file_path": "macros/array_agg.sql", "name": "redshift__array_agg", "macro_sql": "{% macro redshift__array_agg(field_to_agg) %}\n    listagg({{ field_to_agg }}, ',')\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.2364092}, "macro.fivetran_utils.empty_variable_warning": {"unique_id": "macro.fivetran_utils.empty_variable_warning", "package_name": "fivetran_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/fivetran_utils", "path": "macros/empty_variable_warning.sql", "original_file_path": "macros/empty_variable_warning.sql", "name": "empty_variable_warning", "macro_sql": "{% macro empty_variable_warning(variable, downstream_model) %}\n\n{% if not var(variable) %}\n{{ log(\n    \"\"\"\n    Warning: You have passed an empty list to the \"\"\" ~ variable ~ \"\"\".\n    As a result, you won't see the history of any columns in the \"\"\" ~ downstream_model ~ \"\"\" model.\n    \"\"\",\n    info=True\n) }}\n{% endif %}\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.237689}, "macro.fivetran_utils.enabled_vars_one_true": {"unique_id": "macro.fivetran_utils.enabled_vars_one_true", "package_name": "fivetran_utils", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/fivetran_utils", "path": "macros/enabled_vars_one_true.sql", "original_file_path": "macros/enabled_vars_one_true.sql", "name": "enabled_vars_one_true", "macro_sql": "{% macro enabled_vars_one_true(vars) %}\n\n{% for v in vars %}\n    \n    {% if var(v, False) == True %}\n    {{ return(True) }}\n    {% endif %}\n\n{% endfor %}\n\n{{ return(False) }}\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.2390022}, "macro.zendesk_source.get_domain_name_columns": {"unique_id": "macro.zendesk_source.get_domain_name_columns", "package_name": "zendesk_source", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/zendesk_source", "path": "macros/get_domain_name_columns.sql", "original_file_path": "macros/get_domain_name_columns.sql", "name": "get_domain_name_columns", "macro_sql": "{% macro get_domain_name_columns() %}\n\n{% set columns = [\n    {\"name\": \"_fivetran_synced\", \"datatype\": dbt_utils.type_timestamp()},\n    {\"name\": \"domain_name\", \"datatype\": dbt_utils.type_string()},\n    {\"name\": \"index\", \"datatype\": dbt_utils.type_int()},\n    {\"name\": \"organization_id\", \"datatype\": dbt_utils.type_int()}\n] %}\n\n{{ return(columns) }}\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.type_timestamp", "macro.dbt_utils.type_string", "macro.dbt_utils.type_int"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.240816}, "macro.zendesk_source.get_user_tag_columns": {"unique_id": "macro.zendesk_source.get_user_tag_columns", "package_name": "zendesk_source", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/zendesk_source", "path": "macros/get_user_tag_columns.sql", "original_file_path": "macros/get_user_tag_columns.sql", "name": "get_user_tag_columns", "macro_sql": "{% macro get_user_tag_columns() %}\n\n{% set columns = [\n    {\"name\": \"_fivetran_synced\", \"datatype\": dbt_utils.type_timestamp()},\n    {\"name\": \"user_id\", \"datatype\": dbt_utils.type_int()}\n] %}\n\n{% if target.type == 'redshift' %}\n    {{ columns.append( {\"name\": \"tag\", \"datatype\": dbt_utils.type_string(), \"quote\": True } ) }}\n\n{% elif target.type == 'snowflake' %}\n    {{ columns.append( {\"name\": \"TAG\", \"datatype\": dbt_utils.type_string(), \"quote\": True } ) }}\n\n{% else %}\n    {{ columns.append( {\"name\": \"tag\", \"datatype\": dbt_utils.type_string()} ) }}\n\n{% endif %}\n\n{{ return(columns) }}\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.type_timestamp", "macro.dbt_utils.type_int", "macro.dbt_utils.type_string"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.243743}, "macro.zendesk_source.get_ticket_form_history_columns": {"unique_id": "macro.zendesk_source.get_ticket_form_history_columns", "package_name": "zendesk_source", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/zendesk_source", "path": "macros/get_ticket_form_history_columns.sql", "original_file_path": "macros/get_ticket_form_history_columns.sql", "name": "get_ticket_form_history_columns", "macro_sql": "{% macro get_ticket_form_history_columns() %}\n\n{% set columns = [\n    {\"name\": \"_fivetran_deleted\", \"datatype\": \"boolean\"},\n    {\"name\": \"_fivetran_synced\", \"datatype\": dbt_utils.type_timestamp()},\n    {\"name\": \"active\", \"datatype\": \"boolean\"},\n    {\"name\": \"created_at\", \"datatype\": dbt_utils.type_timestamp()},\n    {\"name\": \"display_name\", \"datatype\": dbt_utils.type_string()},\n    {\"name\": \"end_user_visible\", \"datatype\": \"boolean\"},\n    {\"name\": \"id\", \"datatype\": dbt_utils.type_int()},\n    {\"name\": \"name\", \"datatype\": dbt_utils.type_string()},\n    {\"name\": \"updated_at\", \"datatype\": dbt_utils.type_timestamp()}\n] %}\n\n{{ return(columns) }}\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.type_timestamp", "macro.dbt_utils.type_string", "macro.dbt_utils.type_int"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.2464151}, "macro.zendesk_source.get_schedule_columns": {"unique_id": "macro.zendesk_source.get_schedule_columns", "package_name": "zendesk_source", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/zendesk_source", "path": "macros/get_schedule_columns.sql", "original_file_path": "macros/get_schedule_columns.sql", "name": "get_schedule_columns", "macro_sql": "{% macro get_schedule_columns() %}\n\n{% set columns = [\n    {\"name\": \"_fivetran_deleted\", \"datatype\": \"boolean\"},\n    {\"name\": \"_fivetran_synced\", \"datatype\": dbt_utils.type_timestamp()},\n    {\"name\": \"created_at\", \"datatype\": dbt_utils.type_timestamp()},\n    {\"name\": \"end_time\", \"datatype\": dbt_utils.type_int()},\n    {\"name\": \"end_time_utc\", \"datatype\": dbt_utils.type_int()},\n    {\"name\": \"id\", \"datatype\": dbt_utils.type_int()},\n    {\"name\": \"name\", \"datatype\": dbt_utils.type_string()},\n    {\"name\": \"start_time\", \"datatype\": dbt_utils.type_int()},\n    {\"name\": \"start_time_utc\", \"datatype\": dbt_utils.type_int()},\n    {\"name\": \"time_zone\", \"datatype\": dbt_utils.type_string()}\n] %}\n\n{{ return(columns) }}\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.type_timestamp", "macro.dbt_utils.type_int", "macro.dbt_utils.type_string"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.2495282}, "macro.zendesk_source.get_daylight_time_columns": {"unique_id": "macro.zendesk_source.get_daylight_time_columns", "package_name": "zendesk_source", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/zendesk_source", "path": "macros/get_daylight_time_columns.sql", "original_file_path": "macros/get_daylight_time_columns.sql", "name": "get_daylight_time_columns", "macro_sql": "{% macro get_daylight_time_columns() %}\n\n{% set columns = [\n    {\"name\": \"_fivetran_synced\", \"datatype\": dbt_utils.type_timestamp()},\n    {\"name\": \"daylight_end_utc\", \"datatype\": \"datetime\"},\n    {\"name\": \"daylight_offset\", \"datatype\": dbt_utils.type_int()},\n    {\"name\": \"daylight_start_utc\", \"datatype\": \"datetime\"},\n    {\"name\": \"time_zone\", \"datatype\": dbt_utils.type_string()},\n    {\"name\": \"year\", \"datatype\": dbt_utils.type_int()}\n] %}\n\n{{ return(columns) }}\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.type_timestamp", "macro.dbt_utils.type_int", "macro.dbt_utils.type_string"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.251538}, "macro.zendesk_source.get_time_zone_columns": {"unique_id": "macro.zendesk_source.get_time_zone_columns", "package_name": "zendesk_source", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/zendesk_source", "path": "macros/get_time_zone_columns.sql", "original_file_path": "macros/get_time_zone_columns.sql", "name": "get_time_zone_columns", "macro_sql": "{% macro get_time_zone_columns() %}\n\n{% set columns = [\n    {\"name\": \"_fivetran_synced\", \"datatype\": dbt_utils.type_timestamp()},\n    {\"name\": \"standard_offset\", \"datatype\": dbt_utils.type_string()},\n    {\"name\": \"time_zone\", \"datatype\": dbt_utils.type_string()}\n] %}\n\n{{ return(columns) }}\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.type_timestamp", "macro.dbt_utils.type_string"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.252914}, "macro.zendesk_source.get_ticket_tag_columns": {"unique_id": "macro.zendesk_source.get_ticket_tag_columns", "package_name": "zendesk_source", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/zendesk_source", "path": "macros/get_ticket_tag_columns.sql", "original_file_path": "macros/get_ticket_tag_columns.sql", "name": "get_ticket_tag_columns", "macro_sql": "{% macro get_ticket_tag_columns() %}\n\n{% set columns = [\n    {\"name\": \"_fivetran_synced\", \"datatype\": dbt_utils.type_timestamp()},\n    {\"name\": \"ticket_id\", \"datatype\": dbt_utils.type_int()}\n] %}\n\n{% if target.type == 'redshift' %}\n    {{ columns.append( {\"name\": \"tag\", \"datatype\": dbt_utils.type_string(), \"quote\": True } ) }}\n\n{% elif target.type == 'snowflake' %}\n    {{ columns.append( {\"name\": \"TAG\", \"datatype\": dbt_utils.type_string(), \"quote\": True } ) }}\n\n{% else %}\n    {{ columns.append( {\"name\": \"tag\", \"datatype\": dbt_utils.type_string()} ) }}\n\n{% endif %}\n\n{{ return(columns) }}\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.type_timestamp", "macro.dbt_utils.type_int", "macro.dbt_utils.type_string"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.25574}, "macro.zendesk_source.get_organization_tag_columns": {"unique_id": "macro.zendesk_source.get_organization_tag_columns", "package_name": "zendesk_source", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/zendesk_source", "path": "macros/get_organization_tag_columns.sql", "original_file_path": "macros/get_organization_tag_columns.sql", "name": "get_organization_tag_columns", "macro_sql": "{% macro get_organization_tag_columns() %}\n\n{% set columns = [\n    {\"name\": \"_fivetran_synced\", \"datatype\": dbt_utils.type_timestamp()},\n    {\"name\": \"organization_id\", \"datatype\": dbt_utils.type_int()}\n] %}\n\n{% if target.type == 'redshift' %}\n    {{ columns.append( {\"name\": \"tag\", \"datatype\": dbt_utils.type_string(), \"quote\": True } ) }}\n\n{% elif target.type == 'snowflake' %}\n    {{ columns.append( {\"name\": \"TAG\", \"datatype\": dbt_utils.type_string(), \"quote\": True } ) }}\n\n{% else %}\n    {{ columns.append( {\"name\": \"tag\", \"datatype\": dbt_utils.type_string()} ) }}\n\n{% endif %}\n\n{{ return(columns) }}\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.type_timestamp", "macro.dbt_utils.type_int", "macro.dbt_utils.type_string"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.2586508}, "macro.zendesk_source.get_group_columns": {"unique_id": "macro.zendesk_source.get_group_columns", "package_name": "zendesk_source", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/zendesk_source", "path": "macros/get_group_columns.sql", "original_file_path": "macros/get_group_columns.sql", "name": "get_group_columns", "macro_sql": "{% macro get_group_columns() %}\n\n{% set columns = [\n    {\"name\": \"_fivetran_deleted\", \"datatype\": \"boolean\"},\n    {\"name\": \"_fivetran_synced\", \"datatype\": dbt_utils.type_timestamp()},\n    {\"name\": \"created_at\", \"datatype\": dbt_utils.type_timestamp()},\n    {\"name\": \"id\", \"datatype\": dbt_utils.type_int()},\n    {\"name\": \"name\", \"datatype\": dbt_utils.type_string()},\n    {\"name\": \"updated_at\", \"datatype\": dbt_utils.type_timestamp()},\n    {\"name\": \"url\", \"datatype\": dbt_utils.type_string()}\n] %}\n\n{{ return(columns) }}\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.type_timestamp", "macro.dbt_utils.type_int", "macro.dbt_utils.type_string"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.260923}, "macro.zendesk_source.get_user_columns": {"unique_id": "macro.zendesk_source.get_user_columns", "package_name": "zendesk_source", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/zendesk_source", "path": "macros/get_user_columns.sql", "original_file_path": "macros/get_user_columns.sql", "name": "get_user_columns", "macro_sql": "{% macro get_user_columns() %}\n\n{% set columns = [\n    {\"name\": \"_fivetran_synced\", \"datatype\": dbt_utils.type_timestamp()},\n    {\"name\": \"active\", \"datatype\": \"boolean\"},\n    {\"name\": \"alias\", \"datatype\": dbt_utils.type_string()},\n    {\"name\": \"authenticity_token\", \"datatype\": dbt_utils.type_int()},\n    {\"name\": \"chat_only\", \"datatype\": \"boolean\"},\n    {\"name\": \"created_at\", \"datatype\": dbt_utils.type_timestamp()},\n    {\"name\": \"details\", \"datatype\": dbt_utils.type_int()},\n    {\"name\": \"email\", \"datatype\": dbt_utils.type_string()},\n    {\"name\": \"external_id\", \"datatype\": dbt_utils.type_int()},\n    {\"name\": \"id\", \"datatype\": dbt_utils.type_int()},\n    {\"name\": \"last_login_at\", \"datatype\": dbt_utils.type_timestamp()},\n    {\"name\": \"locale\", \"datatype\": dbt_utils.type_string()},\n    {\"name\": \"locale_id\", \"datatype\": dbt_utils.type_int()},\n    {\"name\": \"moderator\", \"datatype\": \"boolean\"},\n    {\"name\": \"name\", \"datatype\": dbt_utils.type_string()},\n    {\"name\": \"notes\", \"datatype\": dbt_utils.type_int()},\n    {\"name\": \"only_private_comments\", \"datatype\": \"boolean\"},\n    {\"name\": \"organization_id\", \"datatype\": dbt_utils.type_int()},\n    {\"name\": \"phone\", \"datatype\": dbt_utils.type_int()},\n    {\"name\": \"remote_photo_url\", \"datatype\": dbt_utils.type_int()},\n    {\"name\": \"restricted_agent\", \"datatype\": \"boolean\"},\n    {\"name\": \"role\", \"datatype\": dbt_utils.type_string()},\n    {\"name\": \"shared\", \"datatype\": \"boolean\"},\n    {\"name\": \"shared_agent\", \"datatype\": \"boolean\"},\n    {\"name\": \"signature\", \"datatype\": dbt_utils.type_int()},\n    {\"name\": \"suspended\", \"datatype\": \"boolean\"},\n    {\"name\": \"ticket_restriction\", \"datatype\": dbt_utils.type_string()},\n    {\"name\": \"time_zone\", \"datatype\": dbt_utils.type_string()},\n    {\"name\": \"two_factor_auth_enabled\", \"datatype\": \"boolean\"},\n    {\"name\": \"updated_at\", \"datatype\": dbt_utils.type_string()},\n    {\"name\": \"url\", \"datatype\": dbt_utils.type_string()},\n    {\"name\": \"verified\", \"datatype\": \"boolean\"}\n] %}\n\n{{ return(columns) }}\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.type_timestamp", "macro.dbt_utils.type_string", "macro.dbt_utils.type_int"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.268967}, "macro.zendesk_source.get_ticket_columns": {"unique_id": "macro.zendesk_source.get_ticket_columns", "package_name": "zendesk_source", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/zendesk_source", "path": "macros/get_ticket_columns.sql", "original_file_path": "macros/get_ticket_columns.sql", "name": "get_ticket_columns", "macro_sql": "{% macro get_ticket_columns() %}\n\n{% set columns = [\n    {\"name\": \"_fivetran_synced\", \"datatype\": dbt_utils.type_timestamp()},\n    {\"name\": \"allow_channelback\", \"datatype\": \"boolean\"},\n    {\"name\": \"assignee_id\", \"datatype\": dbt_utils.type_int()},\n    {\"name\": \"brand_id\", \"datatype\": dbt_utils.type_int()},\n    {\"name\": \"created_at\", \"datatype\": dbt_utils.type_timestamp()},\n    {\"name\": \"description\", \"datatype\": dbt_utils.type_string()},\n    {\"name\": \"due_at\", \"datatype\": dbt_utils.type_timestamp()},\n    {\"name\": \"external_id\", \"datatype\": dbt_utils.type_int()},\n    {\"name\": \"forum_topic_id\", \"datatype\": dbt_utils.type_int()},\n    {\"name\": \"group_id\", \"datatype\": dbt_utils.type_int()},\n    {\"name\": \"has_incidents\", \"datatype\": \"boolean\"},\n    {\"name\": \"id\", \"datatype\": dbt_utils.type_int()},\n    {\"name\": \"is_public\", \"datatype\": \"boolean\"},\n    {\"name\": \"merged_ticket_ids\", \"datatype\": dbt_utils.type_string()},\n    {\"name\": \"organization_id\", \"datatype\": dbt_utils.type_int()},\n    {\"name\": \"priority\", \"datatype\": dbt_utils.type_string()},\n    {\"name\": \"problem_id\", \"datatype\": dbt_utils.type_int()},\n    {\"name\": \"recipient\", \"datatype\": dbt_utils.type_int()},\n    {\"name\": \"requester_id\", \"datatype\": dbt_utils.type_int()},\n    {\"name\": \"status\", \"datatype\": dbt_utils.type_string()},\n    {\"name\": \"subject\", \"datatype\": dbt_utils.type_string()},\n    {\"name\": \"submitter_id\", \"datatype\": dbt_utils.type_int()},\n    {\"name\": \"system_ccs\", \"datatype\": dbt_utils.type_int()},\n    {\"name\": \"system_client\", \"datatype\": dbt_utils.type_string()},\n    {\"name\": \"system_ip_address\", \"datatype\": dbt_utils.type_string()},\n    {\"name\": \"system_json_email_identifier\", \"datatype\": dbt_utils.type_int()},\n    {\"name\": \"system_latitude\", \"datatype\": dbt_utils.type_float()},\n    {\"name\": \"system_location\", \"datatype\": dbt_utils.type_string()},\n    {\"name\": \"system_longitude\", \"datatype\": dbt_utils.type_float()},\n    {\"name\": \"system_machine_generated\", \"datatype\": dbt_utils.type_int()},\n    {\"name\": \"system_message_id\", \"datatype\": dbt_utils.type_int()},\n    {\"name\": \"system_raw_email_identifier\", \"datatype\": dbt_utils.type_int()},\n    {\"name\": \"ticket_form_id\", \"datatype\": dbt_utils.type_int()},\n    {\"name\": \"type\", \"datatype\": dbt_utils.type_string()},\n    {\"name\": \"updated_at\", \"datatype\": dbt_utils.type_string()},\n    {\"name\": \"url\", \"datatype\": dbt_utils.type_string()},\n    {\"name\": \"via_channel\", \"datatype\": dbt_utils.type_string()},\n    {\"name\": \"via_source_from_address\", \"datatype\": dbt_utils.type_int()},\n    {\"name\": \"via_source_from_id\", \"datatype\": dbt_utils.type_int()},\n    {\"name\": \"via_source_from_title\", \"datatype\": dbt_utils.type_int()},\n    {\"name\": \"via_source_rel\", \"datatype\": dbt_utils.type_int()},\n    {\"name\": \"via_source_to_address\", \"datatype\": dbt_utils.type_int()},\n    {\"name\": \"via_source_to_name\", \"datatype\": dbt_utils.type_int()}\n] %}\n\n{{ return(columns) }}\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.type_timestamp", "macro.dbt_utils.type_int", "macro.dbt_utils.type_string", "macro.dbt_utils.type_float"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.2809331}, "macro.zendesk_source.get_ticket_field_history_columns": {"unique_id": "macro.zendesk_source.get_ticket_field_history_columns", "package_name": "zendesk_source", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/zendesk_source", "path": "macros/get_ticket_field_history_columns.sql", "original_file_path": "macros/get_ticket_field_history_columns.sql", "name": "get_ticket_field_history_columns", "macro_sql": "{% macro get_ticket_field_history_columns() %}\n\n{% set columns = [\n    {\"name\": \"_fivetran_synced\", \"datatype\": dbt_utils.type_timestamp()},\n    {\"name\": \"field_name\", \"datatype\": dbt_utils.type_string()},\n    {\"name\": \"ticket_id\", \"datatype\": dbt_utils.type_int()},\n    {\"name\": \"updated\", \"datatype\": dbt_utils.type_timestamp()},\n    {\"name\": \"user_id\", \"datatype\": dbt_utils.type_int()},\n    {\"name\": \"value\", \"datatype\": dbt_utils.type_string()}\n] %}\n\n{{ return(columns) }}\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.type_timestamp", "macro.dbt_utils.type_string", "macro.dbt_utils.type_int"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.283133}, "macro.zendesk_source.get_ticket_schedule_columns": {"unique_id": "macro.zendesk_source.get_ticket_schedule_columns", "package_name": "zendesk_source", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/zendesk_source", "path": "macros/get_ticket_schedule_columns.sql", "original_file_path": "macros/get_ticket_schedule_columns.sql", "name": "get_ticket_schedule_columns", "macro_sql": "{% macro get_ticket_schedule_columns() %}\n\n{% set columns = [\n    {\"name\": \"_fivetran_synced\", \"datatype\": dbt_utils.type_timestamp()},\n    {\"name\": \"created_at\", \"datatype\": dbt_utils.type_timestamp()},\n    {\"name\": \"schedule_id\", \"datatype\": dbt_utils.type_int()},\n    {\"name\": \"ticket_id\", \"datatype\": dbt_utils.type_int()}\n] %}\n\n{{ return(columns) }}\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.type_timestamp", "macro.dbt_utils.type_int"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.2847328}, "macro.zendesk_source.get_organization_columns": {"unique_id": "macro.zendesk_source.get_organization_columns", "package_name": "zendesk_source", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/zendesk_source", "path": "macros/get_organization_columns.sql", "original_file_path": "macros/get_organization_columns.sql", "name": "get_organization_columns", "macro_sql": "{% macro get_organization_columns() %}\n\n{% set columns = [\n    {\"name\": \"_fivetran_synced\", \"datatype\": dbt_utils.type_timestamp()},\n    {\"name\": \"created_at\", \"datatype\": dbt_utils.type_timestamp()},\n    {\"name\": \"details\", \"datatype\": dbt_utils.type_int()},\n    {\"name\": \"external_id\", \"datatype\": dbt_utils.type_int()},\n    {\"name\": \"group_id\", \"datatype\": dbt_utils.type_int()},\n    {\"name\": \"id\", \"datatype\": dbt_utils.type_int()},\n    {\"name\": \"name\", \"datatype\": dbt_utils.type_string()},\n    {\"name\": \"notes\", \"datatype\": dbt_utils.type_int()},\n    {\"name\": \"shared_comments\", \"datatype\": \"boolean\"},\n    {\"name\": \"shared_tickets\", \"datatype\": \"boolean\"},\n    {\"name\": \"updated_at\", \"datatype\": dbt_utils.type_timestamp()},\n    {\"name\": \"url\", \"datatype\": dbt_utils.type_string()}\n] %}\n\n{{ return(columns) }}\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.type_timestamp", "macro.dbt_utils.type_int", "macro.dbt_utils.type_string"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.288091}, "macro.zendesk_source.get_ticket_comment_columns": {"unique_id": "macro.zendesk_source.get_ticket_comment_columns", "package_name": "zendesk_source", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/zendesk_source", "path": "macros/get_ticket_comment_columns.sql", "original_file_path": "macros/get_ticket_comment_columns.sql", "name": "get_ticket_comment_columns", "macro_sql": "{% macro get_ticket_comment_columns() %}\n\n{% set columns = [\n    {\"name\": \"_fivetran_synced\", \"datatype\": dbt_utils.type_string()},\n    {\"name\": \"body\", \"datatype\": dbt_utils.type_string()},\n    {\"name\": \"call_duration\", \"datatype\": dbt_utils.type_int()},\n    {\"name\": \"call_id\", \"datatype\": dbt_utils.type_int()},\n    {\"name\": \"created\", \"datatype\": dbt_utils.type_timestamp()},\n    {\"name\": \"facebook_comment\", \"datatype\": \"boolean\"},\n    {\"name\": \"id\", \"datatype\": dbt_utils.type_int()},\n    {\"name\": \"location\", \"datatype\": dbt_utils.type_int()},\n    {\"name\": \"public\", \"datatype\": \"boolean\"},\n    {\"name\": \"recording_url\", \"datatype\": dbt_utils.type_int()},\n    {\"name\": \"started_at\", \"datatype\": dbt_utils.type_timestamp()},\n    {\"name\": \"ticket_id\", \"datatype\": dbt_utils.type_int()},\n    {\"name\": \"transcription_status\", \"datatype\": dbt_utils.type_int()},\n    {\"name\": \"transcription_text\", \"datatype\": dbt_utils.type_int()},\n    {\"name\": \"trusted\", \"datatype\": dbt_utils.type_int()},\n    {\"name\": \"tweet\", \"datatype\": \"boolean\"},\n    {\"name\": \"user_id\", \"datatype\": dbt_utils.type_int()},\n    {\"name\": \"voice_comment\", \"datatype\": \"boolean\"},\n    {\"name\": \"voice_comment_transcription_visible\", \"datatype\": dbt_utils.type_int()}\n] %}\n\n{{ return(columns) }}\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.type_string", "macro.dbt_utils.type_int", "macro.dbt_utils.type_timestamp"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.293152}, "macro.zendesk_source.get_brand_columns": {"unique_id": "macro.zendesk_source.get_brand_columns", "package_name": "zendesk_source", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/zendesk_source", "path": "macros/get_brand_columns.sql", "original_file_path": "macros/get_brand_columns.sql", "name": "get_brand_columns", "macro_sql": "{% macro get_brand_columns() %}\n\n{% set columns = [\n    {\"name\": \"_fivetran_deleted\", \"datatype\": \"boolean\"},\n    {\"name\": \"_fivetran_synced\", \"datatype\": dbt_utils.type_timestamp()},\n    {\"name\": \"active\", \"datatype\": \"boolean\"},\n    {\"name\": \"brand_url\", \"datatype\": dbt_utils.type_string()},\n    {\"name\": \"has_help_center\", \"datatype\": \"boolean\"},\n    {\"name\": \"help_center_state\", \"datatype\": dbt_utils.type_string()},\n    {\"name\": \"id\", \"datatype\": dbt_utils.type_int()},\n    {\"name\": \"logo_content_type\", \"datatype\": dbt_utils.type_string()},\n    {\"name\": \"logo_content_url\", \"datatype\": dbt_utils.type_string()},\n    {\"name\": \"logo_deleted\", \"datatype\": \"boolean\"},\n    {\"name\": \"logo_file_name\", \"datatype\": dbt_utils.type_string()},\n    {\"name\": \"logo_height\", \"datatype\": dbt_utils.type_int()},\n    {\"name\": \"logo_id\", \"datatype\": dbt_utils.type_int()},\n    {\"name\": \"logo_inline\", \"datatype\": \"boolean\"},\n    {\"name\": \"logo_mapped_content_url\", \"datatype\": dbt_utils.type_string()},\n    {\"name\": \"logo_size\", \"datatype\": dbt_utils.type_int()},\n    {\"name\": \"logo_url\", \"datatype\": dbt_utils.type_string()},\n    {\"name\": \"logo_width\", \"datatype\": dbt_utils.type_int()},\n    {\"name\": \"name\", \"datatype\": dbt_utils.type_string()},\n    {\"name\": \"subdomain\", \"datatype\": dbt_utils.type_string()},\n    {\"name\": \"url\", \"datatype\": dbt_utils.type_string()}\n] %}\n\n{{ return(columns) }}\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.type_timestamp", "macro.dbt_utils.type_string", "macro.dbt_utils.type_int"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1647014736.2986062}}, "docs": {"dbt.__overview__": {"unique_id": "dbt.__overview__", "package_name": "dbt", "root_path": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dbt/include/global_project", "path": "overview.md", "original_file_path": "docs/overview.md", "name": "__overview__", "block_contents": "### Welcome!\n\nWelcome to the auto-generated documentation for your dbt project!\n\n### Navigation\n\nYou can use the `Project` and `Database` navigation tabs on the left side of the window to explore the models\nin your project.\n\n#### Project Tab\nThe `Project` tab mirrors the directory structure of your dbt project. In this tab, you can see all of the\nmodels defined in your dbt project, as well as models imported from dbt packages.\n\n#### Database Tab\nThe `Database` tab also exposes your models, but in a format that looks more like a database explorer. This view\nshows relations (tables and views) grouped into database schemas. Note that ephemeral models are _not_ shown\nin this interface, as they do not exist in the database.\n\n### Graph Exploration\nYou can click the blue icon on the bottom-right corner of the page to view the lineage graph of your models.\n\nOn model pages, you'll see the immediate parents and children of the model you're exploring. By clicking the `Expand`\nbutton at the top-right of this lineage pane, you'll be able to see all of the models that are used to build,\nor are built from, the model you're exploring.\n\nOnce expanded, you'll be able to use the `--select` and `--exclude` model selection syntax to filter the\nmodels in the graph. For more information on model selection, check out the [dbt docs](https://docs.getdbt.com/docs/model-selection-syntax).\n\nNote that you can also right-click on models to interactively filter and explore the graph.\n\n---\n\n### More information\n\n- [What is dbt](https://docs.getdbt.com/docs/introduction)?\n- Read the [dbt viewpoint](https://docs.getdbt.com/docs/viewpoint)\n- [Installation](https://docs.getdbt.com/docs/installation)\n- Join the [dbt Community](https://www.getdbt.com/community/) for questions and discussion"}}, "exposures": {}, "metrics": {}, "selectors": {}, "disabled": {"model.zendesk_source.stg_zendesk__user_tag": [{"raw_sql": "--To disable this model, set the using_user_tags variable within your dbt_project.yml file to False.\n{{ config(enabled=var('using_user_tags', True)) }}\n\nwith base as (\n\n    select * \n    from {{ ref('stg_zendesk__user_tag_tmp') }}\n\n),\n\nfields as (\n\n    select\n        /*\n        The below macro is used to generate the correct SQL for package staging models. It takes a list of columns \n        that are expected/needed (staging_columns from dbt_zendesk_source/models/tmp/) and compares it with columns \n        in the source (source_columns from dbt_zendesk_source/macros/).\n        For more information refer to our dbt_fivetran_utils documentation (https://github.com/fivetran/dbt_fivetran_utils.git).\n        */\n        {{\n            fivetran_utils.fill_staging_columns(\n                source_columns=adapter.get_columns_in_relation(ref('stg_zendesk__user_tag_tmp')),\n                staging_columns=get_user_tag_columns()\n            )\n        }}\n        \n    from base\n),\n\nfinal as (\n    \n    select \n        user_id,\n        {% if target.type == 'redshift' %}\n        'tag'\n        {% else %}\n        tag\n        {% endif %}\n        as tags\n    from fields\n)\n\nselect * \nfrom final", "resource_type": "model", "depends_on": {"macros": ["macro.zendesk_source.get_user_tag_columns", "macro.fivetran_utils.fill_staging_columns"], "nodes": []}, "config": {"enabled": false, "alias": null, "schema": "zendesk_docs", "database": null, "tags": [], "meta": {}, "materialized": "table", "persist_docs": {}, "quoting": {}, "column_types": {}, "full_refresh": null, "on_schema_change": "ignore", "post-hook": [], "pre-hook": []}, "database": "bq-project", "schema": "dbt_joe_zendesk_docs", "fqn": ["zendesk_source", "stg_zendesk__user_tag"], "unique_id": "model.zendesk_source.stg_zendesk__user_tag", "package_name": "zendesk_source", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/zendesk_source", "path": "stg_zendesk__user_tag.sql", "original_file_path": "models/stg_zendesk__user_tag.sql", "name": "stg_zendesk__user_tag", "alias": "stg_zendesk__user_tag", "checksum": {"name": "sha256", "checksum": "ea77c976e7ee820ea7cc353ea3d30231f262f834d75e4cb251e1a72c92a93462"}, "tags": [], "refs": [["stg_zendesk__user_tag_tmp"], ["stg_zendesk__user_tag_tmp"]], "sources": [], "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": "zendesk_source://models/stg_zendesk.yml", "compiled_path": null, "build_path": null, "deferred": false, "unrendered_config": {"materialized": "table", "schema": "zendesk_docs", "enabled": false}, "created_at": 1647014737.349051}], "model.zendesk_source.stg_zendesk__domain_name": [{"raw_sql": "--To disable this model, set the using_domain_names variable within your dbt_project.yml file to False.\n{{ config(enabled=var('using_domain_names', True)) }}\n\nwith base as (\n\n    select * \n    from {{ ref('stg_zendesk__domain_name_tmp') }}\n\n),\n\nfields as (\n\n    select\n        /*\n        The below macro is used to generate the correct SQL for package staging models. It takes a list of columns \n        that are expected/needed (staging_columns from dbt_zendesk_source/models/tmp/) and compares it with columns \n        in the source (source_columns from dbt_zendesk_source/macros/).\n        For more information refer to our dbt_fivetran_utils documentation (https://github.com/fivetran/dbt_fivetran_utils.git).\n        */\n        {{\n            fivetran_utils.fill_staging_columns(\n                source_columns=adapter.get_columns_in_relation(ref('stg_zendesk__domain_name_tmp')),\n                staging_columns=get_domain_name_columns()\n            )\n        }}\n        \n    from base\n),\n\nfinal as (\n    \n    select \n        organization_id,\n        domain_name,\n        index\n    from fields\n)\n\nselect * \nfrom final", "resource_type": "model", "depends_on": {"macros": ["macro.zendesk_source.get_domain_name_columns", "macro.fivetran_utils.fill_staging_columns"], "nodes": []}, "config": {"enabled": false, "alias": null, "schema": "zendesk_docs", "database": null, "tags": [], "meta": {}, "materialized": "table", "persist_docs": {}, "quoting": {}, "column_types": {}, "full_refresh": null, "on_schema_change": "ignore", "post-hook": [], "pre-hook": []}, "database": "bq-project", "schema": "dbt_joe_zendesk_docs", "fqn": ["zendesk_source", "stg_zendesk__domain_name"], "unique_id": "model.zendesk_source.stg_zendesk__domain_name", "package_name": "zendesk_source", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/zendesk_source", "path": "stg_zendesk__domain_name.sql", "original_file_path": "models/stg_zendesk__domain_name.sql", "name": "stg_zendesk__domain_name", "alias": "stg_zendesk__domain_name", "checksum": {"name": "sha256", "checksum": "356988d2b8fc14f75da81db2a0c8bef9531c7224ff0b3d6efac425ea5175a1b6"}, "tags": [], "refs": [["stg_zendesk__domain_name_tmp"], ["stg_zendesk__domain_name_tmp"]], "sources": [], "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": "zendesk_source://models/stg_zendesk.yml", "compiled_path": null, "build_path": null, "deferred": false, "unrendered_config": {"materialized": "table", "schema": "zendesk_docs", "enabled": false}, "created_at": 1647014737.576213}], "model.zendesk_source.stg_zendesk__organization_tag": [{"raw_sql": "--To disable this model, set the using_organization_tags variable within your dbt_project.yml file to False.\n{{ config(enabled=var('using_organization_tags', True)) }}\n\nwith base as (\n\n    select * \n    from {{ ref('stg_zendesk__organization_tag_tmp') }}\n\n),\n\nfields as (\n\n    select\n        /*\n        The below macro is used to generate the correct SQL for package staging models. It takes a list of columns \n        that are expected/needed (staging_columns from dbt_zendesk_source/models/tmp/) and compares it with columns \n        in the source (source_columns from dbt_zendesk_source/macros/).\n        For more information refer to our dbt_fivetran_utils documentation (https://github.com/fivetran/dbt_fivetran_utils.git).\n        */\n        {{\n            fivetran_utils.fill_staging_columns(\n                source_columns=adapter.get_columns_in_relation(ref('stg_zendesk__organization_tag_tmp')),\n                staging_columns=get_organization_tag_columns()\n            )\n        }}\n        \n    from base\n),\n\nfinal as (\n    \n    select \n        organization_id,\n        {% if target.type == 'redshift' %}\n        'tag'\n        {% else %}\n        tag\n        {% endif %}\n        as tags\n    from fields\n)\n\nselect * \nfrom final", "resource_type": "model", "depends_on": {"macros": ["macro.zendesk_source.get_organization_tag_columns", "macro.fivetran_utils.fill_staging_columns"], "nodes": []}, "config": {"enabled": false, "alias": null, "schema": "zendesk_docs", "database": null, "tags": [], "meta": {}, "materialized": "table", "persist_docs": {}, "quoting": {}, "column_types": {}, "full_refresh": null, "on_schema_change": "ignore", "post-hook": [], "pre-hook": []}, "database": "bq-project", "schema": "dbt_joe_zendesk_docs", "fqn": ["zendesk_source", "stg_zendesk__organization_tag"], "unique_id": "model.zendesk_source.stg_zendesk__organization_tag", "package_name": "zendesk_source", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/zendesk_source", "path": "stg_zendesk__organization_tag.sql", "original_file_path": "models/stg_zendesk__organization_tag.sql", "name": "stg_zendesk__organization_tag", "alias": "stg_zendesk__organization_tag", "checksum": {"name": "sha256", "checksum": "f52a16a097e2baeeaa61469f2ae266294958f1c50c98c42444f2262f2fd48a29"}, "tags": [], "refs": [["stg_zendesk__organization_tag_tmp"], ["stg_zendesk__organization_tag_tmp"]], "sources": [], "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": "zendesk_source://models/stg_zendesk.yml", "compiled_path": null, "build_path": null, "deferred": false, "unrendered_config": {"materialized": "table", "schema": "zendesk_docs", "enabled": false}, "created_at": 1647014737.586643}], "model.zendesk_source.stg_zendesk__user_tag_tmp": [{"raw_sql": "--To disable this model, set the using_user_tags variable within your dbt_project.yml file to False.\n{{ config(enabled=var('using_user_tags', True)) }}\n\nselect * \nfrom {{ var('user_tag') }}", "resource_type": "model", "depends_on": {"macros": [], "nodes": []}, "config": {"enabled": false, "alias": null, "schema": "zendesk_docs", "database": null, "tags": [], "meta": {}, "materialized": "view", "persist_docs": {}, "quoting": {}, "column_types": {}, "full_refresh": null, "on_schema_change": "ignore", "post-hook": [], "pre-hook": []}, "database": "bq-project", "schema": "dbt_joe_zendesk_docs", "fqn": ["zendesk_source", "tmp", "stg_zendesk__user_tag_tmp"], "unique_id": "model.zendesk_source.stg_zendesk__user_tag_tmp", "package_name": "zendesk_source", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/zendesk_source", "path": "tmp/stg_zendesk__user_tag_tmp.sql", "original_file_path": "models/tmp/stg_zendesk__user_tag_tmp.sql", "name": "stg_zendesk__user_tag_tmp", "alias": "stg_zendesk__user_tag_tmp", "checksum": {"name": "sha256", "checksum": "b852c972b7d1dbdf738108c7d5b1b6aff4f2215a1bb6afbb6bb1696c2be0f0c9"}, "tags": [], "refs": [], "sources": [["zendesk", "user_tag"]], "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "compiled_path": null, "build_path": null, "deferred": false, "unrendered_config": {"materialized": "view", "schema": "zendesk_docs", "enabled": false}, "created_at": 1647014737.674212}], "model.zendesk_source.stg_zendesk__organization_tag_tmp": [{"raw_sql": "--To disable this model, set the using_organization_tags variable within your dbt_project.yml file to False.\n{{ config(enabled=var('using_organization_tags', True)) }}\n\nselect * \nfrom {{ var('organization_tag') }}", "resource_type": "model", "depends_on": {"macros": [], "nodes": []}, "config": {"enabled": false, "alias": null, "schema": "zendesk_docs", "database": null, "tags": [], "meta": {}, "materialized": "view", "persist_docs": {}, "quoting": {}, "column_types": {}, "full_refresh": null, "on_schema_change": "ignore", "post-hook": [], "pre-hook": []}, "database": "bq-project", "schema": "dbt_joe_zendesk_docs", "fqn": ["zendesk_source", "tmp", "stg_zendesk__organization_tag_tmp"], "unique_id": "model.zendesk_source.stg_zendesk__organization_tag_tmp", "package_name": "zendesk_source", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/zendesk_source", "path": "tmp/stg_zendesk__organization_tag_tmp.sql", "original_file_path": "models/tmp/stg_zendesk__organization_tag_tmp.sql", "name": "stg_zendesk__organization_tag_tmp", "alias": "stg_zendesk__organization_tag_tmp", "checksum": {"name": "sha256", "checksum": "371025f2faaebbcaa7b7d612cad719c47e7bb7ec0adb2d514be59dd154000924"}, "tags": [], "refs": [], "sources": [["zendesk", "organization_tag"]], "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "compiled_path": null, "build_path": null, "deferred": false, "unrendered_config": {"materialized": "view", "schema": "zendesk_docs", "enabled": false}, "created_at": 1647014737.696099}], "model.zendesk_source.stg_zendesk__domain_name_tmp": [{"raw_sql": "--To disable this model, set the using_domain_names variable within your dbt_project.yml file to False.\n{{ config(enabled=var('using_domain_names', True)) }}\n\nselect * \nfrom {{ var('domain_name') }}", "resource_type": "model", "depends_on": {"macros": [], "nodes": []}, "config": {"enabled": false, "alias": null, "schema": "zendesk_docs", "database": null, "tags": [], "meta": {}, "materialized": "view", "persist_docs": {}, "quoting": {}, "column_types": {}, "full_refresh": null, "on_schema_change": "ignore", "post-hook": [], "pre-hook": []}, "database": "bq-project", "schema": "dbt_joe_zendesk_docs", "fqn": ["zendesk_source", "tmp", "stg_zendesk__domain_name_tmp"], "unique_id": "model.zendesk_source.stg_zendesk__domain_name_tmp", "package_name": "zendesk_source", "root_path": "/Users/joseph.markiewicz/Documents/dbt_packages/Zendesk/development/dbt_packages/zendesk_source", "path": "tmp/stg_zendesk__domain_name_tmp.sql", "original_file_path": "models/tmp/stg_zendesk__domain_name_tmp.sql", "name": "stg_zendesk__domain_name_tmp", "alias": "stg_zendesk__domain_name_tmp", "checksum": {"name": "sha256", "checksum": "0146a0dae63eb5aec2a78e50244874689f5ad1db8135f68c9f2806314e22d477"}, "tags": [], "refs": [], "sources": [["zendesk", "domain_name"]], "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "compiled_path": null, "build_path": null, "deferred": false, "unrendered_config": {"materialized": "view", "schema": "zendesk_docs", "enabled": false}, "created_at": 1647014737.7222788}]}, "parent_map": {"model.zendesk.zendesk__ticket_enriched": ["model.zendesk.int_zendesk__assignee_updates", "model.zendesk.int_zendesk__latest_ticket_form", "model.zendesk.int_zendesk__organization_aggregates", "model.zendesk.int_zendesk__requester_updates", "model.zendesk.int_zendesk__ticket_aggregates", "model.zendesk.int_zendesk__ticket_historical_satisfaction", "model.zendesk.int_zendesk__user_aggregates", "model.zendesk_source.stg_zendesk__group"], "model.zendesk.zendesk__ticket_metrics": ["model.zendesk.int_zendesk__comment_metrics", "model.zendesk.int_zendesk__ticket_first_reply_time_business", "model.zendesk.int_zendesk__ticket_first_resolution_time_business", "model.zendesk.int_zendesk__ticket_full_resolution_time_business", "model.zendesk.int_zendesk__ticket_reply_times_calendar", "model.zendesk.int_zendesk__ticket_resolution_times_calendar", "model.zendesk.int_zendesk__ticket_work_time_business", "model.zendesk.int_zendesk__ticket_work_time_calendar", "model.zendesk.zendesk__ticket_enriched"], "model.zendesk.zendesk__ticket_summary": ["model.zendesk.zendesk__ticket_metrics", "model.zendesk_source.stg_zendesk__user"], "model.zendesk.zendesk__ticket_field_history": ["model.zendesk.int_zendesk__field_calendar_spine", "model.zendesk.int_zendesk__field_history_scd", "model.zendesk.int_zendesk__field_history_scd"], "model.zendesk.zendesk__sla_policies": ["model.zendesk.int_zendesk__agent_work_time_business_hours", "model.zendesk.int_zendesk__agent_work_time_calendar_hours", "model.zendesk.int_zendesk__reply_time_combined", "model.zendesk.int_zendesk__requester_wait_time_business_hours", "model.zendesk.int_zendesk__requester_wait_time_calendar_hours"], "model.zendesk.zendesk__ticket_backlog": ["model.zendesk.zendesk__ticket_field_history", "model.zendesk_source.stg_zendesk__brand", "model.zendesk_source.stg_zendesk__group", "model.zendesk_source.stg_zendesk__organization", "model.zendesk_source.stg_zendesk__ticket", "model.zendesk_source.stg_zendesk__user"], "model.zendesk.int_zendesk__sla_policy_applied": ["model.zendesk.int_zendesk__ticket_aggregates", "model.zendesk.int_zendesk__updates", "model.zendesk.int_zendesk__updates"], "model.zendesk.int_zendesk__agent_work_time_business_hours": ["model.zendesk.int_zendesk__agent_work_time_filtered_statuses", "model.zendesk.int_zendesk__schedule_spine", "model.zendesk.int_zendesk__ticket_schedules"], "model.zendesk.int_zendesk__agent_work_time_calendar_hours": ["model.zendesk.int_zendesk__agent_work_time_filtered_statuses"], "model.zendesk.int_zendesk__agent_work_time_filtered_statuses": ["model.zendesk.int_zendesk__sla_policy_applied", "model.zendesk.int_zendesk__ticket_historical_status"], "model.zendesk.int_zendesk__reply_time_business_hours": ["model.zendesk.int_zendesk__schedule_spine", "model.zendesk.int_zendesk__sla_policy_applied", "model.zendesk.int_zendesk__ticket_schedules", "model.zendesk_source.stg_zendesk__schedule"], "model.zendesk.int_zendesk__reply_time_calendar_hours": ["model.zendesk.int_zendesk__sla_policy_applied"], "model.zendesk.int_zendesk__reply_time_combined": ["model.zendesk.int_zendesk__reply_time_business_hours", "model.zendesk.int_zendesk__reply_time_calendar_hours", "model.zendesk.int_zendesk__updates", "model.zendesk.int_zendesk__user_aggregates"], "model.zendesk.int_zendesk__requester_wait_time_calendar_hours": ["model.zendesk.int_zendesk__requester_wait_time_filtered_statuses"], "model.zendesk.int_zendesk__requester_wait_time_business_hours": ["model.zendesk.int_zendesk__requester_wait_time_filtered_statuses", "model.zendesk.int_zendesk__schedule_spine", "model.zendesk.int_zendesk__ticket_schedules"], "model.zendesk.int_zendesk__requester_wait_time_filtered_statuses": ["model.zendesk.int_zendesk__sla_policy_applied", "model.zendesk.int_zendesk__ticket_historical_status"], "model.zendesk.int_zendesk__ticket_reply_times": ["model.zendesk.int_zendesk__comments_enriched"], "model.zendesk.int_zendesk__ticket_reply_times_calendar": ["model.zendesk.int_zendesk__ticket_reply_times", "model.zendesk_source.stg_zendesk__ticket"], "model.zendesk.int_zendesk__comments_enriched": ["model.zendesk.int_zendesk__updates", "model.zendesk_source.stg_zendesk__user"], "model.zendesk.int_zendesk__ticket_first_reply_time_business": ["model.zendesk.int_zendesk__schedule_spine", "model.zendesk.int_zendesk__ticket_reply_times", "model.zendesk.int_zendesk__ticket_schedules"], "model.zendesk.int_zendesk__field_history_enriched": ["model.zendesk.int_zendesk__updater_information", "model.zendesk_source.stg_zendesk__ticket_field_history"], "model.zendesk.int_zendesk__field_history_pivot": ["model.zendesk.int_zendesk__field_history_enriched", "model.zendesk_source.stg_zendesk__ticket_field_history"], "model.zendesk.int_zendesk__updater_information": ["model.zendesk.int_zendesk__organization_aggregates", "model.zendesk.int_zendesk__user_aggregates"], "model.zendesk.int_zendesk__field_history_scd": ["model.zendesk.int_zendesk__field_history_pivot", "model.zendesk.int_zendesk__field_history_pivot"], "model.zendesk.int_zendesk__field_calendar_spine": ["model.zendesk.int_zendesk__calendar_spine", "model.zendesk_source.stg_zendesk__ticket"], "model.zendesk.int_zendesk__ticket_work_time_calendar": ["model.zendesk.int_zendesk__ticket_historical_status"], "model.zendesk.int_zendesk__ticket_work_time_business": ["model.zendesk.int_zendesk__schedule_spine", "model.zendesk.int_zendesk__ticket_historical_status", "model.zendesk.int_zendesk__ticket_schedules"], "model.zendesk.int_zendesk__calendar_spine": ["model.zendesk_source.stg_zendesk__ticket"], "model.zendesk.int_zendesk__ticket_resolution_times_calendar": ["model.zendesk.int_zendesk__ticket_historical_assignee", "model.zendesk.int_zendesk__ticket_historical_group", "model.zendesk.int_zendesk__ticket_historical_status", "model.zendesk_source.stg_zendesk__ticket"], "model.zendesk.int_zendesk__ticket_first_resolution_time_business": ["model.zendesk.int_zendesk__schedule_spine", "model.zendesk.int_zendesk__ticket_resolution_times_calendar", "model.zendesk.int_zendesk__ticket_schedules"], "model.zendesk.int_zendesk__ticket_full_resolution_time_business": ["model.zendesk.int_zendesk__schedule_spine", "model.zendesk.int_zendesk__ticket_resolution_times_calendar", "model.zendesk.int_zendesk__ticket_schedules"], "model.zendesk.int_zendesk__updates": ["model.zendesk_source.stg_zendesk__ticket", "model.zendesk_source.stg_zendesk__ticket_comment", "model.zendesk_source.stg_zendesk__ticket_field_history"], "model.zendesk.int_zendesk__ticket_historical_assignee": ["model.zendesk.int_zendesk__updates"], "model.zendesk.int_zendesk__ticket_historical_status": ["model.zendesk.int_zendesk__updates"], "model.zendesk.int_zendesk__user_aggregates": ["model.zendesk_source.stg_zendesk__user"], "model.zendesk.int_zendesk__schedule_spine": ["model.zendesk_source.stg_zendesk__daylight_time", "model.zendesk_source.stg_zendesk__schedule", "model.zendesk_source.stg_zendesk__time_zone"], "model.zendesk.int_zendesk__ticket_schedules": ["model.zendesk_source.stg_zendesk__schedule", "model.zendesk_source.stg_zendesk__ticket", "model.zendesk_source.stg_zendesk__ticket_schedule"], "model.zendesk.int_zendesk__assignee_updates": ["model.zendesk.int_zendesk__updates", "model.zendesk_source.stg_zendesk__ticket"], "model.zendesk.int_zendesk__comment_metrics": ["model.zendesk.int_zendesk__comments_enriched"], "model.zendesk.int_zendesk__ticket_historical_group": ["model.zendesk.int_zendesk__updates"], "model.zendesk.int_zendesk__requester_updates": ["model.zendesk.int_zendesk__updates", "model.zendesk_source.stg_zendesk__ticket"], "model.zendesk.int_zendesk__ticket_historical_satisfaction": ["model.zendesk.int_zendesk__updates"], "model.zendesk.int_zendesk__latest_ticket_form": ["model.zendesk_source.stg_zendesk__ticket_form_history"], "model.zendesk.int_zendesk__ticket_aggregates": ["model.zendesk_source.stg_zendesk__brand", "model.zendesk_source.stg_zendesk__ticket", "model.zendesk_source.stg_zendesk__ticket_tag"], "model.zendesk.int_zendesk__organization_aggregates": ["model.zendesk_source.stg_zendesk__organization"], "operation.zendesk.zendesk-on-run-start-0": [], "model.zendesk_source.stg_zendesk__ticket_tag": ["model.zendesk_source.stg_zendesk__ticket_tag_tmp", "model.zendesk_source.stg_zendesk__ticket_tag_tmp"], "model.zendesk_source.stg_zendesk__ticket_field_history": ["model.zendesk_source.stg_zendesk__ticket_field_history_tmp", "model.zendesk_source.stg_zendesk__ticket_field_history_tmp"], "model.zendesk_source.stg_zendesk__daylight_time": ["model.zendesk_source.stg_zendesk__daylight_time_tmp", "model.zendesk_source.stg_zendesk__daylight_time_tmp"], "model.zendesk_source.stg_zendesk__organization": ["model.zendesk_source.stg_zendesk__organization_tmp", "model.zendesk_source.stg_zendesk__organization_tmp"], "model.zendesk_source.stg_zendesk__time_zone": ["model.zendesk_source.stg_zendesk__time_zone_tmp", "model.zendesk_source.stg_zendesk__time_zone_tmp"], "model.zendesk_source.stg_zendesk__group": ["model.zendesk_source.stg_zendesk__group_tmp", "model.zendesk_source.stg_zendesk__group_tmp"], "model.zendesk_source.stg_zendesk__ticket_comment": ["model.zendesk_source.stg_zendesk__ticket_comment_tmp", "model.zendesk_source.stg_zendesk__ticket_comment_tmp"], "model.zendesk_source.stg_zendesk__ticket_schedule": ["model.zendesk_source.stg_zendesk__ticket_schedule_tmp", "model.zendesk_source.stg_zendesk__ticket_schedule_tmp"], "model.zendesk_source.stg_zendesk__schedule": ["model.zendesk_source.stg_zendesk__schedule_tmp", "model.zendesk_source.stg_zendesk__schedule_tmp"], "model.zendesk_source.stg_zendesk__user": ["model.zendesk_source.stg_zendesk__user_tmp", "model.zendesk_source.stg_zendesk__user_tmp"], "model.zendesk_source.stg_zendesk__brand": ["model.zendesk_source.stg_zendesk__brand_tmp", "model.zendesk_source.stg_zendesk__brand_tmp"], "model.zendesk_source.stg_zendesk__ticket_form_history": ["model.zendesk_source.stg_zendesk__ticket_form_history_tmp", "model.zendesk_source.stg_zendesk__ticket_form_history_tmp"], "model.zendesk_source.stg_zendesk__ticket": ["model.zendesk_source.stg_zendesk__ticket_tmp", "model.zendesk_source.stg_zendesk__ticket_tmp"], "model.zendesk_source.stg_zendesk__daylight_time_tmp": ["source.zendesk_source.zendesk.daylight_time"], "model.zendesk_source.stg_zendesk__user_tmp": ["source.zendesk_source.zendesk.user"], "model.zendesk_source.stg_zendesk__group_tmp": ["source.zendesk_source.zendesk.group"], "model.zendesk_source.stg_zendesk__ticket_tmp": ["source.zendesk_source.zendesk.ticket"], "model.zendesk_source.stg_zendesk__brand_tmp": ["source.zendesk_source.zendesk.brand"], "model.zendesk_source.stg_zendesk__ticket_tag_tmp": ["source.zendesk_source.zendesk.ticket_tag"], "model.zendesk_source.stg_zendesk__ticket_field_history_tmp": ["source.zendesk_source.zendesk.ticket_field_history"], "model.zendesk_source.stg_zendesk__ticket_form_history_tmp": ["source.zendesk_source.zendesk.ticket_form_history"], "model.zendesk_source.stg_zendesk__ticket_comment_tmp": ["source.zendesk_source.zendesk.ticket_comment"], "model.zendesk_source.stg_zendesk__schedule_tmp": ["source.zendesk_source.zendesk.schedule"], "model.zendesk_source.stg_zendesk__organization_tmp": ["source.zendesk_source.zendesk.organization"], "model.zendesk_source.stg_zendesk__ticket_schedule_tmp": ["source.zendesk_source.zendesk.ticket_schedule", "source.zendesk_source.zendesk.ticket_schedule", "source.zendesk_source.zendesk.ticket_schedule"], "model.zendesk_source.stg_zendesk__time_zone_tmp": ["source.zendesk_source.zendesk.time_zone"], "test.zendesk.unique_zendesk__ticket_enriched_ticket_id.7c3c6ca9ef": ["model.zendesk.zendesk__ticket_enriched"], "test.zendesk.not_null_zendesk__ticket_enriched_ticket_id.e3efc5bf0a": ["model.zendesk.zendesk__ticket_enriched"], "test.zendesk.unique_zendesk__sla_policies_sla_event_id.5daff4d2bd": ["model.zendesk.zendesk__sla_policies"], "test.zendesk.unique_zendesk__ticket_metrics_ticket_id.f3dc8eba5c": ["model.zendesk.zendesk__ticket_metrics"], "test.zendesk.not_null_zendesk__ticket_metrics_ticket_id.3466b76bbd": ["model.zendesk.zendesk__ticket_metrics"], "test.zendesk_source.unique_stg_zendesk__ticket_ticket_id.4be7124521": ["model.zendesk_source.stg_zendesk__ticket"], "test.zendesk_source.not_null_stg_zendesk__ticket_ticket_id.a8229e6981": ["model.zendesk_source.stg_zendesk__ticket"], "test.zendesk_source.unique_stg_zendesk__brand_brand_id.fdf8e23c9e": ["model.zendesk_source.stg_zendesk__brand"], "test.zendesk_source.not_null_stg_zendesk__brand_brand_id.a2419e1741": ["model.zendesk_source.stg_zendesk__brand"], "test.zendesk_source.not_null_stg_zendesk__domain_name_organization_id.a2b5ff8fd3": [], "test.zendesk_source.unique_stg_zendesk__group_group_id.f0658dabcd": ["model.zendesk_source.stg_zendesk__group"], "test.zendesk_source.not_null_stg_zendesk__group_group_id.7659ed83ec": ["model.zendesk_source.stg_zendesk__group"], "test.zendesk_source.unique_stg_zendesk__organization_organization_id.152be1ab31": ["model.zendesk_source.stg_zendesk__organization"], "test.zendesk_source.not_null_stg_zendesk__organization_organization_id.de7b98c06a": ["model.zendesk_source.stg_zendesk__organization"], "test.zendesk_source.unique_stg_zendesk__ticket_comment_ticket_comment_id.ba353330cd": ["model.zendesk_source.stg_zendesk__ticket_comment"], "test.zendesk_source.not_null_stg_zendesk__ticket_comment_ticket_comment_id.b821f4a606": ["model.zendesk_source.stg_zendesk__ticket_comment"], "test.zendesk_source.unique_stg_zendesk__user_user_id.3d3e346b11": ["model.zendesk_source.stg_zendesk__user"], "test.zendesk_source.not_null_stg_zendesk__user_user_id.102d572926": ["model.zendesk_source.stg_zendesk__user"], "test.zendesk_source.not_null_stg_zendesk__ticket_form_history_ticket_form_id.1afe781a17": ["model.zendesk_source.stg_zendesk__ticket_form_history"], "test.zendesk_source.dbt_utils_unique_combination_of_columns_stg_zendesk__daylight_time_time_zone__year.88227aef3d": ["model.zendesk_source.stg_zendesk__daylight_time"], "test.zendesk_source.unique_stg_zendesk__time_zone_time_zone.67995adbaf": ["model.zendesk_source.stg_zendesk__time_zone"], "test.zendesk_source.not_null_stg_zendesk__time_zone_time_zone.b25b3452b1": ["model.zendesk_source.stg_zendesk__time_zone"], "source.zendesk_source.zendesk.ticket": [], "source.zendesk_source.zendesk.brand": [], "source.zendesk_source.zendesk.domain_name": [], "source.zendesk_source.zendesk.group": [], "source.zendesk_source.zendesk.organization_tag": [], "source.zendesk_source.zendesk.organization": [], "source.zendesk_source.zendesk.ticket_comment": [], "source.zendesk_source.zendesk.user_tag": [], "source.zendesk_source.zendesk.user": [], "source.zendesk_source.zendesk.schedule": [], "source.zendesk_source.zendesk.ticket_schedule": [], "source.zendesk_source.zendesk.ticket_form_history": [], "source.zendesk_source.zendesk.ticket_tag": [], "source.zendesk_source.zendesk.ticket_field_history": [], "source.zendesk_source.zendesk.daylight_time": [], "source.zendesk_source.zendesk.time_zone": []}, "child_map": {"model.zendesk.zendesk__ticket_enriched": ["model.zendesk.zendesk__ticket_metrics", "test.zendesk.not_null_zendesk__ticket_enriched_ticket_id.e3efc5bf0a", "test.zendesk.unique_zendesk__ticket_enriched_ticket_id.7c3c6ca9ef"], "model.zendesk.zendesk__ticket_metrics": ["model.zendesk.zendesk__ticket_summary", "test.zendesk.not_null_zendesk__ticket_metrics_ticket_id.3466b76bbd", "test.zendesk.unique_zendesk__ticket_metrics_ticket_id.f3dc8eba5c"], "model.zendesk.zendesk__ticket_summary": [], "model.zendesk.zendesk__ticket_field_history": ["model.zendesk.zendesk__ticket_backlog"], "model.zendesk.zendesk__sla_policies": ["test.zendesk.unique_zendesk__sla_policies_sla_event_id.5daff4d2bd"], "model.zendesk.zendesk__ticket_backlog": [], "model.zendesk.int_zendesk__sla_policy_applied": ["model.zendesk.int_zendesk__agent_work_time_filtered_statuses", "model.zendesk.int_zendesk__reply_time_business_hours", "model.zendesk.int_zendesk__reply_time_calendar_hours", "model.zendesk.int_zendesk__requester_wait_time_filtered_statuses"], "model.zendesk.int_zendesk__agent_work_time_business_hours": ["model.zendesk.zendesk__sla_policies"], "model.zendesk.int_zendesk__agent_work_time_calendar_hours": ["model.zendesk.zendesk__sla_policies"], "model.zendesk.int_zendesk__agent_work_time_filtered_statuses": ["model.zendesk.int_zendesk__agent_work_time_business_hours", "model.zendesk.int_zendesk__agent_work_time_calendar_hours"], "model.zendesk.int_zendesk__reply_time_business_hours": ["model.zendesk.int_zendesk__reply_time_combined"], "model.zendesk.int_zendesk__reply_time_calendar_hours": ["model.zendesk.int_zendesk__reply_time_combined"], "model.zendesk.int_zendesk__reply_time_combined": ["model.zendesk.zendesk__sla_policies"], "model.zendesk.int_zendesk__requester_wait_time_calendar_hours": ["model.zendesk.zendesk__sla_policies"], "model.zendesk.int_zendesk__requester_wait_time_business_hours": ["model.zendesk.zendesk__sla_policies"], "model.zendesk.int_zendesk__requester_wait_time_filtered_statuses": ["model.zendesk.int_zendesk__requester_wait_time_business_hours", "model.zendesk.int_zendesk__requester_wait_time_calendar_hours"], "model.zendesk.int_zendesk__ticket_reply_times": ["model.zendesk.int_zendesk__ticket_first_reply_time_business", "model.zendesk.int_zendesk__ticket_reply_times_calendar"], "model.zendesk.int_zendesk__ticket_reply_times_calendar": ["model.zendesk.zendesk__ticket_metrics"], "model.zendesk.int_zendesk__comments_enriched": ["model.zendesk.int_zendesk__comment_metrics", "model.zendesk.int_zendesk__ticket_reply_times"], "model.zendesk.int_zendesk__ticket_first_reply_time_business": ["model.zendesk.zendesk__ticket_metrics"], "model.zendesk.int_zendesk__field_history_enriched": ["model.zendesk.int_zendesk__field_history_pivot"], "model.zendesk.int_zendesk__field_history_pivot": ["model.zendesk.int_zendesk__field_history_scd", "model.zendesk.int_zendesk__field_history_scd"], "model.zendesk.int_zendesk__updater_information": ["model.zendesk.int_zendesk__field_history_enriched"], "model.zendesk.int_zendesk__field_history_scd": ["model.zendesk.zendesk__ticket_field_history", "model.zendesk.zendesk__ticket_field_history"], "model.zendesk.int_zendesk__field_calendar_spine": ["model.zendesk.zendesk__ticket_field_history"], "model.zendesk.int_zendesk__ticket_work_time_calendar": ["model.zendesk.zendesk__ticket_metrics"], "model.zendesk.int_zendesk__ticket_work_time_business": ["model.zendesk.zendesk__ticket_metrics"], "model.zendesk.int_zendesk__calendar_spine": ["model.zendesk.int_zendesk__field_calendar_spine"], "model.zendesk.int_zendesk__ticket_resolution_times_calendar": ["model.zendesk.int_zendesk__ticket_first_resolution_time_business", "model.zendesk.int_zendesk__ticket_full_resolution_time_business", "model.zendesk.zendesk__ticket_metrics"], "model.zendesk.int_zendesk__ticket_first_resolution_time_business": ["model.zendesk.zendesk__ticket_metrics"], "model.zendesk.int_zendesk__ticket_full_resolution_time_business": ["model.zendesk.zendesk__ticket_metrics"], "model.zendesk.int_zendesk__updates": ["model.zendesk.int_zendesk__assignee_updates", "model.zendesk.int_zendesk__comments_enriched", "model.zendesk.int_zendesk__reply_time_combined", "model.zendesk.int_zendesk__requester_updates", "model.zendesk.int_zendesk__sla_policy_applied", "model.zendesk.int_zendesk__sla_policy_applied", "model.zendesk.int_zendesk__ticket_historical_assignee", "model.zendesk.int_zendesk__ticket_historical_group", "model.zendesk.int_zendesk__ticket_historical_satisfaction", "model.zendesk.int_zendesk__ticket_historical_status"], "model.zendesk.int_zendesk__ticket_historical_assignee": ["model.zendesk.int_zendesk__ticket_resolution_times_calendar"], "model.zendesk.int_zendesk__ticket_historical_status": ["model.zendesk.int_zendesk__agent_work_time_filtered_statuses", "model.zendesk.int_zendesk__requester_wait_time_filtered_statuses", "model.zendesk.int_zendesk__ticket_resolution_times_calendar", "model.zendesk.int_zendesk__ticket_work_time_business", "model.zendesk.int_zendesk__ticket_work_time_calendar"], "model.zendesk.int_zendesk__user_aggregates": ["model.zendesk.int_zendesk__reply_time_combined", "model.zendesk.int_zendesk__updater_information", "model.zendesk.zendesk__ticket_enriched"], "model.zendesk.int_zendesk__schedule_spine": ["model.zendesk.int_zendesk__agent_work_time_business_hours", "model.zendesk.int_zendesk__reply_time_business_hours", "model.zendesk.int_zendesk__requester_wait_time_business_hours", "model.zendesk.int_zendesk__ticket_first_reply_time_business", "model.zendesk.int_zendesk__ticket_first_resolution_time_business", "model.zendesk.int_zendesk__ticket_full_resolution_time_business", "model.zendesk.int_zendesk__ticket_work_time_business"], "model.zendesk.int_zendesk__ticket_schedules": ["model.zendesk.int_zendesk__agent_work_time_business_hours", "model.zendesk.int_zendesk__reply_time_business_hours", "model.zendesk.int_zendesk__requester_wait_time_business_hours", "model.zendesk.int_zendesk__ticket_first_reply_time_business", "model.zendesk.int_zendesk__ticket_first_resolution_time_business", "model.zendesk.int_zendesk__ticket_full_resolution_time_business", "model.zendesk.int_zendesk__ticket_work_time_business"], "model.zendesk.int_zendesk__assignee_updates": ["model.zendesk.zendesk__ticket_enriched"], "model.zendesk.int_zendesk__comment_metrics": ["model.zendesk.zendesk__ticket_metrics"], "model.zendesk.int_zendesk__ticket_historical_group": ["model.zendesk.int_zendesk__ticket_resolution_times_calendar"], "model.zendesk.int_zendesk__requester_updates": ["model.zendesk.zendesk__ticket_enriched"], "model.zendesk.int_zendesk__ticket_historical_satisfaction": ["model.zendesk.zendesk__ticket_enriched"], "model.zendesk.int_zendesk__latest_ticket_form": ["model.zendesk.zendesk__ticket_enriched"], "model.zendesk.int_zendesk__ticket_aggregates": ["model.zendesk.int_zendesk__sla_policy_applied", "model.zendesk.zendesk__ticket_enriched"], "model.zendesk.int_zendesk__organization_aggregates": ["model.zendesk.int_zendesk__updater_information", "model.zendesk.zendesk__ticket_enriched"], "operation.zendesk.zendesk-on-run-start-0": [], "model.zendesk_source.stg_zendesk__ticket_tag": ["model.zendesk.int_zendesk__ticket_aggregates"], "model.zendesk_source.stg_zendesk__ticket_field_history": ["model.zendesk.int_zendesk__field_history_enriched", "model.zendesk.int_zendesk__field_history_pivot", "model.zendesk.int_zendesk__updates"], "model.zendesk_source.stg_zendesk__daylight_time": ["model.zendesk.int_zendesk__schedule_spine", "test.zendesk_source.dbt_utils_unique_combination_of_columns_stg_zendesk__daylight_time_time_zone__year.88227aef3d"], "model.zendesk_source.stg_zendesk__organization": ["model.zendesk.int_zendesk__organization_aggregates", "model.zendesk.zendesk__ticket_backlog", "test.zendesk_source.not_null_stg_zendesk__organization_organization_id.de7b98c06a", "test.zendesk_source.unique_stg_zendesk__organization_organization_id.152be1ab31"], "model.zendesk_source.stg_zendesk__time_zone": ["model.zendesk.int_zendesk__schedule_spine", "test.zendesk_source.not_null_stg_zendesk__time_zone_time_zone.b25b3452b1", "test.zendesk_source.unique_stg_zendesk__time_zone_time_zone.67995adbaf"], "model.zendesk_source.stg_zendesk__group": ["model.zendesk.zendesk__ticket_backlog", "model.zendesk.zendesk__ticket_enriched", "test.zendesk_source.not_null_stg_zendesk__group_group_id.7659ed83ec", "test.zendesk_source.unique_stg_zendesk__group_group_id.f0658dabcd"], "model.zendesk_source.stg_zendesk__ticket_comment": ["model.zendesk.int_zendesk__updates", "test.zendesk_source.not_null_stg_zendesk__ticket_comment_ticket_comment_id.b821f4a606", "test.zendesk_source.unique_stg_zendesk__ticket_comment_ticket_comment_id.ba353330cd"], "model.zendesk_source.stg_zendesk__ticket_schedule": ["model.zendesk.int_zendesk__ticket_schedules"], "model.zendesk_source.stg_zendesk__schedule": ["model.zendesk.int_zendesk__reply_time_business_hours", "model.zendesk.int_zendesk__schedule_spine", "model.zendesk.int_zendesk__ticket_schedules"], "model.zendesk_source.stg_zendesk__user": ["model.zendesk.int_zendesk__comments_enriched", "model.zendesk.int_zendesk__user_aggregates", "model.zendesk.zendesk__ticket_backlog", "model.zendesk.zendesk__ticket_summary", "test.zendesk_source.not_null_stg_zendesk__user_user_id.102d572926", "test.zendesk_source.unique_stg_zendesk__user_user_id.3d3e346b11"], "model.zendesk_source.stg_zendesk__brand": ["model.zendesk.int_zendesk__ticket_aggregates", "model.zendesk.zendesk__ticket_backlog", "test.zendesk_source.not_null_stg_zendesk__brand_brand_id.a2419e1741", "test.zendesk_source.unique_stg_zendesk__brand_brand_id.fdf8e23c9e"], "model.zendesk_source.stg_zendesk__ticket_form_history": ["model.zendesk.int_zendesk__latest_ticket_form", "test.zendesk_source.not_null_stg_zendesk__ticket_form_history_ticket_form_id.1afe781a17"], "model.zendesk_source.stg_zendesk__ticket": ["model.zendesk.int_zendesk__assignee_updates", "model.zendesk.int_zendesk__calendar_spine", "model.zendesk.int_zendesk__field_calendar_spine", "model.zendesk.int_zendesk__requester_updates", "model.zendesk.int_zendesk__ticket_aggregates", "model.zendesk.int_zendesk__ticket_reply_times_calendar", "model.zendesk.int_zendesk__ticket_resolution_times_calendar", "model.zendesk.int_zendesk__ticket_schedules", "model.zendesk.int_zendesk__updates", "model.zendesk.zendesk__ticket_backlog", "test.zendesk_source.not_null_stg_zendesk__ticket_ticket_id.a8229e6981", "test.zendesk_source.unique_stg_zendesk__ticket_ticket_id.4be7124521"], "model.zendesk_source.stg_zendesk__daylight_time_tmp": ["model.zendesk_source.stg_zendesk__daylight_time", "model.zendesk_source.stg_zendesk__daylight_time"], "model.zendesk_source.stg_zendesk__user_tmp": ["model.zendesk_source.stg_zendesk__user", "model.zendesk_source.stg_zendesk__user"], "model.zendesk_source.stg_zendesk__group_tmp": ["model.zendesk_source.stg_zendesk__group", "model.zendesk_source.stg_zendesk__group"], "model.zendesk_source.stg_zendesk__ticket_tmp": ["model.zendesk_source.stg_zendesk__ticket", "model.zendesk_source.stg_zendesk__ticket"], "model.zendesk_source.stg_zendesk__brand_tmp": ["model.zendesk_source.stg_zendesk__brand", "model.zendesk_source.stg_zendesk__brand"], "model.zendesk_source.stg_zendesk__ticket_tag_tmp": ["model.zendesk_source.stg_zendesk__ticket_tag", "model.zendesk_source.stg_zendesk__ticket_tag"], "model.zendesk_source.stg_zendesk__ticket_field_history_tmp": ["model.zendesk_source.stg_zendesk__ticket_field_history", "model.zendesk_source.stg_zendesk__ticket_field_history"], "model.zendesk_source.stg_zendesk__ticket_form_history_tmp": ["model.zendesk_source.stg_zendesk__ticket_form_history", "model.zendesk_source.stg_zendesk__ticket_form_history"], "model.zendesk_source.stg_zendesk__ticket_comment_tmp": ["model.zendesk_source.stg_zendesk__ticket_comment", "model.zendesk_source.stg_zendesk__ticket_comment"], "model.zendesk_source.stg_zendesk__schedule_tmp": ["model.zendesk_source.stg_zendesk__schedule", "model.zendesk_source.stg_zendesk__schedule"], "model.zendesk_source.stg_zendesk__organization_tmp": ["model.zendesk_source.stg_zendesk__organization", "model.zendesk_source.stg_zendesk__organization"], "model.zendesk_source.stg_zendesk__ticket_schedule_tmp": ["model.zendesk_source.stg_zendesk__ticket_schedule", "model.zendesk_source.stg_zendesk__ticket_schedule"], "model.zendesk_source.stg_zendesk__time_zone_tmp": ["model.zendesk_source.stg_zendesk__time_zone", "model.zendesk_source.stg_zendesk__time_zone"], "test.zendesk.unique_zendesk__ticket_enriched_ticket_id.7c3c6ca9ef": [], "test.zendesk.not_null_zendesk__ticket_enriched_ticket_id.e3efc5bf0a": [], "test.zendesk.unique_zendesk__sla_policies_sla_event_id.5daff4d2bd": [], "test.zendesk.unique_zendesk__ticket_metrics_ticket_id.f3dc8eba5c": [], "test.zendesk.not_null_zendesk__ticket_metrics_ticket_id.3466b76bbd": [], "test.zendesk_source.unique_stg_zendesk__ticket_ticket_id.4be7124521": [], "test.zendesk_source.not_null_stg_zendesk__ticket_ticket_id.a8229e6981": [], "test.zendesk_source.unique_stg_zendesk__brand_brand_id.fdf8e23c9e": [], "test.zendesk_source.not_null_stg_zendesk__brand_brand_id.a2419e1741": [], "test.zendesk_source.not_null_stg_zendesk__domain_name_organization_id.a2b5ff8fd3": [], "test.zendesk_source.unique_stg_zendesk__group_group_id.f0658dabcd": [], "test.zendesk_source.not_null_stg_zendesk__group_group_id.7659ed83ec": [], "test.zendesk_source.unique_stg_zendesk__organization_organization_id.152be1ab31": [], "test.zendesk_source.not_null_stg_zendesk__organization_organization_id.de7b98c06a": [], "test.zendesk_source.unique_stg_zendesk__ticket_comment_ticket_comment_id.ba353330cd": [], "test.zendesk_source.not_null_stg_zendesk__ticket_comment_ticket_comment_id.b821f4a606": [], "test.zendesk_source.unique_stg_zendesk__user_user_id.3d3e346b11": [], "test.zendesk_source.not_null_stg_zendesk__user_user_id.102d572926": [], "test.zendesk_source.not_null_stg_zendesk__ticket_form_history_ticket_form_id.1afe781a17": [], "test.zendesk_source.dbt_utils_unique_combination_of_columns_stg_zendesk__daylight_time_time_zone__year.88227aef3d": [], "test.zendesk_source.unique_stg_zendesk__time_zone_time_zone.67995adbaf": [], "test.zendesk_source.not_null_stg_zendesk__time_zone_time_zone.b25b3452b1": [], "source.zendesk_source.zendesk.ticket": ["model.zendesk_source.stg_zendesk__ticket_tmp"], "source.zendesk_source.zendesk.brand": ["model.zendesk_source.stg_zendesk__brand_tmp"], "source.zendesk_source.zendesk.domain_name": [], "source.zendesk_source.zendesk.group": ["model.zendesk_source.stg_zendesk__group_tmp"], "source.zendesk_source.zendesk.organization_tag": [], "source.zendesk_source.zendesk.organization": ["model.zendesk_source.stg_zendesk__organization_tmp"], "source.zendesk_source.zendesk.ticket_comment": ["model.zendesk_source.stg_zendesk__ticket_comment_tmp"], "source.zendesk_source.zendesk.user_tag": [], "source.zendesk_source.zendesk.user": ["model.zendesk_source.stg_zendesk__user_tmp"], "source.zendesk_source.zendesk.schedule": ["model.zendesk_source.stg_zendesk__schedule_tmp"], "source.zendesk_source.zendesk.ticket_schedule": ["model.zendesk_source.stg_zendesk__ticket_schedule_tmp", "model.zendesk_source.stg_zendesk__ticket_schedule_tmp", "model.zendesk_source.stg_zendesk__ticket_schedule_tmp"], "source.zendesk_source.zendesk.ticket_form_history": ["model.zendesk_source.stg_zendesk__ticket_form_history_tmp"], "source.zendesk_source.zendesk.ticket_tag": ["model.zendesk_source.stg_zendesk__ticket_tag_tmp"], "source.zendesk_source.zendesk.ticket_field_history": ["model.zendesk_source.stg_zendesk__ticket_field_history_tmp"], "source.zendesk_source.zendesk.daylight_time": ["model.zendesk_source.stg_zendesk__daylight_time_tmp"], "source.zendesk_source.zendesk.time_zone": ["model.zendesk_source.stg_zendesk__time_zone_tmp"]}}